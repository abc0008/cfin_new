# Project File Structure
*Generated with file-structure-to-md script*
## Root Path: /Users/alexc/Documents/AlexCoding/cfin

## Directory: nextjs\-fdas
**Path**: /Users/alexc/Documents/AlexCoding/cfin/nextjs\-fdas
### File Tree
```
âš ï¸ .DS_Store [excluded]
ğŸ“„ .babelrc.js
âš ï¸ .env.local [excluded]
ğŸ“„ jest.config.js
ğŸ“„ jest.setup.js
ğŸ“„ jsconfig.json
ğŸ“„ next-env.d.ts
ğŸ“„ next.config.js
ğŸ“„ package-lock.json
ğŸ“„ package.json
ğŸ“„ postcss.config.js
ğŸ“ src/
  âš ï¸ .DS_Store [excluded]
  ğŸ“ app/
    ğŸ“ api/
      ğŸ“ analysis/
      ğŸ“ conversation/
        ğŸ“ [sessionId]/
          ğŸ“ message/
      ğŸ“ documents/
        ğŸ“ [id]/
          ğŸ“ content/
    ğŸ“ dashboard/
      ğŸ“„ layout.tsx
      ğŸ“„ page.tsx
    ğŸ“„ globals.css
    ğŸ“„ layout.tsx
    ğŸ“„ page.tsx
    ğŸ“ pdf-viewer/
      ğŸ“ [documentId]/
        ğŸ“„ page.tsx
    ğŸ“ test-markdown/
      ğŸ“„ page.tsx
    ğŸ“ workspace/
      ğŸ“„ layout.tsx
      ğŸ“„ page.tsx
  ğŸ“ components/
    ğŸ“„ DocumentList.tsx
    ğŸ“„ UploadForm.tsx
    ğŸ“ analysis/
      ğŸ“„ AnalysisBlock.tsx
      ğŸ“„ AnalysisControls.tsx
    ğŸ“ charts/
      ğŸ“„ AreaChart.tsx
      ğŸ“„ BarChart.tsx
      ğŸ“„ ChartRenderer.tsx
      ğŸ“„ LineChart.tsx
      ğŸ“„ MultiBarChart.tsx
      ğŸ“„ PieChart.tsx
      ğŸ“„ ScatterChart.tsx
    ğŸ“ chat/
      ğŸ“„ ChatInterface.tsx
      ğŸ“„ FinancialTerms.tsx
      ğŸ“„ InteractiveElements.tsx
      ğŸ“„ MarkdownRenderer.tsx
      ğŸ“„ MessageReference.tsx
      ğŸ“„ MessageRenderer.tsx
    ğŸ“ citation/
    ğŸ“ document/
      ğŸ“„ PDFViewer.tsx
      ğŸ“„ UploadForm.tsx
    ğŸ“ layout/
      ğŸ“„ Header.tsx
    ğŸ“ metrics/
      ğŸ“„ ComparativePeriodDisplay.tsx
      ğŸ“„ MetricCard.tsx
      ğŸ“„ MetricGrid.tsx
    ğŸ“ tables/
      ğŸ“„ TableRenderer.tsx
    ğŸ“ ui/
      ğŸ“„ button.tsx
      ğŸ“„ collapsible.tsx
      ğŸ“„ input.tsx
      ğŸ“„ tabs.tsx
      ğŸ“„ textarea.tsx
    ğŸ“ visualization/
      ğŸ“„ Canvas.tsx
      ğŸ“„ EnhancedChart.tsx
  ğŸ“ hooks/
  ğŸ“ lib/
    ğŸ“ api/
      ğŸ“„ analysis.ts
      ğŸ“„ apiService.ts
      ğŸ“„ conversation.ts
      ğŸ“„ conversation.ts.bak
      ğŸ“„ conversations.ts
      ğŸ“„ documents.ts
      ğŸ“„ index.ts
    ğŸ“ errors/
      ğŸ“„ ApiError.ts
    ğŸ“ pdf/
      ğŸ“„ citationService.ts
    ğŸ“ utils/
    ğŸ“„ utils.ts
    ğŸ“ validation/
      ğŸ“„ api-validation.ts
  ğŸ“ services/
    ğŸ“„ visualizationService.ts
  ğŸ“ types/
    ğŸ“„ enhanced.ts
    ğŸ“„ index.ts
    ğŸ“„ visualization.ts
  ğŸ“ utils/
    ğŸ“„ formatters.ts
  ğŸ“ validation/
    ğŸ“„ schemas.ts
    ğŸ“„ validate.ts
ğŸ“„ tailwind.config.js
ğŸ“„ tsconfig.json
```
### File Contents
#### \.babelrc\.js
*Size: 401 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/.babelrc.js">
module.exports = {
  presets: [
    ['@babel/preset-env', { targets: { node: 'current' } }],
    '@babel/preset-typescript',
    ['@babel/preset-react', { runtime: 'automatic' }]
  ],
  env: {
    test: {
      presets: [
        ['@babel/preset-env', { targets: { node: 'current' } }],
        '@babel/preset-typescript',
        ['@babel/preset-react', { runtime: 'automatic' }]
      ]
    }
  }
} 
</file>
```

#### jest\.config\.js
*Size: 481 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/jest.config.js">
module.exports = {
  testEnvironment: 'jsdom',
  setupFilesAfterEnv: ['<rootDir>/jest.setup.js'],
  moduleNameMapper: {
    '^@/(.*)$': '<rootDir>/src/$1',
    '\\.(css|less|sass|scss)$': 'identity-obj-proxy',
  },
  transform: {
    '^.+\\.(js|jsx|ts|tsx)$': 'babel-jest',
  },
  testPathIgnorePatterns: ['<rootDir>/.next/', '<rootDir>/node_modules/'],
  collectCoverageFrom: [
    'src/**/*.{js,jsx,ts,tsx}',
    '!src/**/*.d.ts',
    '!src/**/*.stories.{js,jsx,ts,tsx}',
  ],
} 
</file>
```

#### jest\.setup\.js
*Size: 35 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/jest.setup.js">
import '@testing-library/jest-dom' 
</file>
```

#### jsconfig\.json
*Size: 97 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/jsconfig.json">
{
  "compilerOptions": {
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    }
  }
} 
</file>
```

#### next\-env\.d\.ts
*Size: 201 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/next-env.d.ts">
/// <reference types="next" />
/// <reference types="next/image-types/global" />

// NOTE: This file should not be edited
// see https://nextjs.org/docs/basic-features/typescript for more information.
</file>
```

#### next\.config\.js
*Size: 645 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/next.config.js">
/** @type {import('next').NextConfig} */
const nextConfig = {
  images: {
    domains: ['localhost'],
  },
  // Explicitly enable SWC
  swcMinify: true,
  experimental: {
    // Force SWC transform
    forceSwcTransforms: true,
  },
  webpack: (config) => {
    // Support loading PDF files
    config.module.rules.push({
      test: /\.pdf$/,
      use: [
        {
          loader: 'file-loader',
          options: {
            name: '[path][name].[ext]',
          },
        },
      ],
    });
    return config;
  },
  // For PDF Highlighter compatibility
  transpilePackages: ["react-pdf-highlighter"],
};

module.exports = nextConfig;
</file>
```

#### package\-lock\.json
*Size: 574.4 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/package-lock.json">
{
  "name": "fdas-nextjs",
  "version": "0.1.0",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {
    "": {
      "name": "fdas-nextjs",
      "version": "0.1.0",
      "dependencies": {
        "@anthropic-ai/sdk": "^0.16.1",
        "@radix-ui/react-avatar": "^1.0.4",
        "@radix-ui/react-collapsible": "^1.1.3",
        "@radix-ui/react-dialog": "^1.0.5",
        "@radix-ui/react-dropdown-menu": "^2.0.6",
        "@radix-ui/react-popover": "^1.0.7",
        "@radix-ui/react-select": "^2.0.0",
        "@radix-ui/react-slot": "^1.0.2",
        "@radix-ui/react-tabs": "^1.0.4",
        "@radix-ui/react-toast": "^1.1.5",
        "class-variance-authority": "^0.7.0",
        "clsx": "^2.1.0",
        "langchain": "^0.1.25",
        "langsmith": "^0.1.25",
        "lucide-react": "^0.359.0",
        "mdast-util-to-markdown": "^2.1.2",
        "next": "14.2.4",
        "pdfjs-dist": "^4.3.136",
        "react": "^18",
        "react-dom": "^18",
        "react-hook-form": "^7.51.1",
        "react-markdown": "^10.1.0",
        "react-pdf-highlighter": "^6.1.0",
        "react-syntax-highlighter": "^15.6.1",
        "recharts": "^2.15.1",
        "remark-gfm": "^4.0.1",
        "tailwind-merge": "^2.2.2",
        "tailwindcss-animate": "^1.0.7",
        "zod": "^3.22.4"
      },
      "devDependencies": {
        "@babel/core": "^7.26.10",
        "@babel/preset-env": "^7.26.9",
        "@babel/preset-react": "^7.26.3",
        "@babel/preset-typescript": "^7.27.0",
        "@testing-library/jest-dom": "^6.6.3",
        "@testing-library/react": "^16.2.0",
        "@types/jest": "^29.5.14",
        "@types/node": "^20",
        "@types/react": "^18",
        "@types/react-dom": "^18",
        "autoprefixer": "^10.0.1",
        "babel-jest": "^29.7.0",
        "eslint": "^8",
        "eslint-config-next": "14.2.4",
        "identity-obj-proxy": "^3.0.0",
        "jest": "^29.7.0",
        "jest-environment-jsdom": "^29.7.0",
        "postcss": "^8",
        "tailwindcss": "^3.3.0",
        "typescript": "^5"
      }
    },
    "node_modules/@adobe/css-tools": {
      "version": "4.4.2",
      "resolved": "https://registry.npmjs.org/@adobe/css-tools/-/css-tools-4.4.2.tgz",
      "integrity": "sha512-baYZExFpsdkBNuvGKTKWCwKH57HRZLVtycZS05WTQNVOiXVSeAki3nU35zlRbToeMW8aHlJfyS+1C4BOv27q0A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@alloc/quick-lru": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/@alloc/quick-lru/-/quick-lru-5.2.0.tgz",
      "integrity": "sha512-UrcABB+4bUrFABwbluTIBErXwvbsU/V7TZWfmbgJfbkwiBuziS9gxdODUyuiecfdGQ85jglMW6juS3+z5TsKLw==",
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/@ampproject/remapping": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/@ampproject/remapping/-/remapping-2.3.0.tgz",
      "integrity": "sha512-30iZtAPgz+LTIYoeivqYo853f02jBYSd5uGnGpkFV0M3xOt9aN73erkgYAmZU43x4VfqcnLxW9Kpg3R5LC4YYw==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@jridgewell/gen-mapping": "^0.3.5",
        "@jridgewell/trace-mapping": "^0.3.24"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@anthropic-ai/sdk": {
      "version": "0.16.1",
      "resolved": "https://registry.npmjs.org/@anthropic-ai/sdk/-/sdk-0.16.1.tgz",
      "integrity": "sha512-vHgvfWEyFy5ktqam56Nrhv8MVa7EJthsRYNi+1OrFFfyrj9tR2/aji1QbVbQjYU/pPhPFaYrdCEC/MLPFrmKwA==",
      "license": "MIT",
      "dependencies": {
        "@types/node": "^18.11.18",
        "@types/node-fetch": "^2.6.4",
        "abort-controller": "^3.0.0",
        "agentkeepalive": "^4.2.1",
        "digest-fetch": "^1.3.0",
        "form-data-encoder": "1.7.2",
        "formdata-node": "^4.3.2",
        "node-fetch": "^2.6.7",
        "web-streams-polyfill": "^3.2.1"
      }
    },
    "node_modules/@anthropic-ai/sdk/node_modules/@types/node": {
      "version": "18.19.80",
      "resolved": "https://registry.npmjs.org/@types/node/-/node-18.19.80.tgz",
      "integrity": "sha512-kEWeMwMeIvxYkeg1gTc01awpwLbfMRZXdIhwRcakd/KlK53jmRC26LqcbIt7fnAQTu5GzlnWmzA3H6+l1u6xxQ==",
      "license": "MIT",
      "dependencies": {
        "undici-types": "~5.26.4"
      }
    },
    "node_modules/@anthropic-ai/sdk/node_modules/undici-types": {
      "version": "5.26.5",
      "resolved": "https://registry.npmjs.org/undici-types/-/undici-types-5.26.5.tgz",
      "integrity": "sha512-JlCMO+ehdEIKqlFxk6IfVoAUVmgz7cU7zD/h9XZ0qzeosSHmUJVOzSQvvYSYWXkFXC+IfLKSIffhv0sVZup6pA==",
      "license": "MIT"
    },
    "node_modules/@babel/code-frame": {
      "version": "7.26.2",
      "resolved": "https://registry.npmjs.org/@babel/code-frame/-/code-frame-7.26.2.tgz",
      "integrity": "sha512-RJlIHRueQgwWitWgF8OdFYGZX328Ax5BCemNGlqHfplnRT9ESi8JkFlvaVYbS+UubVY6dpv87Fs2u5M29iNFVQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-validator-identifier": "^7.25.9",
        "js-tokens": "^4.0.0",
        "picocolors": "^1.0.0"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/compat-data": {
      "version": "7.26.8",
      "resolved": "https://registry.npmjs.org/@babel/compat-data/-/compat-data-7.26.8.tgz",
      "integrity": "sha512-oH5UPLMWR3L2wEFLnFJ1TZXqHufiTKAiLfqw5zkhS4dKXLJ10yVztfil/twG8EDTA4F/tvVNw9nOl4ZMslB8rQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/core": {
      "version": "7.26.10",
      "resolved": "https://registry.npmjs.org/@babel/core/-/core-7.26.10.tgz",
      "integrity": "sha512-vMqyb7XCDMPvJFFOaT9kxtiRh42GwlZEg1/uIgtZshS5a/8OaduUfCi7kynKgc3Tw/6Uo2D+db9qBttghhmxwQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@ampproject/remapping": "^2.2.0",
        "@babel/code-frame": "^7.26.2",
        "@babel/generator": "^7.26.10",
        "@babel/helper-compilation-targets": "^7.26.5",
        "@babel/helper-module-transforms": "^7.26.0",
        "@babel/helpers": "^7.26.10",
        "@babel/parser": "^7.26.10",
        "@babel/template": "^7.26.9",
        "@babel/traverse": "^7.26.10",
        "@babel/types": "^7.26.10",
        "convert-source-map": "^2.0.0",
        "debug": "^4.1.0",
        "gensync": "^1.0.0-beta.2",
        "json5": "^2.2.3",
        "semver": "^6.3.1"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/babel"
      }
    },
    "node_modules/@babel/core/node_modules/json5": {
      "version": "2.2.3",
      "resolved": "https://registry.npmjs.org/json5/-/json5-2.2.3.tgz",
      "integrity": "sha512-XmOWe7eyHYH14cLdVPoyg+GOH3rYX++KpzrylJwSW98t3Nk+U8XOl8FWKOgwtzdb8lXGf6zYwDUzeHMWfxasyg==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "json5": "lib/cli.js"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/@babel/core/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/@babel/generator": {
      "version": "7.27.0",
      "resolved": "https://registry.npmjs.org/@babel/generator/-/generator-7.27.0.tgz",
      "integrity": "sha512-VybsKvpiN1gU1sdMZIp7FcqphVVKEwcuj02x73uvcHE0PTihx1nlBcowYWhDwjpoAXRv43+gDzyggGnn1XZhVw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/parser": "^7.27.0",
        "@babel/types": "^7.27.0",
        "@jridgewell/gen-mapping": "^0.3.5",
        "@jridgewell/trace-mapping": "^0.3.25",
        "jsesc": "^3.0.2"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-annotate-as-pure": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-annotate-as-pure/-/helper-annotate-as-pure-7.25.9.tgz",
      "integrity": "sha512-gv7320KBUFJz1RnylIg5WWYPRXKZ884AGkYpgpWW02TH66Dl+HaC1t1CKd0z3R4b6hdYEcmrNZHUmfCP+1u3/g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/types": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-compilation-targets": {
      "version": "7.27.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-compilation-targets/-/helper-compilation-targets-7.27.0.tgz",
      "integrity": "sha512-LVk7fbXml0H2xH34dFzKQ7TDZ2G4/rVTOrq9V+icbbadjbVxxeFeDsNHv2SrZeWoA+6ZiTyWYWtScEIW07EAcA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/compat-data": "^7.26.8",
        "@babel/helper-validator-option": "^7.25.9",
        "browserslist": "^4.24.0",
        "lru-cache": "^5.1.1",
        "semver": "^6.3.1"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-compilation-targets/node_modules/lru-cache": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/lru-cache/-/lru-cache-5.1.1.tgz",
      "integrity": "sha512-KpNARQA3Iwv+jTA0utUVVbrh+Jlrr1Fv0e56GGzAFOXN7dk/FviaDW8LHmK52DlcH4WP2n6gI8vN1aesBFgo9w==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "yallist": "^3.0.2"
      }
    },
    "node_modules/@babel/helper-compilation-targets/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/@babel/helper-create-class-features-plugin": {
      "version": "7.27.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-create-class-features-plugin/-/helper-create-class-features-plugin-7.27.0.tgz",
      "integrity": "sha512-vSGCvMecvFCd/BdpGlhpXYNhhC4ccxyvQWpbGL4CWbvfEoLFWUZuSuf7s9Aw70flgQF+6vptvgK2IfOnKlRmBg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-annotate-as-pure": "^7.25.9",
        "@babel/helper-member-expression-to-functions": "^7.25.9",
        "@babel/helper-optimise-call-expression": "^7.25.9",
        "@babel/helper-replace-supers": "^7.26.5",
        "@babel/helper-skip-transparent-expression-wrappers": "^7.25.9",
        "@babel/traverse": "^7.27.0",
        "semver": "^6.3.1"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/helper-create-class-features-plugin/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/@babel/helper-create-regexp-features-plugin": {
      "version": "7.27.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-create-regexp-features-plugin/-/helper-create-regexp-features-plugin-7.27.0.tgz",
      "integrity": "sha512-fO8l08T76v48BhpNRW/nQ0MxfnSdoSKUJBMjubOAYffsVuGG5qOfMq7N6Es7UJvi7Y8goXXo07EfcHZXDPuELQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-annotate-as-pure": "^7.25.9",
        "regexpu-core": "^6.2.0",
        "semver": "^6.3.1"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/helper-create-regexp-features-plugin/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/@babel/helper-define-polyfill-provider": {
      "version": "0.6.4",
      "resolved": "https://registry.npmjs.org/@babel/helper-define-polyfill-provider/-/helper-define-polyfill-provider-0.6.4.tgz",
      "integrity": "sha512-jljfR1rGnXXNWnmQg2K3+bvhkxB51Rl32QRaOTuwwjviGrHzIbSc8+x9CpraDtbT7mfyjXObULP4w/adunNwAw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-compilation-targets": "^7.22.6",
        "@babel/helper-plugin-utils": "^7.22.5",
        "debug": "^4.1.1",
        "lodash.debounce": "^4.0.8",
        "resolve": "^1.14.2"
      },
      "peerDependencies": {
        "@babel/core": "^7.4.0 || ^8.0.0-0 <8.0.0"
      }
    },
    "node_modules/@babel/helper-member-expression-to-functions": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-member-expression-to-functions/-/helper-member-expression-to-functions-7.25.9.tgz",
      "integrity": "sha512-wbfdZ9w5vk0C0oyHqAJbc62+vet5prjj01jjJ8sKn3j9h3MQQlflEdXYvuqRWjHnM12coDEqiC1IRCi0U/EKwQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/traverse": "^7.25.9",
        "@babel/types": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-module-imports": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-module-imports/-/helper-module-imports-7.25.9.tgz",
      "integrity": "sha512-tnUA4RsrmflIM6W6RFTLFSXITtl0wKjgpnLgXyowocVPrbYrLUXSBXDgTs8BlbmIzIdlBySRQjINYs2BAkiLtw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/traverse": "^7.25.9",
        "@babel/types": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-module-transforms": {
      "version": "7.26.0",
      "resolved": "https://registry.npmjs.org/@babel/helper-module-transforms/-/helper-module-transforms-7.26.0.tgz",
      "integrity": "sha512-xO+xu6B5K2czEnQye6BHA7DolFFmS3LB7stHZFaOLb1pAwO1HWLS8fXA+eh0A2yIvltPVmx3eNNDBJA2SLHXFw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-module-imports": "^7.25.9",
        "@babel/helper-validator-identifier": "^7.25.9",
        "@babel/traverse": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/helper-optimise-call-expression": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-optimise-call-expression/-/helper-optimise-call-expression-7.25.9.tgz",
      "integrity": "sha512-FIpuNaz5ow8VyrYcnXQTDRGvV6tTjkNtCK/RYNDXGSLlUD6cBuQTSw43CShGxjvfBTfcUA/r6UhUCbtYqkhcuQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/types": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-plugin-utils": {
      "version": "7.26.5",
      "resolved": "https://registry.npmjs.org/@babel/helper-plugin-utils/-/helper-plugin-utils-7.26.5.tgz",
      "integrity": "sha512-RS+jZcRdZdRFzMyr+wcsaqOmld1/EqTghfaBGQQd/WnRdzdlvSZ//kF7U8VQTxf1ynZ4cjUcYgjVGx13ewNPMg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-remap-async-to-generator": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-remap-async-to-generator/-/helper-remap-async-to-generator-7.25.9.tgz",
      "integrity": "sha512-IZtukuUeBbhgOcaW2s06OXTzVNJR0ybm4W5xC1opWFFJMZbwRj5LCk+ByYH7WdZPZTt8KnFwA8pvjN2yqcPlgw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-annotate-as-pure": "^7.25.9",
        "@babel/helper-wrap-function": "^7.25.9",
        "@babel/traverse": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/helper-replace-supers": {
      "version": "7.26.5",
      "resolved": "https://registry.npmjs.org/@babel/helper-replace-supers/-/helper-replace-supers-7.26.5.tgz",
      "integrity": "sha512-bJ6iIVdYX1YooY2X7w1q6VITt+LnUILtNk7zT78ykuwStx8BauCzxvFqFaHjOpW1bVnSUM1PN1f0p5P21wHxvg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-member-expression-to-functions": "^7.25.9",
        "@babel/helper-optimise-call-expression": "^7.25.9",
        "@babel/traverse": "^7.26.5"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/helper-skip-transparent-expression-wrappers": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-skip-transparent-expression-wrappers/-/helper-skip-transparent-expression-wrappers-7.25.9.tgz",
      "integrity": "sha512-K4Du3BFa3gvyhzgPcntrkDgZzQaq6uozzcpGbOO1OEJaI+EJdqWIMTLgFgQf6lrfiDFo5FU+BxKepI9RmZqahA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/traverse": "^7.25.9",
        "@babel/types": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-string-parser": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-string-parser/-/helper-string-parser-7.25.9.tgz",
      "integrity": "sha512-4A/SCr/2KLd5jrtOMFzaKjVtAei3+2r/NChoBNoZ3EyP/+GlhoaEGoWOZUmFmoITP7zOJyHIMm+DYRd8o3PvHA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-validator-identifier": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-validator-identifier/-/helper-validator-identifier-7.25.9.tgz",
      "integrity": "sha512-Ed61U6XJc3CVRfkERJWDz4dJwKe7iLmmJsbOGu9wSloNSFttHV0I8g6UAgb7qnK5ly5bGLPd4oXZlxCdANBOWQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-validator-option": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-validator-option/-/helper-validator-option-7.25.9.tgz",
      "integrity": "sha512-e/zv1co8pp55dNdEcCynfj9X7nyUKUXoUEwfXqaZt0omVOmDe9oOTdKStH4GmAw6zxMFs50ZayuMfHDKlO7Tfw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helper-wrap-function": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/helper-wrap-function/-/helper-wrap-function-7.25.9.tgz",
      "integrity": "sha512-ETzz9UTjQSTmw39GboatdymDq4XIQbR8ySgVrylRhPOFpsd+JrKHIuF0de7GCWmem+T4uC5z7EZguod7Wj4A4g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/template": "^7.25.9",
        "@babel/traverse": "^7.25.9",
        "@babel/types": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/helpers": {
      "version": "7.27.0",
      "resolved": "https://registry.npmjs.org/@babel/helpers/-/helpers-7.27.0.tgz",
      "integrity": "sha512-U5eyP/CTFPuNE3qk+WZMxFkp/4zUzdceQlfzf7DdGdhp+Fezd7HD+i8Y24ZuTMKX3wQBld449jijbGq6OdGNQg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/template": "^7.27.0",
        "@babel/types": "^7.27.0"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/parser": {
      "version": "7.27.0",
      "resolved": "https://registry.npmjs.org/@babel/parser/-/parser-7.27.0.tgz",
      "integrity": "sha512-iaepho73/2Pz7w2eMS0Q5f83+0RKI7i4xmiYeBmDzfRVbQtTOG7Ts0S4HzJVsTMGI9keU8rNfuZr8DKfSt7Yyg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/types": "^7.27.0"
      },
      "bin": {
        "parser": "bin/babel-parser.js"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@babel/plugin-bugfix-firefox-class-in-computed-class-key": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-bugfix-firefox-class-in-computed-class-key/-/plugin-bugfix-firefox-class-in-computed-class-key-7.25.9.tgz",
      "integrity": "sha512-ZkRyVkThtxQ/J6nv3JFYv1RYY+JT5BvU0y3k5bWrmuG4woXypRa4PXmm9RhOwodRkYFWqC0C0cqcJ4OqR7kW+g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9",
        "@babel/traverse": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/plugin-bugfix-safari-class-field-initializer-scope": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-bugfix-safari-class-field-initializer-scope/-/plugin-bugfix-safari-class-field-initializer-scope-7.25.9.tgz",
      "integrity": "sha512-MrGRLZxLD/Zjj0gdU15dfs+HH/OXvnw/U4jJD8vpcP2CJQapPEv1IWwjc/qMg7ItBlPwSv1hRBbb7LeuANdcnw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/plugin-bugfix-safari-id-destructuring-collision-in-function-expression": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-bugfix-safari-id-destructuring-collision-in-function-expression/-/plugin-bugfix-safari-id-destructuring-collision-in-function-expression-7.25.9.tgz",
      "integrity": "sha512-2qUwwfAFpJLZqxd02YW9btUCZHl+RFvdDkNfZwaIJrvB8Tesjsk8pEQkTvGwZXLqXUx/2oyY3ySRhm6HOXuCug==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/plugin-bugfix-v8-spread-parameters-in-optional-chaining": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-bugfix-v8-spread-parameters-in-optional-chaining/-/plugin-bugfix-v8-spread-parameters-in-optional-chaining-7.25.9.tgz",
      "integrity": "sha512-6xWgLZTJXwilVjlnV7ospI3xi+sl8lN8rXXbBD6vYn3UYDlGsag8wrZkKcSI8G6KgqKP7vNFaDgeDnfAABq61g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9",
        "@babel/helper-skip-transparent-expression-wrappers": "^7.25.9",
        "@babel/plugin-transform-optional-chaining": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.13.0"
      }
    },
    "node_modules/@babel/plugin-bugfix-v8-static-class-fields-redefine-readonly": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-bugfix-v8-static-class-fields-redefine-readonly/-/plugin-bugfix-v8-static-class-fields-redefine-readonly-7.25.9.tgz",
      "integrity": "sha512-aLnMXYPnzwwqhYSCyXfKkIkYgJ8zv9RK+roo9DkTXz38ynIhd9XCbN08s3MGvqL2MYGVUGdRQLL/JqBIeJhJBg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9",
        "@babel/traverse": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/plugin-proposal-private-property-in-object": {
      "version": "7.21.0-placeholder-for-preset-env.2",
      "resolved": "https://registry.npmjs.org/@babel/plugin-proposal-private-property-in-object/-/plugin-proposal-private-property-in-object-7.21.0-placeholder-for-preset-env.2.tgz",
      "integrity": "sha512-SOSkfJDddaM7mak6cPEpswyTRnuRltl429hMraQEglW+OkovnCzsiszTmsrlY//qLFjCpQDFRvjdm2wA5pPm9w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-async-generators": {
      "version": "7.8.4",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-async-generators/-/plugin-syntax-async-generators-7.8.4.tgz",
      "integrity": "sha512-tycmZxkGfZaxhMRbXlPXuVFpdWlXpir2W4AMhSJgRKzk/eDlIXOhb2LHWoLpDF7TEHylV5zNhykX6KAgHJmTNw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-bigint": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-bigint/-/plugin-syntax-bigint-7.8.3.tgz",
      "integrity": "sha512-wnTnFlG+YxQm3vDxpGE57Pj0srRU4sHE/mDkt1qv2YJJSeUAec2ma4WLUnUPeKjyrfntVwe/N6dCXpU+zL3Npg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-class-properties": {
      "version": "7.12.13",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-class-properties/-/plugin-syntax-class-properties-7.12.13.tgz",
      "integrity": "sha512-fm4idjKla0YahUNgFNLCB0qySdsoPiZP3iQE3rky0mBUtMZ23yDJ9SJdg6dXTSDnulOVqiF3Hgr9nbXvXTQZYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.12.13"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-class-static-block": {
      "version": "7.14.5",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-class-static-block/-/plugin-syntax-class-static-block-7.14.5.tgz",
      "integrity": "sha512-b+YyPmr6ldyNnM6sqYeMWE+bgJcJpO6yS4QD7ymxgH34GBPNDM/THBh8iunyvKIZztiwLH4CJZ0RxTk9emgpjw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.14.5"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-import-assertions": {
      "version": "7.26.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-import-assertions/-/plugin-syntax-import-assertions-7.26.0.tgz",
      "integrity": "sha512-QCWT5Hh830hK5EQa7XzuqIkQU9tT/whqbDz7kuaZMHFl1inRRg7JnuAEOQ0Ur0QUl0NufCk1msK2BeY79Aj/eg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-import-attributes": {
      "version": "7.26.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-import-attributes/-/plugin-syntax-import-attributes-7.26.0.tgz",
      "integrity": "sha512-e2dttdsJ1ZTpi3B9UYGLw41hifAubg19AtCu/2I/F1QNVclOBr1dYpTdmdyZ84Xiz43BS/tCUkMAZNLv12Pi+A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-import-meta": {
      "version": "7.10.4",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-import-meta/-/plugin-syntax-import-meta-7.10.4.tgz",
      "integrity": "sha512-Yqfm+XDx0+Prh3VSeEQCPU81yC+JWZ2pDPFSS4ZdpfZhp4MkFMaDC1UqseovEKwSUpnIL7+vK+Clp7bfh0iD7g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.10.4"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-json-strings": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-json-strings/-/plugin-syntax-json-strings-7.8.3.tgz",
      "integrity": "sha512-lY6kdGpWHvjoe2vk4WrAapEuBR69EMxZl+RoGRhrFGNYVK8mOPAW8VfbT/ZgrFbXlDNiiaxQnAtgVCZ6jv30EA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-jsx": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-jsx/-/plugin-syntax-jsx-7.25.9.tgz",
      "integrity": "sha512-ld6oezHQMZsZfp6pWtbjaNDF2tiiCYYDqQszHt5VV437lewP9aSi2Of99CK0D0XB21k7FLgnLcmQKyKzynfeAA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-logical-assignment-operators": {
      "version": "7.10.4",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-logical-assignment-operators/-/plugin-syntax-logical-assignment-operators-7.10.4.tgz",
      "integrity": "sha512-d8waShlpFDinQ5MtvGU9xDAOzKH47+FFoney2baFIoMr952hKOLp1HR7VszoZvOsV/4+RRszNY7D17ba0te0ig==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.10.4"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-nullish-coalescing-operator": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-nullish-coalescing-operator/-/plugin-syntax-nullish-coalescing-operator-7.8.3.tgz",
      "integrity": "sha512-aSff4zPII1u2QD7y+F8oDsz19ew4IGEJg9SVW+bqwpwtfFleiQDMdzA/R+UlWDzfnHFCxxleFT0PMIrR36XLNQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-numeric-separator": {
      "version": "7.10.4",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-numeric-separator/-/plugin-syntax-numeric-separator-7.10.4.tgz",
      "integrity": "sha512-9H6YdfkcK/uOnY/K7/aA2xpzaAgkQn37yzWUMRK7OaPOqOpGS1+n0H5hxT9AUw9EsSjPW8SVyMJwYRtWs3X3ug==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.10.4"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-object-rest-spread": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-object-rest-spread/-/plugin-syntax-object-rest-spread-7.8.3.tgz",
      "integrity": "sha512-XoqMijGZb9y3y2XskN+P1wUGiVwWZ5JmoDRwx5+3GmEplNyVM2s2Dg8ILFQm8rWM48orGy5YpI5Bl8U1y7ydlA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-optional-catch-binding": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-optional-catch-binding/-/plugin-syntax-optional-catch-binding-7.8.3.tgz",
      "integrity": "sha512-6VPD0Pc1lpTqw0aKoeRTMiB+kWhAoT24PA+ksWSBrFtl5SIRVpZlwN3NNPQjehA2E/91FV3RjLWoVTglWcSV3Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-optional-chaining": {
      "version": "7.8.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-optional-chaining/-/plugin-syntax-optional-chaining-7.8.3.tgz",
      "integrity": "sha512-KoK9ErH1MBlCPxV0VANkXW2/dw4vlbGDrFgz8bmUsBGYkFRcbRwMh6cIJubdPrkxRwuGdtCk0v/wPTKbQgBjkg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.8.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-private-property-in-object": {
      "version": "7.14.5",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-private-property-in-object/-/plugin-syntax-private-property-in-object-7.14.5.tgz",
      "integrity": "sha512-0wVnp9dxJ72ZUJDV27ZfbSj6iHLoytYZmh3rFcxNnvsJF3ktkzLDZPy/mA17HGsaQT3/DQsWYX1f1QGWkCoVUg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.14.5"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-top-level-await": {
      "version": "7.14.5",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-top-level-await/-/plugin-syntax-top-level-await-7.14.5.tgz",
      "integrity": "sha512-hx++upLv5U1rgYfwe1xBQUhRmU41NEvpUvrp8jkrSCdvGSnM5/qdRMtylJ6PG5OFkBaHkbTAKTnd3/YyESRHFw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.14.5"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-typescript": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-typescript/-/plugin-syntax-typescript-7.25.9.tgz",
      "integrity": "sha512-hjMgRy5hb8uJJjUcdWunWVcoi9bGpJp8p5Ol1229PoN6aytsLwNMgmdftO23wnCLMfVmTwZDWMPNq/D1SY60JQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-syntax-unicode-sets-regex": {
      "version": "7.18.6",
      "resolved": "https://registry.npmjs.org/@babel/plugin-syntax-unicode-sets-regex/-/plugin-syntax-unicode-sets-regex-7.18.6.tgz",
      "integrity": "sha512-727YkEAPwSIQTv5im8QHz3upqp92JTWhidIC81Tdx4VJYIte/VndKf1qKrfnnhPLiPghStWfvC/iFaMCQu7Nqg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-create-regexp-features-plugin": "^7.18.6",
        "@babel/helper-plugin-utils": "^7.18.6"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/plugin-transform-arrow-functions": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-arrow-functions/-/plugin-transform-arrow-functions-7.25.9.tgz",
      "integrity": "sha512-6jmooXYIwn9ca5/RylZADJ+EnSxVUS5sjeJ9UPk6RWRzXCmOJCy6dqItPJFpw2cuCangPK4OYr5uhGKcmrm5Qg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-async-generator-functions": {
      "version": "7.26.8",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-async-generator-functions/-/plugin-transform-async-generator-functions-7.26.8.tgz",
      "integrity": "sha512-He9Ej2X7tNf2zdKMAGOsmg2MrFc+hfoAhd3po4cWfo/NWjzEAKa0oQruj1ROVUdl0e6fb6/kE/G3SSxE0lRJOg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.26.5",
        "@babel/helper-remap-async-to-generator": "^7.25.9",
        "@babel/traverse": "^7.26.8"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-async-to-generator": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-async-to-generator/-/plugin-transform-async-to-generator-7.25.9.tgz",
      "integrity": "sha512-NT7Ejn7Z/LjUH0Gv5KsBCxh7BH3fbLTV0ptHvpeMvrt3cPThHfJfst9Wrb7S8EvJ7vRTFI7z+VAvFVEQn/m5zQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-module-imports": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9",
        "@babel/helper-remap-async-to-generator": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-block-scoped-functions": {
      "version": "7.26.5",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-block-scoped-functions/-/plugin-transform-block-scoped-functions-7.26.5.tgz",
      "integrity": "sha512-chuTSY+hq09+/f5lMj8ZSYgCFpppV2CbYrhNFJ1BFoXpiWPnnAb7R0MqrafCpN8E1+YRrtM1MXZHJdIx8B6rMQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.26.5"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-block-scoping": {
      "version": "7.27.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-block-scoping/-/plugin-transform-block-scoping-7.27.0.tgz",
      "integrity": "sha512-u1jGphZ8uDI2Pj/HJj6YQ6XQLZCNjOlprjxB5SVz6rq2T6SwAR+CdrWK0CP7F+9rDVMXdB0+r6Am5G5aobOjAQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.26.5"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-class-properties": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-class-properties/-/plugin-transform-class-properties-7.25.9.tgz",
      "integrity": "sha512-bbMAII8GRSkcd0h0b4X+36GksxuheLFjP65ul9w6C3KgAamI3JqErNgSrosX6ZPj+Mpim5VvEbawXxJCyEUV3Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-create-class-features-plugin": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-class-static-block": {
      "version": "7.26.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-class-static-block/-/plugin-transform-class-static-block-7.26.0.tgz",
      "integrity": "sha512-6J2APTs7BDDm+UMqP1useWqhcRAXo0WIoVj26N7kPFB6S73Lgvyka4KTZYIxtgYXiN5HTyRObA72N2iu628iTQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-create-class-features-plugin": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.12.0"
      }
    },
    "node_modules/@babel/plugin-transform-classes": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-classes/-/plugin-transform-classes-7.25.9.tgz",
      "integrity": "sha512-mD8APIXmseE7oZvZgGABDyM34GUmK45Um2TXiBUt7PnuAxrgoSVf123qUzPxEr/+/BHrRn5NMZCdE2m/1F8DGg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-annotate-as-pure": "^7.25.9",
        "@babel/helper-compilation-targets": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9",
        "@babel/helper-replace-supers": "^7.25.9",
        "@babel/traverse": "^7.25.9",
        "globals": "^11.1.0"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-classes/node_modules/globals": {
      "version": "11.12.0",
      "resolved": "https://registry.npmjs.org/globals/-/globals-11.12.0.tgz",
      "integrity": "sha512-WOBp/EEGUiIsJSp7wcv/y6MO+lV9UoncWqxuFfm8eBwzWNgyfBd6Gz+IeKQ9jCmyhoH99g15M3T+QaVHFjizVA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/@babel/plugin-transform-computed-properties": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-computed-properties/-/plugin-transform-computed-properties-7.25.9.tgz",
      "integrity": "sha512-HnBegGqXZR12xbcTHlJ9HGxw1OniltT26J5YpfruGqtUHlz/xKf/G2ak9e+t0rVqrjXa9WOhvYPz1ERfMj23AA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9",
        "@babel/template": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-destructuring": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-destructuring/-/plugin-transform-destructuring-7.25.9.tgz",
      "integrity": "sha512-WkCGb/3ZxXepmMiX101nnGiU+1CAdut8oHyEOHxkKuS1qKpU2SMXE2uSvfz8PBuLd49V6LEsbtyPhWC7fnkgvQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-dotall-regex": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-dotall-regex/-/plugin-transform-dotall-regex-7.25.9.tgz",
      "integrity": "sha512-t7ZQ7g5trIgSRYhI9pIJtRl64KHotutUJsh4Eze5l7olJv+mRSg4/MmbZ0tv1eeqRbdvo/+trvJD/Oc5DmW2cA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-create-regexp-features-plugin": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-duplicate-keys": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-duplicate-keys/-/plugin-transform-duplicate-keys-7.25.9.tgz",
      "integrity": "sha512-LZxhJ6dvBb/f3x8xwWIuyiAHy56nrRG3PeYTpBkkzkYRRQ6tJLu68lEF5VIqMUZiAV7a8+Tb78nEoMCMcqjXBw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-duplicate-named-capturing-groups-regex": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-duplicate-named-capturing-groups-regex/-/plugin-transform-duplicate-named-capturing-groups-regex-7.25.9.tgz",
      "integrity": "sha512-0UfuJS0EsXbRvKnwcLjFtJy/Sxc5J5jhLHnFhy7u4zih97Hz6tJkLU+O+FMMrNZrosUPxDi6sYxJ/EA8jDiAog==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-create-regexp-features-plugin": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/plugin-transform-dynamic-import": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-dynamic-import/-/plugin-transform-dynamic-import-7.25.9.tgz",
      "integrity": "sha512-GCggjexbmSLaFhqsojeugBpeaRIgWNTcgKVq/0qIteFEqY2A+b9QidYadrWlnbWQUrW5fn+mCvf3tr7OeBFTyg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-exponentiation-operator": {
      "version": "7.26.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-exponentiation-operator/-/plugin-transform-exponentiation-operator-7.26.3.tgz",
      "integrity": "sha512-7CAHcQ58z2chuXPWblnn1K6rLDnDWieghSOEmqQsrBenH0P9InCUtOJYD89pvngljmZlJcz3fcmgYsXFNGa1ZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-export-namespace-from": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-export-namespace-from/-/plugin-transform-export-namespace-from-7.25.9.tgz",
      "integrity": "sha512-2NsEz+CxzJIVOPx2o9UsW1rXLqtChtLoVnwYHHiB04wS5sgn7mrV45fWMBX0Kk+ub9uXytVYfNP2HjbVbCB3Ww==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-for-of": {
      "version": "7.26.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-for-of/-/plugin-transform-for-of-7.26.9.tgz",
      "integrity": "sha512-Hry8AusVm8LW5BVFgiyUReuoGzPUpdHQQqJY5bZnbbf+ngOHWuCuYFKw/BqaaWlvEUrF91HMhDtEaI1hZzNbLg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.26.5",
        "@babel/helper-skip-transparent-expression-wrappers": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-function-name": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-function-name/-/plugin-transform-function-name-7.25.9.tgz",
      "integrity": "sha512-8lP+Yxjv14Vc5MuWBpJsoUCd3hD6V9DgBon2FVYL4jJgbnVQ9fTgYmonchzZJOVNgzEgbxp4OwAf6xz6M/14XA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-compilation-targets": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9",
        "@babel/traverse": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-json-strings": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-json-strings/-/plugin-transform-json-strings-7.25.9.tgz",
      "integrity": "sha512-xoTMk0WXceiiIvsaquQQUaLLXSW1KJ159KP87VilruQm0LNNGxWzahxSS6T6i4Zg3ezp4vA4zuwiNUR53qmQAw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-literals": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-literals/-/plugin-transform-literals-7.25.9.tgz",
      "integrity": "sha512-9N7+2lFziW8W9pBl2TzaNht3+pgMIRP74zizeCSrtnSKVdUl8mAjjOP2OOVQAfZ881P2cNjDj1uAMEdeD50nuQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-logical-assignment-operators": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-logical-assignment-operators/-/plugin-transform-logical-assignment-operators-7.25.9.tgz",
      "integrity": "sha512-wI4wRAzGko551Y8eVf6iOY9EouIDTtPb0ByZx+ktDGHwv6bHFimrgJM/2T021txPZ2s4c7bqvHbd+vXG6K948Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-member-expression-literals": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-member-expression-literals/-/plugin-transform-member-expression-literals-7.25.9.tgz",
      "integrity": "sha512-PYazBVfofCQkkMzh2P6IdIUaCEWni3iYEerAsRWuVd8+jlM1S9S9cz1dF9hIzyoZ8IA3+OwVYIp9v9e+GbgZhA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-modules-amd": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-modules-amd/-/plugin-transform-modules-amd-7.25.9.tgz",
      "integrity": "sha512-g5T11tnI36jVClQlMlt4qKDLlWnG5pP9CSM4GhdRciTNMRgkfpo5cR6b4rGIOYPgRRuFAvwjPQ/Yk+ql4dyhbw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-module-transforms": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-modules-commonjs": {
      "version": "7.26.3",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-modules-commonjs/-/plugin-transform-modules-commonjs-7.26.3.tgz",
      "integrity": "sha512-MgR55l4q9KddUDITEzEFYn5ZsGDXMSsU9E+kh7fjRXTIC3RHqfCo8RPRbyReYJh44HQ/yomFkqbOFohXvDCiIQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-module-transforms": "^7.26.0",
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-modules-systemjs": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-modules-systemjs/-/plugin-transform-modules-systemjs-7.25.9.tgz",
      "integrity": "sha512-hyss7iIlH/zLHaehT+xwiymtPOpsiwIIRlCAOwBB04ta5Tt+lNItADdlXw3jAWZ96VJ2jlhl/c+PNIQPKNfvcA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-module-transforms": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9",
        "@babel/helper-validator-identifier": "^7.25.9",
        "@babel/traverse": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-modules-umd": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-modules-umd/-/plugin-transform-modules-umd-7.25.9.tgz",
      "integrity": "sha512-bS9MVObUgE7ww36HEfwe6g9WakQ0KF07mQF74uuXdkoziUPfKyu/nIm663kz//e5O1nPInPFx36z7WJmJ4yNEw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-module-transforms": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-named-capturing-groups-regex": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-named-capturing-groups-regex/-/plugin-transform-named-capturing-groups-regex-7.25.9.tgz",
      "integrity": "sha512-oqB6WHdKTGl3q/ItQhpLSnWWOpjUJLsOCLVyeFgeTktkBSCiurvPOsyt93gibI9CmuKvTUEtWmG5VhZD+5T/KA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-create-regexp-features-plugin": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/plugin-transform-new-target": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-new-target/-/plugin-transform-new-target-7.25.9.tgz",
      "integrity": "sha512-U/3p8X1yCSoKyUj2eOBIx3FOn6pElFOKvAAGf8HTtItuPyB+ZeOqfn+mvTtg9ZlOAjsPdK3ayQEjqHjU/yLeVQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-nullish-coalescing-operator": {
      "version": "7.26.6",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-nullish-coalescing-operator/-/plugin-transform-nullish-coalescing-operator-7.26.6.tgz",
      "integrity": "sha512-CKW8Vu+uUZneQCPtXmSBUC6NCAUdya26hWCElAWh5mVSlSRsmiCPUUDKb3Z0szng1hiAJa098Hkhg9o4SE35Qw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.26.5"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-numeric-separator": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-numeric-separator/-/plugin-transform-numeric-separator-7.25.9.tgz",
      "integrity": "sha512-TlprrJ1GBZ3r6s96Yq8gEQv82s8/5HnCVHtEJScUj90thHQbwe+E5MLhi2bbNHBEJuzrvltXSru+BUxHDoog7Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-object-rest-spread": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-object-rest-spread/-/plugin-transform-object-rest-spread-7.25.9.tgz",
      "integrity": "sha512-fSaXafEE9CVHPweLYw4J0emp1t8zYTXyzN3UuG+lylqkvYd7RMrsOQ8TYx5RF231be0vqtFC6jnx3UmpJmKBYg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-compilation-targets": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9",
        "@babel/plugin-transform-parameters": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-object-super": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-object-super/-/plugin-transform-object-super-7.25.9.tgz",
      "integrity": "sha512-Kj/Gh+Rw2RNLbCK1VAWj2U48yxxqL2x0k10nPtSdRa0O2xnHXalD0s+o1A6a0W43gJ00ANo38jxkQreckOzv5A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9",
        "@babel/helper-replace-supers": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-optional-catch-binding": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-optional-catch-binding/-/plugin-transform-optional-catch-binding-7.25.9.tgz",
      "integrity": "sha512-qM/6m6hQZzDcZF3onzIhZeDHDO43bkNNlOX0i8n3lR6zLbu0GN2d8qfM/IERJZYauhAHSLHy39NF0Ctdvcid7g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-optional-chaining": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-optional-chaining/-/plugin-transform-optional-chaining-7.25.9.tgz",
      "integrity": "sha512-6AvV0FsLULbpnXeBjrY4dmWF8F7gf8QnvTEoO/wX/5xm/xE1Xo8oPuD3MPS+KS9f9XBEAWN7X1aWr4z9HdOr7A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9",
        "@babel/helper-skip-transparent-expression-wrappers": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-parameters": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-parameters/-/plugin-transform-parameters-7.25.9.tgz",
      "integrity": "sha512-wzz6MKwpnshBAiRmn4jR8LYz/g8Ksg0o80XmwZDlordjwEk9SxBzTWC7F5ef1jhbrbOW2DJ5J6ayRukrJmnr0g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-private-methods": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-private-methods/-/plugin-transform-private-methods-7.25.9.tgz",
      "integrity": "sha512-D/JUozNpQLAPUVusvqMxyvjzllRaF8/nSrP1s2YGQT/W4LHK4xxsMcHjhOGTS01mp9Hda8nswb+FblLdJornQw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-create-class-features-plugin": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-private-property-in-object": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-private-property-in-object/-/plugin-transform-private-property-in-object-7.25.9.tgz",
      "integrity": "sha512-Evf3kcMqzXA3xfYJmZ9Pg1OvKdtqsDMSWBDzZOPLvHiTt36E75jLDQo5w1gtRU95Q4E5PDttrTf25Fw8d/uWLw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-annotate-as-pure": "^7.25.9",
        "@babel/helper-create-class-features-plugin": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-property-literals": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-property-literals/-/plugin-transform-property-literals-7.25.9.tgz",
      "integrity": "sha512-IvIUeV5KrS/VPavfSM/Iu+RE6llrHrYIKY1yfCzyO/lMXHQ+p7uGhonmGVisv6tSBSVgWzMBohTcvkC9vQcQFA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-react-display-name": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-react-display-name/-/plugin-transform-react-display-name-7.25.9.tgz",
      "integrity": "sha512-KJfMlYIUxQB1CJfO3e0+h0ZHWOTLCPP115Awhaz8U0Zpq36Gl/cXlpoyMRnUWlhNUBAzldnCiAZNvCDj7CrKxQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-react-jsx": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-react-jsx/-/plugin-transform-react-jsx-7.25.9.tgz",
      "integrity": "sha512-s5XwpQYCqGerXl+Pu6VDL3x0j2d82eiV77UJ8a2mDHAW7j9SWRqQ2y1fNo1Z74CdcYipl5Z41zvjj4Nfzq36rw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-annotate-as-pure": "^7.25.9",
        "@babel/helper-module-imports": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9",
        "@babel/plugin-syntax-jsx": "^7.25.9",
        "@babel/types": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-react-jsx-development": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-react-jsx-development/-/plugin-transform-react-jsx-development-7.25.9.tgz",
      "integrity": "sha512-9mj6rm7XVYs4mdLIpbZnHOYdpW42uoiBCTVowg7sP1thUOiANgMb4UtpRivR0pp5iL+ocvUv7X4mZgFRpJEzGw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/plugin-transform-react-jsx": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-react-pure-annotations": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-react-pure-annotations/-/plugin-transform-react-pure-annotations-7.25.9.tgz",
      "integrity": "sha512-KQ/Takk3T8Qzj5TppkS1be588lkbTp5uj7w6a0LeQaTMSckU/wK0oJ/pih+T690tkgI5jfmg2TqDJvd41Sj1Cg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-annotate-as-pure": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-regenerator": {
      "version": "7.27.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-regenerator/-/plugin-transform-regenerator-7.27.0.tgz",
      "integrity": "sha512-LX/vCajUJQDqE7Aum/ELUMZAY19+cDpghxrnyt5I1tV6X5PyC86AOoWXWFYFeIvauyeSA6/ktn4tQVn/3ZifsA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.26.5",
        "regenerator-transform": "^0.15.2"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-regexp-modifiers": {
      "version": "7.26.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-regexp-modifiers/-/plugin-transform-regexp-modifiers-7.26.0.tgz",
      "integrity": "sha512-vN6saax7lrA2yA/Pak3sCxuD6F5InBjn9IcrIKQPjpsLvuHYLVroTxjdlVRHjjBWxKOqIwpTXDkOssYT4BFdRw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-create-regexp-features-plugin": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/plugin-transform-reserved-words": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-reserved-words/-/plugin-transform-reserved-words-7.25.9.tgz",
      "integrity": "sha512-7DL7DKYjn5Su++4RXu8puKZm2XBPHyjWLUidaPEkCUBbE7IPcsrkRHggAOOKydH1dASWdcUBxrkOGNxUv5P3Jg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-shorthand-properties": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-shorthand-properties/-/plugin-transform-shorthand-properties-7.25.9.tgz",
      "integrity": "sha512-MUv6t0FhO5qHnS/W8XCbHmiRWOphNufpE1IVxhK5kuN3Td9FT1x4rx4K42s3RYdMXCXpfWkGSbCSd0Z64xA7Ng==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-spread": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-spread/-/plugin-transform-spread-7.25.9.tgz",
      "integrity": "sha512-oNknIB0TbURU5pqJFVbOOFspVlrpVwo2H1+HUIsVDvp5VauGGDP1ZEvO8Nn5xyMEs3dakajOxlmkNW7kNgSm6A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9",
        "@babel/helper-skip-transparent-expression-wrappers": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-sticky-regex": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-sticky-regex/-/plugin-transform-sticky-regex-7.25.9.tgz",
      "integrity": "sha512-WqBUSgeVwucYDP9U/xNRQam7xV8W5Zf+6Eo7T2SRVUFlhRiMNFdFz58u0KZmCVVqs2i7SHgpRnAhzRNmKfi2uA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-template-literals": {
      "version": "7.26.8",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-template-literals/-/plugin-transform-template-literals-7.26.8.tgz",
      "integrity": "sha512-OmGDL5/J0CJPJZTHZbi2XpO0tyT2Ia7fzpW5GURwdtp2X3fMmN8au/ej6peC/T33/+CRiIpA8Krse8hFGVmT5Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.26.5"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-typeof-symbol": {
      "version": "7.27.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-typeof-symbol/-/plugin-transform-typeof-symbol-7.27.0.tgz",
      "integrity": "sha512-+LLkxA9rKJpNoGsbLnAgOCdESl73vwYn+V6b+5wHbrE7OGKVDPHIQvbFSzqE6rwqaCw2RE+zdJrlLkcf8YOA0w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.26.5"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-typescript": {
      "version": "7.27.0",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-typescript/-/plugin-transform-typescript-7.27.0.tgz",
      "integrity": "sha512-fRGGjO2UEGPjvEcyAZXRXAS8AfdaQoq7HnxAbJoAoW10B9xOKesmmndJv+Sym2a+9FHWZ9KbyyLCe9s0Sn5jtg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-annotate-as-pure": "^7.25.9",
        "@babel/helper-create-class-features-plugin": "^7.27.0",
        "@babel/helper-plugin-utils": "^7.26.5",
        "@babel/helper-skip-transparent-expression-wrappers": "^7.25.9",
        "@babel/plugin-syntax-typescript": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-unicode-escapes": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-unicode-escapes/-/plugin-transform-unicode-escapes-7.25.9.tgz",
      "integrity": "sha512-s5EDrE6bW97LtxOcGj1Khcx5AaXwiMmi4toFWRDP9/y0Woo6pXC+iyPu/KuhKtfSrNFd7jJB+/fkOtZy6aIC6Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-unicode-property-regex": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-unicode-property-regex/-/plugin-transform-unicode-property-regex-7.25.9.tgz",
      "integrity": "sha512-Jt2d8Ga+QwRluxRQ307Vlxa6dMrYEMZCgGxoPR8V52rxPyldHu3hdlHspxaqYmE7oID5+kB+UKUB/eWS+DkkWg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-create-regexp-features-plugin": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-unicode-regex": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-unicode-regex/-/plugin-transform-unicode-regex-7.25.9.tgz",
      "integrity": "sha512-yoxstj7Rg9dlNn9UQxzk4fcNivwv4nUYz7fYXBaKxvw/lnmPuOm/ikoELygbYq68Bls3D/D+NBPHiLwZdZZ4HA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-create-regexp-features-plugin": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/plugin-transform-unicode-sets-regex": {
      "version": "7.25.9",
      "resolved": "https://registry.npmjs.org/@babel/plugin-transform-unicode-sets-regex/-/plugin-transform-unicode-sets-regex-7.25.9.tgz",
      "integrity": "sha512-8BYqO3GeVNHtx69fdPshN3fnzUNLrWdHhk/icSwigksJGczKSizZ+Z6SBCxTs723Fr5VSNorTIK7a+R2tISvwQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-create-regexp-features-plugin": "^7.25.9",
        "@babel/helper-plugin-utils": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/@babel/preset-env": {
      "version": "7.26.9",
      "resolved": "https://registry.npmjs.org/@babel/preset-env/-/preset-env-7.26.9.tgz",
      "integrity": "sha512-vX3qPGE8sEKEAZCWk05k3cpTAE3/nOYca++JA+Rd0z2NCNzabmYvEiSShKzm10zdquOIAVXsy2Ei/DTW34KlKQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/compat-data": "^7.26.8",
        "@babel/helper-compilation-targets": "^7.26.5",
        "@babel/helper-plugin-utils": "^7.26.5",
        "@babel/helper-validator-option": "^7.25.9",
        "@babel/plugin-bugfix-firefox-class-in-computed-class-key": "^7.25.9",
        "@babel/plugin-bugfix-safari-class-field-initializer-scope": "^7.25.9",
        "@babel/plugin-bugfix-safari-id-destructuring-collision-in-function-expression": "^7.25.9",
        "@babel/plugin-bugfix-v8-spread-parameters-in-optional-chaining": "^7.25.9",
        "@babel/plugin-bugfix-v8-static-class-fields-redefine-readonly": "^7.25.9",
        "@babel/plugin-proposal-private-property-in-object": "7.21.0-placeholder-for-preset-env.2",
        "@babel/plugin-syntax-import-assertions": "^7.26.0",
        "@babel/plugin-syntax-import-attributes": "^7.26.0",
        "@babel/plugin-syntax-unicode-sets-regex": "^7.18.6",
        "@babel/plugin-transform-arrow-functions": "^7.25.9",
        "@babel/plugin-transform-async-generator-functions": "^7.26.8",
        "@babel/plugin-transform-async-to-generator": "^7.25.9",
        "@babel/plugin-transform-block-scoped-functions": "^7.26.5",
        "@babel/plugin-transform-block-scoping": "^7.25.9",
        "@babel/plugin-transform-class-properties": "^7.25.9",
        "@babel/plugin-transform-class-static-block": "^7.26.0",
        "@babel/plugin-transform-classes": "^7.25.9",
        "@babel/plugin-transform-computed-properties": "^7.25.9",
        "@babel/plugin-transform-destructuring": "^7.25.9",
        "@babel/plugin-transform-dotall-regex": "^7.25.9",
        "@babel/plugin-transform-duplicate-keys": "^7.25.9",
        "@babel/plugin-transform-duplicate-named-capturing-groups-regex": "^7.25.9",
        "@babel/plugin-transform-dynamic-import": "^7.25.9",
        "@babel/plugin-transform-exponentiation-operator": "^7.26.3",
        "@babel/plugin-transform-export-namespace-from": "^7.25.9",
        "@babel/plugin-transform-for-of": "^7.26.9",
        "@babel/plugin-transform-function-name": "^7.25.9",
        "@babel/plugin-transform-json-strings": "^7.25.9",
        "@babel/plugin-transform-literals": "^7.25.9",
        "@babel/plugin-transform-logical-assignment-operators": "^7.25.9",
        "@babel/plugin-transform-member-expression-literals": "^7.25.9",
        "@babel/plugin-transform-modules-amd": "^7.25.9",
        "@babel/plugin-transform-modules-commonjs": "^7.26.3",
        "@babel/plugin-transform-modules-systemjs": "^7.25.9",
        "@babel/plugin-transform-modules-umd": "^7.25.9",
        "@babel/plugin-transform-named-capturing-groups-regex": "^7.25.9",
        "@babel/plugin-transform-new-target": "^7.25.9",
        "@babel/plugin-transform-nullish-coalescing-operator": "^7.26.6",
        "@babel/plugin-transform-numeric-separator": "^7.25.9",
        "@babel/plugin-transform-object-rest-spread": "^7.25.9",
        "@babel/plugin-transform-object-super": "^7.25.9",
        "@babel/plugin-transform-optional-catch-binding": "^7.25.9",
        "@babel/plugin-transform-optional-chaining": "^7.25.9",
        "@babel/plugin-transform-parameters": "^7.25.9",
        "@babel/plugin-transform-private-methods": "^7.25.9",
        "@babel/plugin-transform-private-property-in-object": "^7.25.9",
        "@babel/plugin-transform-property-literals": "^7.25.9",
        "@babel/plugin-transform-regenerator": "^7.25.9",
        "@babel/plugin-transform-regexp-modifiers": "^7.26.0",
        "@babel/plugin-transform-reserved-words": "^7.25.9",
        "@babel/plugin-transform-shorthand-properties": "^7.25.9",
        "@babel/plugin-transform-spread": "^7.25.9",
        "@babel/plugin-transform-sticky-regex": "^7.25.9",
        "@babel/plugin-transform-template-literals": "^7.26.8",
        "@babel/plugin-transform-typeof-symbol": "^7.26.7",
        "@babel/plugin-transform-unicode-escapes": "^7.25.9",
        "@babel/plugin-transform-unicode-property-regex": "^7.25.9",
        "@babel/plugin-transform-unicode-regex": "^7.25.9",
        "@babel/plugin-transform-unicode-sets-regex": "^7.25.9",
        "@babel/preset-modules": "0.1.6-no-external-plugins",
        "babel-plugin-polyfill-corejs2": "^0.4.10",
        "babel-plugin-polyfill-corejs3": "^0.11.0",
        "babel-plugin-polyfill-regenerator": "^0.6.1",
        "core-js-compat": "^3.40.0",
        "semver": "^6.3.1"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/preset-env/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/@babel/preset-modules": {
      "version": "0.1.6-no-external-plugins",
      "resolved": "https://registry.npmjs.org/@babel/preset-modules/-/preset-modules-0.1.6-no-external-plugins.tgz",
      "integrity": "sha512-HrcgcIESLm9aIR842yhJ5RWan/gebQUJ6E/E5+rf0y9o6oj7w0Br+sWuL6kEQ/o/AdfvR1Je9jG18/gnpwjEyA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@babel/types": "^7.4.4",
        "esutils": "^2.0.2"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0 || ^8.0.0-0 <8.0.0"
      }
    },
    "node_modules/@babel/preset-react": {
      "version": "7.26.3",
      "resolved": "https://registry.npmjs.org/@babel/preset-react/-/preset-react-7.26.3.tgz",
      "integrity": "sha512-Nl03d6T9ky516DGK2YMxrTqvnpUW63TnJMOMonj+Zae0JiPC5BC9xPMSL6L8fiSpA5vP88qfygavVQvnLp+6Cw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.25.9",
        "@babel/helper-validator-option": "^7.25.9",
        "@babel/plugin-transform-react-display-name": "^7.25.9",
        "@babel/plugin-transform-react-jsx": "^7.25.9",
        "@babel/plugin-transform-react-jsx-development": "^7.25.9",
        "@babel/plugin-transform-react-pure-annotations": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/preset-typescript": {
      "version": "7.27.0",
      "resolved": "https://registry.npmjs.org/@babel/preset-typescript/-/preset-typescript-7.27.0.tgz",
      "integrity": "sha512-vxaPFfJtHhgeOVXRKuHpHPAOgymmy8V8I65T1q53R7GCZlefKeCaTyDs3zOPHTTbmquvNlQYC5klEvWsBAtrBQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.26.5",
        "@babel/helper-validator-option": "^7.25.9",
        "@babel/plugin-syntax-jsx": "^7.25.9",
        "@babel/plugin-transform-modules-commonjs": "^7.26.3",
        "@babel/plugin-transform-typescript": "^7.27.0"
      },
      "engines": {
        "node": ">=6.9.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0-0"
      }
    },
    "node_modules/@babel/runtime": {
      "version": "7.26.10",
      "resolved": "https://registry.npmjs.org/@babel/runtime/-/runtime-7.26.10.tgz",
      "integrity": "sha512-2WJMeRQPHKSPemqk/awGrAiuFfzBmOIPXKizAsVhWH9YJqLZ0H+HS4c8loHGgW6utJ3E/ejXQUsiGaQy2NZ9Fw==",
      "license": "MIT",
      "dependencies": {
        "regenerator-runtime": "^0.14.0"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/template": {
      "version": "7.27.0",
      "resolved": "https://registry.npmjs.org/@babel/template/-/template-7.27.0.tgz",
      "integrity": "sha512-2ncevenBqXI6qRMukPlXwHKHchC7RyMuu4xv5JBXRfOGVcTy1mXCD12qrp7Jsoxll1EV3+9sE4GugBVRjT2jFA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/code-frame": "^7.26.2",
        "@babel/parser": "^7.27.0",
        "@babel/types": "^7.27.0"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/traverse": {
      "version": "7.27.0",
      "resolved": "https://registry.npmjs.org/@babel/traverse/-/traverse-7.27.0.tgz",
      "integrity": "sha512-19lYZFzYVQkkHkl4Cy4WrAVcqBkgvV2YM2TU3xG6DIwO7O3ecbDPfW3yM3bjAGcqcQHi+CCtjMR3dIEHxsd6bA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/code-frame": "^7.26.2",
        "@babel/generator": "^7.27.0",
        "@babel/parser": "^7.27.0",
        "@babel/template": "^7.27.0",
        "@babel/types": "^7.27.0",
        "debug": "^4.3.1",
        "globals": "^11.1.0"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@babel/traverse/node_modules/globals": {
      "version": "11.12.0",
      "resolved": "https://registry.npmjs.org/globals/-/globals-11.12.0.tgz",
      "integrity": "sha512-WOBp/EEGUiIsJSp7wcv/y6MO+lV9UoncWqxuFfm8eBwzWNgyfBd6Gz+IeKQ9jCmyhoH99g15M3T+QaVHFjizVA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/@babel/types": {
      "version": "7.27.0",
      "resolved": "https://registry.npmjs.org/@babel/types/-/types-7.27.0.tgz",
      "integrity": "sha512-H45s8fVLYjbhFH62dIJ3WtmJ6RSPt/3DRO0ZcT2SUiYiQyz3BLVb9ADEnLl91m74aQPS3AzzeajZHYOalWe3bg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-string-parser": "^7.25.9",
        "@babel/helper-validator-identifier": "^7.25.9"
      },
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/@bcoe/v8-coverage": {
      "version": "0.2.3",
      "resolved": "https://registry.npmjs.org/@bcoe/v8-coverage/-/v8-coverage-0.2.3.tgz",
      "integrity": "sha512-0hYQ8SB4Db5zvZB4axdMHGwEaQjkZzFjQiN9LVYvIFB2nSUHW9tYpxWriPrWDASIxiaXax83REcLxuSdnGPZtw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@eslint-community/eslint-utils": {
      "version": "4.5.0",
      "resolved": "https://registry.npmjs.org/@eslint-community/eslint-utils/-/eslint-utils-4.5.0.tgz",
      "integrity": "sha512-RoV8Xs9eNwiDvhv7M+xcL4PWyRyIXRY/FLp3buU4h1EYfdF7unWUy3dOjPqb3C7rMUewIcqwW850PgS8h1o1yg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "eslint-visitor-keys": "^3.4.3"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      },
      "peerDependencies": {
        "eslint": "^6.0.0 || ^7.0.0 || >=8.0.0"
      }
    },
    "node_modules/@eslint-community/regexpp": {
      "version": "4.12.1",
      "resolved": "https://registry.npmjs.org/@eslint-community/regexpp/-/regexpp-4.12.1.tgz",
      "integrity": "sha512-CCZCDJuduB9OUkFkY2IgppNZMi2lBQgD2qzwXkEia16cge2pijY/aXi96CJMquDMn3nJdlPV1A5KrJEXwfLNzQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^12.0.0 || ^14.0.0 || >=16.0.0"
      }
    },
    "node_modules/@eslint/eslintrc": {
      "version": "2.1.4",
      "resolved": "https://registry.npmjs.org/@eslint/eslintrc/-/eslintrc-2.1.4.tgz",
      "integrity": "sha512-269Z39MS6wVJtsoUl10L60WdkhJVdPG24Q4eZTH3nnF6lpvSShEK3wQjDX9JRWAUPvPh7COouPpU9IrqaZFvtQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ajv": "^6.12.4",
        "debug": "^4.3.2",
        "espree": "^9.6.0",
        "globals": "^13.19.0",
        "ignore": "^5.2.0",
        "import-fresh": "^3.2.1",
        "js-yaml": "^4.1.0",
        "minimatch": "^3.1.2",
        "strip-json-comments": "^3.1.1"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/@eslint/js": {
      "version": "8.57.1",
      "resolved": "https://registry.npmjs.org/@eslint/js/-/js-8.57.1.tgz",
      "integrity": "sha512-d9zaMRSTIKDLhctzH12MtXvJKSSUhaHcjV+2Z+GK+EEY7XKpP5yR4x+N3TAcHTcu963nIr+TMcCb4DBCYX1z6Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      }
    },
    "node_modules/@floating-ui/core": {
      "version": "1.6.9",
      "resolved": "https://registry.npmjs.org/@floating-ui/core/-/core-1.6.9.tgz",
      "integrity": "sha512-uMXCuQ3BItDUbAMhIXw7UPXRfAlOAvZzdK9BWpE60MCn+Svt3aLn9jsPTi/WNGlRUu2uI0v5S7JiIUsbsvh3fw==",
      "license": "MIT",
      "dependencies": {
        "@floating-ui/utils": "^0.2.9"
      }
    },
    "node_modules/@floating-ui/dom": {
      "version": "1.6.13",
      "resolved": "https://registry.npmjs.org/@floating-ui/dom/-/dom-1.6.13.tgz",
      "integrity": "sha512-umqzocjDgNRGTuO7Q8CU32dkHkECqI8ZdMZ5Swb6QAM0t5rnlrN3lGo1hdpscRd3WS8T6DKYK4ephgIH9iRh3w==",
      "license": "MIT",
      "dependencies": {
        "@floating-ui/core": "^1.6.0",
        "@floating-ui/utils": "^0.2.9"
      }
    },
    "node_modules/@floating-ui/react-dom": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/@floating-ui/react-dom/-/react-dom-2.1.2.tgz",
      "integrity": "sha512-06okr5cgPzMNBy+Ycse2A6udMi4bqwW/zgBF/rwjcNqWkyr82Mcg8b0vjX8OJpZFy/FKjJmw6wV7t44kK6kW7A==",
      "license": "MIT",
      "dependencies": {
        "@floating-ui/dom": "^1.0.0"
      },
      "peerDependencies": {
        "react": ">=16.8.0",
        "react-dom": ">=16.8.0"
      }
    },
    "node_modules/@floating-ui/utils": {
      "version": "0.2.9",
      "resolved": "https://registry.npmjs.org/@floating-ui/utils/-/utils-0.2.9.tgz",
      "integrity": "sha512-MDWhGtE+eHw5JW7lq4qhc5yRLS11ERl1c7Z6Xd0a58DozHES6EnNNwUWbMiG4J9Cgj053Bhk8zvlhFYKVhULwg==",
      "license": "MIT"
    },
    "node_modules/@humanwhocodes/config-array": {
      "version": "0.13.0",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/config-array/-/config-array-0.13.0.tgz",
      "integrity": "sha512-DZLEEqFWQFiyK6h5YIeynKx7JlvCYWL0cImfSRXZ9l4Sg2efkFGTuFf6vzXjK1cq6IYkU+Eg/JizXw+TD2vRNw==",
      "deprecated": "Use @eslint/config-array instead",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "@humanwhocodes/object-schema": "^2.0.3",
        "debug": "^4.3.1",
        "minimatch": "^3.0.5"
      },
      "engines": {
        "node": ">=10.10.0"
      }
    },
    "node_modules/@humanwhocodes/module-importer": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/module-importer/-/module-importer-1.0.1.tgz",
      "integrity": "sha512-bxveV4V8v5Yb4ncFTT3rPSgZBOpCkjfK0y4oVVVJwIuDVBRMDXrPyXRL988i5ap9m9bnyEEjWfm5WkBmtffLfA==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=12.22"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/nzakas"
      }
    },
    "node_modules/@humanwhocodes/object-schema": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/@humanwhocodes/object-schema/-/object-schema-2.0.3.tgz",
      "integrity": "sha512-93zYdMES/c1D69yZiKDBj0V24vqNzB/koF26KPaagAfd3P/4gUlh3Dys5ogAK+Exi9QyzlD8x/08Zt7wIKcDcA==",
      "deprecated": "Use @eslint/object-schema instead",
      "dev": true,
      "license": "BSD-3-Clause"
    },
    "node_modules/@isaacs/cliui": {
      "version": "8.0.2",
      "resolved": "https://registry.npmjs.org/@isaacs/cliui/-/cliui-8.0.2.tgz",
      "integrity": "sha512-O8jcjabXaleOG9DQ0+ARXWZBTfnP4WNAqzuiJK7ll44AmxGKv/J2M4TPjxjY3znBCfvBXFzucm1twdyFybFqEA==",
      "license": "ISC",
      "dependencies": {
        "string-width": "^5.1.2",
        "string-width-cjs": "npm:string-width@^4.2.0",
        "strip-ansi": "^7.0.1",
        "strip-ansi-cjs": "npm:strip-ansi@^6.0.1",
        "wrap-ansi": "^8.1.0",
        "wrap-ansi-cjs": "npm:wrap-ansi@^7.0.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@isaacs/cliui/node_modules/ansi-regex": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.1.0.tgz",
      "integrity": "sha512-7HSX4QQb4CspciLpVFwyRe79O3xsIZDDLER21kERQ71oaPodF8jL725AgJMFAYbooIqolJoRLuM81SpeUkpkvA==",
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
      }
    },
    "node_modules/@isaacs/cliui/node_modules/strip-ansi": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.0.tgz",
      "integrity": "sha512-iq6eVVI64nQQTRYq2KtEg2d2uU7LElhTJwsH4YzIHZshxlgZms/wIc4VoDQTlG/IvVIrBKG06CrZnp0qv7hkcQ==",
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^6.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
      }
    },
    "node_modules/@istanbuljs/load-nyc-config": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@istanbuljs/load-nyc-config/-/load-nyc-config-1.1.0.tgz",
      "integrity": "sha512-VjeHSlIzpv/NyD3N0YuHfXOPDIixcA1q2ZV98wsMqcYlPmv2n3Yb2lYP9XMElnaFVXg5A7YLTeLu6V84uQDjmQ==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "camelcase": "^5.3.1",
        "find-up": "^4.1.0",
        "get-package-type": "^0.1.0",
        "js-yaml": "^3.13.1",
        "resolve-from": "^5.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/@istanbuljs/load-nyc-config/node_modules/argparse": {
      "version": "1.0.10",
      "resolved": "https://registry.npmjs.org/argparse/-/argparse-1.0.10.tgz",
      "integrity": "sha512-o5Roy6tNG4SL/FOkCAN6RzjiakZS25RLYFrcMttJqbdd8BWrnA+fGz57iN5Pb06pvBGvl5gQ0B48dJlslXvoTg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "sprintf-js": "~1.0.2"
      }
    },
    "node_modules/@istanbuljs/load-nyc-config/node_modules/camelcase": {
      "version": "5.3.1",
      "resolved": "https://registry.npmjs.org/camelcase/-/camelcase-5.3.1.tgz",
      "integrity": "sha512-L28STB170nwWS63UjtlEOE3dldQApaJXZkOI1uMFfzf3rRuPegHaHesyee+YxQ+W6SvRDQV6UrdOdRiR153wJg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/@istanbuljs/load-nyc-config/node_modules/find-up": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/find-up/-/find-up-4.1.0.tgz",
      "integrity": "sha512-PpOwAdQ/YlXQ2vj8a3h8IipDuYRi3wceVQQGYWxNINccq40Anw7BlsEXCMbt1Zt+OLA6Fq9suIpIWD0OsnISlw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "locate-path": "^5.0.0",
        "path-exists": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/@istanbuljs/load-nyc-config/node_modules/js-yaml": {
      "version": "3.14.1",
      "resolved": "https://registry.npmjs.org/js-yaml/-/js-yaml-3.14.1.tgz",
      "integrity": "sha512-okMH7OXXJ7YrN9Ok3/SXrnu4iX9yOk+25nqX4imS2npuvTYDmo/QEZoqwZkYaIDk3jVvBOTOIEgEhaLOynBS9g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "argparse": "^1.0.7",
        "esprima": "^4.0.0"
      },
      "bin": {
        "js-yaml": "bin/js-yaml.js"
      }
    },
    "node_modules/@istanbuljs/load-nyc-config/node_modules/locate-path": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-5.0.0.tgz",
      "integrity": "sha512-t7hw9pI+WvuwNJXwk5zVHpyhIqzg2qTlklJOf0mVxGSbe3Fp2VieZcduNYjaLDoy6p9uGpQEGWG87WpMKlNq8g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-locate": "^4.1.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/@istanbuljs/load-nyc-config/node_modules/p-limit": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-2.3.0.tgz",
      "integrity": "sha512-//88mFWSJx8lxCzwdAABTJL2MyWB12+eIY7MDL2SqLmAkeKU9qxRvWuSyTjm3FUmpBEMuFfckAIqEaVGUDxb6w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-try": "^2.0.0"
      },
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/@istanbuljs/load-nyc-config/node_modules/p-locate": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-4.1.0.tgz",
      "integrity": "sha512-R79ZZ/0wAxKGu3oYMlz8jy/kbhsNrS7SKZ7PxEHBgJ5+F2mtFW2fK2cOtBh1cHYkQsbzFV7I+EoRKe6Yt0oK7A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-limit": "^2.2.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/@istanbuljs/load-nyc-config/node_modules/resolve-from": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/resolve-from/-/resolve-from-5.0.0.tgz",
      "integrity": "sha512-qYg9KP24dD5qka9J47d0aVky0N+b4fTU89LN9iDnjB5waksiC49rvMB0PrUJQGoTmH50XPiqOvAjDfaijGxYZw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/@istanbuljs/schema": {
      "version": "0.1.3",
      "resolved": "https://registry.npmjs.org/@istanbuljs/schema/-/schema-0.1.3.tgz",
      "integrity": "sha512-ZXRY4jNvVgSVQ8DL3LTcakaAtXwTVUxE81hslsyD2AtoXW/wVob10HkOJ1X/pAlcI7D+2YoZKg5do8G/w6RYgA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/@jest/console": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/console/-/console-29.7.0.tgz",
      "integrity": "sha512-5Ni4CU7XHQi32IJ398EEP4RrB8eV09sXP2ROqD4bksHrnTree52PsxvX8tpL8LvTZ3pFzXyPbNQReSN41CAhOg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "jest-message-util": "^29.7.0",
        "jest-util": "^29.7.0",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/core": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/core/-/core-29.7.0.tgz",
      "integrity": "sha512-n7aeXWKMnGtDA48y8TLWJPJmLmmZ642Ceo78cYWEpiD7FzDgmNDV/GCVRorPABdXLJZ/9wzzgZAlHjXjxDHGsg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/console": "^29.7.0",
        "@jest/reporters": "^29.7.0",
        "@jest/test-result": "^29.7.0",
        "@jest/transform": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "ansi-escapes": "^4.2.1",
        "chalk": "^4.0.0",
        "ci-info": "^3.2.0",
        "exit": "^0.1.2",
        "graceful-fs": "^4.2.9",
        "jest-changed-files": "^29.7.0",
        "jest-config": "^29.7.0",
        "jest-haste-map": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-regex-util": "^29.6.3",
        "jest-resolve": "^29.7.0",
        "jest-resolve-dependencies": "^29.7.0",
        "jest-runner": "^29.7.0",
        "jest-runtime": "^29.7.0",
        "jest-snapshot": "^29.7.0",
        "jest-util": "^29.7.0",
        "jest-validate": "^29.7.0",
        "jest-watcher": "^29.7.0",
        "micromatch": "^4.0.4",
        "pretty-format": "^29.7.0",
        "slash": "^3.0.0",
        "strip-ansi": "^6.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "node-notifier": "^8.0.1 || ^9.0.0 || ^10.0.0"
      },
      "peerDependenciesMeta": {
        "node-notifier": {
          "optional": true
        }
      }
    },
    "node_modules/@jest/core/node_modules/ansi-styles": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-5.2.0.tgz",
      "integrity": "sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/@jest/core/node_modules/pretty-format": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/pretty-format/-/pretty-format-29.7.0.tgz",
      "integrity": "sha512-Pdlw/oPxN+aXdmM9R00JVC9WVFoCLTKJvDVLgmJ+qAffBMxsV85l/Lu7sNx4zSzPyoL2euImuEwHhOXdEgNFZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/schemas": "^29.6.3",
        "ansi-styles": "^5.0.0",
        "react-is": "^18.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/core/node_modules/react-is": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-18.3.1.tgz",
      "integrity": "sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@jest/environment": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/environment/-/environment-29.7.0.tgz",
      "integrity": "sha512-aQIfHDq33ExsN4jP1NWGXhxgQ/wixs60gDiKO+XVMd8Mn0NWPWgc34ZQDTb2jKaUWQ7MuwoitXAsN2XVXNMpAw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/fake-timers": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "jest-mock": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/expect": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/expect/-/expect-29.7.0.tgz",
      "integrity": "sha512-8uMeAMycttpva3P1lBHB8VciS9V0XAr3GymPpipdyQXbBcuhkLQOSe8E/p92RyAdToS6ZD1tFkX+CkhoECE0dQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "expect": "^29.7.0",
        "jest-snapshot": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/expect-utils": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/expect-utils/-/expect-utils-29.7.0.tgz",
      "integrity": "sha512-GlsNBWiFQFCVi9QVSx7f5AgMeLxe9YCCs5PuP2O2LdjDAA8Jh9eX7lA1Jq/xdXw3Wb3hyvlFNfZIfcRetSzYcA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "jest-get-type": "^29.6.3"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/fake-timers": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/fake-timers/-/fake-timers-29.7.0.tgz",
      "integrity": "sha512-q4DH1Ha4TTFPdxLsqDXK1d3+ioSL7yL5oCMJZgDYm6i+6CygW5E5xVr/D1HdsGxjt1ZWSfUAs9OxSB/BNelWrQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "@sinonjs/fake-timers": "^10.0.2",
        "@types/node": "*",
        "jest-message-util": "^29.7.0",
        "jest-mock": "^29.7.0",
        "jest-util": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/globals": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/globals/-/globals-29.7.0.tgz",
      "integrity": "sha512-mpiz3dutLbkW2MNFubUGUEVLkTGiqW6yLVTA+JbP6fI6J5iL9Y0Nlg8k95pcF8ctKwCS7WVxteBs29hhfAotzQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/environment": "^29.7.0",
        "@jest/expect": "^29.7.0",
        "@jest/types": "^29.6.3",
        "jest-mock": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/reporters": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/reporters/-/reporters-29.7.0.tgz",
      "integrity": "sha512-DApq0KJbJOEzAFYjHADNNxAE3KbhxQB1y5Kplb5Waqw6zVbuWatSnMjE5gs8FUgEPmNsnZA3NCWl9NG0ia04Pg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@bcoe/v8-coverage": "^0.2.3",
        "@jest/console": "^29.7.0",
        "@jest/test-result": "^29.7.0",
        "@jest/transform": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@jridgewell/trace-mapping": "^0.3.18",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "collect-v8-coverage": "^1.0.0",
        "exit": "^0.1.2",
        "glob": "^7.1.3",
        "graceful-fs": "^4.2.9",
        "istanbul-lib-coverage": "^3.0.0",
        "istanbul-lib-instrument": "^6.0.0",
        "istanbul-lib-report": "^3.0.0",
        "istanbul-lib-source-maps": "^4.0.0",
        "istanbul-reports": "^3.1.3",
        "jest-message-util": "^29.7.0",
        "jest-util": "^29.7.0",
        "jest-worker": "^29.7.0",
        "slash": "^3.0.0",
        "string-length": "^4.0.1",
        "strip-ansi": "^6.0.0",
        "v8-to-istanbul": "^9.0.1"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "node-notifier": "^8.0.1 || ^9.0.0 || ^10.0.0"
      },
      "peerDependenciesMeta": {
        "node-notifier": {
          "optional": true
        }
      }
    },
    "node_modules/@jest/reporters/node_modules/glob": {
      "version": "7.2.3",
      "resolved": "https://registry.npmjs.org/glob/-/glob-7.2.3.tgz",
      "integrity": "sha512-nFR0zLpU2YCaRxwoCJvL6UvCH2JFyFVIvwTLsIf21AuHlMskA1hhTdk+LlYJtOlYt9v6dvszD2BGRqBL+iQK9Q==",
      "deprecated": "Glob versions prior to v9 are no longer supported",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "fs.realpath": "^1.0.0",
        "inflight": "^1.0.4",
        "inherits": "2",
        "minimatch": "^3.1.1",
        "once": "^1.3.0",
        "path-is-absolute": "^1.0.0"
      },
      "engines": {
        "node": "*"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/@jest/schemas": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/@jest/schemas/-/schemas-29.6.3.tgz",
      "integrity": "sha512-mo5j5X+jIZmJQveBKeS/clAueipV7KgiX1vMgCxam1RNYiqE1w62n0/tJJnHtjW8ZHcQco5gY85jA3mi0L+nSA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@sinclair/typebox": "^0.27.8"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/source-map": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/@jest/source-map/-/source-map-29.6.3.tgz",
      "integrity": "sha512-MHjT95QuipcPrpLM+8JMSzFx6eHp5Bm+4XeFDJlwsvVBjmKNiIAvasGK2fxz2WbGRlnvqehFbh07MMa7n3YJnw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/trace-mapping": "^0.3.18",
        "callsites": "^3.0.0",
        "graceful-fs": "^4.2.9"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/test-result": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/test-result/-/test-result-29.7.0.tgz",
      "integrity": "sha512-Fdx+tv6x1zlkJPcWXmMDAG2HBnaR9XPSd5aDWQVsfrZmLVT3lU1cwyxLgRmXR9yrq4NBoEm9BMsfgFzTQAbJYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/console": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/istanbul-lib-coverage": "^2.0.0",
        "collect-v8-coverage": "^1.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/test-sequencer": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/test-sequencer/-/test-sequencer-29.7.0.tgz",
      "integrity": "sha512-GQwJ5WZVrKnOJuiYiAF52UNUJXgTZx1NHjFSEB0qEMmSZKAkdMoIzw/Cj6x6NF4AvV23AUqDpFzQkN/eYCYTxw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/test-result": "^29.7.0",
        "graceful-fs": "^4.2.9",
        "jest-haste-map": "^29.7.0",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/transform": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/@jest/transform/-/transform-29.7.0.tgz",
      "integrity": "sha512-ok/BTPFzFKVMwO5eOHRrvnBVHdRy9IrsrW1GpMaQ9MCnilNLXQKmAX8s1YXDFaai9xJpac2ySzV0YeRRECr2Vw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/core": "^7.11.6",
        "@jest/types": "^29.6.3",
        "@jridgewell/trace-mapping": "^0.3.18",
        "babel-plugin-istanbul": "^6.1.1",
        "chalk": "^4.0.0",
        "convert-source-map": "^2.0.0",
        "fast-json-stable-stringify": "^2.1.0",
        "graceful-fs": "^4.2.9",
        "jest-haste-map": "^29.7.0",
        "jest-regex-util": "^29.6.3",
        "jest-util": "^29.7.0",
        "micromatch": "^4.0.4",
        "pirates": "^4.0.4",
        "slash": "^3.0.0",
        "write-file-atomic": "^4.0.2"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jest/types": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/@jest/types/-/types-29.6.3.tgz",
      "integrity": "sha512-u3UPsIilWKOM3F9CXtrG8LEJmNxwoCQC/XVj4IKYXvvpx7QIi/Kg1LI5uDmDpKlac62NUtX7eLjRh+jVZcLOzw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/schemas": "^29.6.3",
        "@types/istanbul-lib-coverage": "^2.0.0",
        "@types/istanbul-reports": "^3.0.0",
        "@types/node": "*",
        "@types/yargs": "^17.0.8",
        "chalk": "^4.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@jridgewell/gen-mapping": {
      "version": "0.3.8",
      "resolved": "https://registry.npmjs.org/@jridgewell/gen-mapping/-/gen-mapping-0.3.8.tgz",
      "integrity": "sha512-imAbBGkb+ebQyxKgzv5Hu2nmROxoDOXHh80evxdoXNOrvAnVx7zimzc1Oo5h9RlfV4vPXaE2iM5pOFbvOCClWA==",
      "license": "MIT",
      "dependencies": {
        "@jridgewell/set-array": "^1.2.1",
        "@jridgewell/sourcemap-codec": "^1.4.10",
        "@jridgewell/trace-mapping": "^0.3.24"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/resolve-uri": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/@jridgewell/resolve-uri/-/resolve-uri-3.1.2.tgz",
      "integrity": "sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==",
      "license": "MIT",
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/set-array": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/@jridgewell/set-array/-/set-array-1.2.1.tgz",
      "integrity": "sha512-R8gLRTZeyp03ymzP/6Lil/28tGeGEzhx1q2k703KGWRAI1VdvPIXdG70VJc2pAMw3NA6JKL5hhFu1sJX0Mnn/A==",
      "license": "MIT",
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/sourcemap-codec": {
      "version": "1.5.0",
      "resolved": "https://registry.npmjs.org/@jridgewell/sourcemap-codec/-/sourcemap-codec-1.5.0.tgz",
      "integrity": "sha512-gv3ZRaISU3fjPAgNsriBRqGWQL6quFx04YMPW/zD8XMLsU32mhCCbfbO6KZFLjvYpCZ8zyDEgqsgf+PwPaM7GQ==",
      "license": "MIT"
    },
    "node_modules/@jridgewell/trace-mapping": {
      "version": "0.3.25",
      "resolved": "https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.25.tgz",
      "integrity": "sha512-vNk6aEwybGtawWmy/PzwnGDOjCkLWSD2wqvjGGAgOAwCGWySYXfYoxt00IJkTF+8Lb57DwOb3Aa0o9CApepiYQ==",
      "license": "MIT",
      "dependencies": {
        "@jridgewell/resolve-uri": "^3.1.0",
        "@jridgewell/sourcemap-codec": "^1.4.14"
      }
    },
    "node_modules/@langchain/community": {
      "version": "0.0.57",
      "resolved": "https://registry.npmjs.org/@langchain/community/-/community-0.0.57.tgz",
      "integrity": "sha512-tib4UJNkyA4TPNsTNChiBtZmThVJBr7X/iooSmKeCr+yUEha2Yxly3A4OAO95Vlpj4Q+od8HAfCbZih/1XqAMw==",
      "license": "MIT",
      "dependencies": {
        "@langchain/core": "~0.1.60",
        "@langchain/openai": "~0.0.28",
        "expr-eval": "^2.0.2",
        "flat": "^5.0.2",
        "langsmith": "~0.1.1",
        "uuid": "^9.0.0",
        "zod": "^3.22.3",
        "zod-to-json-schema": "^3.22.5"
      },
      "engines": {
        "node": ">=18"
      },
      "peerDependencies": {
        "@aws-crypto/sha256-js": "^5.0.0",
        "@aws-sdk/client-bedrock-agent-runtime": "^3.485.0",
        "@aws-sdk/client-bedrock-runtime": "^3.422.0",
        "@aws-sdk/client-dynamodb": "^3.310.0",
        "@aws-sdk/client-kendra": "^3.352.0",
        "@aws-sdk/client-lambda": "^3.310.0",
        "@aws-sdk/client-sagemaker-runtime": "^3.310.0",
        "@aws-sdk/client-sfn": "^3.310.0",
        "@aws-sdk/credential-provider-node": "^3.388.0",
        "@azure/search-documents": "^12.0.0",
        "@clickhouse/client": "^0.2.5",
        "@cloudflare/ai": "*",
        "@datastax/astra-db-ts": "^1.0.0",
        "@elastic/elasticsearch": "^8.4.0",
        "@getmetal/metal-sdk": "*",
        "@getzep/zep-js": "^0.9.0",
        "@gomomento/sdk": "^1.51.1",
        "@gomomento/sdk-core": "^1.51.1",
        "@google-ai/generativelanguage": "^0.2.1",
        "@gradientai/nodejs-sdk": "^1.2.0",
        "@huggingface/inference": "^2.6.4",
        "@mlc-ai/web-llm": "^0.2.35",
        "@mozilla/readability": "*",
        "@neondatabase/serverless": "*",
        "@opensearch-project/opensearch": "*",
        "@pinecone-database/pinecone": "*",
        "@planetscale/database": "^1.8.0",
        "@premai/prem-sdk": "^0.3.25",
        "@qdrant/js-client-rest": "^1.8.2",
        "@raycast/api": "^1.55.2",
        "@rockset/client": "^0.9.1",
        "@smithy/eventstream-codec": "^2.0.5",
        "@smithy/protocol-http": "^3.0.6",
        "@smithy/signature-v4": "^2.0.10",
        "@smithy/util-utf8": "^2.0.0",
        "@supabase/postgrest-js": "^1.1.1",
        "@supabase/supabase-js": "^2.10.0",
        "@tensorflow-models/universal-sentence-encoder": "*",
        "@tensorflow/tfjs-converter": "*",
        "@tensorflow/tfjs-core": "*",
        "@upstash/redis": "^1.20.6",
        "@upstash/vector": "^1.0.7",
        "@vercel/kv": "^0.2.3",
        "@vercel/postgres": "^0.5.0",
        "@writerai/writer-sdk": "^0.40.2",
        "@xata.io/client": "^0.28.0",
        "@xenova/transformers": "^2.5.4",
        "@zilliz/milvus2-sdk-node": ">=2.2.7",
        "better-sqlite3": "^9.4.0",
        "cassandra-driver": "^4.7.2",
        "cborg": "^4.1.1",
        "chromadb": "*",
        "closevector-common": "0.1.3",
        "closevector-node": "0.1.6",
        "closevector-web": "0.1.6",
        "cohere-ai": "*",
        "convex": "^1.3.1",
        "couchbase": "^4.3.0",
        "discord.js": "^14.14.1",
        "dria": "^0.0.3",
        "duck-duck-scrape": "^2.2.5",
        "faiss-node": "^0.5.1",
        "firebase-admin": "^11.9.0 || ^12.0.0",
        "google-auth-library": "^8.9.0",
        "googleapis": "^126.0.1",
        "hnswlib-node": "^3.0.0",
        "html-to-text": "^9.0.5",
        "interface-datastore": "^8.2.11",
        "ioredis": "^5.3.2",
        "it-all": "^3.0.4",
        "jsdom": "*",
        "jsonwebtoken": "^9.0.2",
        "llmonitor": "^0.5.9",
        "lodash": "^4.17.21",
        "lunary": "^0.6.11",
        "mongodb": ">=5.2.0",
        "mysql2": "^3.3.3",
        "neo4j-driver": "*",
        "node-llama-cpp": "*",
        "pg": "^8.11.0",
        "pg-copy-streams": "^6.0.5",
        "pickleparser": "^0.2.1",
        "portkey-ai": "^0.1.11",
        "redis": "*",
        "replicate": "^0.18.0",
        "typeorm": "^0.3.12",
        "typesense": "^1.5.3",
        "usearch": "^1.1.1",
        "vectordb": "^0.1.4",
        "voy-search": "0.6.2",
        "weaviate-ts-client": "*",
        "web-auth-library": "^1.0.3",
        "ws": "^8.14.2"
      },
      "peerDependenciesMeta": {
        "@aws-crypto/sha256-js": {
          "optional": true
        },
        "@aws-sdk/client-bedrock-agent-runtime": {
          "optional": true
        },
        "@aws-sdk/client-bedrock-runtime": {
          "optional": true
        },
        "@aws-sdk/client-dynamodb": {
          "optional": true
        },
        "@aws-sdk/client-kendra": {
          "optional": true
        },
        "@aws-sdk/client-lambda": {
          "optional": true
        },
        "@aws-sdk/client-sagemaker-runtime": {
          "optional": true
        },
        "@aws-sdk/client-sfn": {
          "optional": true
        },
        "@aws-sdk/credential-provider-node": {
          "optional": true
        },
        "@azure/search-documents": {
          "optional": true
        },
        "@clickhouse/client": {
          "optional": true
        },
        "@cloudflare/ai": {
          "optional": true
        },
        "@datastax/astra-db-ts": {
          "optional": true
        },
        "@elastic/elasticsearch": {
          "optional": true
        },
        "@getmetal/metal-sdk": {
          "optional": true
        },
        "@getzep/zep-js": {
          "optional": true
        },
        "@gomomento/sdk": {
          "optional": true
        },
        "@gomomento/sdk-core": {
          "optional": true
        },
        "@google-ai/generativelanguage": {
          "optional": true
        },
        "@gradientai/nodejs-sdk": {
          "optional": true
        },
        "@huggingface/inference": {
          "optional": true
        },
        "@mlc-ai/web-llm": {
          "optional": true
        },
        "@mozilla/readability": {
          "optional": true
        },
        "@neondatabase/serverless": {
          "optional": true
        },
        "@opensearch-project/opensearch": {
          "optional": true
        },
        "@pinecone-database/pinecone": {
          "optional": true
        },
        "@planetscale/database": {
          "optional": true
        },
        "@premai/prem-sdk": {
          "optional": true
        },
        "@qdrant/js-client-rest": {
          "optional": true
        },
        "@raycast/api": {
          "optional": true
        },
        "@rockset/client": {
          "optional": true
        },
        "@smithy/eventstream-codec": {
          "optional": true
        },
        "@smithy/protocol-http": {
          "optional": true
        },
        "@smithy/signature-v4": {
          "optional": true
        },
        "@smithy/util-utf8": {
          "optional": true
        },
        "@supabase/postgrest-js": {
          "optional": true
        },
        "@supabase/supabase-js": {
          "optional": true
        },
        "@tensorflow-models/universal-sentence-encoder": {
          "optional": true
        },
        "@tensorflow/tfjs-converter": {
          "optional": true
        },
        "@tensorflow/tfjs-core": {
          "optional": true
        },
        "@upstash/redis": {
          "optional": true
        },
        "@upstash/vector": {
          "optional": true
        },
        "@vercel/kv": {
          "optional": true
        },
        "@vercel/postgres": {
          "optional": true
        },
        "@writerai/writer-sdk": {
          "optional": true
        },
        "@xata.io/client": {
          "optional": true
        },
        "@xenova/transformers": {
          "optional": true
        },
        "@zilliz/milvus2-sdk-node": {
          "optional": true
        },
        "better-sqlite3": {
          "optional": true
        },
        "cassandra-driver": {
          "optional": true
        },
        "cborg": {
          "optional": true
        },
        "chromadb": {
          "optional": true
        },
        "closevector-common": {
          "optional": true
        },
        "closevector-node": {
          "optional": true
        },
        "closevector-web": {
          "optional": true
        },
        "cohere-ai": {
          "optional": true
        },
        "convex": {
          "optional": true
        },
        "couchbase": {
          "optional": true
        },
        "discord.js": {
          "optional": true
        },
        "dria": {
          "optional": true
        },
        "duck-duck-scrape": {
          "optional": true
        },
        "faiss-node": {
          "optional": true
        },
        "firebase-admin": {
          "optional": true
        },
        "google-auth-library": {
          "optional": true
        },
        "googleapis": {
          "optional": true
        },
        "hnswlib-node": {
          "optional": true
        },
        "html-to-text": {
          "optional": true
        },
        "interface-datastore": {
          "optional": true
        },
        "ioredis": {
          "optional": true
        },
        "it-all": {
          "optional": true
        },
        "jsdom": {
          "optional": true
        },
        "jsonwebtoken": {
          "optional": true
        },
        "llmonitor": {
          "optional": true
        },
        "lodash": {
          "optional": true
        },
        "lunary": {
          "optional": true
        },
        "mongodb": {
          "optional": true
        },
        "mysql2": {
          "optional": true
        },
        "neo4j-driver": {
          "optional": true
        },
        "node-llama-cpp": {
          "optional": true
        },
        "pg": {
          "optional": true
        },
        "pg-copy-streams": {
          "optional": true
        },
        "pickleparser": {
          "optional": true
        },
        "portkey-ai": {
          "optional": true
        },
        "redis": {
          "optional": true
        },
        "replicate": {
          "optional": true
        },
        "typeorm": {
          "optional": true
        },
        "typesense": {
          "optional": true
        },
        "usearch": {
          "optional": true
        },
        "vectordb": {
          "optional": true
        },
        "voy-search": {
          "optional": true
        },
        "weaviate-ts-client": {
          "optional": true
        },
        "web-auth-library": {
          "optional": true
        },
        "ws": {
          "optional": true
        }
      }
    },
    "node_modules/@langchain/core": {
      "version": "0.1.63",
      "resolved": "https://registry.npmjs.org/@langchain/core/-/core-0.1.63.tgz",
      "integrity": "sha512-+fjyYi8wy6x1P+Ee1RWfIIEyxd9Ee9jksEwvrggPwwI/p45kIDTdYTblXsM13y4mNWTiACyLSdbwnPaxxdoz+w==",
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^5.0.0",
        "camelcase": "6",
        "decamelize": "1.2.0",
        "js-tiktoken": "^1.0.12",
        "langsmith": "~0.1.7",
        "ml-distance": "^4.0.0",
        "mustache": "^4.2.0",
        "p-queue": "^6.6.2",
        "p-retry": "4",
        "uuid": "^9.0.0",
        "zod": "^3.22.4",
        "zod-to-json-schema": "^3.22.3"
      },
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@langchain/core/node_modules/ansi-styles": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-5.2.0.tgz",
      "integrity": "sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==",
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/@langchain/openai": {
      "version": "0.0.34",
      "resolved": "https://registry.npmjs.org/@langchain/openai/-/openai-0.0.34.tgz",
      "integrity": "sha512-M+CW4oXle5fdoz2T2SwdOef8pl3/1XmUx1vjn2mXUVM/128aO0l23FMF0SNBsAbRV6P+p/TuzjodchJbi0Ht/A==",
      "license": "MIT",
      "dependencies": {
        "@langchain/core": ">0.1.56 <0.3.0",
        "js-tiktoken": "^1.0.12",
        "openai": "^4.41.1",
        "zod": "^3.22.4",
        "zod-to-json-schema": "^3.22.3"
      },
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@langchain/textsplitters": {
      "version": "0.0.3",
      "resolved": "https://registry.npmjs.org/@langchain/textsplitters/-/textsplitters-0.0.3.tgz",
      "integrity": "sha512-cXWgKE3sdWLSqAa8ykbCcUsUF1Kyr5J3HOWYGuobhPEycXW4WI++d5DhzdpL238mzoEXTi90VqfSCra37l5YqA==",
      "license": "MIT",
      "dependencies": {
        "@langchain/core": ">0.2.0 <0.3.0",
        "js-tiktoken": "^1.0.12"
      },
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@langchain/textsplitters/node_modules/@langchain/core": {
      "version": "0.2.36",
      "resolved": "https://registry.npmjs.org/@langchain/core/-/core-0.2.36.tgz",
      "integrity": "sha512-qHLvScqERDeH7y2cLuJaSAlMwg3f/3Oc9nayRSXRU2UuaK/SOhI42cxiPLj1FnuHJSmN0rBQFkrLx02gI4mcVg==",
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^5.0.0",
        "camelcase": "6",
        "decamelize": "1.2.0",
        "js-tiktoken": "^1.0.12",
        "langsmith": "^0.1.56-rc.1",
        "mustache": "^4.2.0",
        "p-queue": "^6.6.2",
        "p-retry": "4",
        "uuid": "^10.0.0",
        "zod": "^3.22.4",
        "zod-to-json-schema": "^3.22.3"
      },
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@langchain/textsplitters/node_modules/ansi-styles": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-5.2.0.tgz",
      "integrity": "sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==",
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/@langchain/textsplitters/node_modules/uuid": {
      "version": "10.0.0",
      "resolved": "https://registry.npmjs.org/uuid/-/uuid-10.0.0.tgz",
      "integrity": "sha512-8XkAphELsDnEGrDxUOHB3RGvXz6TeuYSGEZBOjtTtPm2lwhGBjLgOzLHB63IUWfBpNucQjND6d3AOudO+H3RWQ==",
      "funding": [
        "https://github.com/sponsors/broofa",
        "https://github.com/sponsors/ctavan"
      ],
      "license": "MIT",
      "bin": {
        "uuid": "dist/bin/uuid"
      }
    },
    "node_modules/@napi-rs/canvas": {
      "version": "0.1.68",
      "resolved": "https://registry.npmjs.org/@napi-rs/canvas/-/canvas-0.1.68.tgz",
      "integrity": "sha512-LQESrePLEBLvhuFkXx9jjBXRC2ClYsO5mqQ1m/puth5z9SOuM3N/B3vDuqnC3RJFktDktyK9khGvo7dTkqO9uQ==",
      "license": "MIT",
      "optional": true,
      "engines": {
        "node": ">= 10"
      },
      "optionalDependencies": {
        "@napi-rs/canvas-android-arm64": "0.1.68",
        "@napi-rs/canvas-darwin-arm64": "0.1.68",
        "@napi-rs/canvas-darwin-x64": "0.1.68",
        "@napi-rs/canvas-linux-arm-gnueabihf": "0.1.68",
        "@napi-rs/canvas-linux-arm64-gnu": "0.1.68",
        "@napi-rs/canvas-linux-arm64-musl": "0.1.68",
        "@napi-rs/canvas-linux-riscv64-gnu": "0.1.68",
        "@napi-rs/canvas-linux-x64-gnu": "0.1.68",
        "@napi-rs/canvas-linux-x64-musl": "0.1.68",
        "@napi-rs/canvas-win32-x64-msvc": "0.1.68"
      }
    },
    "node_modules/@napi-rs/canvas-android-arm64": {
      "version": "0.1.68",
      "resolved": "https://registry.npmjs.org/@napi-rs/canvas-android-arm64/-/canvas-android-arm64-0.1.68.tgz",
      "integrity": "sha512-h1KcSR4LKLfRfzeBH65xMxbWOGa1OtMFQbCMVlxPCkN1Zr+2gK+70pXO5ktojIYcUrP6KDcOwoc8clho5ccM/w==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "android"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@napi-rs/canvas-darwin-arm64": {
      "version": "0.1.68",
      "resolved": "https://registry.npmjs.org/@napi-rs/canvas-darwin-arm64/-/canvas-darwin-arm64-0.1.68.tgz",
      "integrity": "sha512-/VURlrAD4gDoxW1GT/b0nP3fRz/fhxmHI/xznTq2FTwkQLPOlLkDLCvTmQ7v6LtGKdc2Ed6rvYpRan+JXThInQ==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@napi-rs/canvas-darwin-x64": {
      "version": "0.1.68",
      "resolved": "https://registry.npmjs.org/@napi-rs/canvas-darwin-x64/-/canvas-darwin-x64-0.1.68.tgz",
      "integrity": "sha512-tEpvGR6vCLTo1Tx9wmDnoOKROpw57wiCWwCpDOuVlj/7rqEJOUYr9ixW4aRJgmeGBrZHgevI0EURys2ER6whmg==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@napi-rs/canvas-linux-arm-gnueabihf": {
      "version": "0.1.68",
      "resolved": "https://registry.npmjs.org/@napi-rs/canvas-linux-arm-gnueabihf/-/canvas-linux-arm-gnueabihf-0.1.68.tgz",
      "integrity": "sha512-U9xbJsumPOiAYeAFZMlHf62b9dGs2HJ6Q5xt7xTB0uEyPeurwhgYBWGgabdsEidyj38YuzI/c3LGBbSQB3vagw==",
      "cpu": [
        "arm"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@napi-rs/canvas-linux-arm64-gnu": {
      "version": "0.1.68",
      "resolved": "https://registry.npmjs.org/@napi-rs/canvas-linux-arm64-gnu/-/canvas-linux-arm64-gnu-0.1.68.tgz",
      "integrity": "sha512-KFkn8wEm3mPnWD4l8+OUUkxylSJuN5q9PnJRZJgv15RtCA1bgxIwTkBhI/+xuyVMcHqON9sXq7cDkEJtHm35dg==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@napi-rs/canvas-linux-arm64-musl": {
      "version": "0.1.68",
      "resolved": "https://registry.npmjs.org/@napi-rs/canvas-linux-arm64-musl/-/canvas-linux-arm64-musl-0.1.68.tgz",
      "integrity": "sha512-IQzts91rCdOALXBWQxLZRCEDrfFTGDtNRJMNu+2SKZ1uT8cmPQkPwVk5rycvFpvgAcmiFiOSCp1aRrlfU8KPpQ==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@napi-rs/canvas-linux-riscv64-gnu": {
      "version": "0.1.68",
      "resolved": "https://registry.npmjs.org/@napi-rs/canvas-linux-riscv64-gnu/-/canvas-linux-riscv64-gnu-0.1.68.tgz",
      "integrity": "sha512-e9AS5UttoIKqXSmBzKZdd3NErSVyOEYzJfNOCGtafGk1//gibTwQXGlSXmAKuErqMp09pyk9aqQRSYzm1AQfBw==",
      "cpu": [
        "riscv64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@napi-rs/canvas-linux-x64-gnu": {
      "version": "0.1.68",
      "resolved": "https://registry.npmjs.org/@napi-rs/canvas-linux-x64-gnu/-/canvas-linux-x64-gnu-0.1.68.tgz",
      "integrity": "sha512-Pa/I36VE3j57I3Obhrr+J48KGFfkZk2cJN/2NmW/vCgmoF7kCP6aTVq5n+cGdGWLd/cN9CJ9JvNwEoMRDghu0g==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@napi-rs/canvas-linux-x64-musl": {
      "version": "0.1.68",
      "resolved": "https://registry.npmjs.org/@napi-rs/canvas-linux-x64-musl/-/canvas-linux-x64-musl-0.1.68.tgz",
      "integrity": "sha512-9c6rkc5195wNxuUHJdf4/mmnq433OQey9TNvQ9LspJazvHbfSkTij8wtKjASVQsJyPDva4fkWOeV/OQ7cLw0GQ==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@napi-rs/canvas-win32-x64-msvc": {
      "version": "0.1.68",
      "resolved": "https://registry.npmjs.org/@napi-rs/canvas-win32-x64-msvc/-/canvas-win32-x64-msvc-0.1.68.tgz",
      "integrity": "sha512-Fc5Dez23u0FoSATurT6/w1oMytiRnKWEinHivdMvXpge6nG4YvhrASrtqMk8dGJMVQpHr8QJYF45rOrx2YU2Aw==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/env": {
      "version": "14.2.4",
      "resolved": "https://registry.npmjs.org/@next/env/-/env-14.2.4.tgz",
      "integrity": "sha512-3EtkY5VDkuV2+lNmKlbkibIJxcO4oIHEhBWne6PaAp+76J9KoSsGvNikp6ivzAT8dhhBMYrm6op2pS1ApG0Hzg==",
      "license": "MIT"
    },
    "node_modules/@next/eslint-plugin-next": {
      "version": "14.2.4",
      "resolved": "https://registry.npmjs.org/@next/eslint-plugin-next/-/eslint-plugin-next-14.2.4.tgz",
      "integrity": "sha512-svSFxW9f3xDaZA3idQmlFw7SusOuWTpDTAeBlO3AEPDltrraV+lqs7mAc6A27YdnpQVVIA3sODqUAAHdWhVWsA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "glob": "10.3.10"
      }
    },
    "node_modules/@next/swc-darwin-arm64": {
      "version": "14.2.4",
      "resolved": "https://registry.npmjs.org/@next/swc-darwin-arm64/-/swc-darwin-arm64-14.2.4.tgz",
      "integrity": "sha512-AH3mO4JlFUqsYcwFUHb1wAKlebHU/Hv2u2kb1pAuRanDZ7pD/A/KPD98RHZmwsJpdHQwfEc/06mgpSzwrJYnNg==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-darwin-x64": {
      "version": "14.2.4",
      "resolved": "https://registry.npmjs.org/@next/swc-darwin-x64/-/swc-darwin-x64-14.2.4.tgz",
      "integrity": "sha512-QVadW73sWIO6E2VroyUjuAxhWLZWEpiFqHdZdoQ/AMpN9YWGuHV8t2rChr0ahy+irKX5mlDU7OY68k3n4tAZTg==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-arm64-gnu": {
      "version": "14.2.4",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-arm64-gnu/-/swc-linux-arm64-gnu-14.2.4.tgz",
      "integrity": "sha512-KT6GUrb3oyCfcfJ+WliXuJnD6pCpZiosx2X3k66HLR+DMoilRb76LpWPGb4tZprawTtcnyrv75ElD6VncVamUQ==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-arm64-musl": {
      "version": "14.2.4",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-arm64-musl/-/swc-linux-arm64-musl-14.2.4.tgz",
      "integrity": "sha512-Alv8/XGSs/ytwQcbCHwze1HmiIkIVhDHYLjczSVrf0Wi2MvKn/blt7+S6FJitj3yTlMwMxII1gIJ9WepI4aZ/A==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-x64-gnu": {
      "version": "14.2.4",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-x64-gnu/-/swc-linux-x64-gnu-14.2.4.tgz",
      "integrity": "sha512-ze0ShQDBPCqxLImzw4sCdfnB3lRmN3qGMB2GWDRlq5Wqy4G36pxtNOo2usu/Nm9+V2Rh/QQnrRc2l94kYFXO6Q==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-linux-x64-musl": {
      "version": "14.2.4",
      "resolved": "https://registry.npmjs.org/@next/swc-linux-x64-musl/-/swc-linux-x64-musl-14.2.4.tgz",
      "integrity": "sha512-8dwC0UJoc6fC7PX70csdaznVMNr16hQrTDAMPvLPloazlcaWfdPogq+UpZX6Drqb1OBlwowz8iG7WR0Tzk/diQ==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "linux"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-win32-arm64-msvc": {
      "version": "14.2.4",
      "resolved": "https://registry.npmjs.org/@next/swc-win32-arm64-msvc/-/swc-win32-arm64-msvc-14.2.4.tgz",
      "integrity": "sha512-jxyg67NbEWkDyvM+O8UDbPAyYRZqGLQDTPwvrBBeOSyVWW/jFQkQKQ70JDqDSYg1ZDdl+E3nkbFbq8xM8E9x8A==",
      "cpu": [
        "arm64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-win32-ia32-msvc": {
      "version": "14.2.4",
      "resolved": "https://registry.npmjs.org/@next/swc-win32-ia32-msvc/-/swc-win32-ia32-msvc-14.2.4.tgz",
      "integrity": "sha512-twrmN753hjXRdcrZmZttb/m5xaCBFa48Dt3FbeEItpJArxriYDunWxJn+QFXdJ3hPkm4u7CKxncVvnmgQMY1ag==",
      "cpu": [
        "ia32"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@next/swc-win32-x64-msvc": {
      "version": "14.2.4",
      "resolved": "https://registry.npmjs.org/@next/swc-win32-x64-msvc/-/swc-win32-x64-msvc-14.2.4.tgz",
      "integrity": "sha512-tkLrjBzqFTP8DVrAAQmZelEahfR9OxWpFR++vAI9FBhCiIxtwHwBHC23SBHCTURBtwB4kc/x44imVOnkKGNVGg==",
      "cpu": [
        "x64"
      ],
      "license": "MIT",
      "optional": true,
      "os": [
        "win32"
      ],
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@nodelib/fs.scandir": {
      "version": "2.1.5",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.scandir/-/fs.scandir-2.1.5.tgz",
      "integrity": "sha512-vq24Bq3ym5HEQm2NKCr3yXDwjc7vTsEThRDnkp2DK9p1uqLR+DHurm/NOTo0KG7HYHU7eppKZj3MyqYuMBf62g==",
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.stat": "2.0.5",
        "run-parallel": "^1.1.9"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nodelib/fs.stat": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.stat/-/fs.stat-2.0.5.tgz",
      "integrity": "sha512-RkhPPp2zrqDAQA/2jNhnztcPAlv64XdhIp7a7454A5ovI7Bukxgt7MX7udwAu3zg1DcpPU0rz3VV1SeaqvY4+A==",
      "license": "MIT",
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nodelib/fs.walk": {
      "version": "1.2.8",
      "resolved": "https://registry.npmjs.org/@nodelib/fs.walk/-/fs.walk-1.2.8.tgz",
      "integrity": "sha512-oGB+UxlgWcgQkgwo8GcEGwemoTFt3FIO9ababBmaGwXIoBKZ+GTy0pP185beGg7Llih/NSHSV2XAs1lnznocSg==",
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.scandir": "2.1.5",
        "fastq": "^1.6.0"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/@nolyfill/is-core-module": {
      "version": "1.0.39",
      "resolved": "https://registry.npmjs.org/@nolyfill/is-core-module/-/is-core-module-1.0.39.tgz",
      "integrity": "sha512-nn5ozdjYQpUCZlWGuxcJY/KpxkWQs4DcbMCmKojjyrYDEAGy4Ce19NN4v5MduafTwJlbKc99UA8YhSVqq9yPZA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12.4.0"
      }
    },
    "node_modules/@pkgjs/parseargs": {
      "version": "0.11.0",
      "resolved": "https://registry.npmjs.org/@pkgjs/parseargs/-/parseargs-0.11.0.tgz",
      "integrity": "sha512-+1VkjdD0QBLPodGrJUeqarH8VAIvQODIbwh9XpP5Syisf7YoQgsJKPNFoqqLQlu+VQ/tVSshMR6loPMn8U+dPg==",
      "license": "MIT",
      "optional": true,
      "engines": {
        "node": ">=14"
      }
    },
    "node_modules/@radix-ui/number": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@radix-ui/number/-/number-1.1.0.tgz",
      "integrity": "sha512-V3gRzhVNU1ldS5XhAPTom1fOIo4ccrjjJgmE+LI2h/WaFpHmx0MQApT+KZHnx8abG6Avtfcz4WoEciMnpFT3HQ==",
      "license": "MIT"
    },
    "node_modules/@radix-ui/primitive": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/primitive/-/primitive-1.1.1.tgz",
      "integrity": "sha512-SJ31y+Q/zAyShtXJc8x83i9TYdbAfHZ++tUZnvjJJqFjzsdUnKsxPL6IEtBlxKkU7yzer//GQtZSV4GbldL3YA==",
      "license": "MIT"
    },
    "node_modules/@radix-ui/react-arrow": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-arrow/-/react-arrow-1.1.2.tgz",
      "integrity": "sha512-G+KcpzXHq24iH0uGG/pF8LyzpFJYGD4RfLjCIBfGdSLXvjLHST31RUiRVrupIBMvIppMgSzQ6l66iAxl03tdlg==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-primitive": "2.0.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-avatar": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-avatar/-/react-avatar-1.1.3.tgz",
      "integrity": "sha512-Paen00T4P8L8gd9bNsRMw7Cbaz85oxiv+hzomsRZgFm2byltPFDtfcoqlWJ8GyZlIBWgLssJlzLCnKU0G0302g==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-context": "1.1.1",
        "@radix-ui/react-primitive": "2.0.2",
        "@radix-ui/react-use-callback-ref": "1.1.0",
        "@radix-ui/react-use-layout-effect": "1.1.0"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-collapsible": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-collapsible/-/react-collapsible-1.1.3.tgz",
      "integrity": "sha512-jFSerheto1X03MUC0g6R7LedNW9EEGWdg9W1+MlpkMLwGkgkbUXLPBH/KIuWKXUoeYRVY11llqbTBDzuLg7qrw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.1",
        "@radix-ui/react-compose-refs": "1.1.1",
        "@radix-ui/react-context": "1.1.1",
        "@radix-ui/react-id": "1.1.0",
        "@radix-ui/react-presence": "1.1.2",
        "@radix-ui/react-primitive": "2.0.2",
        "@radix-ui/react-use-controllable-state": "1.1.0",
        "@radix-ui/react-use-layout-effect": "1.1.0"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-collection": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-collection/-/react-collection-1.1.2.tgz",
      "integrity": "sha512-9z54IEKRxIa9VityapoEYMuByaG42iSy1ZXlY2KcuLSEtq8x4987/N6m15ppoMffgZX72gER2uHe1D9Y6Unlcw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-compose-refs": "1.1.1",
        "@radix-ui/react-context": "1.1.1",
        "@radix-ui/react-primitive": "2.0.2",
        "@radix-ui/react-slot": "1.1.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-compose-refs": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-compose-refs/-/react-compose-refs-1.1.1.tgz",
      "integrity": "sha512-Y9VzoRDSJtgFMUCoiZBDVo084VQ5hfpXxVE+NgkdNsjiDBByiImMZKKhxMwCbdHvhlENG6a833CbFkOQvTricw==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-context": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-context/-/react-context-1.1.1.tgz",
      "integrity": "sha512-UASk9zi+crv9WteK/NU4PLvOoL3OuE6BWVKNF6hPRBtYBDXQ2u5iu3O59zUlJiTVvkyuycnqrztsHVJwcK9K+Q==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-dialog": {
      "version": "1.1.6",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-dialog/-/react-dialog-1.1.6.tgz",
      "integrity": "sha512-/IVhJV5AceX620DUJ4uYVMymzsipdKBzo3edo+omeskCKGm9FRHM0ebIdbPnlQVJqyuHbuBltQUOG2mOTq2IYw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.1",
        "@radix-ui/react-compose-refs": "1.1.1",
        "@radix-ui/react-context": "1.1.1",
        "@radix-ui/react-dismissable-layer": "1.1.5",
        "@radix-ui/react-focus-guards": "1.1.1",
        "@radix-ui/react-focus-scope": "1.1.2",
        "@radix-ui/react-id": "1.1.0",
        "@radix-ui/react-portal": "1.1.4",
        "@radix-ui/react-presence": "1.1.2",
        "@radix-ui/react-primitive": "2.0.2",
        "@radix-ui/react-slot": "1.1.2",
        "@radix-ui/react-use-controllable-state": "1.1.0",
        "aria-hidden": "^1.2.4",
        "react-remove-scroll": "^2.6.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-direction": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-direction/-/react-direction-1.1.0.tgz",
      "integrity": "sha512-BUuBvgThEiAXh2DWu93XsT+a3aWrGqolGlqqw5VU1kG7p/ZH2cuDlM1sRLNnY3QcBS69UIz2mcKhMxDsdewhjg==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-dismissable-layer": {
      "version": "1.1.5",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-dismissable-layer/-/react-dismissable-layer-1.1.5.tgz",
      "integrity": "sha512-E4TywXY6UsXNRhFrECa5HAvE5/4BFcGyfTyK36gP+pAW1ed7UTK4vKwdr53gAJYwqbfCWC6ATvJa3J3R/9+Qrg==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.1",
        "@radix-ui/react-compose-refs": "1.1.1",
        "@radix-ui/react-primitive": "2.0.2",
        "@radix-ui/react-use-callback-ref": "1.1.0",
        "@radix-ui/react-use-escape-keydown": "1.1.0"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-dropdown-menu": {
      "version": "2.1.6",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-dropdown-menu/-/react-dropdown-menu-2.1.6.tgz",
      "integrity": "sha512-no3X7V5fD487wab/ZYSHXq3H37u4NVeLDKI/Ks724X/eEFSSEFYZxWgsIlr1UBeEyDaM29HM5x9p1Nv8DuTYPA==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.1",
        "@radix-ui/react-compose-refs": "1.1.1",
        "@radix-ui/react-context": "1.1.1",
        "@radix-ui/react-id": "1.1.0",
        "@radix-ui/react-menu": "2.1.6",
        "@radix-ui/react-primitive": "2.0.2",
        "@radix-ui/react-use-controllable-state": "1.1.0"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-focus-guards": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-focus-guards/-/react-focus-guards-1.1.1.tgz",
      "integrity": "sha512-pSIwfrT1a6sIoDASCSpFwOasEwKTZWDw/iBdtnqKO7v6FeOzYJ7U53cPzYFVR3geGGXgVHaH+CdngrrAzqUGxg==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-focus-scope": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-focus-scope/-/react-focus-scope-1.1.2.tgz",
      "integrity": "sha512-zxwE80FCU7lcXUGWkdt6XpTTCKPitG1XKOwViTxHVKIJhZl9MvIl2dVHeZENCWD9+EdWv05wlaEkRXUykU27RA==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-compose-refs": "1.1.1",
        "@radix-ui/react-primitive": "2.0.2",
        "@radix-ui/react-use-callback-ref": "1.1.0"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-id": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-id/-/react-id-1.1.0.tgz",
      "integrity": "sha512-EJUrI8yYh7WOjNOqpoJaf1jlFIH2LvtgAl+YcFqNCa+4hj64ZXmPkAKOFs/ukjz3byN6bdb/AVUqHkI8/uWWMA==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-use-layout-effect": "1.1.0"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-menu": {
      "version": "2.1.6",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-menu/-/react-menu-2.1.6.tgz",
      "integrity": "sha512-tBBb5CXDJW3t2mo9WlO7r6GTmWV0F0uzHZVFmlRmYpiSK1CDU5IKojP1pm7oknpBOrFZx/YgBRW9oorPO2S/Lg==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.1",
        "@radix-ui/react-collection": "1.1.2",
        "@radix-ui/react-compose-refs": "1.1.1",
        "@radix-ui/react-context": "1.1.1",
        "@radix-ui/react-direction": "1.1.0",
        "@radix-ui/react-dismissable-layer": "1.1.5",
        "@radix-ui/react-focus-guards": "1.1.1",
        "@radix-ui/react-focus-scope": "1.1.2",
        "@radix-ui/react-id": "1.1.0",
        "@radix-ui/react-popper": "1.2.2",
        "@radix-ui/react-portal": "1.1.4",
        "@radix-ui/react-presence": "1.1.2",
        "@radix-ui/react-primitive": "2.0.2",
        "@radix-ui/react-roving-focus": "1.1.2",
        "@radix-ui/react-slot": "1.1.2",
        "@radix-ui/react-use-callback-ref": "1.1.0",
        "aria-hidden": "^1.2.4",
        "react-remove-scroll": "^2.6.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-popover": {
      "version": "1.1.6",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-popover/-/react-popover-1.1.6.tgz",
      "integrity": "sha512-NQouW0x4/GnkFJ/pRqsIS3rM/k97VzKnVb2jB7Gq7VEGPy5g7uNV1ykySFt7eWSp3i2uSGFwaJcvIRJBAHmmFg==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.1",
        "@radix-ui/react-compose-refs": "1.1.1",
        "@radix-ui/react-context": "1.1.1",
        "@radix-ui/react-dismissable-layer": "1.1.5",
        "@radix-ui/react-focus-guards": "1.1.1",
        "@radix-ui/react-focus-scope": "1.1.2",
        "@radix-ui/react-id": "1.1.0",
        "@radix-ui/react-popper": "1.2.2",
        "@radix-ui/react-portal": "1.1.4",
        "@radix-ui/react-presence": "1.1.2",
        "@radix-ui/react-primitive": "2.0.2",
        "@radix-ui/react-slot": "1.1.2",
        "@radix-ui/react-use-controllable-state": "1.1.0",
        "aria-hidden": "^1.2.4",
        "react-remove-scroll": "^2.6.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-popper": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-popper/-/react-popper-1.2.2.tgz",
      "integrity": "sha512-Rvqc3nOpwseCyj/rgjlJDYAgyfw7OC1tTkKn2ivhaMGcYt8FSBlahHOZak2i3QwkRXUXgGgzeEe2RuqeEHuHgA==",
      "license": "MIT",
      "dependencies": {
        "@floating-ui/react-dom": "^2.0.0",
        "@radix-ui/react-arrow": "1.1.2",
        "@radix-ui/react-compose-refs": "1.1.1",
        "@radix-ui/react-context": "1.1.1",
        "@radix-ui/react-primitive": "2.0.2",
        "@radix-ui/react-use-callback-ref": "1.1.0",
        "@radix-ui/react-use-layout-effect": "1.1.0",
        "@radix-ui/react-use-rect": "1.1.0",
        "@radix-ui/react-use-size": "1.1.0",
        "@radix-ui/rect": "1.1.0"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-portal": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-portal/-/react-portal-1.1.4.tgz",
      "integrity": "sha512-sn2O9k1rPFYVyKd5LAJfo96JlSGVFpa1fS6UuBJfrZadudiw5tAmru+n1x7aMRQ84qDM71Zh1+SzK5QwU0tJfA==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-primitive": "2.0.2",
        "@radix-ui/react-use-layout-effect": "1.1.0"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-presence": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-presence/-/react-presence-1.1.2.tgz",
      "integrity": "sha512-18TFr80t5EVgL9x1SwF/YGtfG+l0BS0PRAlCWBDoBEiDQjeKgnNZRVJp/oVBl24sr3Gbfwc/Qpj4OcWTQMsAEg==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-compose-refs": "1.1.1",
        "@radix-ui/react-use-layout-effect": "1.1.0"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-primitive": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-primitive/-/react-primitive-2.0.2.tgz",
      "integrity": "sha512-Ec/0d38EIuvDF+GZjcMU/Ze6MxntVJYO/fRlCPhCaVUyPY9WTalHJw54tp9sXeJo3tlShWpy41vQRgLRGOuz+w==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-slot": "1.1.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-roving-focus": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-roving-focus/-/react-roving-focus-1.1.2.tgz",
      "integrity": "sha512-zgMQWkNO169GtGqRvYrzb0Zf8NhMHS2DuEB/TiEmVnpr5OqPU3i8lfbxaAmC2J/KYuIQxyoQQ6DxepyXp61/xw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.1",
        "@radix-ui/react-collection": "1.1.2",
        "@radix-ui/react-compose-refs": "1.1.1",
        "@radix-ui/react-context": "1.1.1",
        "@radix-ui/react-direction": "1.1.0",
        "@radix-ui/react-id": "1.1.0",
        "@radix-ui/react-primitive": "2.0.2",
        "@radix-ui/react-use-callback-ref": "1.1.0",
        "@radix-ui/react-use-controllable-state": "1.1.0"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-select": {
      "version": "2.1.6",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-select/-/react-select-2.1.6.tgz",
      "integrity": "sha512-T6ajELxRvTuAMWH0YmRJ1qez+x4/7Nq7QIx7zJ0VK3qaEWdnWpNbEDnmWldG1zBDwqrLy5aLMUWcoGirVj5kMg==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/number": "1.1.0",
        "@radix-ui/primitive": "1.1.1",
        "@radix-ui/react-collection": "1.1.2",
        "@radix-ui/react-compose-refs": "1.1.1",
        "@radix-ui/react-context": "1.1.1",
        "@radix-ui/react-direction": "1.1.0",
        "@radix-ui/react-dismissable-layer": "1.1.5",
        "@radix-ui/react-focus-guards": "1.1.1",
        "@radix-ui/react-focus-scope": "1.1.2",
        "@radix-ui/react-id": "1.1.0",
        "@radix-ui/react-popper": "1.2.2",
        "@radix-ui/react-portal": "1.1.4",
        "@radix-ui/react-primitive": "2.0.2",
        "@radix-ui/react-slot": "1.1.2",
        "@radix-ui/react-use-callback-ref": "1.1.0",
        "@radix-ui/react-use-controllable-state": "1.1.0",
        "@radix-ui/react-use-layout-effect": "1.1.0",
        "@radix-ui/react-use-previous": "1.1.0",
        "@radix-ui/react-visually-hidden": "1.1.2",
        "aria-hidden": "^1.2.4",
        "react-remove-scroll": "^2.6.3"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-slot": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-slot/-/react-slot-1.1.2.tgz",
      "integrity": "sha512-YAKxaiGsSQJ38VzKH86/BPRC4rh+b1Jpa+JneA5LRE7skmLPNAyeG8kPJj/oo4STLvlrs8vkf/iYyc3A5stYCQ==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-compose-refs": "1.1.1"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-tabs": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-tabs/-/react-tabs-1.1.3.tgz",
      "integrity": "sha512-9mFyI30cuRDImbmFF6O2KUJdgEOsGh9Vmx9x/Dh9tOhL7BngmQPQfwW4aejKm5OHpfWIdmeV6ySyuxoOGjtNng==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.1",
        "@radix-ui/react-context": "1.1.1",
        "@radix-ui/react-direction": "1.1.0",
        "@radix-ui/react-id": "1.1.0",
        "@radix-ui/react-presence": "1.1.2",
        "@radix-ui/react-primitive": "2.0.2",
        "@radix-ui/react-roving-focus": "1.1.2",
        "@radix-ui/react-use-controllable-state": "1.1.0"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-toast": {
      "version": "1.2.6",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-toast/-/react-toast-1.2.6.tgz",
      "integrity": "sha512-gN4dpuIVKEgpLn1z5FhzT9mYRUitbfZq9XqN/7kkBMUgFTzTG8x/KszWJugJXHcwxckY8xcKDZPz7kG3o6DsUA==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/primitive": "1.1.1",
        "@radix-ui/react-collection": "1.1.2",
        "@radix-ui/react-compose-refs": "1.1.1",
        "@radix-ui/react-context": "1.1.1",
        "@radix-ui/react-dismissable-layer": "1.1.5",
        "@radix-ui/react-portal": "1.1.4",
        "@radix-ui/react-presence": "1.1.2",
        "@radix-ui/react-primitive": "2.0.2",
        "@radix-ui/react-use-callback-ref": "1.1.0",
        "@radix-ui/react-use-controllable-state": "1.1.0",
        "@radix-ui/react-use-layout-effect": "1.1.0",
        "@radix-ui/react-visually-hidden": "1.1.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-callback-ref": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-callback-ref/-/react-use-callback-ref-1.1.0.tgz",
      "integrity": "sha512-CasTfvsy+frcFkbXtSJ2Zu9JHpN8TYKxkgJGWbjiZhFivxaeW7rMeZt7QELGVLaYVfFMsKHjb7Ak0nMEe+2Vfw==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-controllable-state": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-controllable-state/-/react-use-controllable-state-1.1.0.tgz",
      "integrity": "sha512-MtfMVJiSr2NjzS0Aa90NPTnvTSg6C/JLCV7ma0W6+OMV78vd8OyRpID+Ng9LxzsPbLeuBnWBA1Nq30AtBIDChw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-use-callback-ref": "1.1.0"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-escape-keydown": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-escape-keydown/-/react-use-escape-keydown-1.1.0.tgz",
      "integrity": "sha512-L7vwWlR1kTTQ3oh7g1O0CBF3YCyyTj8NmhLR+phShpyA50HCfBFKVJTpshm9PzLiKmehsrQzTYTpX9HvmC9rhw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-use-callback-ref": "1.1.0"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-layout-effect": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-layout-effect/-/react-use-layout-effect-1.1.0.tgz",
      "integrity": "sha512-+FPE0rOdziWSrH9athwI1R0HDVbWlEhd+FR+aSDk4uWGmSJ9Z54sdZVDQPZAinJhJXwfT+qnj969mCsT2gfm5w==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-previous": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-previous/-/react-use-previous-1.1.0.tgz",
      "integrity": "sha512-Z/e78qg2YFnnXcW88A4JmTtm4ADckLno6F7OXotmkQfeuCVaKuYzqAATPhVzl3delXE7CxIV8shofPn3jPc5Og==",
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-rect": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-rect/-/react-use-rect-1.1.0.tgz",
      "integrity": "sha512-0Fmkebhr6PiseyZlYAOtLS+nb7jLmpqTrJyv61Pe68MKYW6OWdRE2kI70TaYY27u7H0lajqM3hSMMLFq18Z7nQ==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/rect": "1.1.0"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-use-size": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-use-size/-/react-use-size-1.1.0.tgz",
      "integrity": "sha512-XW3/vWuIXHa+2Uwcc2ABSfcCledmXhhQPlGbfcRXbiUQI5Icjcg19BGCZVKKInYbvUCut/ufbbLLPFC5cbb1hw==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-use-layout-effect": "1.1.0"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/react-visually-hidden": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/@radix-ui/react-visually-hidden/-/react-visually-hidden-1.1.2.tgz",
      "integrity": "sha512-1SzA4ns2M1aRlvxErqhLHsBHoS5eI5UUcI2awAMgGUp4LoaoWOKYmvqDY2s/tltuPkh3Yk77YF/r3IRj+Amx4Q==",
      "license": "MIT",
      "dependencies": {
        "@radix-ui/react-primitive": "2.0.2"
      },
      "peerDependencies": {
        "@types/react": "*",
        "@types/react-dom": "*",
        "react": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc",
        "react-dom": "^16.8 || ^17.0 || ^18.0 || ^19.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@radix-ui/rect": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@radix-ui/rect/-/rect-1.1.0.tgz",
      "integrity": "sha512-A9+lCBZoaMJlVKcRBz2YByCG+Cp2t6nAnMnNba+XiWxnj6r4JUFqfsgwocMBZU9LPtdxC6wB56ySYpc7LQIoJg==",
      "license": "MIT"
    },
    "node_modules/@rtsao/scc": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/@rtsao/scc/-/scc-1.1.0.tgz",
      "integrity": "sha512-zt6OdqaDoOnJ1ZYsCYGt9YmWzDXl4vQdKTyJev62gFhRGKdx7mcT54V9KIjg+d2wi9EXsPvAPKe7i7WjfVWB8g==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@rushstack/eslint-patch": {
      "version": "1.11.0",
      "resolved": "https://registry.npmjs.org/@rushstack/eslint-patch/-/eslint-patch-1.11.0.tgz",
      "integrity": "sha512-zxnHvoMQVqewTJr/W4pKjF0bMGiKJv1WX7bSrkl46Hg0QjESbzBROWK0Wg4RphzSOS5Jiy7eFimmM3UgMrMZbQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@sinclair/typebox": {
      "version": "0.27.8",
      "resolved": "https://registry.npmjs.org/@sinclair/typebox/-/typebox-0.27.8.tgz",
      "integrity": "sha512-+Fj43pSMwJs4KRrH/938Uf+uAELIgVBmQzg/q1YG10djyfA3TnrU8N8XzqCh/okZdszqBQTZf96idMfE5lnwTA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@sinonjs/commons": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/@sinonjs/commons/-/commons-3.0.1.tgz",
      "integrity": "sha512-K3mCHKQ9sVh8o1C9cxkwxaOmXoAMlDxC1mYyHrjqOWEcBjYr76t96zL2zlj5dUGZ3HSw240X1qgH3Mjf1yJWpQ==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "type-detect": "4.0.8"
      }
    },
    "node_modules/@sinonjs/fake-timers": {
      "version": "10.3.0",
      "resolved": "https://registry.npmjs.org/@sinonjs/fake-timers/-/fake-timers-10.3.0.tgz",
      "integrity": "sha512-V4BG07kuYSUkTCSBHG8G8TNhM+F19jXFWnQtzj+we8DrkpSBCee9Z3Ms8yiGer/dlmhe35/Xdgyo3/0rQKg7YA==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "@sinonjs/commons": "^3.0.0"
      }
    },
    "node_modules/@swc/counter": {
      "version": "0.1.3",
      "resolved": "https://registry.npmjs.org/@swc/counter/-/counter-0.1.3.tgz",
      "integrity": "sha512-e2BR4lsJkkRlKZ/qCHPw9ZaSxc0MVUd7gtbtaB7aMvHeJVYe8sOB8DBZkP2DtISHGSku9sCK6T6cnY0CtXrOCQ==",
      "license": "Apache-2.0"
    },
    "node_modules/@swc/helpers": {
      "version": "0.5.5",
      "resolved": "https://registry.npmjs.org/@swc/helpers/-/helpers-0.5.5.tgz",
      "integrity": "sha512-KGYxvIOXcceOAbEk4bi/dVLEK9z8sZ0uBB3Il5b1rhfClSpcX0yfRO0KmTkqR2cnQDymwLB+25ZyMzICg/cm/A==",
      "license": "Apache-2.0",
      "dependencies": {
        "@swc/counter": "^0.1.3",
        "tslib": "^2.4.0"
      }
    },
    "node_modules/@testing-library/dom": {
      "version": "10.4.0",
      "resolved": "https://registry.npmjs.org/@testing-library/dom/-/dom-10.4.0.tgz",
      "integrity": "sha512-pemlzrSESWbdAloYml3bAJMEfNh1Z7EduzqPKprCH5S341frlpYnUEW0H72dLxa6IsYr+mPno20GiSm+h9dEdQ==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "@babel/code-frame": "^7.10.4",
        "@babel/runtime": "^7.12.5",
        "@types/aria-query": "^5.0.1",
        "aria-query": "5.3.0",
        "chalk": "^4.1.0",
        "dom-accessibility-api": "^0.5.9",
        "lz-string": "^1.5.0",
        "pretty-format": "^27.0.2"
      },
      "engines": {
        "node": ">=18"
      }
    },
    "node_modules/@testing-library/dom/node_modules/aria-query": {
      "version": "5.3.0",
      "resolved": "https://registry.npmjs.org/aria-query/-/aria-query-5.3.0.tgz",
      "integrity": "sha512-b0P0sZPKtyu8HkeRAfCq0IfURZK+SuwMjY1UXGBU27wpAiTwQAIlq56IbIO+ytk/JjS1fMR14ee5WBBfKi5J6A==",
      "dev": true,
      "license": "Apache-2.0",
      "peer": true,
      "dependencies": {
        "dequal": "^2.0.3"
      }
    },
    "node_modules/@testing-library/jest-dom": {
      "version": "6.6.3",
      "resolved": "https://registry.npmjs.org/@testing-library/jest-dom/-/jest-dom-6.6.3.tgz",
      "integrity": "sha512-IteBhl4XqYNkM54f4ejhLRJiZNqcSCoXUOG2CPK7qbD322KjQozM4kHQOfkG2oln9b9HTYqs+Sae8vBATubxxA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@adobe/css-tools": "^4.4.0",
        "aria-query": "^5.0.0",
        "chalk": "^3.0.0",
        "css.escape": "^1.5.1",
        "dom-accessibility-api": "^0.6.3",
        "lodash": "^4.17.21",
        "redent": "^3.0.0"
      },
      "engines": {
        "node": ">=14",
        "npm": ">=6",
        "yarn": ">=1"
      }
    },
    "node_modules/@testing-library/jest-dom/node_modules/chalk": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/chalk/-/chalk-3.0.0.tgz",
      "integrity": "sha512-4D3B6Wf41KOYRFdszmDqMCGq5VV/uMAB273JILmO+3jAlh8X4qDtdtgCR3fxtbLEMzSx22QdhnDcJvu2u1fVwg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.1.0",
        "supports-color": "^7.1.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/@testing-library/jest-dom/node_modules/dom-accessibility-api": {
      "version": "0.6.3",
      "resolved": "https://registry.npmjs.org/dom-accessibility-api/-/dom-accessibility-api-0.6.3.tgz",
      "integrity": "sha512-7ZgogeTnjuHbo+ct10G9Ffp0mif17idi0IyWNVA/wcwcm7NPOD/WEHVP3n7n3MhXqxoIYm8d6MuZohYWIZ4T3w==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@testing-library/react": {
      "version": "16.2.0",
      "resolved": "https://registry.npmjs.org/@testing-library/react/-/react-16.2.0.tgz",
      "integrity": "sha512-2cSskAvA1QNtKc8Y9VJQRv0tm3hLVgxRGDB+KYhIaPQJ1I+RHbhIXcM+zClKXzMes/wshsMVzf4B9vS4IZpqDQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/runtime": "^7.12.5"
      },
      "engines": {
        "node": ">=18"
      },
      "peerDependencies": {
        "@testing-library/dom": "^10.0.0",
        "@types/react": "^18.0.0 || ^19.0.0",
        "@types/react-dom": "^18.0.0 || ^19.0.0",
        "react": "^18.0.0 || ^19.0.0",
        "react-dom": "^18.0.0 || ^19.0.0"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        },
        "@types/react-dom": {
          "optional": true
        }
      }
    },
    "node_modules/@tootallnate/once": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/@tootallnate/once/-/once-2.0.0.tgz",
      "integrity": "sha512-XCuKFP5PS55gnMVu3dty8KPatLqUoy/ZYzDzAGCQ8JNFCkLXzmI7vNHCR+XpbZaMWQK/vQubr7PkYq8g470J/A==",
      "devOptional": true,
      "license": "MIT",
      "engines": {
        "node": ">= 10"
      }
    },
    "node_modules/@types/aria-query": {
      "version": "5.0.4",
      "resolved": "https://registry.npmjs.org/@types/aria-query/-/aria-query-5.0.4.tgz",
      "integrity": "sha512-rfT93uj5s0PRL7EzccGMs3brplhcrghnDoV26NqKhCAS1hVo+WdNsPvE/yb6ilfr5hi2MEk6d5EWJTKdxg8jVw==",
      "dev": true,
      "license": "MIT",
      "peer": true
    },
    "node_modules/@types/babel__core": {
      "version": "7.20.5",
      "resolved": "https://registry.npmjs.org/@types/babel__core/-/babel__core-7.20.5.tgz",
      "integrity": "sha512-qoQprZvz5wQFJwMDqeseRXWv3rqMvhgpbXFfVyWhbx9X47POIA6i/+dXefEmZKoAgOaTdaIgNSMqMIU61yRyzA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/parser": "^7.20.7",
        "@babel/types": "^7.20.7",
        "@types/babel__generator": "*",
        "@types/babel__template": "*",
        "@types/babel__traverse": "*"
      }
    },
    "node_modules/@types/babel__generator": {
      "version": "7.6.8",
      "resolved": "https://registry.npmjs.org/@types/babel__generator/-/babel__generator-7.6.8.tgz",
      "integrity": "sha512-ASsj+tpEDsEiFr1arWrlN6V3mdfjRMZt6LtK/Vp/kreFLnr5QH5+DhvD5nINYZXzwJvXeGq+05iUXcAzVrqWtw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/types": "^7.0.0"
      }
    },
    "node_modules/@types/babel__template": {
      "version": "7.4.4",
      "resolved": "https://registry.npmjs.org/@types/babel__template/-/babel__template-7.4.4.tgz",
      "integrity": "sha512-h/NUaSyG5EyxBIp8YRxo4RMe2/qQgvyowRwVMzhYhBCONbW8PUsg4lkFMrhgZhUe5z3L3MiLDuvyJ/CaPa2A8A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/parser": "^7.1.0",
        "@babel/types": "^7.0.0"
      }
    },
    "node_modules/@types/babel__traverse": {
      "version": "7.20.7",
      "resolved": "https://registry.npmjs.org/@types/babel__traverse/-/babel__traverse-7.20.7.tgz",
      "integrity": "sha512-dkO5fhS7+/oos4ciWxyEyjWe48zmG6wbCheo/G2ZnHx4fs3EU6YC6UM8rk56gAjNJ9P3MTH2jo5jb92/K6wbng==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/types": "^7.20.7"
      }
    },
    "node_modules/@types/d3-array": {
      "version": "3.2.1",
      "resolved": "https://registry.npmjs.org/@types/d3-array/-/d3-array-3.2.1.tgz",
      "integrity": "sha512-Y2Jn2idRrLzUfAKV2LyRImR+y4oa2AntrgID95SHJxuMUrkNXmanDSed71sRNZysveJVt1hLLemQZIady0FpEg==",
      "license": "MIT"
    },
    "node_modules/@types/d3-color": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/@types/d3-color/-/d3-color-3.1.3.tgz",
      "integrity": "sha512-iO90scth9WAbmgv7ogoq57O9YpKmFBbmoEoCHDB2xMBY0+/KVrqAaCDyCE16dUspeOvIxFFRI+0sEtqDqy2b4A==",
      "license": "MIT"
    },
    "node_modules/@types/d3-ease": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/@types/d3-ease/-/d3-ease-3.0.2.tgz",
      "integrity": "sha512-NcV1JjO5oDzoK26oMzbILE6HW7uVXOHLQvHshBUW4UMdZGfiY6v5BeQwh9a9tCzv+CeefZQHJt5SRgK154RtiA==",
      "license": "MIT"
    },
    "node_modules/@types/d3-interpolate": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/@types/d3-interpolate/-/d3-interpolate-3.0.4.tgz",
      "integrity": "sha512-mgLPETlrpVV1YRJIglr4Ez47g7Yxjl1lj7YKsiMCb27VJH9W8NVM6Bb9d8kkpG/uAQS5AmbA48q2IAolKKo1MA==",
      "license": "MIT",
      "dependencies": {
        "@types/d3-color": "*"
      }
    },
    "node_modules/@types/d3-path": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/@types/d3-path/-/d3-path-3.1.1.tgz",
      "integrity": "sha512-VMZBYyQvbGmWyWVea0EHs/BwLgxc+MKi1zLDCONksozI4YJMcTt8ZEuIR4Sb1MMTE8MMW49v0IwI5+b7RmfWlg==",
      "license": "MIT"
    },
    "node_modules/@types/d3-scale": {
      "version": "4.0.9",
      "resolved": "https://registry.npmjs.org/@types/d3-scale/-/d3-scale-4.0.9.tgz",
      "integrity": "sha512-dLmtwB8zkAeO/juAMfnV+sItKjlsw2lKdZVVy6LRr0cBmegxSABiLEpGVmSJJ8O08i4+sGR6qQtb6WtuwJdvVw==",
      "license": "MIT",
      "dependencies": {
        "@types/d3-time": "*"
      }
    },
    "node_modules/@types/d3-shape": {
      "version": "3.1.7",
      "resolved": "https://registry.npmjs.org/@types/d3-shape/-/d3-shape-3.1.7.tgz",
      "integrity": "sha512-VLvUQ33C+3J+8p+Daf+nYSOsjB4GXp19/S/aGo60m9h1v6XaxjiT82lKVWJCfzhtuZ3yD7i/TPeC/fuKLLOSmg==",
      "license": "MIT",
      "dependencies": {
        "@types/d3-path": "*"
      }
    },
    "node_modules/@types/d3-time": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/@types/d3-time/-/d3-time-3.0.4.tgz",
      "integrity": "sha512-yuzZug1nkAAaBlBBikKZTgzCeA+k1uy4ZFwWANOfKw5z5LRhV0gNA7gNkKm7HoK+HRN0wX3EkxGk0fpbWhmB7g==",
      "license": "MIT"
    },
    "node_modules/@types/d3-timer": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/@types/d3-timer/-/d3-timer-3.0.2.tgz",
      "integrity": "sha512-Ps3T8E8dZDam6fUyNiMkekK3XUsaUEik+idO9/YjPtfj2qruF8tFBXS7XhtE4iIXBLxhmLjP3SXpLhVf21I9Lw==",
      "license": "MIT"
    },
    "node_modules/@types/debug": {
      "version": "4.1.12",
      "resolved": "https://registry.npmjs.org/@types/debug/-/debug-4.1.12.tgz",
      "integrity": "sha512-vIChWdVG3LG1SMxEvI/AK+FWJthlrqlTu7fbrlywTkkaONwk/UAGaULXRlf8vkzFBLVm0zkMdCquhL5aOjhXPQ==",
      "license": "MIT",
      "dependencies": {
        "@types/ms": "*"
      }
    },
    "node_modules/@types/estree": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/@types/estree/-/estree-1.0.6.tgz",
      "integrity": "sha512-AYnb1nQyY49te+VRAVgmzfcgjYS91mY5P0TKUDCLEM+gNnA+3T6rWITXRLYCpahpqSQbN5cE+gHpnPyXjHWxcw==",
      "license": "MIT"
    },
    "node_modules/@types/estree-jsx": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/@types/estree-jsx/-/estree-jsx-1.0.5.tgz",
      "integrity": "sha512-52CcUVNFyfb1A2ALocQw/Dd1BQFNmSdkuC3BkZ6iqhdMfQz7JWOFRuJFloOzjk+6WijU56m9oKXFAXc7o3Towg==",
      "license": "MIT",
      "dependencies": {
        "@types/estree": "*"
      }
    },
    "node_modules/@types/graceful-fs": {
      "version": "4.1.9",
      "resolved": "https://registry.npmjs.org/@types/graceful-fs/-/graceful-fs-4.1.9.tgz",
      "integrity": "sha512-olP3sd1qOEe5dXTSaFvQG+02VdRXcdytWLAZsAq1PecU8uqQAhkrnbli7DagjtXKW/Bl7YJbUsa8MPcuc8LHEQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/node": "*"
      }
    },
    "node_modules/@types/hast": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/@types/hast/-/hast-3.0.4.tgz",
      "integrity": "sha512-WPs+bbQw5aCj+x6laNGWLH3wviHtoCv/P3+otBhbOhJgG8qtpdAMlTCxLtsTWA7LH1Oh/bFCHsBn0TPS5m30EQ==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "*"
      }
    },
    "node_modules/@types/istanbul-lib-coverage": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/@types/istanbul-lib-coverage/-/istanbul-lib-coverage-2.0.6.tgz",
      "integrity": "sha512-2QF/t/auWm0lsy8XtKVPG19v3sSOQlJe/YHZgfjb/KBBHOGSV+J2q/S671rcq9uTBrLAXmZpqJiaQbMT+zNU1w==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/istanbul-lib-report": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/@types/istanbul-lib-report/-/istanbul-lib-report-3.0.3.tgz",
      "integrity": "sha512-NQn7AHQnk/RSLOxrBbGyJM/aVQ+pjj5HCgasFxc0K/KhoATfQ/47AyUl15I2yBUpihjmas+a+VJBOqecrFH+uA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/istanbul-lib-coverage": "*"
      }
    },
    "node_modules/@types/istanbul-reports": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/@types/istanbul-reports/-/istanbul-reports-3.0.4.tgz",
      "integrity": "sha512-pk2B1NWalF9toCRu6gjBzR69syFjP4Od8WRAX+0mmf9lAjCRicLOWc+ZrxZHx/0XRjotgkF9t6iaMJ+aXcOdZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/istanbul-lib-report": "*"
      }
    },
    "node_modules/@types/jest": {
      "version": "29.5.14",
      "resolved": "https://registry.npmjs.org/@types/jest/-/jest-29.5.14.tgz",
      "integrity": "sha512-ZN+4sdnLUbo8EVvVc2ao0GFW6oVrQRPn4K2lglySj7APvSrgzxHiNNK99us4WDMi57xxA2yggblIAMNhXOotLQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "expect": "^29.0.0",
        "pretty-format": "^29.0.0"
      }
    },
    "node_modules/@types/jest/node_modules/ansi-styles": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-5.2.0.tgz",
      "integrity": "sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/@types/jest/node_modules/pretty-format": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/pretty-format/-/pretty-format-29.7.0.tgz",
      "integrity": "sha512-Pdlw/oPxN+aXdmM9R00JVC9WVFoCLTKJvDVLgmJ+qAffBMxsV85l/Lu7sNx4zSzPyoL2euImuEwHhOXdEgNFZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/schemas": "^29.6.3",
        "ansi-styles": "^5.0.0",
        "react-is": "^18.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/@types/jest/node_modules/react-is": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-18.3.1.tgz",
      "integrity": "sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/jsdom": {
      "version": "20.0.1",
      "resolved": "https://registry.npmjs.org/@types/jsdom/-/jsdom-20.0.1.tgz",
      "integrity": "sha512-d0r18sZPmMQr1eG35u12FZfhIXNrnsPU/g5wvRKCUf/tOGilKKwYMYGqh33BNR6ba+2gkHw1EUiHoN3mn7E5IQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/node": "*",
        "@types/tough-cookie": "*",
        "parse5": "^7.0.0"
      }
    },
    "node_modules/@types/json5": {
      "version": "0.0.29",
      "resolved": "https://registry.npmjs.org/@types/json5/-/json5-0.0.29.tgz",
      "integrity": "sha512-dRLjCWHYg4oaA77cxO64oO+7JwCwnIzkZPdrrC71jQmQtlhM556pwKo5bUzqvZndkVbeFLIIi+9TC40JNF5hNQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/mdast": {
      "version": "4.0.4",
      "resolved": "https://registry.npmjs.org/@types/mdast/-/mdast-4.0.4.tgz",
      "integrity": "sha512-kGaNbPh1k7AFzgpud/gMdvIm5xuECykRR+JnWKQno9TAXVa6WIVCGTPvYGekIDL4uwCZQSYbUxNBSb1aUo79oA==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "*"
      }
    },
    "node_modules/@types/ms": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/@types/ms/-/ms-2.1.0.tgz",
      "integrity": "sha512-GsCCIZDE/p3i96vtEqx+7dBUGXrc7zeSK3wwPHIaRThS+9OhWIXRqzs4d6k1SVU8g91DrNRWxWUGhp5KXQb2VA==",
      "license": "MIT"
    },
    "node_modules/@types/node": {
      "version": "20.17.24",
      "resolved": "https://registry.npmjs.org/@types/node/-/node-20.17.24.tgz",
      "integrity": "sha512-d7fGCyB96w9BnWQrOsJtpyiSaBcAYYr75bnK6ZRjDbql2cGLj/3GsL5OYmLPNq76l7Gf2q4Rv9J2o6h5CrD9sA==",
      "license": "MIT",
      "dependencies": {
        "undici-types": "~6.19.2"
      }
    },
    "node_modules/@types/node-fetch": {
      "version": "2.6.12",
      "resolved": "https://registry.npmjs.org/@types/node-fetch/-/node-fetch-2.6.12.tgz",
      "integrity": "sha512-8nneRWKCg3rMtF69nLQJnOYUcbafYeFSjqkw3jCRLsqkWFlHaoQrr5mXmofFGOx3DKn7UfmBMyov8ySvLRVldA==",
      "license": "MIT",
      "dependencies": {
        "@types/node": "*",
        "form-data": "^4.0.0"
      }
    },
    "node_modules/@types/prop-types": {
      "version": "15.7.14",
      "resolved": "https://registry.npmjs.org/@types/prop-types/-/prop-types-15.7.14.tgz",
      "integrity": "sha512-gNMvNH49DJ7OJYv+KAKn0Xp45p8PLl6zo2YnvDIbTd4J6MER2BmWN49TG7n9LvkyihINxeKW8+3bfS2yDC9dzQ==",
      "license": "MIT"
    },
    "node_modules/@types/react": {
      "version": "18.3.18",
      "resolved": "https://registry.npmjs.org/@types/react/-/react-18.3.18.tgz",
      "integrity": "sha512-t4yC+vtgnkYjNSKlFx1jkAhH8LgTo2N/7Qvi83kdEaUtMDiwpbLAktKDaAMlRcJ5eSxZkH74eEGt1ky31d7kfQ==",
      "license": "MIT",
      "dependencies": {
        "@types/prop-types": "*",
        "csstype": "^3.0.2"
      }
    },
    "node_modules/@types/react-dom": {
      "version": "18.3.5",
      "resolved": "https://registry.npmjs.org/@types/react-dom/-/react-dom-18.3.5.tgz",
      "integrity": "sha512-P4t6saawp+b/dFrUr2cvkVsfvPguwsxtH6dNIYRllMsefqFzkZk5UIjzyDOv5g1dXIPdG4Sp1yCR4Z6RCUsG/Q==",
      "devOptional": true,
      "license": "MIT",
      "peerDependencies": {
        "@types/react": "^18.0.0"
      }
    },
    "node_modules/@types/retry": {
      "version": "0.12.0",
      "resolved": "https://registry.npmjs.org/@types/retry/-/retry-0.12.0.tgz",
      "integrity": "sha512-wWKOClTTiizcZhXnPY4wikVAwmdYHp8q6DmC+EJUzAMsycb7HB32Kh9RN4+0gExjmPmZSAQjgURXIGATPegAvA==",
      "license": "MIT"
    },
    "node_modules/@types/stack-utils": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/@types/stack-utils/-/stack-utils-2.0.3.tgz",
      "integrity": "sha512-9aEbYZ3TbYMznPdcdr3SmIrLXwC/AKZXQeCf9Pgao5CKb8CyHuEX5jzWPTkvregvhRJHcpRO6BFoGW9ycaOkYw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/tough-cookie": {
      "version": "4.0.5",
      "resolved": "https://registry.npmjs.org/@types/tough-cookie/-/tough-cookie-4.0.5.tgz",
      "integrity": "sha512-/Ad8+nIOV7Rl++6f1BdKxFSMgmoqEoYbHRpPcx3JEfv8VRsQe9Z4mCXeJBzxs7mbHY/XOZZuXlRNfhpVPbs6ZA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/unist": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/@types/unist/-/unist-3.0.3.tgz",
      "integrity": "sha512-ko/gIFJRv177XgZsZcBwnqJN5x/Gien8qNOn0D5bQU/zAzVf9Zt3BlcUiLqhV9y4ARk0GbT3tnUiPNgnTXzc/Q==",
      "license": "MIT"
    },
    "node_modules/@types/uuid": {
      "version": "10.0.0",
      "resolved": "https://registry.npmjs.org/@types/uuid/-/uuid-10.0.0.tgz",
      "integrity": "sha512-7gqG38EyHgyP1S+7+xomFtL+ZNHcKv6DwNaCZmJmo1vgMugyF3TCnXVg4t1uk89mLNwnLtnY3TpOpCOyp1/xHQ==",
      "license": "MIT"
    },
    "node_modules/@types/yargs": {
      "version": "17.0.33",
      "resolved": "https://registry.npmjs.org/@types/yargs/-/yargs-17.0.33.tgz",
      "integrity": "sha512-WpxBCKWPLr4xSsHgz511rFJAM+wS28w2zEO1QDNY5zM/S8ok70NNfztH0xwhqKyaK0OHCbN98LDAZuy1ctxDkA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/yargs-parser": "*"
      }
    },
    "node_modules/@types/yargs-parser": {
      "version": "21.0.3",
      "resolved": "https://registry.npmjs.org/@types/yargs-parser/-/yargs-parser-21.0.3.tgz",
      "integrity": "sha512-I4q9QU9MQv4oEOz4tAHJtNz1cwuLxn2F3xcc2iV5WdqLPpUnj30aUuxt1mAxYTG+oe8CZMV/+6rU4S4gRDzqtQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@typescript-eslint/parser": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/parser/-/parser-7.2.0.tgz",
      "integrity": "sha512-5FKsVcHTk6TafQKQbuIVkXq58Fnbkd2wDL4LB7AURN7RUOu1utVP+G8+6u3ZhEroW3DF6hyo3ZEXxgKgp4KeCg==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "@typescript-eslint/scope-manager": "7.2.0",
        "@typescript-eslint/types": "7.2.0",
        "@typescript-eslint/typescript-estree": "7.2.0",
        "@typescript-eslint/visitor-keys": "7.2.0",
        "debug": "^4.3.4"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependencies": {
        "eslint": "^8.56.0"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/@typescript-eslint/scope-manager": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/scope-manager/-/scope-manager-7.2.0.tgz",
      "integrity": "sha512-Qh976RbQM/fYtjx9hs4XkayYujB/aPwglw2choHmf3zBjB4qOywWSdt9+KLRdHubGcoSwBnXUH2sR3hkyaERRg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/types": "7.2.0",
        "@typescript-eslint/visitor-keys": "7.2.0"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@typescript-eslint/types": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/types/-/types-7.2.0.tgz",
      "integrity": "sha512-XFtUHPI/abFhm4cbCDc5Ykc8npOKBSJePY3a3s+lwumt7XWJuzP5cZcfZ610MIPHjQjNsOLlYK8ASPaNG8UiyA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@typescript-eslint/typescript-estree": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/typescript-estree/-/typescript-estree-7.2.0.tgz",
      "integrity": "sha512-cyxS5WQQCoBwSakpMrvMXuMDEbhOo9bNHHrNcEWis6XHx6KF518tkF1wBvKIn/tpq5ZpUYK7Bdklu8qY0MsFIA==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "@typescript-eslint/types": "7.2.0",
        "@typescript-eslint/visitor-keys": "7.2.0",
        "debug": "^4.3.4",
        "globby": "^11.1.0",
        "is-glob": "^4.0.3",
        "minimatch": "9.0.3",
        "semver": "^7.5.4",
        "ts-api-utils": "^1.0.1"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/@typescript-eslint/typescript-estree/node_modules/brace-expansion": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-2.0.1.tgz",
      "integrity": "sha512-XnAIvQ8eM+kC6aULx6wuQiwVsnzsi9d3WxzV3FpWTGA19F621kwdbsAcFKXgKUHZWsy+mY6iL1sHTxWEFCytDA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0"
      }
    },
    "node_modules/@typescript-eslint/typescript-estree/node_modules/minimatch": {
      "version": "9.0.3",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-9.0.3.tgz",
      "integrity": "sha512-RHiac9mvaRw0x3AYRgDC1CxAP7HTcNrrECeA8YYJeWnpo+2Q5CegtZjaotWTWxDG3UeGA1coE05iH1mPjT/2mg==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^2.0.1"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/@typescript-eslint/visitor-keys": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/@typescript-eslint/visitor-keys/-/visitor-keys-7.2.0.tgz",
      "integrity": "sha512-c6EIQRHhcpl6+tO8EMR+kjkkV+ugUNXOmeASA1rlzkd8EPIriavpWoiEz1HR/VLhbVIdhqnV6E7JZm00cBDx2A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@typescript-eslint/types": "7.2.0",
        "eslint-visitor-keys": "^3.4.1"
      },
      "engines": {
        "node": "^16.0.0 || >=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/typescript-eslint"
      }
    },
    "node_modules/@ungap/structured-clone": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/@ungap/structured-clone/-/structured-clone-1.3.0.tgz",
      "integrity": "sha512-WmoN8qaIAo7WTYWbAZuG8PYEhn5fkz7dZrqTBZ7dtt//lL2Gwms1IcnQ5yHqjDfX8Ft5j4YzDM23f87zBfDe9g==",
      "license": "ISC"
    },
    "node_modules/abab": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/abab/-/abab-2.0.6.tgz",
      "integrity": "sha512-j2afSsaIENvHZN2B8GOpF566vZ5WVk5opAiMTvWgaQT8DkbOqsTfvNAvHoRGU2zzP8cPoqys+xHTRDWW8L+/BA==",
      "deprecated": "Use your platform's native atob() and btoa() methods instead",
      "devOptional": true,
      "license": "BSD-3-Clause"
    },
    "node_modules/abort-controller": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/abort-controller/-/abort-controller-3.0.0.tgz",
      "integrity": "sha512-h8lQ8tacZYnR3vNQTgibj+tODHI5/+l06Au2Pcriv/Gmet0eaj4TwWH41sO9wnHDiQsEj19q0drzdWdeAHtweg==",
      "license": "MIT",
      "dependencies": {
        "event-target-shim": "^5.0.0"
      },
      "engines": {
        "node": ">=6.5"
      }
    },
    "node_modules/acorn": {
      "version": "8.14.1",
      "resolved": "https://registry.npmjs.org/acorn/-/acorn-8.14.1.tgz",
      "integrity": "sha512-OvQ/2pUDKmgfCg++xsTX1wGxfTaszcHVcTctW4UJB4hibJx2HXxxO5UmVgyjMa+ZDsiaf5wWLXYpRWMmBI0QHg==",
      "devOptional": true,
      "license": "MIT",
      "bin": {
        "acorn": "bin/acorn"
      },
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/acorn-globals": {
      "version": "7.0.1",
      "resolved": "https://registry.npmjs.org/acorn-globals/-/acorn-globals-7.0.1.tgz",
      "integrity": "sha512-umOSDSDrfHbTNPuNpC2NSnnA3LUrqpevPb4T9jRx4MagXNS0rs+gwiTcAvqCRmsD6utzsrzNt+ebm00SNWiC3Q==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "acorn": "^8.1.0",
        "acorn-walk": "^8.0.2"
      }
    },
    "node_modules/acorn-jsx": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/acorn-jsx/-/acorn-jsx-5.3.2.tgz",
      "integrity": "sha512-rq9s+JNhf0IChjtDXxllJ7g41oZk5SlXtp0LHwyA5cejwn7vKmKp4pPri6YEePv2PU65sAsegbXtIinmDFDXgQ==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "acorn": "^6.0.0 || ^7.0.0 || ^8.0.0"
      }
    },
    "node_modules/acorn-walk": {
      "version": "8.3.4",
      "resolved": "https://registry.npmjs.org/acorn-walk/-/acorn-walk-8.3.4.tgz",
      "integrity": "sha512-ueEepnujpqee2o5aIYnvHU6C0A42MNdsIDeqy5BydrkuC5R1ZuUFnm27EeFJGoEHJQgn3uleRvmTXaJgfXbt4g==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "acorn": "^8.11.0"
      },
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/agent-base": {
      "version": "6.0.2",
      "resolved": "https://registry.npmjs.org/agent-base/-/agent-base-6.0.2.tgz",
      "integrity": "sha512-RZNwNclF7+MS/8bDg70amg32dyeZGZxiDuQmZxKLAlQjr3jGyLx+4Kkk58UO7D2QdgFIQCovuSuZESne6RG6XQ==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "debug": "4"
      },
      "engines": {
        "node": ">= 6.0.0"
      }
    },
    "node_modules/agentkeepalive": {
      "version": "4.6.0",
      "resolved": "https://registry.npmjs.org/agentkeepalive/-/agentkeepalive-4.6.0.tgz",
      "integrity": "sha512-kja8j7PjmncONqaTsB8fQ+wE2mSU2DJ9D4XKoJ5PFWIdRMa6SLSN1ff4mOr4jCbfRSsxR4keIiySJU0N9T5hIQ==",
      "license": "MIT",
      "dependencies": {
        "humanize-ms": "^1.2.1"
      },
      "engines": {
        "node": ">= 8.0.0"
      }
    },
    "node_modules/ajv": {
      "version": "6.12.6",
      "resolved": "https://registry.npmjs.org/ajv/-/ajv-6.12.6.tgz",
      "integrity": "sha512-j3fVLgvTo527anyYyJOGTYJbG+vnnQYvE0m5mmkc1TK+nxAppkCLMIL0aZ4dblVCNoGShhm+kzE4ZUykBoMg4g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fast-deep-equal": "^3.1.1",
        "fast-json-stable-stringify": "^2.0.0",
        "json-schema-traverse": "^0.4.1",
        "uri-js": "^4.2.2"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/epoberezkin"
      }
    },
    "node_modules/ansi-escapes": {
      "version": "4.3.2",
      "resolved": "https://registry.npmjs.org/ansi-escapes/-/ansi-escapes-4.3.2.tgz",
      "integrity": "sha512-gKXj5ALrKWQLsYG9jlTRmR/xKluxHV+Z9QEwNIgCfM1/uwPMCuzVVnh5mwTd+OuBZcwSIMbqssNWRm1lE51QaQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "type-fest": "^0.21.3"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/ansi-escapes/node_modules/type-fest": {
      "version": "0.21.3",
      "resolved": "https://registry.npmjs.org/type-fest/-/type-fest-0.21.3.tgz",
      "integrity": "sha512-t0rzBq87m3fVcduHDUFhKmyyX+9eo6WQjZvf51Ea/M0Q7+T374Jp1aUiyUl0GKxp8M/OETVHSDvmkyPgvX+X2w==",
      "dev": true,
      "license": "(MIT OR CC0-1.0)",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/ansi-regex": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-5.0.1.tgz",
      "integrity": "sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ==",
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/ansi-styles": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-4.3.0.tgz",
      "integrity": "sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==",
      "license": "MIT",
      "dependencies": {
        "color-convert": "^2.0.1"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/any-promise": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/any-promise/-/any-promise-1.3.0.tgz",
      "integrity": "sha512-7UvmKalWRt1wgjL1RrGxoSJW/0QZFIegpeGvZG9kjp8vrRu55XTHbwnqq2GpXm9uLbcuhxm3IqX9OB4MZR1b2A==",
      "license": "MIT"
    },
    "node_modules/anymatch": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/anymatch/-/anymatch-3.1.3.tgz",
      "integrity": "sha512-KMReFUr0B4t+D+OBkjR3KYqvocp2XaSzO55UcB6mgQMd3KbcE+mWTyvVV7D/zsdEbNnV6acZUutkiHQXvTr1Rw==",
      "license": "ISC",
      "dependencies": {
        "normalize-path": "^3.0.0",
        "picomatch": "^2.0.4"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/arg": {
      "version": "5.0.2",
      "resolved": "https://registry.npmjs.org/arg/-/arg-5.0.2.tgz",
      "integrity": "sha512-PYjyFOLKQ9y57JvQ6QLo8dAgNqswh8M1RMJYdQduT6xbWSgK36P/Z/v+p888pM69jMMfS8Xd8F6I1kQ/I9HUGg==",
      "license": "MIT"
    },
    "node_modules/argparse": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/argparse/-/argparse-2.0.1.tgz",
      "integrity": "sha512-8+9WqebbFzpX9OR+Wa6O29asIogeRMzcGtAINdpMHHyAg10f05aSFVBbcEqGf/PXw1EjAZ+q2/bEBg3DvurK3Q==",
      "license": "Python-2.0"
    },
    "node_modules/aria-hidden": {
      "version": "1.2.4",
      "resolved": "https://registry.npmjs.org/aria-hidden/-/aria-hidden-1.2.4.tgz",
      "integrity": "sha512-y+CcFFwelSXpLZk/7fMB2mUbGtX9lKycf1MWJ7CaTIERyitVlyQx6C+sxcROU2BAJ24OiZyK+8wj2i8AlBoS3A==",
      "license": "MIT",
      "dependencies": {
        "tslib": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/aria-query": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/aria-query/-/aria-query-5.3.2.tgz",
      "integrity": "sha512-COROpnaoap1E2F000S62r6A60uHZnmlvomhfyT2DlTcrY1OrBKn2UhH7qn5wTC9zMvD0AY7csdPSNwKP+7WiQw==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/array-buffer-byte-length": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/array-buffer-byte-length/-/array-buffer-byte-length-1.0.2.tgz",
      "integrity": "sha512-LHE+8BuR7RYGDKvnrmcuSq3tDcKv9OFEXQt/HpbZhY7V6h0zlUXutnAD82GiFx9rdieCMjkvtcsPqBwgUl1Iiw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "is-array-buffer": "^3.0.5"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array-includes": {
      "version": "3.1.8",
      "resolved": "https://registry.npmjs.org/array-includes/-/array-includes-3.1.8.tgz",
      "integrity": "sha512-itaWrbYbqpGXkGhZPGUulwnhVf5Hpy1xiCFsGqyIGglbBxmG5vSjxQen3/WGOjPpNEv1RtBLKxbmVXm8HpJStQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2",
        "es-object-atoms": "^1.0.0",
        "get-intrinsic": "^1.2.4",
        "is-string": "^1.0.7"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array-union": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/array-union/-/array-union-2.1.0.tgz",
      "integrity": "sha512-HGyxoOTYUyCM6stUe6EJgnd4EoewAI7zMdfqO+kGjnlZmBDz/cR5pf8r/cR4Wq60sL/p0IkcjUEEPwS3GFrIyw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/array.prototype.findlast": {
      "version": "1.2.5",
      "resolved": "https://registry.npmjs.org/array.prototype.findlast/-/array.prototype.findlast-1.2.5.tgz",
      "integrity": "sha512-CVvd6FHg1Z3POpBLxO6E6zr+rSKEQ9L6rZHAaY7lLfhKsWYUBBOuMs0e9o24oopj6H+geRCX0YJ+TJLBK2eHyQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.findlastindex": {
      "version": "1.2.5",
      "resolved": "https://registry.npmjs.org/array.prototype.findlastindex/-/array.prototype.findlastindex-1.2.5.tgz",
      "integrity": "sha512-zfETvRFA8o7EiNn++N5f/kaCw221hrpGsDmcpndVupkPzEc1Wuf3VgC0qby1BbHs7f5DVYjgtEU2LLh5bqeGfQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.flat": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/array.prototype.flat/-/array.prototype.flat-1.3.3.tgz",
      "integrity": "sha512-rwG/ja1neyLqCuGZ5YYrznA62D4mZXg0i1cIskIUKSiqF3Cje9/wXAls9B9s1Wa2fomMsIv8czB8jZcPmxCXFg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.5",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.flatmap": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/array.prototype.flatmap/-/array.prototype.flatmap-1.3.3.tgz",
      "integrity": "sha512-Y7Wt51eKJSyi80hFrJCePGGNo5ktJCslFuboqJsbf57CCPcm5zztluPlc4/aD8sWsKvlwatezpV4U1efk8kpjg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.5",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/array.prototype.tosorted": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/array.prototype.tosorted/-/array.prototype.tosorted-1.1.4.tgz",
      "integrity": "sha512-p6Fx8B7b7ZhL/gmUsAy0D15WhvDccw3mnGNbZpi3pmeJdxtWsj2jEaI4Y6oo3XiHfzuSgPwKc04MYt6KgvC/wA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.3",
        "es-errors": "^1.3.0",
        "es-shim-unscopables": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/arraybuffer.prototype.slice": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/arraybuffer.prototype.slice/-/arraybuffer.prototype.slice-1.0.4.tgz",
      "integrity": "sha512-BNoCY6SXXPQ7gF2opIP4GBE+Xw7U+pHMYKuzjgCN3GwiaIR09UUeKfheyIry77QtrCBlC0KK0q5/TER/tYh3PQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-buffer-byte-length": "^1.0.1",
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.5",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.6",
        "is-array-buffer": "^3.0.4"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/ast-types-flow": {
      "version": "0.0.8",
      "resolved": "https://registry.npmjs.org/ast-types-flow/-/ast-types-flow-0.0.8.tgz",
      "integrity": "sha512-OH/2E5Fg20h2aPrbe+QL8JZQFko0YZaF+j4mnQ7BGhfavO7OpSLa8a0y9sBwomHdSbkhTS8TQNayBfnW5DwbvQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/async-function": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/async-function/-/async-function-1.0.0.tgz",
      "integrity": "sha512-hsU18Ae8CDTR6Kgu9DYf0EbCr/a5iGL0rytQDobUcdpYOKokk8LEjVphnXkDkgpi0wYVsqrXuP0bZxJaTqdgoA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/asynckit": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/asynckit/-/asynckit-0.4.0.tgz",
      "integrity": "sha512-Oei9OH4tRh0YqU3GxhX79dM/mwVgvbZJaSNaRk+bshkj0S5cfHcgYakreBjrHwatXKbz+IoIdYLxrKim2MjW0Q==",
      "license": "MIT"
    },
    "node_modules/autoprefixer": {
      "version": "10.4.21",
      "resolved": "https://registry.npmjs.org/autoprefixer/-/autoprefixer-10.4.21.tgz",
      "integrity": "sha512-O+A6LWV5LDHSJD3LjHYoNi4VLsj/Whi7k6zG12xTYaU4cQ8oxQGckXNX8cRHK5yOZ/ppVHe0ZBXGzSV9jXdVbQ==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/autoprefixer"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "browserslist": "^4.24.4",
        "caniuse-lite": "^1.0.30001702",
        "fraction.js": "^4.3.7",
        "normalize-range": "^0.1.2",
        "picocolors": "^1.1.1",
        "postcss-value-parser": "^4.2.0"
      },
      "bin": {
        "autoprefixer": "bin/autoprefixer"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      },
      "peerDependencies": {
        "postcss": "^8.1.0"
      }
    },
    "node_modules/available-typed-arrays": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/available-typed-arrays/-/available-typed-arrays-1.0.7.tgz",
      "integrity": "sha512-wvUjBtSGN7+7SjNpq/9M2Tg350UZD3q62IFZLbRAR1bSMlCo1ZaeW+BJ+D090e4hIIZLBcTDWe4Mh4jvUDajzQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "possible-typed-array-names": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/axe-core": {
      "version": "4.10.3",
      "resolved": "https://registry.npmjs.org/axe-core/-/axe-core-4.10.3.tgz",
      "integrity": "sha512-Xm7bpRXnDSX2YE2YFfBk2FnF0ep6tmG7xPh8iHee8MIcrgq762Nkce856dYtJYLkuIoYZvGfTs/PbZhideTcEg==",
      "dev": true,
      "license": "MPL-2.0",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/axobject-query": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/axobject-query/-/axobject-query-4.1.0.tgz",
      "integrity": "sha512-qIj0G9wZbMGNLjLmg1PT6v2mE9AH2zlnADJD/2tC6E00hgmhUOfEB6greHPAfLRSufHqROIUTkw6E+M3lH0PTQ==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/babel-jest": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/babel-jest/-/babel-jest-29.7.0.tgz",
      "integrity": "sha512-BrvGY3xZSwEcCzKvKsCi2GgHqDqsYkOP4/by5xCgIwGXQxIEh+8ew3gmrE1y7XRR6LHZIj6yLYnUi/mm2KXKBg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/transform": "^29.7.0",
        "@types/babel__core": "^7.1.14",
        "babel-plugin-istanbul": "^6.1.1",
        "babel-preset-jest": "^29.6.3",
        "chalk": "^4.0.0",
        "graceful-fs": "^4.2.9",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.8.0"
      }
    },
    "node_modules/babel-plugin-istanbul": {
      "version": "6.1.1",
      "resolved": "https://registry.npmjs.org/babel-plugin-istanbul/-/babel-plugin-istanbul-6.1.1.tgz",
      "integrity": "sha512-Y1IQok9821cC9onCx5otgFfRm7Lm+I+wwxOx738M/WLPZ9Q42m4IG5W0FNX8WLL2gYMZo3JkuXIH2DOpWM+qwA==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "@babel/helper-plugin-utils": "^7.0.0",
        "@istanbuljs/load-nyc-config": "^1.0.0",
        "@istanbuljs/schema": "^0.1.2",
        "istanbul-lib-instrument": "^5.0.4",
        "test-exclude": "^6.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/babel-plugin-istanbul/node_modules/istanbul-lib-instrument": {
      "version": "5.2.1",
      "resolved": "https://registry.npmjs.org/istanbul-lib-instrument/-/istanbul-lib-instrument-5.2.1.tgz",
      "integrity": "sha512-pzqtp31nLv/XFOzXGuvhCb8qhjmTVo5vjVk19XE4CRlSWz0KoeJ3bw9XsA7nOp9YBf4qHjwBxkDzKcME/J29Yg==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "@babel/core": "^7.12.3",
        "@babel/parser": "^7.14.7",
        "@istanbuljs/schema": "^0.1.2",
        "istanbul-lib-coverage": "^3.2.0",
        "semver": "^6.3.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/babel-plugin-istanbul/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/babel-plugin-jest-hoist": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/babel-plugin-jest-hoist/-/babel-plugin-jest-hoist-29.6.3.tgz",
      "integrity": "sha512-ESAc/RJvGTFEzRwOTT4+lNDk/GNHMkKbNzsvT0qKRfDyyYTskxB5rnU2njIDYVxXCBHHEI1c0YwHob3WaYujOg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/template": "^7.3.3",
        "@babel/types": "^7.3.3",
        "@types/babel__core": "^7.1.14",
        "@types/babel__traverse": "^7.0.6"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/babel-plugin-polyfill-corejs2": {
      "version": "0.4.13",
      "resolved": "https://registry.npmjs.org/babel-plugin-polyfill-corejs2/-/babel-plugin-polyfill-corejs2-0.4.13.tgz",
      "integrity": "sha512-3sX/eOms8kd3q2KZ6DAhKPc0dgm525Gqq5NtWKZ7QYYZEv57OQ54KtblzJzH1lQF/eQxO8KjWGIK9IPUJNus5g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/compat-data": "^7.22.6",
        "@babel/helper-define-polyfill-provider": "^0.6.4",
        "semver": "^6.3.1"
      },
      "peerDependencies": {
        "@babel/core": "^7.4.0 || ^8.0.0-0 <8.0.0"
      }
    },
    "node_modules/babel-plugin-polyfill-corejs2/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/babel-plugin-polyfill-corejs3": {
      "version": "0.11.1",
      "resolved": "https://registry.npmjs.org/babel-plugin-polyfill-corejs3/-/babel-plugin-polyfill-corejs3-0.11.1.tgz",
      "integrity": "sha512-yGCqvBT4rwMczo28xkH/noxJ6MZ4nJfkVYdoDaC/utLtWrXxv27HVrzAeSbqR8SxDsp46n0YF47EbHoixy6rXQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-define-polyfill-provider": "^0.6.3",
        "core-js-compat": "^3.40.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.4.0 || ^8.0.0-0 <8.0.0"
      }
    },
    "node_modules/babel-plugin-polyfill-regenerator": {
      "version": "0.6.4",
      "resolved": "https://registry.npmjs.org/babel-plugin-polyfill-regenerator/-/babel-plugin-polyfill-regenerator-0.6.4.tgz",
      "integrity": "sha512-7gD3pRadPrbjhjLyxebmx/WrFYcuSjZ0XbdUujQMZ/fcE9oeewk2U/7PCvez84UeuK3oSjmPZ0Ch0dlupQvGzw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/helper-define-polyfill-provider": "^0.6.4"
      },
      "peerDependencies": {
        "@babel/core": "^7.4.0 || ^8.0.0-0 <8.0.0"
      }
    },
    "node_modules/babel-preset-current-node-syntax": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/babel-preset-current-node-syntax/-/babel-preset-current-node-syntax-1.1.0.tgz",
      "integrity": "sha512-ldYss8SbBlWva1bs28q78Ju5Zq1F+8BrqBZZ0VFhLBvhh6lCpC2o3gDJi/5DRLs9FgYZCnmPYIVFU4lRXCkyUw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/plugin-syntax-async-generators": "^7.8.4",
        "@babel/plugin-syntax-bigint": "^7.8.3",
        "@babel/plugin-syntax-class-properties": "^7.12.13",
        "@babel/plugin-syntax-class-static-block": "^7.14.5",
        "@babel/plugin-syntax-import-attributes": "^7.24.7",
        "@babel/plugin-syntax-import-meta": "^7.10.4",
        "@babel/plugin-syntax-json-strings": "^7.8.3",
        "@babel/plugin-syntax-logical-assignment-operators": "^7.10.4",
        "@babel/plugin-syntax-nullish-coalescing-operator": "^7.8.3",
        "@babel/plugin-syntax-numeric-separator": "^7.10.4",
        "@babel/plugin-syntax-object-rest-spread": "^7.8.3",
        "@babel/plugin-syntax-optional-catch-binding": "^7.8.3",
        "@babel/plugin-syntax-optional-chaining": "^7.8.3",
        "@babel/plugin-syntax-private-property-in-object": "^7.14.5",
        "@babel/plugin-syntax-top-level-await": "^7.14.5"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/babel-preset-jest": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/babel-preset-jest/-/babel-preset-jest-29.6.3.tgz",
      "integrity": "sha512-0B3bhxR6snWXJZtR/RliHTDPRgn1sNHOR0yVtq/IiQFyuOVjFS+wuio/R4gSNkyYmKmJB4wGZv2NZanmKmTnNA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "babel-plugin-jest-hoist": "^29.6.3",
        "babel-preset-current-node-syntax": "^1.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "@babel/core": "^7.0.0"
      }
    },
    "node_modules/bail": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/bail/-/bail-2.0.2.tgz",
      "integrity": "sha512-0xO6mYd7JB2YesxDKplafRpsiOzPt9V02ddPCLbY1xYGPOX24NTyN50qnUxgCPcSoYMhKpAuBTjQoRZCAkUDRw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/balanced-match": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/balanced-match/-/balanced-match-1.0.2.tgz",
      "integrity": "sha512-3oSeUO0TMV67hN1AmbXsK4yaqU7tjiHlbxRDZOpH0KW9+CeX4bRAaX0Anxt0tx2MrpRpWwQaPwIlISEJhYU5Pw==",
      "license": "MIT"
    },
    "node_modules/base-64": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/base-64/-/base-64-0.1.0.tgz",
      "integrity": "sha512-Y5gU45svrR5tI2Vt/X9GPd3L0HNIKzGu202EjxrXMpuc2V2CiKgemAbUUsqYmZJvPtCXoUKjNZwBJzsNScUbXA=="
    },
    "node_modules/base64-js": {
      "version": "1.5.1",
      "resolved": "https://registry.npmjs.org/base64-js/-/base64-js-1.5.1.tgz",
      "integrity": "sha512-AKpaYlHn8t4SVbOHCy+b5+KKgvR4vrsD8vbvrbiQJps7fKDTkjkDry6ji0rUJjC0kzbNePLwzxq8iypo41qeWA==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT"
    },
    "node_modules/binary-extensions": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/binary-extensions/-/binary-extensions-2.3.0.tgz",
      "integrity": "sha512-Ceh+7ox5qe7LJuLHoY0feh3pHuUDHAcRUeyL2VYghZwfpkNIy/+8Ocg0a3UuSoYzavmylwuLWQOf3hl0jjMMIw==",
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/binary-search": {
      "version": "1.3.6",
      "resolved": "https://registry.npmjs.org/binary-search/-/binary-search-1.3.6.tgz",
      "integrity": "sha512-nbE1WxOTTrUWIfsfZ4aHGYu5DOuNkbxGokjV6Z2kxfJK3uaAb8zNK1muzOeipoLHZjInT4Br88BHpzevc681xA==",
      "license": "CC0-1.0"
    },
    "node_modules/brace-expansion": {
      "version": "1.1.11",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-1.1.11.tgz",
      "integrity": "sha512-iCuPHDFgrHX7H2vEI/5xpz07zSHB00TpugqhmYtVmMO6518mCuRMoOYFldEBl0g187ufozdaHgWKcYFb61qGiA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0",
        "concat-map": "0.0.1"
      }
    },
    "node_modules/braces": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/braces/-/braces-3.0.3.tgz",
      "integrity": "sha512-yQbXgO/OSZVD2IsiLlro+7Hf6Q18EJrKSEsdoMzKePKXct3gvD8oLcOQdIzGupr5Fj+EDe8gO/lxc1BzfMpxvA==",
      "license": "MIT",
      "dependencies": {
        "fill-range": "^7.1.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/browserslist": {
      "version": "4.24.4",
      "resolved": "https://registry.npmjs.org/browserslist/-/browserslist-4.24.4.tgz",
      "integrity": "sha512-KDi1Ny1gSePi1vm0q4oxSF8b4DR44GF4BbmS2YdhPLOEqd8pDviZOGH/GsmRwoWJ2+5Lr085X7naowMwKHDG1A==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "caniuse-lite": "^1.0.30001688",
        "electron-to-chromium": "^1.5.73",
        "node-releases": "^2.0.19",
        "update-browserslist-db": "^1.1.1"
      },
      "bin": {
        "browserslist": "cli.js"
      },
      "engines": {
        "node": "^6 || ^7 || ^8 || ^9 || ^10 || ^11 || ^12 || >=13.7"
      }
    },
    "node_modules/bser": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/bser/-/bser-2.1.1.tgz",
      "integrity": "sha512-gQxTNE/GAfIIrmHLUE3oJyp5FO6HRBfhjnw4/wMmA63ZGDJnWBmgY/lyQBpnDUkGmAhbSe39tx2d/iTOAfglwQ==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "node-int64": "^0.4.0"
      }
    },
    "node_modules/buffer-from": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/buffer-from/-/buffer-from-1.1.2.tgz",
      "integrity": "sha512-E+XQCRwSbaaiChtv6k6Dwgc+bx+Bs6vuKJHHl5kox/BaKbhiXzqQOwK4cO22yElGp2OCmjwVhT3HmxgyPGnJfQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/busboy": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/busboy/-/busboy-1.6.0.tgz",
      "integrity": "sha512-8SFQbg/0hQ9xy3UNTB0YEnsNBbWfhf7RtnzpL7TkBiTBRfrQ9Fxcnz7VJsleJpyp6rVLvXiuORqjlHi5q+PYuA==",
      "dependencies": {
        "streamsearch": "^1.1.0"
      },
      "engines": {
        "node": ">=10.16.0"
      }
    },
    "node_modules/call-bind": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/call-bind/-/call-bind-1.0.8.tgz",
      "integrity": "sha512-oKlSFMcMwpUg2ednkhQ454wfWiU/ul3CkJe/PEHcTKuiX6RpbehUiFMXu13HalGZxfUwCQzZG747YXBn1im9ww==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.0",
        "es-define-property": "^1.0.0",
        "get-intrinsic": "^1.2.4",
        "set-function-length": "^1.2.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/call-bind-apply-helpers": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/call-bind-apply-helpers/-/call-bind-apply-helpers-1.0.2.tgz",
      "integrity": "sha512-Sp1ablJ0ivDkSzjcaJdxEunN5/XvksFJ2sMBFfq6x0ryhQV/2b/KwFe21cMpmHtPOSij8K99/wSfoEuTObmuMQ==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/call-bound": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/call-bound/-/call-bound-1.0.4.tgz",
      "integrity": "sha512-+ys997U96po4Kx/ABpBCqhA9EuxJaQWDQg7295H4hBphv3IZg0boBKuwYpt4YXp6MZ5AmZQnU/tyMTlRpaSejg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.2",
        "get-intrinsic": "^1.3.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/callsites": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/callsites/-/callsites-3.1.0.tgz",
      "integrity": "sha512-P8BjAsXvZS+VIDUI11hHCQEv74YT67YUi5JJFNWIqL235sBmjX4+qx9Muvls5ivyNENctx46xQLQ3aTuE7ssaQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/camelcase": {
      "version": "6.3.0",
      "resolved": "https://registry.npmjs.org/camelcase/-/camelcase-6.3.0.tgz",
      "integrity": "sha512-Gmy6FhYlCY7uOElZUSbxo2UCDH8owEk996gkbrpsgGtrJLM3J7jGxl9Ic7Qwwj4ivOE5AWZWRMecDdF7hqGjFA==",
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/camelcase-css": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/camelcase-css/-/camelcase-css-2.0.1.tgz",
      "integrity": "sha512-QOSvevhslijgYwRx6Rv7zKdMF8lbRmx+uQGx2+vDc+KI/eBnsy9kit5aj23AgGu3pa4t9AgwbnXWqS+iOY+2aA==",
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/caniuse-lite": {
      "version": "1.0.30001703",
      "resolved": "https://registry.npmjs.org/caniuse-lite/-/caniuse-lite-1.0.30001703.tgz",
      "integrity": "sha512-kRlAGTRWgPsOj7oARC9m1okJEXdL/8fekFVcxA8Hl7GH4r/sN4OJn/i6Flde373T50KS7Y37oFbMwlE8+F42kQ==",
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/caniuse-lite"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "CC-BY-4.0"
    },
    "node_modules/ccount": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/ccount/-/ccount-2.0.1.tgz",
      "integrity": "sha512-eyrF0jiFpY+3drT6383f1qhkbGsLSifNAjA61IUjZjmLCWjItY6LB9ft9YhoDgwfmclB2zhu51Lc7+95b8NRAg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/chalk": {
      "version": "4.1.2",
      "resolved": "https://registry.npmjs.org/chalk/-/chalk-4.1.2.tgz",
      "integrity": "sha512-oKnbhFyRIXpUuez8iBMmyEa4nbj4IOQyuhc/wy9kY7/WVPcwIO9VA668Pu8RkO7+0G76SLROeyw9CpQ061i4mA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.1.0",
        "supports-color": "^7.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/chalk?sponsor=1"
      }
    },
    "node_modules/char-regex": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/char-regex/-/char-regex-1.0.2.tgz",
      "integrity": "sha512-kWWXztvZ5SBQV+eRgKFeh8q5sLuZY2+8WUIzlxWVTg+oGwY14qylx1KbKzHd8P6ZYkAg0xyIDU9JMHhyJMZ1jw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/character-entities": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/character-entities/-/character-entities-2.0.2.tgz",
      "integrity": "sha512-shx7oQ0Awen/BRIdkjkvz54PnEEI/EjwXDSIZp86/KKdbafHh1Df/RYGBhn4hbe2+uKC9FnT5UCEdyPz3ai9hQ==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/character-entities-html4": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/character-entities-html4/-/character-entities-html4-2.1.0.tgz",
      "integrity": "sha512-1v7fgQRj6hnSwFpq1Eu0ynr/CDEw0rXo2B61qXrLNdHZmPKgb7fqS1a2JwF0rISo9q77jDI8VMEHoApn8qDoZA==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/character-entities-legacy": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/character-entities-legacy/-/character-entities-legacy-3.0.0.tgz",
      "integrity": "sha512-RpPp0asT/6ufRm//AJVwpViZbGM/MkjQFxJccQRHmISF/22NBtsHqAWmL+/pmkPWoIUJdWyeVleTl1wydHATVQ==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/character-reference-invalid": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/character-reference-invalid/-/character-reference-invalid-2.0.1.tgz",
      "integrity": "sha512-iBZ4F4wRbyORVsu0jPV7gXkOsGYjGHPmAyv+HiHG8gi5PtC9KI2j1+v8/tlibRvjoWX027ypmG/n0HtO5t7unw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/charenc": {
      "version": "0.0.2",
      "resolved": "https://registry.npmjs.org/charenc/-/charenc-0.0.2.tgz",
      "integrity": "sha512-yrLQ/yVUFXkzg7EDQsPieE/53+0RlaWTs+wBrvW36cyilJ2SaDWfl4Yj7MtLTXleV9uEKefbAGUPv2/iWSooRA==",
      "license": "BSD-3-Clause",
      "engines": {
        "node": "*"
      }
    },
    "node_modules/chokidar": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/chokidar/-/chokidar-3.6.0.tgz",
      "integrity": "sha512-7VT13fmjotKpGipCW9JEQAusEPE+Ei8nl6/g4FBAmIm0GOOLMua9NDDo/DWp0ZAxCr3cPq5ZpBqmPAQgDda2Pw==",
      "license": "MIT",
      "dependencies": {
        "anymatch": "~3.1.2",
        "braces": "~3.0.2",
        "glob-parent": "~5.1.2",
        "is-binary-path": "~2.1.0",
        "is-glob": "~4.0.1",
        "normalize-path": "~3.0.0",
        "readdirp": "~3.6.0"
      },
      "engines": {
        "node": ">= 8.10.0"
      },
      "funding": {
        "url": "https://paulmillr.com/funding/"
      },
      "optionalDependencies": {
        "fsevents": "~2.3.2"
      }
    },
    "node_modules/chokidar/node_modules/glob-parent": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz",
      "integrity": "sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==",
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/ci-info": {
      "version": "3.9.0",
      "resolved": "https://registry.npmjs.org/ci-info/-/ci-info-3.9.0.tgz",
      "integrity": "sha512-NIxF55hv4nSqQswkAeiOi1r83xy8JldOFDTWiug55KBu9Jnblncd2U6ViHmYgHf01TPZS77NJBhBMKdWj9HQMQ==",
      "dev": true,
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/sibiraj-s"
        }
      ],
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/cjs-module-lexer": {
      "version": "1.4.3",
      "resolved": "https://registry.npmjs.org/cjs-module-lexer/-/cjs-module-lexer-1.4.3.tgz",
      "integrity": "sha512-9z8TZaGM1pfswYeXrUpzPrkx8UnWYdhJclsiYMm6x/w5+nN+8Tf/LnAgfLGQCm59qAOxU8WwHEq2vNwF6i4j+Q==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/class-variance-authority": {
      "version": "0.7.1",
      "resolved": "https://registry.npmjs.org/class-variance-authority/-/class-variance-authority-0.7.1.tgz",
      "integrity": "sha512-Ka+9Trutv7G8M6WT6SeiRWz792K5qEqIGEGzXKhAE6xOWAY6pPH8U+9IY3oCMv6kqTmLsv7Xh/2w2RigkePMsg==",
      "license": "Apache-2.0",
      "dependencies": {
        "clsx": "^2.1.1"
      },
      "funding": {
        "url": "https://polar.sh/cva"
      }
    },
    "node_modules/client-only": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/client-only/-/client-only-0.0.1.tgz",
      "integrity": "sha512-IV3Ou0jSMzZrd3pZ48nLkT9DA7Ag1pnPzaiQhpW7c3RbcqqzvzzVu+L8gfqMp/8IM2MQtSiqaCxrrcfu8I8rMA==",
      "license": "MIT"
    },
    "node_modules/cliui": {
      "version": "8.0.1",
      "resolved": "https://registry.npmjs.org/cliui/-/cliui-8.0.1.tgz",
      "integrity": "sha512-BSeNnyus75C4//NQ9gQt1/csTXyo/8Sb+afLAkzAptFuMsod9HFokGNudZpi/oQV73hnVK+sR+5PVRMd+Dr7YQ==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "string-width": "^4.2.0",
        "strip-ansi": "^6.0.1",
        "wrap-ansi": "^7.0.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/cliui/node_modules/emoji-regex": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/cliui/node_modules/string-width": {
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "emoji-regex": "^8.0.0",
        "is-fullwidth-code-point": "^3.0.0",
        "strip-ansi": "^6.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/cliui/node_modules/wrap-ansi": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-7.0.0.tgz",
      "integrity": "sha512-YVGIj2kamLSTxw6NsZjoBxfSwsn0ycdesmc4p+Q21c5zPuZ1pl+NfxVdxPtdHvmNVOQ6XSYG4AUtyt/Fi7D16Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.0.0",
        "string-width": "^4.1.0",
        "strip-ansi": "^6.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
      }
    },
    "node_modules/clsx": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/clsx/-/clsx-2.1.1.tgz",
      "integrity": "sha512-eYm0QWBtUrBWZWG0d386OGAw16Z995PiOVo2B7bjWSbHedGl5e0ZWaq65kOGgUSNesEIDkB9ISbTg/JK9dhCZA==",
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/co": {
      "version": "4.6.0",
      "resolved": "https://registry.npmjs.org/co/-/co-4.6.0.tgz",
      "integrity": "sha512-QVb0dM5HvG+uaxitm8wONl7jltx8dqhfU33DcqtOZcLSVIKSDDLDi7+0LbAKiyI8hD9u42m2YxXSkMGWThaecQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "iojs": ">= 1.0.0",
        "node": ">= 0.12.0"
      }
    },
    "node_modules/collect-v8-coverage": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/collect-v8-coverage/-/collect-v8-coverage-1.0.2.tgz",
      "integrity": "sha512-lHl4d5/ONEbLlJvaJNtsF/Lz+WvB07u2ycqTYbdrq7UypDXailES4valYb2eWiJFxZlVmpGekfqoxQhzyFdT4Q==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/color-convert": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/color-convert/-/color-convert-2.0.1.tgz",
      "integrity": "sha512-RRECPsj7iu/xb5oKYcsFHSppFNnsj/52OVTRKb4zP5onXwVF3zVmmToNcOfGC+CRDpfK/U584fMg38ZHCaElKQ==",
      "license": "MIT",
      "dependencies": {
        "color-name": "~1.1.4"
      },
      "engines": {
        "node": ">=7.0.0"
      }
    },
    "node_modules/color-name": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/color-name/-/color-name-1.1.4.tgz",
      "integrity": "sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA==",
      "license": "MIT"
    },
    "node_modules/combined-stream": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/combined-stream/-/combined-stream-1.0.8.tgz",
      "integrity": "sha512-FQN4MRfuJeHf7cBbBMJFXhKSDq+2kAArBlmRBvcvFE5BB1HZKXtSFASDhdlz9zOYwxh8lDdnvmMOe/+5cdoEdg==",
      "license": "MIT",
      "dependencies": {
        "delayed-stream": "~1.0.0"
      },
      "engines": {
        "node": ">= 0.8"
      }
    },
    "node_modules/comma-separated-tokens": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/comma-separated-tokens/-/comma-separated-tokens-2.0.3.tgz",
      "integrity": "sha512-Fu4hJdvzeylCfQPp9SGWidpzrMs7tTrlu6Vb8XGaRGck8QSNZJJp538Wrb60Lax4fPwR64ViY468OIUTbRlGZg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/commander": {
      "version": "10.0.1",
      "resolved": "https://registry.npmjs.org/commander/-/commander-10.0.1.tgz",
      "integrity": "sha512-y4Mg2tXshplEbSGzx7amzPwKKOCGuoSRP/CjEdwwk0FOGlUbq6lKuoyDZTNZkmxHdJtp54hdfY/JUrdL7Xfdug==",
      "license": "MIT",
      "engines": {
        "node": ">=14"
      }
    },
    "node_modules/concat-map": {
      "version": "0.0.1",
      "resolved": "https://registry.npmjs.org/concat-map/-/concat-map-0.0.1.tgz",
      "integrity": "sha512-/Srv4dswyQNBfohGpz9o6Yb3Gz3SrUDqBH5rTuhGR7ahtlbYKnVxw2bCFMRljaA7EXHaXZ8wsHdodFvbkhKmqg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/convert-source-map": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/convert-source-map/-/convert-source-map-2.0.0.tgz",
      "integrity": "sha512-Kvp459HrV2FEJ1CAsi1Ku+MY3kasH19TFykTz2xWmMeq6bk2NU3XXvfJ+Q61m0xktWwt+1HSYf3JZsTms3aRJg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/core-js-compat": {
      "version": "3.41.0",
      "resolved": "https://registry.npmjs.org/core-js-compat/-/core-js-compat-3.41.0.tgz",
      "integrity": "sha512-RFsU9LySVue9RTwdDVX/T0e2Y6jRYWXERKElIjpuEOEnxaXffI0X7RUwVzfYLfzuLXSNJDYoRYUAmRUcyln20A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "browserslist": "^4.24.4"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/core-js"
      }
    },
    "node_modules/create-jest": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/create-jest/-/create-jest-29.7.0.tgz",
      "integrity": "sha512-Adz2bdH0Vq3F53KEMJOoftQFutWCukm6J24wbPWRO4k1kMY7gS7ds/uoJkNuV8wDCtWWnuwGcJwpWcih+zEW1Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "chalk": "^4.0.0",
        "exit": "^0.1.2",
        "graceful-fs": "^4.2.9",
        "jest-config": "^29.7.0",
        "jest-util": "^29.7.0",
        "prompts": "^2.0.1"
      },
      "bin": {
        "create-jest": "bin/create-jest.js"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/cross-spawn": {
      "version": "7.0.6",
      "resolved": "https://registry.npmjs.org/cross-spawn/-/cross-spawn-7.0.6.tgz",
      "integrity": "sha512-uV2QOWP2nWzsy2aMp8aRibhi9dlzF5Hgh5SHaB9OiTGEyDTiJJyx0uy51QXdyWbtAHNua4XJzUKca3OzKUd3vA==",
      "license": "MIT",
      "dependencies": {
        "path-key": "^3.1.0",
        "shebang-command": "^2.0.0",
        "which": "^2.0.1"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/crypt": {
      "version": "0.0.2",
      "resolved": "https://registry.npmjs.org/crypt/-/crypt-0.0.2.tgz",
      "integrity": "sha512-mCxBlsHFYh9C+HVpiEacem8FEBnMXgU9gy4zmNC+SXAZNB/1idgp/aulFJ4FgCi7GPEVbfyng092GqL2k2rmow==",
      "license": "BSD-3-Clause",
      "engines": {
        "node": "*"
      }
    },
    "node_modules/css.escape": {
      "version": "1.5.1",
      "resolved": "https://registry.npmjs.org/css.escape/-/css.escape-1.5.1.tgz",
      "integrity": "sha512-YUifsXXuknHlUsmlgyY0PKzgPOr7/FjCePfHNt0jxm83wHZi44VDMQ7/fGNkjY3/jV1MC+1CmZbaHzugyeRtpg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/cssesc": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/cssesc/-/cssesc-3.0.0.tgz",
      "integrity": "sha512-/Tb/JcjK111nNScGob5MNtsntNM1aCNUDipB/TkwZFhyDrrE47SOx/18wF2bbjgc3ZzCSKW1T5nt5EbFoAz/Vg==",
      "license": "MIT",
      "bin": {
        "cssesc": "bin/cssesc"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/cssom": {
      "version": "0.5.0",
      "resolved": "https://registry.npmjs.org/cssom/-/cssom-0.5.0.tgz",
      "integrity": "sha512-iKuQcq+NdHqlAcwUY0o/HL69XQrUaQdMjmStJ8JFmUaiiQErlhrmuigkg/CU4E2J0IyUKUrMAgl36TvN67MqTw==",
      "devOptional": true,
      "license": "MIT"
    },
    "node_modules/cssstyle": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/cssstyle/-/cssstyle-2.3.0.tgz",
      "integrity": "sha512-AZL67abkUzIuvcHqk7c09cezpGNcxUxU4Ioi/05xHk4DQeTkWmGYftIE6ctU6AEt+Gn4n1lDStOtj7FKycP71A==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "cssom": "~0.3.6"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/cssstyle/node_modules/cssom": {
      "version": "0.3.8",
      "resolved": "https://registry.npmjs.org/cssom/-/cssom-0.3.8.tgz",
      "integrity": "sha512-b0tGHbfegbhPJpxpiBPU2sCkigAqtM9O121le6bbOlgyV+NyGyCmVfJ6QW9eRjz8CpNfWEOYBIMIGRYkLwsIYg==",
      "devOptional": true,
      "license": "MIT"
    },
    "node_modules/csstype": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/csstype/-/csstype-3.1.3.tgz",
      "integrity": "sha512-M1uQkMl8rQK/szD0LNhtqxIPLpimGm8sOBwU7lLnCpSbTyY3yeU1Vc7l4KT5zT4s/yOxHH5O7tIuuLOCnLADRw==",
      "license": "MIT"
    },
    "node_modules/d3-array": {
      "version": "3.2.4",
      "resolved": "https://registry.npmjs.org/d3-array/-/d3-array-3.2.4.tgz",
      "integrity": "sha512-tdQAmyA18i4J7wprpYq8ClcxZy3SC31QMeByyCFyRt7BVHdREQZ5lpzoe5mFEYZUWe+oq8HBvk9JjpibyEV4Jg==",
      "license": "ISC",
      "dependencies": {
        "internmap": "1 - 2"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-color": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/d3-color/-/d3-color-3.1.0.tgz",
      "integrity": "sha512-zg/chbXyeBtMQ1LbD/WSoW2DpC3I0mpmPdW+ynRTj/x2DAWYrIY7qeZIHidozwV24m4iavr15lNwIwLxRmOxhA==",
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-ease": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/d3-ease/-/d3-ease-3.0.1.tgz",
      "integrity": "sha512-wR/XK3D3XcLIZwpbvQwQ5fK+8Ykds1ip7A2Txe0yxncXSdq1L9skcG7blcedkOX+ZcgxGAmLX1FrRGbADwzi0w==",
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-format": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/d3-format/-/d3-format-3.1.0.tgz",
      "integrity": "sha512-YyUI6AEuY/Wpt8KWLgZHsIU86atmikuoOmCfommt0LYHiQSPjvX2AcFc38PX0CBpr2RCyZhjex+NS/LPOv6YqA==",
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-interpolate": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/d3-interpolate/-/d3-interpolate-3.0.1.tgz",
      "integrity": "sha512-3bYs1rOD33uo8aqJfKP3JWPAibgw8Zm2+L9vBKEHJ2Rg+viTR7o5Mmv5mZcieN+FRYaAOWX5SJATX6k1PWz72g==",
      "license": "ISC",
      "dependencies": {
        "d3-color": "1 - 3"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-path": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/d3-path/-/d3-path-3.1.0.tgz",
      "integrity": "sha512-p3KP5HCf/bvjBSSKuXid6Zqijx7wIfNW+J/maPs+iwR35at5JCbLUT0LzF1cnjbCHWhqzQTIN2Jpe8pRebIEFQ==",
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-scale": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/d3-scale/-/d3-scale-4.0.2.tgz",
      "integrity": "sha512-GZW464g1SH7ag3Y7hXjf8RoUuAFIqklOAq3MRl4OaWabTFJY9PN/E1YklhXLh+OQ3fM9yS2nOkCoS+WLZ6kvxQ==",
      "license": "ISC",
      "dependencies": {
        "d3-array": "2.10.0 - 3",
        "d3-format": "1 - 3",
        "d3-interpolate": "1.2.0 - 3",
        "d3-time": "2.1.1 - 3",
        "d3-time-format": "2 - 4"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-shape": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/d3-shape/-/d3-shape-3.2.0.tgz",
      "integrity": "sha512-SaLBuwGm3MOViRq2ABk3eLoxwZELpH6zhl3FbAoJ7Vm1gofKx6El1Ib5z23NUEhF9AsGl7y+dzLe5Cw2AArGTA==",
      "license": "ISC",
      "dependencies": {
        "d3-path": "^3.1.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-time": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/d3-time/-/d3-time-3.1.0.tgz",
      "integrity": "sha512-VqKjzBLejbSMT4IgbmVgDjpkYrNWUYJnbCGo874u7MMKIWsILRX+OpX/gTk8MqjpT1A/c6HY2dCA77ZN0lkQ2Q==",
      "license": "ISC",
      "dependencies": {
        "d3-array": "2 - 3"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-time-format": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/d3-time-format/-/d3-time-format-4.1.0.tgz",
      "integrity": "sha512-dJxPBlzC7NugB2PDLwo9Q8JiTR3M3e4/XANkreKSUxF8vvXKqm1Yfq4Q5dl8budlunRVlUUaDUgFt7eA8D6NLg==",
      "license": "ISC",
      "dependencies": {
        "d3-time": "1 - 3"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/d3-timer": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/d3-timer/-/d3-timer-3.0.1.tgz",
      "integrity": "sha512-ndfJ/JxxMd3nw31uyKoY2naivF+r29V+Lc0svZxe1JvvIRmi8hUsrMvdOwgS1o6uBHmiz91geQ0ylPP0aj1VUA==",
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/damerau-levenshtein": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/damerau-levenshtein/-/damerau-levenshtein-1.0.8.tgz",
      "integrity": "sha512-sdQSFB7+llfUcQHUQO3+B8ERRj0Oa4w9POWMI/puGtuf7gFywGmkaLCElnudfTiKZV+NvHqL0ifzdrI8Ro7ESA==",
      "dev": true,
      "license": "BSD-2-Clause"
    },
    "node_modules/data-urls": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/data-urls/-/data-urls-3.0.2.tgz",
      "integrity": "sha512-Jy/tj3ldjZJo63sVAvg6LHt2mHvl4V6AgRAmNDtLdm7faqtsx+aJG42rsyCo9JCoRVKwPFzKlIPx3DIibwSIaQ==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "abab": "^2.0.6",
        "whatwg-mimetype": "^3.0.0",
        "whatwg-url": "^11.0.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/data-urls/node_modules/tr46": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/tr46/-/tr46-3.0.0.tgz",
      "integrity": "sha512-l7FvfAHlcmulp8kr+flpQZmVwtu7nfRV7NZujtN0OqES8EL4O4e0qqzL0DC5gAvx/ZC/9lk6rhcUwYvkBnBnYA==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "punycode": "^2.1.1"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/data-urls/node_modules/webidl-conversions": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/webidl-conversions/-/webidl-conversions-7.0.0.tgz",
      "integrity": "sha512-VwddBukDzu71offAQR975unBIGqfKZpM+8ZX6ySk8nYhVoo5CYaZyzt3YBvYtRtO+aoGlqxPg/B87NGVZ/fu6g==",
      "devOptional": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/data-urls/node_modules/whatwg-url": {
      "version": "11.0.0",
      "resolved": "https://registry.npmjs.org/whatwg-url/-/whatwg-url-11.0.0.tgz",
      "integrity": "sha512-RKT8HExMpoYx4igMiVMY83lN6UeITKJlBQ+vR/8ZJ8OCdSiN3RwCq+9gH0+Xzj0+5IrM6i4j/6LuvzbZIQgEcQ==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "tr46": "^3.0.0",
        "webidl-conversions": "^7.0.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/data-view-buffer": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/data-view-buffer/-/data-view-buffer-1.0.2.tgz",
      "integrity": "sha512-EmKO5V3OLXh1rtK2wgXRansaK1/mtVdTUEiEI0W8RkvgT05kfxaH29PliLnpLP73yYO6142Q72QNa8Wx/A5CqQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "es-errors": "^1.3.0",
        "is-data-view": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/data-view-byte-length": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/data-view-byte-length/-/data-view-byte-length-1.0.2.tgz",
      "integrity": "sha512-tuhGbE6CfTM9+5ANGf+oQb72Ky/0+s3xKUpHvShfiz2RxMFgFPjsXuRLBVMtvMs15awe45SRb83D6wH4ew6wlQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "es-errors": "^1.3.0",
        "is-data-view": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/inspect-js"
      }
    },
    "node_modules/data-view-byte-offset": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/data-view-byte-offset/-/data-view-byte-offset-1.0.1.tgz",
      "integrity": "sha512-BS8PfmtDGnrgYdOonGZQdLZslWIeCGFP9tpan0hi1Co2Zr2NKADsvGYA8XxuG/4UWgJ6Cjtv+YJnB6MM69QGlQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "is-data-view": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/debug": {
      "version": "4.4.0",
      "resolved": "https://registry.npmjs.org/debug/-/debug-4.4.0.tgz",
      "integrity": "sha512-6WTZ/IxCY/T6BALoZHaE4ctp9xm+Z5kY/pzYaCHRFeyVhojxlrm+46y68HA6hr0TcwEssoxNiDEUJQjfPZ/RYA==",
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.3"
      },
      "engines": {
        "node": ">=6.0"
      },
      "peerDependenciesMeta": {
        "supports-color": {
          "optional": true
        }
      }
    },
    "node_modules/decamelize": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/decamelize/-/decamelize-1.2.0.tgz",
      "integrity": "sha512-z2S+W9X73hAUUki+N+9Za2lBlun89zigOyGrsax+KUQ6wKW4ZoWpEYBkGhQjwAjjDCkWxhY0VKEhk8wzY7F5cA==",
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/decimal.js": {
      "version": "10.5.0",
      "resolved": "https://registry.npmjs.org/decimal.js/-/decimal.js-10.5.0.tgz",
      "integrity": "sha512-8vDa8Qxvr/+d94hSh5P3IJwI5t8/c0KsMp+g8bNw9cY2icONa5aPfvKeieW1WlG0WQYwwhJ7mjui2xtiePQSXw==",
      "devOptional": true,
      "license": "MIT"
    },
    "node_modules/decimal.js-light": {
      "version": "2.5.1",
      "resolved": "https://registry.npmjs.org/decimal.js-light/-/decimal.js-light-2.5.1.tgz",
      "integrity": "sha512-qIMFpTMZmny+MMIitAB6D7iVPEorVw6YQRWkvarTkT4tBeSLLiHzcwj6q0MmYSFCiVpiqPJTJEYIrpcPzVEIvg==",
      "license": "MIT"
    },
    "node_modules/decode-named-character-reference": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/decode-named-character-reference/-/decode-named-character-reference-1.1.0.tgz",
      "integrity": "sha512-Wy+JTSbFThEOXQIR2L6mxJvEs+veIzpmqD7ynWxMXGpnk3smkHQOp6forLdHsKpAMW9iJpaBBIxz285t1n1C3w==",
      "license": "MIT",
      "dependencies": {
        "character-entities": "^2.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/dedent": {
      "version": "1.5.3",
      "resolved": "https://registry.npmjs.org/dedent/-/dedent-1.5.3.tgz",
      "integrity": "sha512-NHQtfOOW68WD8lgypbLA5oT+Bt0xXJhiYvoR6SmmNXZfpzOGXwdKWmcwG8N7PwVVWV3eF/68nmD9BaJSsTBhyQ==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "babel-plugin-macros": "^3.1.0"
      },
      "peerDependenciesMeta": {
        "babel-plugin-macros": {
          "optional": true
        }
      }
    },
    "node_modules/deep-is": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/deep-is/-/deep-is-0.1.4.tgz",
      "integrity": "sha512-oIPzksmTg4/MriiaYGO+okXDT7ztn/w3Eptv/+gSIdMdKsJo0u4CfYNFJPy+4SKMuCqGw2wxnA+URMg3t8a/bQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/deepmerge": {
      "version": "4.3.1",
      "resolved": "https://registry.npmjs.org/deepmerge/-/deepmerge-4.3.1.tgz",
      "integrity": "sha512-3sUqbMEc77XqpdNO7FRyRog+eW3ph+GYCbj+rK+uYyRMuwsVy0rMiVtPn+QJlKFvWP/1PYpapqYn0Me2knFn+A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/define-data-property": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/define-data-property/-/define-data-property-1.1.4.tgz",
      "integrity": "sha512-rBMvIzlpA8v6E+SJZoo++HAYqsLrkg7MSfIinMPFhmkorw7X+dOXVJQs+QT69zGkzMyfDnIMN2Wid1+NbL3T+A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-define-property": "^1.0.0",
        "es-errors": "^1.3.0",
        "gopd": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/define-properties": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/define-properties/-/define-properties-1.2.1.tgz",
      "integrity": "sha512-8QmQKqEASLd5nx0U1B1okLElbUuuttJ/AnYmRXbbbGDWh6uS208EjD4Xqq/I9wK7u0v6O08XhTWnt5XtEbR6Dg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-data-property": "^1.0.1",
        "has-property-descriptors": "^1.0.0",
        "object-keys": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/delayed-stream": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/delayed-stream/-/delayed-stream-1.0.0.tgz",
      "integrity": "sha512-ZySD7Nf91aLB0RxL4KGrKHBXl7Eds1DAmEdcoVawXnLD7SDhpNgtuII2aAkg7a7QS41jxPSZ17p4VdGnMHk3MQ==",
      "license": "MIT",
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/dequal": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/dequal/-/dequal-2.0.3.tgz",
      "integrity": "sha512-0je+qPKHEMohvfRTCEo3CrPG6cAzAYgmzKyxRiYSSDkS6eGJdyVJm7WaYA5ECaAD9wLB2T4EEeymA5aFVcYXCA==",
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/detect-newline": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/detect-newline/-/detect-newline-3.1.0.tgz",
      "integrity": "sha512-TLz+x/vEXm/Y7P7wn1EJFNLxYpUD4TgMosxY6fAVJUnJMbupHBOncxyWUG9OpTaH9EBD7uFI5LfEgmMOc54DsA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/detect-node-es": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/detect-node-es/-/detect-node-es-1.1.0.tgz",
      "integrity": "sha512-ypdmJU/TbBby2Dxibuv7ZLW3Bs1QEmM7nHjEANfohJLvE0XVujisn1qPJcZxg+qDucsr+bP6fLD1rPS3AhJ7EQ==",
      "license": "MIT"
    },
    "node_modules/devlop": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/devlop/-/devlop-1.1.0.tgz",
      "integrity": "sha512-RWmIqhcFf1lRYBvNmr7qTNuyCt/7/ns2jbpp1+PalgE/rDQcBT0fioSMUpJ93irlUhC5hrg4cYqe6U+0ImW0rA==",
      "license": "MIT",
      "dependencies": {
        "dequal": "^2.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/didyoumean": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/didyoumean/-/didyoumean-1.2.2.tgz",
      "integrity": "sha512-gxtyfqMg7GKyhQmb056K7M3xszy/myH8w+B4RT+QXBQsvAOdc3XymqDDPHx1BgPgsdAA5SIifona89YtRATDzw==",
      "license": "Apache-2.0"
    },
    "node_modules/diff-sequences": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/diff-sequences/-/diff-sequences-29.6.3.tgz",
      "integrity": "sha512-EjePK1srD3P08o2j4f0ExnylqRs5B9tJjcp9t1krH2qRi8CCdsYfwe9JgSLurFBWwq4uOlipzfk5fHNvwFKr8Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/digest-fetch": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/digest-fetch/-/digest-fetch-1.3.0.tgz",
      "integrity": "sha512-CGJuv6iKNM7QyZlM2T3sPAdZWd/p9zQiRNS9G+9COUCwzWFTs0Xp8NF5iePx7wtvhDykReiRRrSeNb4oMmB8lA==",
      "license": "ISC",
      "dependencies": {
        "base-64": "^0.1.0",
        "md5": "^2.3.0"
      }
    },
    "node_modules/dir-glob": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/dir-glob/-/dir-glob-3.0.1.tgz",
      "integrity": "sha512-WkrWp9GR4KXfKGYzOLmTuGVi1UWFfws377n9cc55/tb6DuqyF6pcQ5AbiHEshaDpY9v6oaSr2XCDidGmMwdzIA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "path-type": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/dlv": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/dlv/-/dlv-1.1.3.tgz",
      "integrity": "sha512-+HlytyjlPKnIG8XuRG8WvmBP8xs8P71y+SKKS6ZXWoEgLuePxtDoUEiH7WkdePWrQ5JBpE6aoVqfZfJUQkjXwA==",
      "license": "MIT"
    },
    "node_modules/doctrine": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/doctrine/-/doctrine-3.0.0.tgz",
      "integrity": "sha512-yS+Q5i3hBf7GBkd4KG8a7eBNNWNGLTaEwwYWUijIYM7zrlYDM0BFXHjjPWlWZ1Rg7UaddZeIDmi9jF3HmqiQ2w==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "esutils": "^2.0.2"
      },
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/dom-accessibility-api": {
      "version": "0.5.16",
      "resolved": "https://registry.npmjs.org/dom-accessibility-api/-/dom-accessibility-api-0.5.16.tgz",
      "integrity": "sha512-X7BJ2yElsnOJ30pZF4uIIDfBEVgF4XEBxL9Bxhy6dnrm5hkzqmsWHGTiHqRiITNhMyFLyAiWndIJP7Z1NTteDg==",
      "dev": true,
      "license": "MIT",
      "peer": true
    },
    "node_modules/dom-helpers": {
      "version": "5.2.1",
      "resolved": "https://registry.npmjs.org/dom-helpers/-/dom-helpers-5.2.1.tgz",
      "integrity": "sha512-nRCa7CK3VTrM2NmGkIy4cbK7IZlgBE/PYMn55rrXefr5xXDP0LdtfPnblFDoVdcAfslJ7or6iqAUnx0CCGIWQA==",
      "license": "MIT",
      "dependencies": {
        "@babel/runtime": "^7.8.7",
        "csstype": "^3.0.2"
      }
    },
    "node_modules/domexception": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/domexception/-/domexception-4.0.0.tgz",
      "integrity": "sha512-A2is4PLG+eeSfoTMA95/s4pvAoSo2mKtiM5jlHkAVewmiO8ISFTFKZjH7UAM1Atli/OT/7JHOrJRJiMKUZKYBw==",
      "deprecated": "Use your platform's native DOMException instead",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "webidl-conversions": "^7.0.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/domexception/node_modules/webidl-conversions": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/webidl-conversions/-/webidl-conversions-7.0.0.tgz",
      "integrity": "sha512-VwddBukDzu71offAQR975unBIGqfKZpM+8ZX6ySk8nYhVoo5CYaZyzt3YBvYtRtO+aoGlqxPg/B87NGVZ/fu6g==",
      "devOptional": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/dommatrix": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/dommatrix/-/dommatrix-1.0.3.tgz",
      "integrity": "sha512-l32Xp/TLgWb8ReqbVJAFIvXmY7go4nTxxlWiAFyhoQw9RKEOHBZNnyGvJWqDVSPmq3Y9HlM4npqF/T6VMOXhww==",
      "deprecated": "dommatrix is no longer maintained. Please use @thednp/dommatrix.",
      "license": "MIT"
    },
    "node_modules/dunder-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/dunder-proto/-/dunder-proto-1.0.1.tgz",
      "integrity": "sha512-KIN/nDJBQRcXw0MLVhZE9iQHmG68qAVIBg9CqmUYjmQIhgij9U5MFvrqkUL5FbtyyzZuOeOt0zdeRe4UY7ct+A==",
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.1",
        "es-errors": "^1.3.0",
        "gopd": "^1.2.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/eastasianwidth": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/eastasianwidth/-/eastasianwidth-0.2.0.tgz",
      "integrity": "sha512-I88TYZWc9XiYHRQ4/3c5rjjfgkjhLyW2luGIheGERbNQ6OY7yTybanSpDXZa8y7VUP9YmDcYa+eyq4ca7iLqWA==",
      "license": "MIT"
    },
    "node_modules/electron-to-chromium": {
      "version": "1.5.115",
      "resolved": "https://registry.npmjs.org/electron-to-chromium/-/electron-to-chromium-1.5.115.tgz",
      "integrity": "sha512-MN1nahVHAQMOz6dz6bNZ7apgqc9InZy7Ja4DBEVCTdeiUcegbyOYE9bi/f2Z/z6ZxLi0RxLpyJ3EGe+4h3w73A==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/emittery": {
      "version": "0.13.1",
      "resolved": "https://registry.npmjs.org/emittery/-/emittery-0.13.1.tgz",
      "integrity": "sha512-DeWwawk6r5yR9jFgnDKYt4sLS0LmHJJi3ZOnb5/JdbYwj3nW+FxQnHIjhBKz8YLC7oRNPVM9NQ47I3CVx34eqQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sindresorhus/emittery?sponsor=1"
      }
    },
    "node_modules/emoji-regex": {
      "version": "9.2.2",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-9.2.2.tgz",
      "integrity": "sha512-L18DaJsXSUk2+42pv8mLs5jJT2hqFkFE4j21wOmgbUqsZ2hL72NsUU785g9RXgo3s0ZNgVl42TiHp3ZtOv/Vyg==",
      "license": "MIT"
    },
    "node_modules/enhanced-resolve": {
      "version": "5.18.1",
      "resolved": "https://registry.npmjs.org/enhanced-resolve/-/enhanced-resolve-5.18.1.tgz",
      "integrity": "sha512-ZSW3ma5GkcQBIpwZTSRAI8N71Uuwgs93IezB7mf7R60tC8ZbJideoDNKjHn2O9KIlx6rkGTTEk1xUCK2E1Y2Yg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "graceful-fs": "^4.2.4",
        "tapable": "^2.2.0"
      },
      "engines": {
        "node": ">=10.13.0"
      }
    },
    "node_modules/entities": {
      "version": "4.5.0",
      "resolved": "https://registry.npmjs.org/entities/-/entities-4.5.0.tgz",
      "integrity": "sha512-V0hjH4dGPh9Ao5p0MoRY6BVqtwCjhz6vI5LT8AJ55H+4g9/4vbHx1I54fS0XuclLhDHArPQCiMjDxjaL8fPxhw==",
      "devOptional": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=0.12"
      },
      "funding": {
        "url": "https://github.com/fb55/entities?sponsor=1"
      }
    },
    "node_modules/error-ex": {
      "version": "1.3.2",
      "resolved": "https://registry.npmjs.org/error-ex/-/error-ex-1.3.2.tgz",
      "integrity": "sha512-7dFHNmqeFSEt2ZBsCriorKnn3Z2pj+fd9kmI6QoWw4//DL+icEBfc0U7qJCisqrTsKTjw4fNFy2pW9OqStD84g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-arrayish": "^0.2.1"
      }
    },
    "node_modules/es-abstract": {
      "version": "1.23.9",
      "resolved": "https://registry.npmjs.org/es-abstract/-/es-abstract-1.23.9.tgz",
      "integrity": "sha512-py07lI0wjxAC/DcfK1S6G7iANonniZwTISvdPzk9hzeH0IZIshbuuFxLIU96OyF89Yb9hiqWn8M/bY83KY5vzA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-buffer-byte-length": "^1.0.2",
        "arraybuffer.prototype.slice": "^1.0.4",
        "available-typed-arrays": "^1.0.7",
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "data-view-buffer": "^1.0.2",
        "data-view-byte-length": "^1.0.2",
        "data-view-byte-offset": "^1.0.1",
        "es-define-property": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "es-set-tostringtag": "^2.1.0",
        "es-to-primitive": "^1.3.0",
        "function.prototype.name": "^1.1.8",
        "get-intrinsic": "^1.2.7",
        "get-proto": "^1.0.0",
        "get-symbol-description": "^1.1.0",
        "globalthis": "^1.0.4",
        "gopd": "^1.2.0",
        "has-property-descriptors": "^1.0.2",
        "has-proto": "^1.2.0",
        "has-symbols": "^1.1.0",
        "hasown": "^2.0.2",
        "internal-slot": "^1.1.0",
        "is-array-buffer": "^3.0.5",
        "is-callable": "^1.2.7",
        "is-data-view": "^1.0.2",
        "is-regex": "^1.2.1",
        "is-shared-array-buffer": "^1.0.4",
        "is-string": "^1.1.1",
        "is-typed-array": "^1.1.15",
        "is-weakref": "^1.1.0",
        "math-intrinsics": "^1.1.0",
        "object-inspect": "^1.13.3",
        "object-keys": "^1.1.1",
        "object.assign": "^4.1.7",
        "own-keys": "^1.0.1",
        "regexp.prototype.flags": "^1.5.3",
        "safe-array-concat": "^1.1.3",
        "safe-push-apply": "^1.0.0",
        "safe-regex-test": "^1.1.0",
        "set-proto": "^1.0.0",
        "string.prototype.trim": "^1.2.10",
        "string.prototype.trimend": "^1.0.9",
        "string.prototype.trimstart": "^1.0.8",
        "typed-array-buffer": "^1.0.3",
        "typed-array-byte-length": "^1.0.3",
        "typed-array-byte-offset": "^1.0.4",
        "typed-array-length": "^1.0.7",
        "unbox-primitive": "^1.1.0",
        "which-typed-array": "^1.1.18"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/es-define-property": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/es-define-property/-/es-define-property-1.0.1.tgz",
      "integrity": "sha512-e3nRfgfUZ4rNGL232gUgX06QNyyez04KdjFrF+LTRoOXmrOgFKDg4BCdsjW8EnT69eqdYGmRpJwiPVYNrCaW3g==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-errors": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/es-errors/-/es-errors-1.3.0.tgz",
      "integrity": "sha512-Zf5H2Kxt2xjTvbJvP2ZWLEICxA6j+hAmMzIlypy4xcBg1vKVnx89Wy0GbS+kf5cwCVFFzdCFh2XSCFNULS6csw==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-iterator-helpers": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/es-iterator-helpers/-/es-iterator-helpers-1.2.1.tgz",
      "integrity": "sha512-uDn+FE1yrDzyC0pCo961B2IHbdM8y/ACZsKD4dG6WqrjV53BADjwa7D+1aom2rsNVfLyDgU/eigvlJGJ08OQ4w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.6",
        "es-errors": "^1.3.0",
        "es-set-tostringtag": "^2.0.3",
        "function-bind": "^1.1.2",
        "get-intrinsic": "^1.2.6",
        "globalthis": "^1.0.4",
        "gopd": "^1.2.0",
        "has-property-descriptors": "^1.0.2",
        "has-proto": "^1.2.0",
        "has-symbols": "^1.1.0",
        "internal-slot": "^1.1.0",
        "iterator.prototype": "^1.1.4",
        "safe-array-concat": "^1.1.3"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-object-atoms": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/es-object-atoms/-/es-object-atoms-1.1.1.tgz",
      "integrity": "sha512-FGgH2h8zKNim9ljj7dankFPcICIK9Cp5bm+c2gQSYePhpaG5+esrLODihIorn+Pe6FGJzWhXQotPv73jTaldXA==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-set-tostringtag": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/es-set-tostringtag/-/es-set-tostringtag-2.1.0.tgz",
      "integrity": "sha512-j6vWzfrGVfyXxge+O0x5sh6cvxAog0a/4Rdd2K36zCMV5eJ+/+tOAngRO8cODMNWbVRdVlmGZQL2YS3yR8bIUA==",
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.6",
        "has-tostringtag": "^1.0.2",
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-shim-unscopables": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/es-shim-unscopables/-/es-shim-unscopables-1.1.0.tgz",
      "integrity": "sha512-d9T8ucsEhh8Bi1woXCf+TIKDIROLG5WCkxg8geBCbvk22kzwC5G2OnXVMO6FUsvQlgUUXQ2itephWDLqDzbeCw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/es-to-primitive": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/es-to-primitive/-/es-to-primitive-1.3.0.tgz",
      "integrity": "sha512-w+5mJ3GuFL+NjVtJlvydShqE1eN3h3PbI7/5LAsYJP/2qtuMXjfL2LpHSRqo4b4eSF5K/DH1JXKUAHSB2UW50g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-callable": "^1.2.7",
        "is-date-object": "^1.0.5",
        "is-symbol": "^1.0.4"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/escalade": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/escalade/-/escalade-3.2.0.tgz",
      "integrity": "sha512-WUj2qlxaQtO4g6Pq5c29GTcWGDyd8itL8zTlipgECz3JesAiiOKotd8JU6otB3PACgG6xkJUyVhboMS+bje/jA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/escape-string-regexp": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-4.0.0.tgz",
      "integrity": "sha512-TtpcNJ3XAzx3Gq8sWRzJaVajRs0uVxA2YAkdb1jm2YkPz4G6egUFAyA3n5vtEIZefPk5Wa4UXbKuS5fKkJWdgA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/escodegen": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/escodegen/-/escodegen-2.1.0.tgz",
      "integrity": "sha512-2NlIDTwUWJN0mRPQOdtQBzbUHvdGY2P1VXSyU83Q3xKxM7WHX2Ql8dKq782Q9TgQUNOLEzEYu9bzLNj1q88I5w==",
      "devOptional": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "esprima": "^4.0.1",
        "estraverse": "^5.2.0",
        "esutils": "^2.0.2"
      },
      "bin": {
        "escodegen": "bin/escodegen.js",
        "esgenerate": "bin/esgenerate.js"
      },
      "engines": {
        "node": ">=6.0"
      },
      "optionalDependencies": {
        "source-map": "~0.6.1"
      }
    },
    "node_modules/eslint": {
      "version": "8.57.1",
      "resolved": "https://registry.npmjs.org/eslint/-/eslint-8.57.1.tgz",
      "integrity": "sha512-ypowyDxpVSYpkXr9WPv2PAZCtNip1Mv5KTW0SCurXv/9iOpcrH9PaqUElksqEB6pChqHGDRCFTyrZlGhnLNGiA==",
      "deprecated": "This version is no longer supported. Please see https://eslint.org/version-support for other options.",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@eslint-community/eslint-utils": "^4.2.0",
        "@eslint-community/regexpp": "^4.6.1",
        "@eslint/eslintrc": "^2.1.4",
        "@eslint/js": "8.57.1",
        "@humanwhocodes/config-array": "^0.13.0",
        "@humanwhocodes/module-importer": "^1.0.1",
        "@nodelib/fs.walk": "^1.2.8",
        "@ungap/structured-clone": "^1.2.0",
        "ajv": "^6.12.4",
        "chalk": "^4.0.0",
        "cross-spawn": "^7.0.2",
        "debug": "^4.3.2",
        "doctrine": "^3.0.0",
        "escape-string-regexp": "^4.0.0",
        "eslint-scope": "^7.2.2",
        "eslint-visitor-keys": "^3.4.3",
        "espree": "^9.6.1",
        "esquery": "^1.4.2",
        "esutils": "^2.0.2",
        "fast-deep-equal": "^3.1.3",
        "file-entry-cache": "^6.0.1",
        "find-up": "^5.0.0",
        "glob-parent": "^6.0.2",
        "globals": "^13.19.0",
        "graphemer": "^1.4.0",
        "ignore": "^5.2.0",
        "imurmurhash": "^0.1.4",
        "is-glob": "^4.0.0",
        "is-path-inside": "^3.0.3",
        "js-yaml": "^4.1.0",
        "json-stable-stringify-without-jsonify": "^1.0.1",
        "levn": "^0.4.1",
        "lodash.merge": "^4.6.2",
        "minimatch": "^3.1.2",
        "natural-compare": "^1.4.0",
        "optionator": "^0.9.3",
        "strip-ansi": "^6.0.1",
        "text-table": "^0.2.0"
      },
      "bin": {
        "eslint": "bin/eslint.js"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/eslint-config-next": {
      "version": "14.2.4",
      "resolved": "https://registry.npmjs.org/eslint-config-next/-/eslint-config-next-14.2.4.tgz",
      "integrity": "sha512-Qr0wMgG9m6m4uYy2jrYJmyuNlYZzPRQq5Kvb9IDlYwn+7yq6W6sfMNFgb+9guM1KYwuIo6TIaiFhZJ6SnQ/Efw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@next/eslint-plugin-next": "14.2.4",
        "@rushstack/eslint-patch": "^1.3.3",
        "@typescript-eslint/parser": "^5.4.2 || ^6.0.0 || 7.0.0 - 7.2.0",
        "eslint-import-resolver-node": "^0.3.6",
        "eslint-import-resolver-typescript": "^3.5.2",
        "eslint-plugin-import": "^2.28.1",
        "eslint-plugin-jsx-a11y": "^6.7.1",
        "eslint-plugin-react": "^7.33.2",
        "eslint-plugin-react-hooks": "^4.5.0 || 5.0.0-canary-7118f5dd7-20230705"
      },
      "peerDependencies": {
        "eslint": "^7.23.0 || ^8.0.0",
        "typescript": ">=3.3.1"
      },
      "peerDependenciesMeta": {
        "typescript": {
          "optional": true
        }
      }
    },
    "node_modules/eslint-import-resolver-node": {
      "version": "0.3.9",
      "resolved": "https://registry.npmjs.org/eslint-import-resolver-node/-/eslint-import-resolver-node-0.3.9.tgz",
      "integrity": "sha512-WFj2isz22JahUv+B788TlO3N6zL3nNJGU8CcZbPZvVEkBPaJdCV4vy5wyghty5ROFbCRnm132v8BScu5/1BQ8g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "debug": "^3.2.7",
        "is-core-module": "^2.13.0",
        "resolve": "^1.22.4"
      }
    },
    "node_modules/eslint-import-resolver-node/node_modules/debug": {
      "version": "3.2.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.7.tgz",
      "integrity": "sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.1"
      }
    },
    "node_modules/eslint-import-resolver-typescript": {
      "version": "3.8.6",
      "resolved": "https://registry.npmjs.org/eslint-import-resolver-typescript/-/eslint-import-resolver-typescript-3.8.6.tgz",
      "integrity": "sha512-d9UjvYpj/REmUoZvOtDEmayPlwyP4zOwwMBgtC6RtrpZta8u1AIVmxgZBYJIcCKKXwAcLs+DX2yn2LeMaTqKcQ==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "@nolyfill/is-core-module": "1.0.39",
        "debug": "^4.3.7",
        "enhanced-resolve": "^5.15.0",
        "get-tsconfig": "^4.10.0",
        "is-bun-module": "^1.0.2",
        "stable-hash": "^0.0.4",
        "tinyglobby": "^0.2.12"
      },
      "engines": {
        "node": "^14.18.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/unts/projects/eslint-import-resolver-ts"
      },
      "peerDependencies": {
        "eslint": "*",
        "eslint-plugin-import": "*",
        "eslint-plugin-import-x": "*"
      },
      "peerDependenciesMeta": {
        "eslint-plugin-import": {
          "optional": true
        },
        "eslint-plugin-import-x": {
          "optional": true
        }
      }
    },
    "node_modules/eslint-module-utils": {
      "version": "2.12.0",
      "resolved": "https://registry.npmjs.org/eslint-module-utils/-/eslint-module-utils-2.12.0.tgz",
      "integrity": "sha512-wALZ0HFoytlyh/1+4wuZ9FJCD/leWHQzzrxJ8+rebyReSLk7LApMyd3WJaLVoN+D5+WIdJyDK1c6JnE65V4Zyg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "debug": "^3.2.7"
      },
      "engines": {
        "node": ">=4"
      },
      "peerDependenciesMeta": {
        "eslint": {
          "optional": true
        }
      }
    },
    "node_modules/eslint-module-utils/node_modules/debug": {
      "version": "3.2.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.7.tgz",
      "integrity": "sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.1"
      }
    },
    "node_modules/eslint-plugin-import": {
      "version": "2.31.0",
      "resolved": "https://registry.npmjs.org/eslint-plugin-import/-/eslint-plugin-import-2.31.0.tgz",
      "integrity": "sha512-ixmkI62Rbc2/w8Vfxyh1jQRTdRTF52VxwRVHl/ykPAmqG+Nb7/kNn+byLP0LxPgI7zWA16Jt82SybJInmMia3A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@rtsao/scc": "^1.1.0",
        "array-includes": "^3.1.8",
        "array.prototype.findlastindex": "^1.2.5",
        "array.prototype.flat": "^1.3.2",
        "array.prototype.flatmap": "^1.3.2",
        "debug": "^3.2.7",
        "doctrine": "^2.1.0",
        "eslint-import-resolver-node": "^0.3.9",
        "eslint-module-utils": "^2.12.0",
        "hasown": "^2.0.2",
        "is-core-module": "^2.15.1",
        "is-glob": "^4.0.3",
        "minimatch": "^3.1.2",
        "object.fromentries": "^2.0.8",
        "object.groupby": "^1.0.3",
        "object.values": "^1.2.0",
        "semver": "^6.3.1",
        "string.prototype.trimend": "^1.0.8",
        "tsconfig-paths": "^3.15.0"
      },
      "engines": {
        "node": ">=4"
      },
      "peerDependencies": {
        "eslint": "^2 || ^3 || ^4 || ^5 || ^6 || ^7.2.0 || ^8 || ^9"
      }
    },
    "node_modules/eslint-plugin-import/node_modules/debug": {
      "version": "3.2.7",
      "resolved": "https://registry.npmjs.org/debug/-/debug-3.2.7.tgz",
      "integrity": "sha512-CFjzYYAi4ThfiQvizrFQevTTXHtnCqWfe7x1AhgEscTz6ZbLbfoLRLPugTQyBth6f8ZERVUSyWHFD/7Wu4t1XQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "ms": "^2.1.1"
      }
    },
    "node_modules/eslint-plugin-import/node_modules/doctrine": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/doctrine/-/doctrine-2.1.0.tgz",
      "integrity": "sha512-35mSku4ZXK0vfCuHEDAwt55dg2jNajHZ1odvF+8SSr82EsZY4QmXfuWso8oEd8zRhVObSN18aM0CjSdoBX7zIw==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "esutils": "^2.0.2"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/eslint-plugin-import/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/eslint-plugin-jsx-a11y": {
      "version": "6.10.2",
      "resolved": "https://registry.npmjs.org/eslint-plugin-jsx-a11y/-/eslint-plugin-jsx-a11y-6.10.2.tgz",
      "integrity": "sha512-scB3nz4WmG75pV8+3eRUQOHZlNSUhFNq37xnpgRkCCELU3XMvXAxLk1eqWWyE22Ki4Q01Fnsw9BA3cJHDPgn2Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "aria-query": "^5.3.2",
        "array-includes": "^3.1.8",
        "array.prototype.flatmap": "^1.3.2",
        "ast-types-flow": "^0.0.8",
        "axe-core": "^4.10.0",
        "axobject-query": "^4.1.0",
        "damerau-levenshtein": "^1.0.8",
        "emoji-regex": "^9.2.2",
        "hasown": "^2.0.2",
        "jsx-ast-utils": "^3.3.5",
        "language-tags": "^1.0.9",
        "minimatch": "^3.1.2",
        "object.fromentries": "^2.0.8",
        "safe-regex-test": "^1.0.3",
        "string.prototype.includes": "^2.0.1"
      },
      "engines": {
        "node": ">=4.0"
      },
      "peerDependencies": {
        "eslint": "^3 || ^4 || ^5 || ^6 || ^7 || ^8 || ^9"
      }
    },
    "node_modules/eslint-plugin-react": {
      "version": "7.37.4",
      "resolved": "https://registry.npmjs.org/eslint-plugin-react/-/eslint-plugin-react-7.37.4.tgz",
      "integrity": "sha512-BGP0jRmfYyvOyvMoRX/uoUeW+GqNj9y16bPQzqAHf3AYII/tDs+jMN0dBVkl88/OZwNGwrVFxE7riHsXVfy/LQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-includes": "^3.1.8",
        "array.prototype.findlast": "^1.2.5",
        "array.prototype.flatmap": "^1.3.3",
        "array.prototype.tosorted": "^1.1.4",
        "doctrine": "^2.1.0",
        "es-iterator-helpers": "^1.2.1",
        "estraverse": "^5.3.0",
        "hasown": "^2.0.2",
        "jsx-ast-utils": "^2.4.1 || ^3.0.0",
        "minimatch": "^3.1.2",
        "object.entries": "^1.1.8",
        "object.fromentries": "^2.0.8",
        "object.values": "^1.2.1",
        "prop-types": "^15.8.1",
        "resolve": "^2.0.0-next.5",
        "semver": "^6.3.1",
        "string.prototype.matchall": "^4.0.12",
        "string.prototype.repeat": "^1.0.0"
      },
      "engines": {
        "node": ">=4"
      },
      "peerDependencies": {
        "eslint": "^3 || ^4 || ^5 || ^6 || ^7 || ^8 || ^9.7"
      }
    },
    "node_modules/eslint-plugin-react-hooks": {
      "version": "5.0.0-canary-7118f5dd7-20230705",
      "resolved": "https://registry.npmjs.org/eslint-plugin-react-hooks/-/eslint-plugin-react-hooks-5.0.0-canary-7118f5dd7-20230705.tgz",
      "integrity": "sha512-AZYbMo/NW9chdL7vk6HQzQhT+PvTAEVqWk9ziruUoW2kAOcN5qNyelv70e0F1VNQAbvutOC9oc+xfWycI9FxDw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "eslint": "^3.0.0 || ^4.0.0 || ^5.0.0 || ^6.0.0 || ^7.0.0 || ^8.0.0-0"
      }
    },
    "node_modules/eslint-plugin-react/node_modules/doctrine": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/doctrine/-/doctrine-2.1.0.tgz",
      "integrity": "sha512-35mSku4ZXK0vfCuHEDAwt55dg2jNajHZ1odvF+8SSr82EsZY4QmXfuWso8oEd8zRhVObSN18aM0CjSdoBX7zIw==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "esutils": "^2.0.2"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/eslint-plugin-react/node_modules/resolve": {
      "version": "2.0.0-next.5",
      "resolved": "https://registry.npmjs.org/resolve/-/resolve-2.0.0-next.5.tgz",
      "integrity": "sha512-U7WjGVG9sH8tvjW5SmGbQuui75FiyjAX72HX15DwBBwF9dNiQZRQAg9nnPhYy+TUnE0+VcrttuvNI8oSxZcocA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-core-module": "^2.13.0",
        "path-parse": "^1.0.7",
        "supports-preserve-symlinks-flag": "^1.0.0"
      },
      "bin": {
        "resolve": "bin/resolve"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/eslint-plugin-react/node_modules/semver": {
      "version": "6.3.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-6.3.1.tgz",
      "integrity": "sha512-BR7VvDCVHO+q2xBEWskxS6DJE1qRnb7DxzUrogb71CWoSficBxYsiAGd+Kl0mmq/MprG9yArRkyrQxTO6XjMzA==",
      "dev": true,
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      }
    },
    "node_modules/eslint-scope": {
      "version": "7.2.2",
      "resolved": "https://registry.npmjs.org/eslint-scope/-/eslint-scope-7.2.2.tgz",
      "integrity": "sha512-dOt21O7lTMhDM+X9mB4GX+DZrZtCUJPL/wlcTqxyrx5IvO0IYtILdtrQGQp+8n5S0gwSVmOf9NQrjMOgfQZlIg==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "esrecurse": "^4.3.0",
        "estraverse": "^5.2.0"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/eslint-visitor-keys": {
      "version": "3.4.3",
      "resolved": "https://registry.npmjs.org/eslint-visitor-keys/-/eslint-visitor-keys-3.4.3.tgz",
      "integrity": "sha512-wpc+LXeiyiisxPlEkUzU6svyS1frIO3Mgxj1fdy7Pm8Ygzguax2N3Fa/D/ag1WqbOprdI+uY6wMUl8/a2G+iag==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/espree": {
      "version": "9.6.1",
      "resolved": "https://registry.npmjs.org/espree/-/espree-9.6.1.tgz",
      "integrity": "sha512-oruZaFkjorTpF32kDSI5/75ViwGeZginGGy2NoOSg3Q9bnwlnmDm4HLnkl0RE3n+njDXR037aY1+x58Z/zFdwQ==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "acorn": "^8.9.0",
        "acorn-jsx": "^5.3.2",
        "eslint-visitor-keys": "^3.4.1"
      },
      "engines": {
        "node": "^12.22.0 || ^14.17.0 || >=16.0.0"
      },
      "funding": {
        "url": "https://opencollective.com/eslint"
      }
    },
    "node_modules/esprima": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/esprima/-/esprima-4.0.1.tgz",
      "integrity": "sha512-eGuFFw7Upda+g4p+QHvnW0RyTX/SVeJBDM/gCtMARO0cLuT2HcEKnTPvhjV6aGeqrCB/sbNop0Kszm0jsaWU4A==",
      "devOptional": true,
      "license": "BSD-2-Clause",
      "bin": {
        "esparse": "bin/esparse.js",
        "esvalidate": "bin/esvalidate.js"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/esquery": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/esquery/-/esquery-1.6.0.tgz",
      "integrity": "sha512-ca9pw9fomFcKPvFLXhBKUK90ZvGibiGOvRJNbjljY7s7uq/5YO4BOzcYtJqExdx99rF6aAcnRxHmcUHcz6sQsg==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "estraverse": "^5.1.0"
      },
      "engines": {
        "node": ">=0.10"
      }
    },
    "node_modules/esrecurse": {
      "version": "4.3.0",
      "resolved": "https://registry.npmjs.org/esrecurse/-/esrecurse-4.3.0.tgz",
      "integrity": "sha512-KmfKL3b6G+RXvP8N1vr3Tq1kL/oCFgn2NYXEtqP8/L3pKapUA4G8cFVaoF3SU323CD4XypR/ffioHmkti6/Tag==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "estraverse": "^5.2.0"
      },
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/estraverse": {
      "version": "5.3.0",
      "resolved": "https://registry.npmjs.org/estraverse/-/estraverse-5.3.0.tgz",
      "integrity": "sha512-MMdARuVEQziNTeJD8DgMqmhwR11BRQ/cBP+pLtYdSTnf3MIO8fFeiINEbX36ZdNlfU/7A9f3gUw49B3oQsvwBA==",
      "devOptional": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/estree-util-is-identifier-name": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/estree-util-is-identifier-name/-/estree-util-is-identifier-name-3.0.0.tgz",
      "integrity": "sha512-hFtqIDZTIUZ9BXLb8y4pYGyk6+wekIivNVTcmvk8NoOh+VeRn5y6cEHzbURrWbfp1fIqdVipilzj+lfaadNZmg==",
      "license": "MIT",
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/esutils": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/esutils/-/esutils-2.0.3.tgz",
      "integrity": "sha512-kVscqXk4OCp68SZ0dkgEKVi6/8ij300KBWTJq32P/dYeWTSwK41WyTxalN1eRmA5Z9UU/LX9D7FWSmV9SAYx6g==",
      "devOptional": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/event-target-shim": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/event-target-shim/-/event-target-shim-5.0.1.tgz",
      "integrity": "sha512-i/2XbnSz/uxRCU6+NdVJgKWDTM427+MqYbkQzD321DuCQJUqOuJKIA0IM2+W2xtYHdKOmZ4dR6fExsd4SXL+WQ==",
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/eventemitter3": {
      "version": "4.0.7",
      "resolved": "https://registry.npmjs.org/eventemitter3/-/eventemitter3-4.0.7.tgz",
      "integrity": "sha512-8guHBZCwKnFhYdHr2ysuRWErTwhoN2X8XELRlrRwpmfeY2jjuUN4taQMsULKUVo1K4DvZl+0pgfyoysHxvmvEw==",
      "license": "MIT"
    },
    "node_modules/execa": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/execa/-/execa-5.1.1.tgz",
      "integrity": "sha512-8uSpZZocAZRBAPIEINJj3Lo9HyGitllczc27Eh5YYojjMFMn8yHMDMaUHE2Jqfq05D/wucwI4JGURyXt1vchyg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "cross-spawn": "^7.0.3",
        "get-stream": "^6.0.0",
        "human-signals": "^2.1.0",
        "is-stream": "^2.0.0",
        "merge-stream": "^2.0.0",
        "npm-run-path": "^4.0.1",
        "onetime": "^5.1.2",
        "signal-exit": "^3.0.3",
        "strip-final-newline": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sindresorhus/execa?sponsor=1"
      }
    },
    "node_modules/execa/node_modules/signal-exit": {
      "version": "3.0.7",
      "resolved": "https://registry.npmjs.org/signal-exit/-/signal-exit-3.0.7.tgz",
      "integrity": "sha512-wnD2ZE+l+SPC/uoS0vXeE9L1+0wuaMqKlfz9AMUo38JsyLSBWSFcHR1Rri62LZc12vLr1gb3jl7iwQhgwpAbGQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/exit": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/exit/-/exit-0.1.2.tgz",
      "integrity": "sha512-Zk/eNKV2zbjpKzrsQ+n1G6poVbErQxJ0LBOJXaKZ1EViLzH+hrLu9cdXI4zw9dBQJslwBEpbQ2P1oS7nDxs6jQ==",
      "dev": true,
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/expect": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/expect/-/expect-29.7.0.tgz",
      "integrity": "sha512-2Zks0hf1VLFYI1kbh0I5jP3KHHyCHpkfyHBzsSXRFgl/Bg9mWYfMW8oD+PdMPlEwy5HNsR9JutYy6pMeOh61nw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/expect-utils": "^29.7.0",
        "jest-get-type": "^29.6.3",
        "jest-matcher-utils": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-util": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/expr-eval": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/expr-eval/-/expr-eval-2.0.2.tgz",
      "integrity": "sha512-4EMSHGOPSwAfBiibw3ndnP0AvjDWLsMvGOvWEZ2F96IGk0bIVdjQisOHxReSkE13mHcfbuCiXw+G4y0zv6N8Eg==",
      "license": "MIT"
    },
    "node_modules/extend": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/extend/-/extend-3.0.2.tgz",
      "integrity": "sha512-fjquC59cD7CyW6urNXK0FBufkZcoiGG80wTuPujX590cB5Ttln20E2UB4S/WARVqhXffZl2LNgS+gQdPIIim/g==",
      "license": "MIT"
    },
    "node_modules/fast-deep-equal": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/fast-deep-equal/-/fast-deep-equal-3.1.3.tgz",
      "integrity": "sha512-f3qQ9oQy9j2AhBe/H9VC91wLmKBCCU/gDOnKNAYG5hswO7BLKj09Hc5HYNz9cGI++xlpDCIgDaitVs03ATR84Q==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fast-equals": {
      "version": "5.2.2",
      "resolved": "https://registry.npmjs.org/fast-equals/-/fast-equals-5.2.2.tgz",
      "integrity": "sha512-V7/RktU11J3I36Nwq2JnZEM7tNm17eBJz+u25qdxBZeCKiX6BkVSZQjwWIr+IobgnZy+ag73tTZgZi7tr0LrBw==",
      "license": "MIT",
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/fast-glob": {
      "version": "3.3.3",
      "resolved": "https://registry.npmjs.org/fast-glob/-/fast-glob-3.3.3.tgz",
      "integrity": "sha512-7MptL8U0cqcFdzIzwOTHoilX9x5BrNqye7Z/LuC7kCMRio1EMSyqRK3BEAUD7sXRq4iT4AzTVuZdhgQ2TCvYLg==",
      "license": "MIT",
      "dependencies": {
        "@nodelib/fs.stat": "^2.0.2",
        "@nodelib/fs.walk": "^1.2.3",
        "glob-parent": "^5.1.2",
        "merge2": "^1.3.0",
        "micromatch": "^4.0.8"
      },
      "engines": {
        "node": ">=8.6.0"
      }
    },
    "node_modules/fast-glob/node_modules/glob-parent": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-5.1.2.tgz",
      "integrity": "sha512-AOIgSQCepiJYwP3ARnGx+5VnTu2HBYdzbGP45eLw1vr3zB3vZLeyed1sC9hnbcOc9/SrMyM5RPQrkGz4aS9Zow==",
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.1"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/fast-json-stable-stringify": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/fast-json-stable-stringify/-/fast-json-stable-stringify-2.1.0.tgz",
      "integrity": "sha512-lhd/wF+Lk98HZoTCtlVraHtfh5XYijIjalXck7saUtuanSDyLMxnHhSXEDJqHxD7msR8D0uCmqlkwjCV8xvwHw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fast-levenshtein": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/fast-levenshtein/-/fast-levenshtein-2.0.6.tgz",
      "integrity": "sha512-DCXu6Ifhqcks7TZKY3Hxp3y6qphY5SJZmrWMDrKcERSOXWQdMhU9Ig/PYrzyw/ul9jOIyh0N4M0tbC5hodg8dw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/fastq": {
      "version": "1.19.1",
      "resolved": "https://registry.npmjs.org/fastq/-/fastq-1.19.1.tgz",
      "integrity": "sha512-GwLTyxkCXjXbxqIhTsMI2Nui8huMPtnxg7krajPJAjnEG/iiOS7i+zCtWGZR9G0NBKbXKh6X9m9UIsYX/N6vvQ==",
      "license": "ISC",
      "dependencies": {
        "reusify": "^1.0.4"
      }
    },
    "node_modules/fault": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/fault/-/fault-1.0.4.tgz",
      "integrity": "sha512-CJ0HCB5tL5fYTEA7ToAq5+kTwd++Borf1/bifxd9iT70QcXr4MRrO3Llf8Ifs70q+SJcGHFtnIE/Nw6giCtECA==",
      "license": "MIT",
      "dependencies": {
        "format": "^0.2.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/fb-watchman": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/fb-watchman/-/fb-watchman-2.0.2.tgz",
      "integrity": "sha512-p5161BqbuCaSnB8jIbzQHOlpgsPmK5rJVDfDKO91Axs5NC1uu3HRQm6wt9cd9/+GtQQIO53JdGXXoyDpTAsgYA==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "bser": "2.1.1"
      }
    },
    "node_modules/file-entry-cache": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/file-entry-cache/-/file-entry-cache-6.0.1.tgz",
      "integrity": "sha512-7Gps/XWymbLk2QLYK4NzpMOrYjMhdIxXuIvy2QBsLE6ljuodKvdkWs/cpyJJ3CVIVpH0Oi1Hvg1ovbMzLdFBBg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "flat-cache": "^3.0.4"
      },
      "engines": {
        "node": "^10.12.0 || >=12.0.0"
      }
    },
    "node_modules/fill-range": {
      "version": "7.1.1",
      "resolved": "https://registry.npmjs.org/fill-range/-/fill-range-7.1.1.tgz",
      "integrity": "sha512-YsGpe3WHLK8ZYi4tWDg2Jy3ebRz2rXowDxnld4bkQB00cc/1Zw9AWnC0i9ztDJitivtQvaI9KaLyKrc+hBW0yg==",
      "license": "MIT",
      "dependencies": {
        "to-regex-range": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/find-up": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/find-up/-/find-up-5.0.0.tgz",
      "integrity": "sha512-78/PXT1wlLLDgTzDs7sjq9hzz0vXD+zn+7wypEe4fXQxCmdmqfGsEPQxmiCSQI3ajFV91bVSsvNtrJRiW6nGng==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "locate-path": "^6.0.0",
        "path-exists": "^4.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/flat": {
      "version": "5.0.2",
      "resolved": "https://registry.npmjs.org/flat/-/flat-5.0.2.tgz",
      "integrity": "sha512-b6suED+5/3rTpUBdG1gupIl8MPFCAMA0QXwmljLhvCUKcUvdE4gWky9zpuGCcXHOsz4J9wPGNWq6OKpmIzz3hQ==",
      "license": "BSD-3-Clause",
      "bin": {
        "flat": "cli.js"
      }
    },
    "node_modules/flat-cache": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/flat-cache/-/flat-cache-3.2.0.tgz",
      "integrity": "sha512-CYcENa+FtcUKLmhhqyctpclsq7QF38pKjZHsGNiSQF5r4FtoKDWabFDl3hzaEQMvT1LHEysw5twgLvpYYb4vbw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "flatted": "^3.2.9",
        "keyv": "^4.5.3",
        "rimraf": "^3.0.2"
      },
      "engines": {
        "node": "^10.12.0 || >=12.0.0"
      }
    },
    "node_modules/flatted": {
      "version": "3.3.3",
      "resolved": "https://registry.npmjs.org/flatted/-/flatted-3.3.3.tgz",
      "integrity": "sha512-GX+ysw4PBCz0PzosHDepZGANEuFCMLrnRTiEy9McGjmkCQYwRq4A/X786G/fjM/+OjsWSU1ZrY5qyARZmO/uwg==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/for-each": {
      "version": "0.3.5",
      "resolved": "https://registry.npmjs.org/for-each/-/for-each-0.3.5.tgz",
      "integrity": "sha512-dKx12eRCVIzqCxFGplyFKJMPvLEWgmNtUrpTiJIR5u97zEhRG8ySrtboPHZXx7daLxQVrl643cTzbab2tkQjxg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-callable": "^1.2.7"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/foreground-child": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/foreground-child/-/foreground-child-3.3.1.tgz",
      "integrity": "sha512-gIXjKqtFuWEgzFRJA9WCQeSJLZDjgJUOMCMzxtvFq/37KojM1BFGufqsCy0r4qSQmYLsZYMeyRqzIWOMup03sw==",
      "license": "ISC",
      "dependencies": {
        "cross-spawn": "^7.0.6",
        "signal-exit": "^4.0.1"
      },
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/form-data": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/form-data/-/form-data-4.0.2.tgz",
      "integrity": "sha512-hGfm/slu0ZabnNt4oaRZ6uREyfCj6P4fT/n6A1rGV+Z0VdGXjfOhVUpkn6qVQONHGIFwmveGXyDs75+nr6FM8w==",
      "license": "MIT",
      "dependencies": {
        "asynckit": "^0.4.0",
        "combined-stream": "^1.0.8",
        "es-set-tostringtag": "^2.1.0",
        "mime-types": "^2.1.12"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/form-data-encoder": {
      "version": "1.7.2",
      "resolved": "https://registry.npmjs.org/form-data-encoder/-/form-data-encoder-1.7.2.tgz",
      "integrity": "sha512-qfqtYan3rxrnCk1VYaA4H+Ms9xdpPqvLZa6xmMgFvhO32x7/3J/ExcTd6qpxM0vH2GdMI+poehyBZvqfMTto8A==",
      "license": "MIT"
    },
    "node_modules/format": {
      "version": "0.2.2",
      "resolved": "https://registry.npmjs.org/format/-/format-0.2.2.tgz",
      "integrity": "sha512-wzsgA6WOq+09wrU1tsJ09udeR/YZRaeArL9e1wPbFg3GG2yDnC2ldKpxs4xunpFF9DgqCqOIra3bc1HWrJ37Ww==",
      "engines": {
        "node": ">=0.4.x"
      }
    },
    "node_modules/formdata-node": {
      "version": "4.4.1",
      "resolved": "https://registry.npmjs.org/formdata-node/-/formdata-node-4.4.1.tgz",
      "integrity": "sha512-0iirZp3uVDjVGt9p49aTaqjk84TrglENEDuqfdlZQ1roC9CWlPk6Avf8EEnZNcAqPonwkG35x4n3ww/1THYAeQ==",
      "license": "MIT",
      "dependencies": {
        "node-domexception": "1.0.0",
        "web-streams-polyfill": "4.0.0-beta.3"
      },
      "engines": {
        "node": ">= 12.20"
      }
    },
    "node_modules/formdata-node/node_modules/web-streams-polyfill": {
      "version": "4.0.0-beta.3",
      "resolved": "https://registry.npmjs.org/web-streams-polyfill/-/web-streams-polyfill-4.0.0-beta.3.tgz",
      "integrity": "sha512-QW95TCTaHmsYfHDybGMwO5IJIM93I/6vTRk+daHTWFPhwh+C8Cg7j7XyKrwrj8Ib6vYXe0ocYNrmzY4xAAN6ug==",
      "license": "MIT",
      "engines": {
        "node": ">= 14"
      }
    },
    "node_modules/fraction.js": {
      "version": "4.3.7",
      "resolved": "https://registry.npmjs.org/fraction.js/-/fraction.js-4.3.7.tgz",
      "integrity": "sha512-ZsDfxO51wGAXREY55a7la9LScWpwv9RxIrYABrlvOFBlH/ShPnrtsXeuUIfXKKOVicNxQ+o8JTbJvjS4M89yew==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "*"
      },
      "funding": {
        "type": "patreon",
        "url": "https://github.com/sponsors/rawify"
      }
    },
    "node_modules/fs.realpath": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/fs.realpath/-/fs.realpath-1.0.0.tgz",
      "integrity": "sha512-OO0pH2lK6a0hZnAdau5ItzHPI6pUlvI7jMVnxUQRtw4owF2wk8lOSabtGDCTP4Ggrg2MbGnWO9X8K1t4+fGMDw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/fsevents": {
      "version": "2.3.3",
      "resolved": "https://registry.npmjs.org/fsevents/-/fsevents-2.3.3.tgz",
      "integrity": "sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==",
      "hasInstallScript": true,
      "license": "MIT",
      "optional": true,
      "os": [
        "darwin"
      ],
      "engines": {
        "node": "^8.16.0 || ^10.6.0 || >=11.0.0"
      }
    },
    "node_modules/function-bind": {
      "version": "1.1.2",
      "resolved": "https://registry.npmjs.org/function-bind/-/function-bind-1.1.2.tgz",
      "integrity": "sha512-7XHNxH7qX9xG5mIwxkhumTox/MIRNcOgDrxWsMt2pAr23WHp6MrRlN7FBSFpCpr+oVO0F744iUgR82nJMfG2SA==",
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/function.prototype.name": {
      "version": "1.1.8",
      "resolved": "https://registry.npmjs.org/function.prototype.name/-/function.prototype.name-1.1.8.tgz",
      "integrity": "sha512-e5iwyodOHhbMr/yNrc7fDYG4qlbIvI5gajyzPnb5TCwyhjApznQh1BMFou9b30SevY43gCJKXycoCBjMbsuW0Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "functions-have-names": "^1.2.3",
        "hasown": "^2.0.2",
        "is-callable": "^1.2.7"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/functions-have-names": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/functions-have-names/-/functions-have-names-1.2.3.tgz",
      "integrity": "sha512-xckBUXyTIqT97tq2x2AMb+g163b5JFysYk0x4qxNFwbfQkmNZoiRHb6sPzI9/QV33WeuvVYBUIiD4NzNIyqaRQ==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/gensync": {
      "version": "1.0.0-beta.2",
      "resolved": "https://registry.npmjs.org/gensync/-/gensync-1.0.0-beta.2.tgz",
      "integrity": "sha512-3hN7NaskYvMDLQY55gnW3NQ+mesEAepTqlg+VEbj7zzqEMBVNhzcGYYeqFo/TlYz6eQiFcp1HcsCZO+nGgS8zg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.9.0"
      }
    },
    "node_modules/get-caller-file": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/get-caller-file/-/get-caller-file-2.0.5.tgz",
      "integrity": "sha512-DyFP3BM/3YHTQOCUL/w0OZHR0lpKeGrxotcHWcqNEdnltqFwXVfhEBQ94eIo34AfQpo0rGki4cyIiftY06h2Fg==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": "6.* || 8.* || >= 10.*"
      }
    },
    "node_modules/get-intrinsic": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/get-intrinsic/-/get-intrinsic-1.3.0.tgz",
      "integrity": "sha512-9fSjSaos/fRIVIp+xSJlE6lfwhES7LNtKaCBIamHsjr2na1BiABJPo0mOjjz8GJDURarmCPGqaiVg5mfjb98CQ==",
      "license": "MIT",
      "dependencies": {
        "call-bind-apply-helpers": "^1.0.2",
        "es-define-property": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.1.1",
        "function-bind": "^1.1.2",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "has-symbols": "^1.1.0",
        "hasown": "^2.0.2",
        "math-intrinsics": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-nonce": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/get-nonce/-/get-nonce-1.0.1.tgz",
      "integrity": "sha512-FJhYRoDaiatfEkUK8HKlicmu/3SGFD51q3itKDGoSTysQJBnfOcxU5GxnhE1E6soB76MbT0MBtnKJuXyAx+96Q==",
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/get-package-type": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/get-package-type/-/get-package-type-0.1.0.tgz",
      "integrity": "sha512-pjzuKtY64GYfWizNAJ0fr9VqttZkNiK2iS430LtIHzjBEr6bX8Am2zm4sW4Ro5wjWW5cAlRL1qAMTcXbjNAO2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8.0.0"
      }
    },
    "node_modules/get-proto": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/get-proto/-/get-proto-1.0.1.tgz",
      "integrity": "sha512-sTSfBjoXBp89JvIKIefqw7U2CCebsc74kiY6awiGogKtoSGbgjYE/G/+l9sF3MWFPNc9IcoOC4ODfKHfxFmp0g==",
      "license": "MIT",
      "dependencies": {
        "dunder-proto": "^1.0.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/get-stream": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/get-stream/-/get-stream-6.0.1.tgz",
      "integrity": "sha512-ts6Wi+2j3jQjqi70w5AlN8DFnkSwC+MqmxEzdEALB2qXZYV3X/b1CTfgPLGJNMeAWxdPfU8FO1ms3NUfaHCPYg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/get-symbol-description": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/get-symbol-description/-/get-symbol-description-1.1.0.tgz",
      "integrity": "sha512-w9UMqWwJxHNOvoNzSJ2oPF5wvYcvP7jUvYzhp67yEhTi17ZDBBC1z9pTdGuzjD+EFIqLSYRweZjqfiPzQ06Ebg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.6"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/get-tsconfig": {
      "version": "4.10.0",
      "resolved": "https://registry.npmjs.org/get-tsconfig/-/get-tsconfig-4.10.0.tgz",
      "integrity": "sha512-kGzZ3LWWQcGIAmg6iWvXn0ei6WDtV26wzHRMwDSzmAbcXrTEXxHy6IehI6/4eT6VRKyMP1eF1VqwrVUmE/LR7A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "resolve-pkg-maps": "^1.0.0"
      },
      "funding": {
        "url": "https://github.com/privatenumber/get-tsconfig?sponsor=1"
      }
    },
    "node_modules/glob": {
      "version": "10.3.10",
      "resolved": "https://registry.npmjs.org/glob/-/glob-10.3.10.tgz",
      "integrity": "sha512-fa46+tv1Ak0UPK1TOy/pZrIybNNt4HCv7SDzwyfiOZkvZLEbjsZkJBPtDHVshZjbecAoAGSC20MjLDG/qr679g==",
      "license": "ISC",
      "dependencies": {
        "foreground-child": "^3.1.0",
        "jackspeak": "^2.3.5",
        "minimatch": "^9.0.1",
        "minipass": "^5.0.0 || ^6.0.2 || ^7.0.0",
        "path-scurry": "^1.10.1"
      },
      "bin": {
        "glob": "dist/esm/bin.mjs"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/glob-parent": {
      "version": "6.0.2",
      "resolved": "https://registry.npmjs.org/glob-parent/-/glob-parent-6.0.2.tgz",
      "integrity": "sha512-XxwI8EOhVQgWp6iDL+3b0r86f4d6AX6zSU55HfB4ydCEuXLXc5FcYeOu+nnGftS4TEju/11rt4KJPTMgbfmv4A==",
      "license": "ISC",
      "dependencies": {
        "is-glob": "^4.0.3"
      },
      "engines": {
        "node": ">=10.13.0"
      }
    },
    "node_modules/glob/node_modules/brace-expansion": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/brace-expansion/-/brace-expansion-2.0.1.tgz",
      "integrity": "sha512-XnAIvQ8eM+kC6aULx6wuQiwVsnzsi9d3WxzV3FpWTGA19F621kwdbsAcFKXgKUHZWsy+mY6iL1sHTxWEFCytDA==",
      "license": "MIT",
      "dependencies": {
        "balanced-match": "^1.0.0"
      }
    },
    "node_modules/glob/node_modules/minimatch": {
      "version": "9.0.5",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-9.0.5.tgz",
      "integrity": "sha512-G6T0ZX48xgozx7587koeX9Ys2NYy6Gmv//P89sEte9V9whIapMNF4idKxnW2QtCcLiTWlb/wfCabAtAFWhhBow==",
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^2.0.1"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/globals": {
      "version": "13.24.0",
      "resolved": "https://registry.npmjs.org/globals/-/globals-13.24.0.tgz",
      "integrity": "sha512-AhO5QUcj8llrbG09iWhPU2B204J1xnPeL8kQmVorSsy+Sjj1sk8gIyh6cUocGmH4L0UuhAJy+hJMRA4mgA4mFQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "type-fest": "^0.20.2"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/globalthis": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/globalthis/-/globalthis-1.0.4.tgz",
      "integrity": "sha512-DpLKbNU4WylpxJykQujfCcwYWiV/Jhm50Goo0wrVILAv5jOr9d+H+UR3PhSCD2rCCEIg0uc+G+muBTwD54JhDQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-properties": "^1.2.1",
        "gopd": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/globby": {
      "version": "11.1.0",
      "resolved": "https://registry.npmjs.org/globby/-/globby-11.1.0.tgz",
      "integrity": "sha512-jhIXaOzy1sb8IyocaruWSn1TjmnBVs8Ayhcy83rmxNJ8q2uWKCAj3CnJY+KpGSXCueAPc0i05kVvVKtP1t9S3g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-union": "^2.1.0",
        "dir-glob": "^3.0.1",
        "fast-glob": "^3.2.9",
        "ignore": "^5.2.0",
        "merge2": "^1.4.1",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/gopd": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/gopd/-/gopd-1.2.0.tgz",
      "integrity": "sha512-ZUKRh6/kUFoAiTAtTYPZJ3hw9wNxx+BIBOijnlG9PnrJsCcSjs1wyyD6vJpaYtgnzDrKYRSqf3OO6Rfa93xsRg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/graceful-fs": {
      "version": "4.2.11",
      "resolved": "https://registry.npmjs.org/graceful-fs/-/graceful-fs-4.2.11.tgz",
      "integrity": "sha512-RbJ5/jmFcNNCcDV5o9eTnBLJ/HszWV0P73bc+Ff4nS/rJj+YaS6IGyiOL0VoBYX+l1Wrl3k63h/KrH+nhJ0XvQ==",
      "license": "ISC"
    },
    "node_modules/graphemer": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/graphemer/-/graphemer-1.4.0.tgz",
      "integrity": "sha512-EtKwoO6kxCL9WO5xipiHTZlSzBm7WLT627TqC/uVRd0HKmq8NXyebnNYxDoBi7wt8eTWrUrKXCOVaFq9x1kgag==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/harmony-reflect": {
      "version": "1.6.2",
      "resolved": "https://registry.npmjs.org/harmony-reflect/-/harmony-reflect-1.6.2.tgz",
      "integrity": "sha512-HIp/n38R9kQjDEziXyDTuW3vvoxxyxjxFzXLrBr18uB47GnSt+G9D29fqrpM5ZkspMcPICud3XsBJQ4Y2URg8g==",
      "dev": true,
      "license": "(Apache-2.0 OR MPL-1.1)"
    },
    "node_modules/has-bigints": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/has-bigints/-/has-bigints-1.1.0.tgz",
      "integrity": "sha512-R3pbpkcIqv2Pm3dUwgjclDRVmWpTJW2DcMzcIhEXEx1oh/CEMObMm3KLmRJOdvhM7o4uQBnwr8pzRK2sJWIqfg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-flag": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/has-flag/-/has-flag-4.0.0.tgz",
      "integrity": "sha512-EykJT/Q1KjTWctppgIAgfSO0tKVuZUjhgMr17kqTumMl6Afv3EISleU7qZUzoXDFTAHTDC4NOoG/ZxU3EvlMPQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/has-property-descriptors": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/has-property-descriptors/-/has-property-descriptors-1.0.2.tgz",
      "integrity": "sha512-55JNKuIW+vq4Ke1BjOTjM2YctQIvCT7GFzHwmfZPGo5wnrgkid0YQtnAleFSqumZm4az3n2BS+erby5ipJdgrg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-define-property": "^1.0.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-proto": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/has-proto/-/has-proto-1.2.0.tgz",
      "integrity": "sha512-KIL7eQPfHQRC8+XluaIw7BHUwwqL19bQn4hzNgdr+1wXoU0KKj6rufu47lhY7KbJR2C6T6+PfyN0Ea7wkSS+qQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "dunder-proto": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-symbols": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/has-symbols/-/has-symbols-1.1.0.tgz",
      "integrity": "sha512-1cDNdwJ2Jaohmb3sg4OmKaMBwuC48sYni5HUw2DvsC8LjGTLK9h+eb1X6RyuOHe4hT0ULCW68iomhjUoKUqlPQ==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/has-tostringtag": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/has-tostringtag/-/has-tostringtag-1.0.2.tgz",
      "integrity": "sha512-NqADB8VjPFLM2V0VvHUewwwsw0ZWBaIdgo+ieHtK3hasLz4qeCRjYcqfB6AQrBggRKppKF8L52/VqdVsO47Dlw==",
      "license": "MIT",
      "dependencies": {
        "has-symbols": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/hasown": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/hasown/-/hasown-2.0.2.tgz",
      "integrity": "sha512-0hJU9SCPvmMzIBdZFqNPXWa6dqh7WdH0cII9y+CyS8rG3nL48Bclra9HmKhVVUHyPWNH5Y7xDwAB7bfgSjkUMQ==",
      "license": "MIT",
      "dependencies": {
        "function-bind": "^1.1.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/hast-util-parse-selector": {
      "version": "2.2.5",
      "resolved": "https://registry.npmjs.org/hast-util-parse-selector/-/hast-util-parse-selector-2.2.5.tgz",
      "integrity": "sha512-7j6mrk/qqkSehsM92wQjdIgWM2/BW61u/53G6xmC8i1OmEdKLHbk419QKQUjz6LglWsfqoiHmyMRkP1BGjecNQ==",
      "license": "MIT",
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/hast-util-to-jsx-runtime": {
      "version": "2.3.6",
      "resolved": "https://registry.npmjs.org/hast-util-to-jsx-runtime/-/hast-util-to-jsx-runtime-2.3.6.tgz",
      "integrity": "sha512-zl6s8LwNyo1P9uw+XJGvZtdFF1GdAkOg8ujOw+4Pyb76874fLps4ueHXDhXWdk6YHQ6OgUtinliG7RsYvCbbBg==",
      "license": "MIT",
      "dependencies": {
        "@types/estree": "^1.0.0",
        "@types/hast": "^3.0.0",
        "@types/unist": "^3.0.0",
        "comma-separated-tokens": "^2.0.0",
        "devlop": "^1.0.0",
        "estree-util-is-identifier-name": "^3.0.0",
        "hast-util-whitespace": "^3.0.0",
        "mdast-util-mdx-expression": "^2.0.0",
        "mdast-util-mdx-jsx": "^3.0.0",
        "mdast-util-mdxjs-esm": "^2.0.0",
        "property-information": "^7.0.0",
        "space-separated-tokens": "^2.0.0",
        "style-to-js": "^1.0.0",
        "unist-util-position": "^5.0.0",
        "vfile-message": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/hast-util-whitespace": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/hast-util-whitespace/-/hast-util-whitespace-3.0.0.tgz",
      "integrity": "sha512-88JUN06ipLwsnv+dVn+OIYOvAuvBMy/Qoi6O7mQHxdPXpjy+Cd6xRkWwux7DKO+4sYILtLBRIKgsdpS2gQc7qw==",
      "license": "MIT",
      "dependencies": {
        "@types/hast": "^3.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/hastscript": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/hastscript/-/hastscript-6.0.0.tgz",
      "integrity": "sha512-nDM6bvd7lIqDUiYEiu5Sl/+6ReP0BMk/2f4U/Rooccxkj0P5nm+acM5PrGJ/t5I8qPGiqZSE6hVAwZEdZIvP4w==",
      "license": "MIT",
      "dependencies": {
        "@types/hast": "^2.0.0",
        "comma-separated-tokens": "^1.0.0",
        "hast-util-parse-selector": "^2.0.0",
        "property-information": "^5.0.0",
        "space-separated-tokens": "^1.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/hastscript/node_modules/@types/hast": {
      "version": "2.3.10",
      "resolved": "https://registry.npmjs.org/@types/hast/-/hast-2.3.10.tgz",
      "integrity": "sha512-McWspRw8xx8J9HurkVBfYj0xKoE25tOFlHGdx4MJ5xORQrMGZNqJhVQWaIbm6Oyla5kYOXtDiopzKRJzEOkwJw==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^2"
      }
    },
    "node_modules/hastscript/node_modules/@types/unist": {
      "version": "2.0.11",
      "resolved": "https://registry.npmjs.org/@types/unist/-/unist-2.0.11.tgz",
      "integrity": "sha512-CmBKiL6NNo/OqgmMn95Fk9Whlp2mtvIv+KNpQKN2F4SjvrEesubTRWGYSg+BnWZOnlCaSTU1sMpsBOzgbYhnsA==",
      "license": "MIT"
    },
    "node_modules/hastscript/node_modules/comma-separated-tokens": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/comma-separated-tokens/-/comma-separated-tokens-1.0.8.tgz",
      "integrity": "sha512-GHuDRO12Sypu2cV70d1dkA2EUmXHgntrzbpvOB+Qy+49ypNfGgFQIC2fhhXbnyrJRynDCAARsT7Ou0M6hirpfw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/hastscript/node_modules/property-information": {
      "version": "5.6.0",
      "resolved": "https://registry.npmjs.org/property-information/-/property-information-5.6.0.tgz",
      "integrity": "sha512-YUHSPk+A30YPv+0Qf8i9Mbfe/C0hdPXk1s1jPVToV8pk8BQtpw10ct89Eo7OWkutrwqvT0eicAxlOg3dOAu8JA==",
      "license": "MIT",
      "dependencies": {
        "xtend": "^4.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/hastscript/node_modules/space-separated-tokens": {
      "version": "1.1.5",
      "resolved": "https://registry.npmjs.org/space-separated-tokens/-/space-separated-tokens-1.1.5.tgz",
      "integrity": "sha512-q/JSVd1Lptzhf5bkYm4ob4iWPjx0KiRe3sRFBNrVqbJkFaBm5vbbowy1mymoPNLRa52+oadOhJ+K49wsSeSjTA==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/highlight.js": {
      "version": "10.7.3",
      "resolved": "https://registry.npmjs.org/highlight.js/-/highlight.js-10.7.3.tgz",
      "integrity": "sha512-tzcUFauisWKNHaRkN4Wjl/ZA07gENAjFl3J/c480dprkGTg5EQstgaNFqBfUqCq54kZRIEcreTsAgF/m2quD7A==",
      "license": "BSD-3-Clause",
      "engines": {
        "node": "*"
      }
    },
    "node_modules/highlightjs-vue": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/highlightjs-vue/-/highlightjs-vue-1.0.0.tgz",
      "integrity": "sha512-PDEfEF102G23vHmPhLyPboFCD+BkMGu+GuJe2d9/eH4FsCwvgBpnc9n0pGE+ffKdph38s6foEZiEjdgHdzp+IA==",
      "license": "CC0-1.0"
    },
    "node_modules/html-encoding-sniffer": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/html-encoding-sniffer/-/html-encoding-sniffer-3.0.0.tgz",
      "integrity": "sha512-oWv4T4yJ52iKrufjnyZPkrN0CH3QnrUqdB6In1g5Fe1mia8GmF36gnfNySxoZtxD5+NmYw1EElVXiBk93UeskA==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "whatwg-encoding": "^2.0.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/html-escaper": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/html-escaper/-/html-escaper-2.0.2.tgz",
      "integrity": "sha512-H2iMtd0I4Mt5eYiapRdIDjp+XzelXQ0tFE4JS7YFwFevXXMmOp9myNrUvCg0D6ws8iqkRPBfKHgbwig1SmlLfg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/html-url-attributes": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/html-url-attributes/-/html-url-attributes-3.0.1.tgz",
      "integrity": "sha512-ol6UPyBWqsrO6EJySPz2O7ZSr856WDrEzM5zMqp+FJJLGMW35cLYmmZnl0vztAZxRUoNZJFTCohfjuIJ8I4QBQ==",
      "license": "MIT",
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/http-proxy-agent": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/http-proxy-agent/-/http-proxy-agent-5.0.0.tgz",
      "integrity": "sha512-n2hY8YdoRE1i7r6M0w9DIw5GgZN0G25P8zLCRQ8rjXtTU3vsNFBI/vWK/UIeE6g5MUUz6avwAPXmL6Fy9D/90w==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "@tootallnate/once": "2",
        "agent-base": "6",
        "debug": "4"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/https-proxy-agent": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/https-proxy-agent/-/https-proxy-agent-5.0.1.tgz",
      "integrity": "sha512-dFcAjpTQFgoLMzC2VwU+C/CbS7uRL0lWmxDITmqm7C+7F0Odmj6s9l6alZc6AELXhrnggM2CeWSXHGOdX2YtwA==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "agent-base": "6",
        "debug": "4"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/human-signals": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/human-signals/-/human-signals-2.1.0.tgz",
      "integrity": "sha512-B4FFZ6q/T2jhhksgkbEW3HBvWIfDW85snkQgawt07S7J5QXTk6BkNV+0yAeZrM5QpMAdYlocGoljn0sJ/WQkFw==",
      "dev": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=10.17.0"
      }
    },
    "node_modules/humanize-ms": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/humanize-ms/-/humanize-ms-1.2.1.tgz",
      "integrity": "sha512-Fl70vYtsAFb/C06PTS9dZBo7ihau+Tu/DNCk/OyHhea07S+aeMWpFFkUaXRa8fI+ScZbEI8dfSxwY7gxZ9SAVQ==",
      "license": "MIT",
      "dependencies": {
        "ms": "^2.0.0"
      }
    },
    "node_modules/iconv-lite": {
      "version": "0.6.3",
      "resolved": "https://registry.npmjs.org/iconv-lite/-/iconv-lite-0.6.3.tgz",
      "integrity": "sha512-4fCk79wshMdzMp2rH06qWrJE4iolqLhCUH+OiuIgU++RB0+94NlDL81atO7GX55uUKueo0txHNtvEyI6D7WdMw==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "safer-buffer": ">= 2.1.2 < 3.0.0"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/identity-obj-proxy": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/identity-obj-proxy/-/identity-obj-proxy-3.0.0.tgz",
      "integrity": "sha512-00n6YnVHKrinT9t0d9+5yZC6UBNJANpYEQvL2LlX6Ab9lnmxzIRcEmTPuyGScvl1+jKuCICX1Z0Ab1pPKKdikA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "harmony-reflect": "^1.4.6"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/ignore": {
      "version": "5.3.2",
      "resolved": "https://registry.npmjs.org/ignore/-/ignore-5.3.2.tgz",
      "integrity": "sha512-hsBTNUqQTDwkWtcdYI2i06Y/nUBEsNEDJKjWdigLvegy8kDuJAS8uRlpkkcQpyEXL0Z/pjDy5HBmMjRCJ2gq+g==",
      "devOptional": true,
      "license": "MIT",
      "engines": {
        "node": ">= 4"
      }
    },
    "node_modules/import-fresh": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/import-fresh/-/import-fresh-3.3.1.tgz",
      "integrity": "sha512-TR3KfrTZTYLPB6jUjfx6MF9WcWrHL9su5TObK4ZkYgBdWKPOFoSoQIdEuTuR82pmtxH2spWG9h6etwfr1pLBqQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "parent-module": "^1.0.0",
        "resolve-from": "^4.0.0"
      },
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/import-local": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/import-local/-/import-local-3.2.0.tgz",
      "integrity": "sha512-2SPlun1JUPWoM6t3F0dw0FkCF/jWY8kttcY4f599GLTSjh2OCuuhdTkJQsEcZzBqbXZGKMK2OqW1oZsjtf/gQA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "pkg-dir": "^4.2.0",
        "resolve-cwd": "^3.0.0"
      },
      "bin": {
        "import-local-fixture": "fixtures/cli.js"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/imurmurhash": {
      "version": "0.1.4",
      "resolved": "https://registry.npmjs.org/imurmurhash/-/imurmurhash-0.1.4.tgz",
      "integrity": "sha512-JmXMZ6wuvDmLiHEml9ykzqO6lwFbof0GG4IkcGaENdCRDDmMVnny7s5HsIgHCbaq0w2MyPhDqkhTUgS2LU2PHA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.8.19"
      }
    },
    "node_modules/indent-string": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/indent-string/-/indent-string-4.0.0.tgz",
      "integrity": "sha512-EdDDZu4A2OyIK7Lr/2zG+w5jmbuk1DVBnEwREQvBzspBJkCEbRa8GxU1lghYcaGJCnRWibjDXlq779X1/y5xwg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/inflight": {
      "version": "1.0.6",
      "resolved": "https://registry.npmjs.org/inflight/-/inflight-1.0.6.tgz",
      "integrity": "sha512-k92I/b08q4wvFscXCLvqfsHCrjrF7yiXsQuIVvVE7N82W3+aqpzuUdBbfhWcy/FZR3/4IgflMgKLOsvPDrGCJA==",
      "deprecated": "This module is not supported, and leaks memory. Do not use it. Check out lru-cache if you want a good and tested way to coalesce async requests by a key value, which is much more comprehensive and powerful.",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "once": "^1.3.0",
        "wrappy": "1"
      }
    },
    "node_modules/inherits": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/inherits/-/inherits-2.0.4.tgz",
      "integrity": "sha512-k/vGaX4/Yla3WzyMCvTQOXYeIHvqOKtnqBduzTHpzpQZzAskKMhZ2K+EnBiSM9zGSoIFeMpXKxa4dYeZIQqewQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/inline-style-parser": {
      "version": "0.2.4",
      "resolved": "https://registry.npmjs.org/inline-style-parser/-/inline-style-parser-0.2.4.tgz",
      "integrity": "sha512-0aO8FkhNZlj/ZIbNi7Lxxr12obT7cL1moPfE4tg1LkX7LlLfC6DeX4l2ZEud1ukP9jNQyNnfzQVqwbwmAATY4Q==",
      "license": "MIT"
    },
    "node_modules/internal-slot": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/internal-slot/-/internal-slot-1.1.0.tgz",
      "integrity": "sha512-4gd7VpWNQNB4UKKCFFVcp1AVv+FMOgs9NKzjHKusc8jTMhd5eL1NqQqOpE0KzMds804/yHlglp3uxgluOqAPLw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "hasown": "^2.0.2",
        "side-channel": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/internmap": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/internmap/-/internmap-2.0.3.tgz",
      "integrity": "sha512-5Hh7Y1wQbvY5ooGgPbDaL5iYLAPzMTUrjMulskHLH6wnv/A+1q5rgEaiuqEjB+oxGXIVZs1FF+R/KPN3ZSQYYg==",
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/is-alphabetical": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-alphabetical/-/is-alphabetical-2.0.1.tgz",
      "integrity": "sha512-FWyyY60MeTNyeSRpkM2Iry0G9hpr7/9kD40mD/cGQEuilcZYS4okz8SN2Q6rLCJ8gbCt6fN+rC+6tMGS99LaxQ==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/is-alphanumerical": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-alphanumerical/-/is-alphanumerical-2.0.1.tgz",
      "integrity": "sha512-hmbYhX/9MUMF5uh7tOXyK/n0ZvWpad5caBA17GsC6vyuCqaWliRG5K1qS9inmUhEMaOBIW7/whAnSwveW/LtZw==",
      "license": "MIT",
      "dependencies": {
        "is-alphabetical": "^2.0.0",
        "is-decimal": "^2.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/is-any-array": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-any-array/-/is-any-array-2.0.1.tgz",
      "integrity": "sha512-UtilS7hLRu++wb/WBAw9bNuP1Eg04Ivn1vERJck8zJthEvXCBEBpGR/33u/xLKWEQf95803oalHrVDptcAvFdQ==",
      "license": "MIT"
    },
    "node_modules/is-array-buffer": {
      "version": "3.0.5",
      "resolved": "https://registry.npmjs.org/is-array-buffer/-/is-array-buffer-3.0.5.tgz",
      "integrity": "sha512-DDfANUiiG2wC1qawP66qlTugJeL5HyzMpfr8lLK+jMQirGzNod0B12cFB/9q838Ru27sBwfw78/rdoU7RERz6A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "get-intrinsic": "^1.2.6"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-arrayish": {
      "version": "0.2.1",
      "resolved": "https://registry.npmjs.org/is-arrayish/-/is-arrayish-0.2.1.tgz",
      "integrity": "sha512-zz06S8t0ozoDXMG+ube26zeCTNXcKIPJZJi8hBrF4idCLms4CG9QtK7qBl1boi5ODzFpjswb5JPmHCbMpjaYzg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/is-async-function": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/is-async-function/-/is-async-function-2.1.1.tgz",
      "integrity": "sha512-9dgM/cZBnNvjzaMYHVoxxfPj2QXt22Ev7SuuPrs+xav0ukGB0S6d4ydZdEiM48kLx5kDV+QBPrpVnFyefL8kkQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "async-function": "^1.0.0",
        "call-bound": "^1.0.3",
        "get-proto": "^1.0.1",
        "has-tostringtag": "^1.0.2",
        "safe-regex-test": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-bigint": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/is-bigint/-/is-bigint-1.1.0.tgz",
      "integrity": "sha512-n4ZT37wG78iz03xPRKJrHTdZbe3IicyucEtdRsV5yglwc3GyUfbAfpSeD0FJ41NbUNSt5wbhqfp1fS+BgnvDFQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-bigints": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-binary-path": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/is-binary-path/-/is-binary-path-2.1.0.tgz",
      "integrity": "sha512-ZMERYes6pDydyuGidse7OsHxtbI7WVeUEozgR/g7rd0xUimYNlvZRE/K2MgZTjWy725IfelLeVcEM97mmtRGXw==",
      "license": "MIT",
      "dependencies": {
        "binary-extensions": "^2.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-boolean-object": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/is-boolean-object/-/is-boolean-object-1.2.2.tgz",
      "integrity": "sha512-wa56o2/ElJMYqjCjGkXri7it5FbebW5usLw/nPmCMs5DeZ7eziSYZhSmPRn0txqeW4LnAmQQU7FgqLpsEFKM4A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-buffer": {
      "version": "1.1.6",
      "resolved": "https://registry.npmjs.org/is-buffer/-/is-buffer-1.1.6.tgz",
      "integrity": "sha512-NcdALwpXkTm5Zvvbk7owOUSvVvBKDgKP5/ewfXEznmQFfs4ZRmanOeKBTjRVjka3QFoN6XJ+9F3USqfHqTaU5w==",
      "license": "MIT"
    },
    "node_modules/is-bun-module": {
      "version": "1.3.0",
      "resolved": "https://registry.npmjs.org/is-bun-module/-/is-bun-module-1.3.0.tgz",
      "integrity": "sha512-DgXeu5UWI0IsMQundYb5UAOzm6G2eVnarJ0byP6Tm55iZNKceD59LNPA2L4VvsScTtHcw0yEkVwSf7PC+QoLSA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "semver": "^7.6.3"
      }
    },
    "node_modules/is-callable": {
      "version": "1.2.7",
      "resolved": "https://registry.npmjs.org/is-callable/-/is-callable-1.2.7.tgz",
      "integrity": "sha512-1BC0BVFhS/p0qtw6enp8e+8OD0UrK0oFLztSjNzhcKA3WDuJxxAPXzPuPtKkjEY9UUoEWlX/8fgKeu2S8i9JTA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-core-module": {
      "version": "2.16.1",
      "resolved": "https://registry.npmjs.org/is-core-module/-/is-core-module-2.16.1.tgz",
      "integrity": "sha512-UfoeMA6fIJ8wTYFEUjelnaGI67v6+N7qXJEvQuIGa99l4xsCruSYOVSQ0uPANn4dAzm8lkYPaKLrrijLq7x23w==",
      "license": "MIT",
      "dependencies": {
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-data-view": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/is-data-view/-/is-data-view-1.0.2.tgz",
      "integrity": "sha512-RKtWF8pGmS87i2D6gqQu/l7EYRlVdfzemCJN/P3UOs//x1QE7mfhvzHIApBTRf7axvT6DMGwSwBXYCT0nfB9xw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "get-intrinsic": "^1.2.6",
        "is-typed-array": "^1.1.13"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-date-object": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/is-date-object/-/is-date-object-1.1.0.tgz",
      "integrity": "sha512-PwwhEakHVKTdRNVOw+/Gyh0+MzlCl4R6qKvkhuvLtPMggI1WAHt9sOwZxQLSGpUaDnrdyDsomoRgNnCfKNSXXg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-decimal": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-decimal/-/is-decimal-2.0.1.tgz",
      "integrity": "sha512-AAB9hiomQs5DXWcRB1rqsxGUstbRroFOPPVAomNk/3XHR5JyEZChOyTWe2oayKnsSsr/kcGqF+z6yuH6HHpN0A==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/is-extglob": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/is-extglob/-/is-extglob-2.1.1.tgz",
      "integrity": "sha512-SbKbANkN603Vi4jEZv49LeVJMn4yGwsbzZworEoyEiutsN3nJYdbO36zfhGJ6QEDpOZIFkDtnq5JRxmvl3jsoQ==",
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-finalizationregistry": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-finalizationregistry/-/is-finalizationregistry-1.1.1.tgz",
      "integrity": "sha512-1pC6N8qWJbWoPtEjgcL2xyhQOP491EQjeUo3qTKcmV8YSDDJrOepfG8pcC7h/QgnQHYSv0mJ3Z/ZWxmatVrysg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-fullwidth-code-point": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/is-fullwidth-code-point/-/is-fullwidth-code-point-3.0.0.tgz",
      "integrity": "sha512-zymm5+u+sCsSWyD9qNaejV3DFvhCKclKdizYaJUuHA83RLjb7nSuGnddCHGv0hk+KY7BMAlsWeK4Ueg6EV6XQg==",
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-generator-fn": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/is-generator-fn/-/is-generator-fn-2.1.0.tgz",
      "integrity": "sha512-cTIB4yPYL/Grw0EaSzASzg6bBy9gqCofvWN8okThAYIxKJZC+udlRAmGbM0XLeniEJSs8uEgHPGuHSe1XsOLSQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/is-generator-function": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/is-generator-function/-/is-generator-function-1.1.0.tgz",
      "integrity": "sha512-nPUB5km40q9e8UfN/Zc24eLlzdSf9OfKByBw9CIdw4H1giPMeA0OIJvbchsCu4npfI2QcMVBsGEBHKZ7wLTWmQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "get-proto": "^1.0.0",
        "has-tostringtag": "^1.0.2",
        "safe-regex-test": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-glob": {
      "version": "4.0.3",
      "resolved": "https://registry.npmjs.org/is-glob/-/is-glob-4.0.3.tgz",
      "integrity": "sha512-xelSayHH36ZgE7ZWhli7pW34hNbNl8Ojv5KVmkJD4hBdD3th8Tfk9vYasLM+mXWOZhFkgZfxhLSnrwRr4elSSg==",
      "license": "MIT",
      "dependencies": {
        "is-extglob": "^2.1.1"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/is-hexadecimal": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-hexadecimal/-/is-hexadecimal-2.0.1.tgz",
      "integrity": "sha512-DgZQp241c8oO6cA1SbTEWiXeoxV42vlcJxgH+B3hi1AiqqKruZR3ZGF8In3fj4+/y/7rHvlOZLZtgJ/4ttYGZg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/is-map": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/is-map/-/is-map-2.0.3.tgz",
      "integrity": "sha512-1Qed0/Hr2m+YqxnM09CjA2d/i6YZNfF6R2oRAOj36eUdS6qIV/huPJNSEpKbupewFs+ZsJlxsjjPbc0/afW6Lw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-number": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/is-number/-/is-number-7.0.0.tgz",
      "integrity": "sha512-41Cifkg6e8TylSpdtTpeLVMqvSBEVzTttHvERD741+pnZ8ANv0004MRL43QKPDlK9cGvNp6NZWZUBlbGXYxxng==",
      "license": "MIT",
      "engines": {
        "node": ">=0.12.0"
      }
    },
    "node_modules/is-number-object": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-number-object/-/is-number-object-1.1.1.tgz",
      "integrity": "sha512-lZhclumE1G6VYD8VHe35wFaIif+CTy5SJIi5+3y4psDgWu4wPDoBhF8NxUOinEc7pHgiTsT6MaBb92rKhhD+Xw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-path-inside": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/is-path-inside/-/is-path-inside-3.0.3.tgz",
      "integrity": "sha512-Fd4gABb+ycGAmKou8eMftCupSir5lRxqf4aD/vd0cD2qc4HL07OjCeuHMr8Ro4CoMaeCKDB0/ECBOVWjTwUvPQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/is-plain-obj": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/is-plain-obj/-/is-plain-obj-4.1.0.tgz",
      "integrity": "sha512-+Pgi+vMuUNkJyExiMBt5IlFoMyKnr5zhJ4Uspz58WOhBF5QoIZkFyNHIbBAtHwzVAgk5RtndVNsDRN61/mmDqg==",
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/is-potential-custom-element-name": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/is-potential-custom-element-name/-/is-potential-custom-element-name-1.0.1.tgz",
      "integrity": "sha512-bCYeRA2rVibKZd+s2625gGnGF/t7DSqDs4dP7CrLA1m7jKWz6pps0LpYLJN8Q64HtmPKJ1hrN3nzPNKFEKOUiQ==",
      "devOptional": true,
      "license": "MIT"
    },
    "node_modules/is-regex": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/is-regex/-/is-regex-1.2.1.tgz",
      "integrity": "sha512-MjYsKHO5O7mCsmRGxWcLWheFqN9DJ/2TmngvjKXihe6efViPqc274+Fx/4fYj/r03+ESvBdTXK0V6tA3rgez1g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "gopd": "^1.2.0",
        "has-tostringtag": "^1.0.2",
        "hasown": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-set": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/is-set/-/is-set-2.0.3.tgz",
      "integrity": "sha512-iPAjerrse27/ygGLxw+EBR9agv9Y6uLeYVJMu+QNCoouJ1/1ri0mGrcWpfCqFZuzzx3WjtwxG098X+n4OuRkPg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-shared-array-buffer": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/is-shared-array-buffer/-/is-shared-array-buffer-1.0.4.tgz",
      "integrity": "sha512-ISWac8drv4ZGfwKl5slpHG9OwPNty4jOWPRIhBpxOoD+hqITiwuipOQ2bNthAzwA3B4fIjO4Nln74N0S9byq8A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-stream": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/is-stream/-/is-stream-2.0.1.tgz",
      "integrity": "sha512-hFoiJiTl63nn+kstHGBtewWSKnQLpyb155KHheA1l39uvtO9nWIop1p3udqPcUd/xbF1VLMO4n7OI6p7RbngDg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/is-string": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-string/-/is-string-1.1.1.tgz",
      "integrity": "sha512-BtEeSsoaQjlSPBemMQIrY1MY0uM6vnS1g5fmufYOtnxLGUZM2178PKbhsk7Ffv58IX+ZtcvoGwccYsh0PglkAA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-symbol": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-symbol/-/is-symbol-1.1.1.tgz",
      "integrity": "sha512-9gGx6GTtCQM73BgmHQXfDmLtfjjTUDSyoxTCbp5WtoixAhfgsDirWIcVQ/IHpvI5Vgd5i/J5F7B9cN/WlVbC/w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "has-symbols": "^1.1.0",
        "safe-regex-test": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-typed-array": {
      "version": "1.1.15",
      "resolved": "https://registry.npmjs.org/is-typed-array/-/is-typed-array-1.1.15.tgz",
      "integrity": "sha512-p3EcsicXjit7SaskXHs1hA91QxgTw46Fv6EFKKGS5DRFLD8yKnohjF3hxoju94b/OcMZoQukzpPpBE9uLVKzgQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "which-typed-array": "^1.1.16"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-weakmap": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/is-weakmap/-/is-weakmap-2.0.2.tgz",
      "integrity": "sha512-K5pXYOm9wqY1RgjpL3YTkF39tni1XajUIkawTLUo9EZEVUFga5gSQJF8nNS7ZwJQ02y+1YCNYcMh+HIf1ZqE+w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-weakref": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/is-weakref/-/is-weakref-1.1.1.tgz",
      "integrity": "sha512-6i9mGWSlqzNMEqpCp93KwRS1uUOodk2OJ6b+sq7ZPDSy2WuI5NFIxp/254TytR8ftefexkWn5xNiHUNpPOfSew==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/is-weakset": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/is-weakset/-/is-weakset-2.0.4.tgz",
      "integrity": "sha512-mfcwb6IzQyOKTs84CQMrOwW4gQcaTOAWJ0zzJCl2WSPDrWk/OzDaImWFH3djXhb24g4eudZfLRozAvPGw4d9hQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "get-intrinsic": "^1.2.6"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/isarray": {
      "version": "2.0.5",
      "resolved": "https://registry.npmjs.org/isarray/-/isarray-2.0.5.tgz",
      "integrity": "sha512-xHjhDr3cNBK0BzdUJSPXZntQUx/mwMS5Rw4A7lPJ90XGAO6ISP/ePDNuo0vhqOZU+UD5JoodwCAAoZQd3FeAKw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/isexe": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/isexe/-/isexe-2.0.0.tgz",
      "integrity": "sha512-RHxMLp9lnKHGHRng9QFhRCMbYAcVpn69smSGcq3f36xjgVVWThj4qqLbTLlq7Ssj8B+fIQ1EuCEGI2lKsyQeIw==",
      "license": "ISC"
    },
    "node_modules/istanbul-lib-coverage": {
      "version": "3.2.2",
      "resolved": "https://registry.npmjs.org/istanbul-lib-coverage/-/istanbul-lib-coverage-3.2.2.tgz",
      "integrity": "sha512-O8dpsF+r0WV/8MNRKfnmrtCWhuKjxrq2w+jpzBL5UZKTi2LeVWnWOmWRxFlesJONmc+wLAGvKQZEOanko0LFTg==",
      "dev": true,
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/istanbul-lib-instrument": {
      "version": "6.0.3",
      "resolved": "https://registry.npmjs.org/istanbul-lib-instrument/-/istanbul-lib-instrument-6.0.3.tgz",
      "integrity": "sha512-Vtgk7L/R2JHyyGW07spoFlB8/lpjiOLTjMdms6AFMraYt3BaJauod/NGrfnVG/y4Ix1JEuMRPDPEj2ua+zz1/Q==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "@babel/core": "^7.23.9",
        "@babel/parser": "^7.23.9",
        "@istanbuljs/schema": "^0.1.3",
        "istanbul-lib-coverage": "^3.2.0",
        "semver": "^7.5.4"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/istanbul-lib-report": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/istanbul-lib-report/-/istanbul-lib-report-3.0.1.tgz",
      "integrity": "sha512-GCfE1mtsHGOELCU8e/Z7YWzpmybrx/+dSTfLrvY8qRmaY6zXTKWn6WQIjaAFw069icm6GVMNkgu0NzI4iPZUNw==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "istanbul-lib-coverage": "^3.0.0",
        "make-dir": "^4.0.0",
        "supports-color": "^7.1.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/istanbul-lib-source-maps": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/istanbul-lib-source-maps/-/istanbul-lib-source-maps-4.0.1.tgz",
      "integrity": "sha512-n3s8EwkdFIJCG3BPKBYvskgXGoy88ARzvegkitk60NxRdwltLOTaH7CUiMRXvwYorl0Q712iEjcWB+fK/MrWVw==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "debug": "^4.1.1",
        "istanbul-lib-coverage": "^3.0.0",
        "source-map": "^0.6.1"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/istanbul-reports": {
      "version": "3.1.7",
      "resolved": "https://registry.npmjs.org/istanbul-reports/-/istanbul-reports-3.1.7.tgz",
      "integrity": "sha512-BewmUXImeuRk2YY0PVbxgKAysvhRPUQE0h5QRM++nVWyubKGV0l8qQ5op8+B2DOmwSe63Jivj0BjkPQVf8fP5g==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "html-escaper": "^2.0.0",
        "istanbul-lib-report": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/iterator.prototype": {
      "version": "1.1.5",
      "resolved": "https://registry.npmjs.org/iterator.prototype/-/iterator.prototype-1.1.5.tgz",
      "integrity": "sha512-H0dkQoCa3b2VEeKQBOxFph+JAbcrQdE7KC0UkqwpLmv2EC4P41QXP+rqo9wYodACiG5/WM5s9oDApTU8utwj9g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-data-property": "^1.1.4",
        "es-object-atoms": "^1.0.0",
        "get-intrinsic": "^1.2.6",
        "get-proto": "^1.0.0",
        "has-symbols": "^1.1.0",
        "set-function-name": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/jackspeak": {
      "version": "2.3.6",
      "resolved": "https://registry.npmjs.org/jackspeak/-/jackspeak-2.3.6.tgz",
      "integrity": "sha512-N3yCS/NegsOBokc8GAdM8UcmfsKiSS8cipheD/nivzr700H+nsMOxJjQnvwOcRYVuFkdH0wGUvW2WbXGmrZGbQ==",
      "license": "BlueOak-1.0.0",
      "dependencies": {
        "@isaacs/cliui": "^8.0.2"
      },
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      },
      "optionalDependencies": {
        "@pkgjs/parseargs": "^0.11.0"
      }
    },
    "node_modules/jest": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest/-/jest-29.7.0.tgz",
      "integrity": "sha512-NIy3oAFp9shda19hy4HK0HRTWKtPJmGdnvywu01nOqNC2vZg+Z+fvJDxpMQA88eb2I9EcafcdjYgsDthnYTvGw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/core": "^29.7.0",
        "@jest/types": "^29.6.3",
        "import-local": "^3.0.2",
        "jest-cli": "^29.7.0"
      },
      "bin": {
        "jest": "bin/jest.js"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "node-notifier": "^8.0.1 || ^9.0.0 || ^10.0.0"
      },
      "peerDependenciesMeta": {
        "node-notifier": {
          "optional": true
        }
      }
    },
    "node_modules/jest-changed-files": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-changed-files/-/jest-changed-files-29.7.0.tgz",
      "integrity": "sha512-fEArFiwf1BpQ+4bXSprcDc3/x4HSzL4al2tozwVpDFpsxALjLYdyiIK4e5Vz66GQJIbXJ82+35PtysofptNX2w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "execa": "^5.0.0",
        "jest-util": "^29.7.0",
        "p-limit": "^3.1.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-circus": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-circus/-/jest-circus-29.7.0.tgz",
      "integrity": "sha512-3E1nCMgipcTkCocFwM90XXQab9bS+GMsjdpmPrlelaxwD93Ad8iVEjX/vvHPdLPnFf+L40u+5+iutRdA1N9myw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/environment": "^29.7.0",
        "@jest/expect": "^29.7.0",
        "@jest/test-result": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "co": "^4.6.0",
        "dedent": "^1.0.0",
        "is-generator-fn": "^2.0.0",
        "jest-each": "^29.7.0",
        "jest-matcher-utils": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-runtime": "^29.7.0",
        "jest-snapshot": "^29.7.0",
        "jest-util": "^29.7.0",
        "p-limit": "^3.1.0",
        "pretty-format": "^29.7.0",
        "pure-rand": "^6.0.0",
        "slash": "^3.0.0",
        "stack-utils": "^2.0.3"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-circus/node_modules/ansi-styles": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-5.2.0.tgz",
      "integrity": "sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/jest-circus/node_modules/pretty-format": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/pretty-format/-/pretty-format-29.7.0.tgz",
      "integrity": "sha512-Pdlw/oPxN+aXdmM9R00JVC9WVFoCLTKJvDVLgmJ+qAffBMxsV85l/Lu7sNx4zSzPyoL2euImuEwHhOXdEgNFZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/schemas": "^29.6.3",
        "ansi-styles": "^5.0.0",
        "react-is": "^18.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-circus/node_modules/react-is": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-18.3.1.tgz",
      "integrity": "sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/jest-cli": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-cli/-/jest-cli-29.7.0.tgz",
      "integrity": "sha512-OVVobw2IubN/GSYsxETi+gOe7Ka59EFMR/twOU3Jb2GnKKeMGJB5SGUUrEz3SFVmJASUdZUzy83sLNNQ2gZslg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/core": "^29.7.0",
        "@jest/test-result": "^29.7.0",
        "@jest/types": "^29.6.3",
        "chalk": "^4.0.0",
        "create-jest": "^29.7.0",
        "exit": "^0.1.2",
        "import-local": "^3.0.2",
        "jest-config": "^29.7.0",
        "jest-util": "^29.7.0",
        "jest-validate": "^29.7.0",
        "yargs": "^17.3.1"
      },
      "bin": {
        "jest": "bin/jest.js"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "node-notifier": "^8.0.1 || ^9.0.0 || ^10.0.0"
      },
      "peerDependenciesMeta": {
        "node-notifier": {
          "optional": true
        }
      }
    },
    "node_modules/jest-config": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-config/-/jest-config-29.7.0.tgz",
      "integrity": "sha512-uXbpfeQ7R6TZBqI3/TxCU4q4ttk3u0PJeC+E0zbfSoSjq6bJ7buBPxzQPL0ifrkY4DNu4JUdk0ImlBUYi840eQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/core": "^7.11.6",
        "@jest/test-sequencer": "^29.7.0",
        "@jest/types": "^29.6.3",
        "babel-jest": "^29.7.0",
        "chalk": "^4.0.0",
        "ci-info": "^3.2.0",
        "deepmerge": "^4.2.2",
        "glob": "^7.1.3",
        "graceful-fs": "^4.2.9",
        "jest-circus": "^29.7.0",
        "jest-environment-node": "^29.7.0",
        "jest-get-type": "^29.6.3",
        "jest-regex-util": "^29.6.3",
        "jest-resolve": "^29.7.0",
        "jest-runner": "^29.7.0",
        "jest-util": "^29.7.0",
        "jest-validate": "^29.7.0",
        "micromatch": "^4.0.4",
        "parse-json": "^5.2.0",
        "pretty-format": "^29.7.0",
        "slash": "^3.0.0",
        "strip-json-comments": "^3.1.1"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "@types/node": "*",
        "ts-node": ">=9.0.0"
      },
      "peerDependenciesMeta": {
        "@types/node": {
          "optional": true
        },
        "ts-node": {
          "optional": true
        }
      }
    },
    "node_modules/jest-config/node_modules/ansi-styles": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-5.2.0.tgz",
      "integrity": "sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/jest-config/node_modules/glob": {
      "version": "7.2.3",
      "resolved": "https://registry.npmjs.org/glob/-/glob-7.2.3.tgz",
      "integrity": "sha512-nFR0zLpU2YCaRxwoCJvL6UvCH2JFyFVIvwTLsIf21AuHlMskA1hhTdk+LlYJtOlYt9v6dvszD2BGRqBL+iQK9Q==",
      "deprecated": "Glob versions prior to v9 are no longer supported",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "fs.realpath": "^1.0.0",
        "inflight": "^1.0.4",
        "inherits": "2",
        "minimatch": "^3.1.1",
        "once": "^1.3.0",
        "path-is-absolute": "^1.0.0"
      },
      "engines": {
        "node": "*"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/jest-config/node_modules/pretty-format": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/pretty-format/-/pretty-format-29.7.0.tgz",
      "integrity": "sha512-Pdlw/oPxN+aXdmM9R00JVC9WVFoCLTKJvDVLgmJ+qAffBMxsV85l/Lu7sNx4zSzPyoL2euImuEwHhOXdEgNFZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/schemas": "^29.6.3",
        "ansi-styles": "^5.0.0",
        "react-is": "^18.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-config/node_modules/react-is": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-18.3.1.tgz",
      "integrity": "sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/jest-diff": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-diff/-/jest-diff-29.7.0.tgz",
      "integrity": "sha512-LMIgiIrhigmPrs03JHpxUh2yISK3vLFPkAodPeo0+BuF7wA2FoQbkEg1u8gBYBThncu7e1oEDUfIXVuTqLRUjw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "chalk": "^4.0.0",
        "diff-sequences": "^29.6.3",
        "jest-get-type": "^29.6.3",
        "pretty-format": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-diff/node_modules/ansi-styles": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-5.2.0.tgz",
      "integrity": "sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/jest-diff/node_modules/pretty-format": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/pretty-format/-/pretty-format-29.7.0.tgz",
      "integrity": "sha512-Pdlw/oPxN+aXdmM9R00JVC9WVFoCLTKJvDVLgmJ+qAffBMxsV85l/Lu7sNx4zSzPyoL2euImuEwHhOXdEgNFZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/schemas": "^29.6.3",
        "ansi-styles": "^5.0.0",
        "react-is": "^18.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-diff/node_modules/react-is": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-18.3.1.tgz",
      "integrity": "sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/jest-docblock": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-docblock/-/jest-docblock-29.7.0.tgz",
      "integrity": "sha512-q617Auw3A612guyaFgsbFeYpNP5t2aoUNLwBUbc/0kD1R4t9ixDbyFTHd1nok4epoVFpr7PmeWHrhvuV3XaJ4g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "detect-newline": "^3.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-each": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-each/-/jest-each-29.7.0.tgz",
      "integrity": "sha512-gns+Er14+ZrEoC5fhOfYCY1LOHHr0TI+rQUHZS8Ttw2l7gl+80eHc/gFf2Ktkw0+SIACDTeWvpFcv3B04VembQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "chalk": "^4.0.0",
        "jest-get-type": "^29.6.3",
        "jest-util": "^29.7.0",
        "pretty-format": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-each/node_modules/ansi-styles": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-5.2.0.tgz",
      "integrity": "sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/jest-each/node_modules/pretty-format": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/pretty-format/-/pretty-format-29.7.0.tgz",
      "integrity": "sha512-Pdlw/oPxN+aXdmM9R00JVC9WVFoCLTKJvDVLgmJ+qAffBMxsV85l/Lu7sNx4zSzPyoL2euImuEwHhOXdEgNFZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/schemas": "^29.6.3",
        "ansi-styles": "^5.0.0",
        "react-is": "^18.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-each/node_modules/react-is": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-18.3.1.tgz",
      "integrity": "sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/jest-environment-jsdom": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-environment-jsdom/-/jest-environment-jsdom-29.7.0.tgz",
      "integrity": "sha512-k9iQbsf9OyOfdzWH8HDmrRT0gSIcX+FLNW7IQq94tFX0gynPwqDTW0Ho6iMVNjGz/nb+l/vW3dWM2bbLLpkbXA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/environment": "^29.7.0",
        "@jest/fake-timers": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/jsdom": "^20.0.0",
        "@types/node": "*",
        "jest-mock": "^29.7.0",
        "jest-util": "^29.7.0",
        "jsdom": "^20.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "peerDependencies": {
        "canvas": "^2.5.0"
      },
      "peerDependenciesMeta": {
        "canvas": {
          "optional": true
        }
      }
    },
    "node_modules/jest-environment-node": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-environment-node/-/jest-environment-node-29.7.0.tgz",
      "integrity": "sha512-DOSwCRqXirTOyheM+4d5YZOrWcdu0LNZ87ewUoywbcb2XR4wKgqiG8vNeYwhjFMbEkfju7wx2GYH0P2gevGvFw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/environment": "^29.7.0",
        "@jest/fake-timers": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "jest-mock": "^29.7.0",
        "jest-util": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-get-type": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/jest-get-type/-/jest-get-type-29.6.3.tgz",
      "integrity": "sha512-zrteXnqYxfQh7l5FHyL38jL39di8H8rHoecLH3JNxH3BwOrBsNeabdap5e0I23lD4HHI8W5VFBZqG4Eaq5LNcw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-haste-map": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-haste-map/-/jest-haste-map-29.7.0.tgz",
      "integrity": "sha512-fP8u2pyfqx0K1rGn1R9pyE0/KTn+G7PxktWidOBTqFPLYX0b9ksaMFkhK5vrS3DVun09pckLdlx90QthlW7AmA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "@types/graceful-fs": "^4.1.3",
        "@types/node": "*",
        "anymatch": "^3.0.3",
        "fb-watchman": "^2.0.0",
        "graceful-fs": "^4.2.9",
        "jest-regex-util": "^29.6.3",
        "jest-util": "^29.7.0",
        "jest-worker": "^29.7.0",
        "micromatch": "^4.0.4",
        "walker": "^1.0.8"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      },
      "optionalDependencies": {
        "fsevents": "^2.3.2"
      }
    },
    "node_modules/jest-leak-detector": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-leak-detector/-/jest-leak-detector-29.7.0.tgz",
      "integrity": "sha512-kYA8IJcSYtST2BY9I+SMC32nDpBT3J2NvWJx8+JCuCdl/CR1I4EKUJROiP8XtCcxqgTTBGJNdbB1A8XRKbTetw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "jest-get-type": "^29.6.3",
        "pretty-format": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-leak-detector/node_modules/ansi-styles": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-5.2.0.tgz",
      "integrity": "sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/jest-leak-detector/node_modules/pretty-format": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/pretty-format/-/pretty-format-29.7.0.tgz",
      "integrity": "sha512-Pdlw/oPxN+aXdmM9R00JVC9WVFoCLTKJvDVLgmJ+qAffBMxsV85l/Lu7sNx4zSzPyoL2euImuEwHhOXdEgNFZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/schemas": "^29.6.3",
        "ansi-styles": "^5.0.0",
        "react-is": "^18.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-leak-detector/node_modules/react-is": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-18.3.1.tgz",
      "integrity": "sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/jest-matcher-utils": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-matcher-utils/-/jest-matcher-utils-29.7.0.tgz",
      "integrity": "sha512-sBkD+Xi9DtcChsI3L3u0+N0opgPYnCRPtGcQYrgXmR+hmt/fYfWAL0xRXYU8eWOdfuLgBe0YCW3AFtnRLagq/g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "chalk": "^4.0.0",
        "jest-diff": "^29.7.0",
        "jest-get-type": "^29.6.3",
        "pretty-format": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-matcher-utils/node_modules/ansi-styles": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-5.2.0.tgz",
      "integrity": "sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/jest-matcher-utils/node_modules/pretty-format": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/pretty-format/-/pretty-format-29.7.0.tgz",
      "integrity": "sha512-Pdlw/oPxN+aXdmM9R00JVC9WVFoCLTKJvDVLgmJ+qAffBMxsV85l/Lu7sNx4zSzPyoL2euImuEwHhOXdEgNFZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/schemas": "^29.6.3",
        "ansi-styles": "^5.0.0",
        "react-is": "^18.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-matcher-utils/node_modules/react-is": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-18.3.1.tgz",
      "integrity": "sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/jest-message-util": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-message-util/-/jest-message-util-29.7.0.tgz",
      "integrity": "sha512-GBEV4GRADeP+qtB2+6u61stea8mGcOT4mCtrYISZwfu9/ISHFJ/5zOMXYbpBE9RsS5+Gb63DW4FgmnKJ79Kf6w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/code-frame": "^7.12.13",
        "@jest/types": "^29.6.3",
        "@types/stack-utils": "^2.0.0",
        "chalk": "^4.0.0",
        "graceful-fs": "^4.2.9",
        "micromatch": "^4.0.4",
        "pretty-format": "^29.7.0",
        "slash": "^3.0.0",
        "stack-utils": "^2.0.3"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-message-util/node_modules/ansi-styles": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-5.2.0.tgz",
      "integrity": "sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/jest-message-util/node_modules/pretty-format": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/pretty-format/-/pretty-format-29.7.0.tgz",
      "integrity": "sha512-Pdlw/oPxN+aXdmM9R00JVC9WVFoCLTKJvDVLgmJ+qAffBMxsV85l/Lu7sNx4zSzPyoL2euImuEwHhOXdEgNFZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/schemas": "^29.6.3",
        "ansi-styles": "^5.0.0",
        "react-is": "^18.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-message-util/node_modules/react-is": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-18.3.1.tgz",
      "integrity": "sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/jest-mock": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-mock/-/jest-mock-29.7.0.tgz",
      "integrity": "sha512-ITOMZn+UkYS4ZFh83xYAOzWStloNzJFO2s8DWrE4lhtGD+AorgnbkiKERe4wQVBydIGPx059g6riW5Btp6Llnw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "jest-util": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-pnp-resolver": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/jest-pnp-resolver/-/jest-pnp-resolver-1.2.3.tgz",
      "integrity": "sha512-+3NpwQEnRoIBtx4fyhblQDPgJI0H1IEIkX7ShLUjPGA7TtUTvI1oiKi3SR4oBR0hQhQR80l4WAe5RrXBwWMA8w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      },
      "peerDependencies": {
        "jest-resolve": "*"
      },
      "peerDependenciesMeta": {
        "jest-resolve": {
          "optional": true
        }
      }
    },
    "node_modules/jest-regex-util": {
      "version": "29.6.3",
      "resolved": "https://registry.npmjs.org/jest-regex-util/-/jest-regex-util-29.6.3.tgz",
      "integrity": "sha512-KJJBsRCyyLNWCNBOvZyRDnAIfUiRJ8v+hOBQYGn8gDyF3UegwiP4gwRR3/SDa42g1YbVycTidUF3rKjyLFDWbg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-resolve": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-resolve/-/jest-resolve-29.7.0.tgz",
      "integrity": "sha512-IOVhZSrg+UvVAshDSDtHyFCCBUl/Q3AAJv8iZ6ZjnZ74xzvwuzLXid9IIIPgTnY62SJjfuupMKZsZQRsCvxEgA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "chalk": "^4.0.0",
        "graceful-fs": "^4.2.9",
        "jest-haste-map": "^29.7.0",
        "jest-pnp-resolver": "^1.2.2",
        "jest-util": "^29.7.0",
        "jest-validate": "^29.7.0",
        "resolve": "^1.20.0",
        "resolve.exports": "^2.0.0",
        "slash": "^3.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-resolve-dependencies": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-resolve-dependencies/-/jest-resolve-dependencies-29.7.0.tgz",
      "integrity": "sha512-un0zD/6qxJ+S0et7WxeI3H5XSe9lTBBR7bOHCHXkKR6luG5mwDDlIzVQ0V5cZCuoTgEdcdwzTghYkTWfubi+nA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "jest-regex-util": "^29.6.3",
        "jest-snapshot": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-runner": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-runner/-/jest-runner-29.7.0.tgz",
      "integrity": "sha512-fsc4N6cPCAahybGBfTRcq5wFR6fpLznMg47sY5aDpsoejOcVYFb07AHuSnR0liMcPTgBsA3ZJL6kFOjPdoNipQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/console": "^29.7.0",
        "@jest/environment": "^29.7.0",
        "@jest/test-result": "^29.7.0",
        "@jest/transform": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "emittery": "^0.13.1",
        "graceful-fs": "^4.2.9",
        "jest-docblock": "^29.7.0",
        "jest-environment-node": "^29.7.0",
        "jest-haste-map": "^29.7.0",
        "jest-leak-detector": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-resolve": "^29.7.0",
        "jest-runtime": "^29.7.0",
        "jest-util": "^29.7.0",
        "jest-watcher": "^29.7.0",
        "jest-worker": "^29.7.0",
        "p-limit": "^3.1.0",
        "source-map-support": "0.5.13"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-runtime": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-runtime/-/jest-runtime-29.7.0.tgz",
      "integrity": "sha512-gUnLjgwdGqW7B4LvOIkbKs9WGbn+QLqRQQ9juC6HndeDiezIwhDP+mhMwHWCEcfQ5RUXa6OPnFF8BJh5xegwwQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/environment": "^29.7.0",
        "@jest/fake-timers": "^29.7.0",
        "@jest/globals": "^29.7.0",
        "@jest/source-map": "^29.6.3",
        "@jest/test-result": "^29.7.0",
        "@jest/transform": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "cjs-module-lexer": "^1.0.0",
        "collect-v8-coverage": "^1.0.0",
        "glob": "^7.1.3",
        "graceful-fs": "^4.2.9",
        "jest-haste-map": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-mock": "^29.7.0",
        "jest-regex-util": "^29.6.3",
        "jest-resolve": "^29.7.0",
        "jest-snapshot": "^29.7.0",
        "jest-util": "^29.7.0",
        "slash": "^3.0.0",
        "strip-bom": "^4.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-runtime/node_modules/glob": {
      "version": "7.2.3",
      "resolved": "https://registry.npmjs.org/glob/-/glob-7.2.3.tgz",
      "integrity": "sha512-nFR0zLpU2YCaRxwoCJvL6UvCH2JFyFVIvwTLsIf21AuHlMskA1hhTdk+LlYJtOlYt9v6dvszD2BGRqBL+iQK9Q==",
      "deprecated": "Glob versions prior to v9 are no longer supported",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "fs.realpath": "^1.0.0",
        "inflight": "^1.0.4",
        "inherits": "2",
        "minimatch": "^3.1.1",
        "once": "^1.3.0",
        "path-is-absolute": "^1.0.0"
      },
      "engines": {
        "node": "*"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/jest-runtime/node_modules/strip-bom": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/strip-bom/-/strip-bom-4.0.0.tgz",
      "integrity": "sha512-3xurFv5tEgii33Zi8Jtp55wEIILR9eh34FAW00PZf+JnSsTmV/ioewSgQl97JHvgjoRGwPShsWm+IdrxB35d0w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/jest-snapshot": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-snapshot/-/jest-snapshot-29.7.0.tgz",
      "integrity": "sha512-Rm0BMWtxBcioHr1/OX5YCP8Uov4riHvKPknOGs804Zg9JGZgmIBkbtlxJC/7Z4msKYVbIJtfU+tKb8xlYNfdkw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/core": "^7.11.6",
        "@babel/generator": "^7.7.2",
        "@babel/plugin-syntax-jsx": "^7.7.2",
        "@babel/plugin-syntax-typescript": "^7.7.2",
        "@babel/types": "^7.3.3",
        "@jest/expect-utils": "^29.7.0",
        "@jest/transform": "^29.7.0",
        "@jest/types": "^29.6.3",
        "babel-preset-current-node-syntax": "^1.0.0",
        "chalk": "^4.0.0",
        "expect": "^29.7.0",
        "graceful-fs": "^4.2.9",
        "jest-diff": "^29.7.0",
        "jest-get-type": "^29.6.3",
        "jest-matcher-utils": "^29.7.0",
        "jest-message-util": "^29.7.0",
        "jest-util": "^29.7.0",
        "natural-compare": "^1.4.0",
        "pretty-format": "^29.7.0",
        "semver": "^7.5.3"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-snapshot/node_modules/ansi-styles": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-5.2.0.tgz",
      "integrity": "sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/jest-snapshot/node_modules/pretty-format": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/pretty-format/-/pretty-format-29.7.0.tgz",
      "integrity": "sha512-Pdlw/oPxN+aXdmM9R00JVC9WVFoCLTKJvDVLgmJ+qAffBMxsV85l/Lu7sNx4zSzPyoL2euImuEwHhOXdEgNFZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/schemas": "^29.6.3",
        "ansi-styles": "^5.0.0",
        "react-is": "^18.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-snapshot/node_modules/react-is": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-18.3.1.tgz",
      "integrity": "sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/jest-util": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-util/-/jest-util-29.7.0.tgz",
      "integrity": "sha512-z6EbKajIpqGKU56y5KBUgy1dt1ihhQJgWzUlZHArA/+X2ad7Cb5iF+AK1EWVL/Bo7Rz9uurpqw6SiBCefUbCGA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "chalk": "^4.0.0",
        "ci-info": "^3.2.0",
        "graceful-fs": "^4.2.9",
        "picomatch": "^2.2.3"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-validate": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-validate/-/jest-validate-29.7.0.tgz",
      "integrity": "sha512-ZB7wHqaRGVw/9hST/OuFUReG7M8vKeq0/J2egIGLdvjHCmYqGARhzXmtgi+gVeZ5uXFF219aOc3Ls2yLg27tkw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/types": "^29.6.3",
        "camelcase": "^6.2.0",
        "chalk": "^4.0.0",
        "jest-get-type": "^29.6.3",
        "leven": "^3.1.0",
        "pretty-format": "^29.7.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-validate/node_modules/ansi-styles": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-5.2.0.tgz",
      "integrity": "sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/jest-validate/node_modules/pretty-format": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/pretty-format/-/pretty-format-29.7.0.tgz",
      "integrity": "sha512-Pdlw/oPxN+aXdmM9R00JVC9WVFoCLTKJvDVLgmJ+qAffBMxsV85l/Lu7sNx4zSzPyoL2euImuEwHhOXdEgNFZQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/schemas": "^29.6.3",
        "ansi-styles": "^5.0.0",
        "react-is": "^18.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-validate/node_modules/react-is": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-18.3.1.tgz",
      "integrity": "sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/jest-watcher": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-watcher/-/jest-watcher-29.7.0.tgz",
      "integrity": "sha512-49Fg7WXkU3Vl2h6LbLtMQ/HyB6rXSIX7SqvBLQmssRBGN9I0PNvPmAmCWSOY6SOvrjhI/F7/bGAv9RtnsPA03g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jest/test-result": "^29.7.0",
        "@jest/types": "^29.6.3",
        "@types/node": "*",
        "ansi-escapes": "^4.2.1",
        "chalk": "^4.0.0",
        "emittery": "^0.13.1",
        "jest-util": "^29.7.0",
        "string-length": "^4.0.1"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-worker": {
      "version": "29.7.0",
      "resolved": "https://registry.npmjs.org/jest-worker/-/jest-worker-29.7.0.tgz",
      "integrity": "sha512-eIz2msL/EzL9UFTFFx7jBTkeZfku0yUAyZZZmJ93H2TYEiroIx2PQjEXcwYtYl8zXCxb+PAmA2hLIt/6ZEkPHw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/node": "*",
        "jest-util": "^29.7.0",
        "merge-stream": "^2.0.0",
        "supports-color": "^8.0.0"
      },
      "engines": {
        "node": "^14.15.0 || ^16.10.0 || >=18.0.0"
      }
    },
    "node_modules/jest-worker/node_modules/supports-color": {
      "version": "8.1.1",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-8.1.1.tgz",
      "integrity": "sha512-MpUEN2OodtUzxvKQl72cUF7RQ5EiHsGvSsVG0ia9c5RbWGL2CI4C7EpPS8UTBIplnlzZiNuV56w+FuNxy3ty2Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-flag": "^4.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/supports-color?sponsor=1"
      }
    },
    "node_modules/jiti": {
      "version": "1.21.7",
      "resolved": "https://registry.npmjs.org/jiti/-/jiti-1.21.7.tgz",
      "integrity": "sha512-/imKNG4EbWNrVjoNC/1H5/9GFy+tqjGBHCaSsN+P2RnPqjsLmv6UD3Ej+Kj8nBWaRAwyk7kK5ZUc+OEatnTR3A==",
      "license": "MIT",
      "bin": {
        "jiti": "bin/jiti.js"
      }
    },
    "node_modules/js-tiktoken": {
      "version": "1.0.19",
      "resolved": "https://registry.npmjs.org/js-tiktoken/-/js-tiktoken-1.0.19.tgz",
      "integrity": "sha512-XC63YQeEcS47Y53gg950xiZ4IWmkfMe4p2V9OSaBt26q+p47WHn18izuXzSclCI73B7yGqtfRsT6jcZQI0y08g==",
      "license": "MIT",
      "dependencies": {
        "base64-js": "^1.5.1"
      }
    },
    "node_modules/js-tokens": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/js-tokens/-/js-tokens-4.0.0.tgz",
      "integrity": "sha512-RdJUflcE3cUzKiMqQgsCu06FPu9UdIJO0beYbPhHN4k6apgJtifcoCtT9bcxOpYBtpD2kCM6Sbzg4CausW/PKQ==",
      "license": "MIT"
    },
    "node_modules/js-yaml": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/js-yaml/-/js-yaml-4.1.0.tgz",
      "integrity": "sha512-wpxZs9NoxZaJESJGIZTyDEaYpl0FKSA+FB9aJiyemKhMwkxQg63h4T1KJgUGHpTqPDNRcmmYLugrRjJlBtWvRA==",
      "license": "MIT",
      "dependencies": {
        "argparse": "^2.0.1"
      },
      "bin": {
        "js-yaml": "bin/js-yaml.js"
      }
    },
    "node_modules/jsdom": {
      "version": "20.0.3",
      "resolved": "https://registry.npmjs.org/jsdom/-/jsdom-20.0.3.tgz",
      "integrity": "sha512-SYhBvTh89tTfCD/CRdSOm13mOBa42iTaTyfyEWBdKcGdPxPtLFBXuHR8XHb33YNYaP+lLbmSvBTsnoesCNJEsQ==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "abab": "^2.0.6",
        "acorn": "^8.8.1",
        "acorn-globals": "^7.0.0",
        "cssom": "^0.5.0",
        "cssstyle": "^2.3.0",
        "data-urls": "^3.0.2",
        "decimal.js": "^10.4.2",
        "domexception": "^4.0.0",
        "escodegen": "^2.0.0",
        "form-data": "^4.0.0",
        "html-encoding-sniffer": "^3.0.0",
        "http-proxy-agent": "^5.0.0",
        "https-proxy-agent": "^5.0.1",
        "is-potential-custom-element-name": "^1.0.1",
        "nwsapi": "^2.2.2",
        "parse5": "^7.1.1",
        "saxes": "^6.0.0",
        "symbol-tree": "^3.2.4",
        "tough-cookie": "^4.1.2",
        "w3c-xmlserializer": "^4.0.0",
        "webidl-conversions": "^7.0.0",
        "whatwg-encoding": "^2.0.0",
        "whatwg-mimetype": "^3.0.0",
        "whatwg-url": "^11.0.0",
        "ws": "^8.11.0",
        "xml-name-validator": "^4.0.0"
      },
      "engines": {
        "node": ">=14"
      },
      "peerDependencies": {
        "canvas": "^2.5.0"
      },
      "peerDependenciesMeta": {
        "canvas": {
          "optional": true
        }
      }
    },
    "node_modules/jsdom/node_modules/tr46": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/tr46/-/tr46-3.0.0.tgz",
      "integrity": "sha512-l7FvfAHlcmulp8kr+flpQZmVwtu7nfRV7NZujtN0OqES8EL4O4e0qqzL0DC5gAvx/ZC/9lk6rhcUwYvkBnBnYA==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "punycode": "^2.1.1"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/jsdom/node_modules/webidl-conversions": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/webidl-conversions/-/webidl-conversions-7.0.0.tgz",
      "integrity": "sha512-VwddBukDzu71offAQR975unBIGqfKZpM+8ZX6ySk8nYhVoo5CYaZyzt3YBvYtRtO+aoGlqxPg/B87NGVZ/fu6g==",
      "devOptional": true,
      "license": "BSD-2-Clause",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/jsdom/node_modules/whatwg-url": {
      "version": "11.0.0",
      "resolved": "https://registry.npmjs.org/whatwg-url/-/whatwg-url-11.0.0.tgz",
      "integrity": "sha512-RKT8HExMpoYx4igMiVMY83lN6UeITKJlBQ+vR/8ZJ8OCdSiN3RwCq+9gH0+Xzj0+5IrM6i4j/6LuvzbZIQgEcQ==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "tr46": "^3.0.0",
        "webidl-conversions": "^7.0.0"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/jsesc": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/jsesc/-/jsesc-3.1.0.tgz",
      "integrity": "sha512-/sM3dO2FOzXjKQhJuo0Q173wf2KOo8t4I8vHy6lF9poUp7bKT0/NHE8fPX23PwfhnykfqnC2xRxOnVw5XuGIaA==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "jsesc": "bin/jsesc"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/json-buffer": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/json-buffer/-/json-buffer-3.0.1.tgz",
      "integrity": "sha512-4bV5BfR2mqfQTJm+V5tPPdf+ZpuhiIvTuAB5g8kcrXOZpTT/QwwVRWBywX1ozr6lEuPdbHxwaJlm9G6mI2sfSQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json-parse-even-better-errors": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/json-parse-even-better-errors/-/json-parse-even-better-errors-2.3.1.tgz",
      "integrity": "sha512-xyFwyhro/JEof6Ghe2iz2NcXoj2sloNsWr/XsERDK/oiPCfaNhl5ONfp+jQdAZRQQ0IJWNzH9zIZF7li91kh2w==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json-schema-traverse": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/json-schema-traverse/-/json-schema-traverse-0.4.1.tgz",
      "integrity": "sha512-xbbCH5dCYU5T8LcEhhuh7HJ88HXuW3qsI3Y0zOZFKfZEHcpWiHU/Jxzk629Brsab/mMiHQti9wMP+845RPe3Vg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json-stable-stringify-without-jsonify": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/json-stable-stringify-without-jsonify/-/json-stable-stringify-without-jsonify-1.0.1.tgz",
      "integrity": "sha512-Bdboy+l7tA3OGW6FjyFHWkP5LuByj1Tk33Ljyq0axyzdk9//JSi2u3fP1QSmd1KNwq6VOKYGlAu87CisVir6Pw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/json5": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/json5/-/json5-1.0.2.tgz",
      "integrity": "sha512-g1MWMLBiz8FKi1e4w0UyVL3w+iJceWAFBAaBnnGKOpNa5f8TLktkbre1+s6oICydWAm+HRUGTmI+//xv2hvXYA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "minimist": "^1.2.0"
      },
      "bin": {
        "json5": "lib/cli.js"
      }
    },
    "node_modules/jsonpointer": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/jsonpointer/-/jsonpointer-5.0.1.tgz",
      "integrity": "sha512-p/nXbhSEcu3pZRdkW1OfJhpsVtW1gd4Wa1fnQc9YLiTfAjn0312eMKimbdIQzuZl9aa9xUGaRlP9T/CJE/ditQ==",
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/jsx-ast-utils": {
      "version": "3.3.5",
      "resolved": "https://registry.npmjs.org/jsx-ast-utils/-/jsx-ast-utils-3.3.5.tgz",
      "integrity": "sha512-ZZow9HBI5O6EPgSJLUb8n2NKgmVWTwCvHGwFuJlMjvLFqlGG6pjirPhtdsseaLZjSibD8eegzmYpUZwoIlj2cQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "array-includes": "^3.1.6",
        "array.prototype.flat": "^1.3.1",
        "object.assign": "^4.1.4",
        "object.values": "^1.1.6"
      },
      "engines": {
        "node": ">=4.0"
      }
    },
    "node_modules/keyv": {
      "version": "4.5.4",
      "resolved": "https://registry.npmjs.org/keyv/-/keyv-4.5.4.tgz",
      "integrity": "sha512-oxVHkHR/EJf2CNXnWxRLW6mg7JyCCUcG0DtEGmL2ctUo1PNTin1PUil+r/+4r5MpVgC/fn1kjsx7mjSujKqIpw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "json-buffer": "3.0.1"
      }
    },
    "node_modules/kleur": {
      "version": "3.0.3",
      "resolved": "https://registry.npmjs.org/kleur/-/kleur-3.0.3.tgz",
      "integrity": "sha512-eTIzlVOSUR+JxdDFepEYcBMtZ9Qqdef+rnzWdRZuMbOywu5tO2w2N7rqjoANZ5k9vywhL6Br1VRjUIgTQx4E8w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/langchain": {
      "version": "0.1.37",
      "resolved": "https://registry.npmjs.org/langchain/-/langchain-0.1.37.tgz",
      "integrity": "sha512-rpaLEJtRrLYhAViEp7/aHfSkxbgSqHJ5n10tXv3o4kHP/wOin85RpTgewwvGjEaKc3797jOg+sLSk6a7e0UlMg==",
      "license": "MIT",
      "dependencies": {
        "@anthropic-ai/sdk": "^0.9.1",
        "@langchain/community": "~0.0.47",
        "@langchain/core": "~0.1.60",
        "@langchain/openai": "~0.0.28",
        "@langchain/textsplitters": "~0.0.0",
        "binary-extensions": "^2.2.0",
        "js-tiktoken": "^1.0.7",
        "js-yaml": "^4.1.0",
        "jsonpointer": "^5.0.1",
        "langchainhub": "~0.0.8",
        "langsmith": "~0.1.7",
        "ml-distance": "^4.0.0",
        "openapi-types": "^12.1.3",
        "p-retry": "4",
        "uuid": "^9.0.0",
        "yaml": "^2.2.1",
        "zod": "^3.22.4",
        "zod-to-json-schema": "^3.22.3"
      },
      "engines": {
        "node": ">=18"
      },
      "peerDependencies": {
        "@aws-sdk/client-s3": "^3.310.0",
        "@aws-sdk/client-sagemaker-runtime": "^3.310.0",
        "@aws-sdk/client-sfn": "^3.310.0",
        "@aws-sdk/credential-provider-node": "^3.388.0",
        "@azure/storage-blob": "^12.15.0",
        "@browserbasehq/sdk": "*",
        "@gomomento/sdk": "^1.51.1",
        "@gomomento/sdk-core": "^1.51.1",
        "@gomomento/sdk-web": "^1.51.1",
        "@google-ai/generativelanguage": "^0.2.1",
        "@google-cloud/storage": "^6.10.1 || ^7.7.0",
        "@mendable/firecrawl-js": "^0.0.13",
        "@notionhq/client": "^2.2.10",
        "@pinecone-database/pinecone": "*",
        "@supabase/supabase-js": "^2.10.0",
        "@vercel/kv": "^0.2.3",
        "@xata.io/client": "^0.28.0",
        "apify-client": "^2.7.1",
        "assemblyai": "^4.0.0",
        "axios": "*",
        "cheerio": "^1.0.0-rc.12",
        "chromadb": "*",
        "convex": "^1.3.1",
        "couchbase": "^4.3.0",
        "d3-dsv": "^2.0.0",
        "epub2": "^3.0.1",
        "fast-xml-parser": "*",
        "google-auth-library": "^8.9.0",
        "handlebars": "^4.7.8",
        "html-to-text": "^9.0.5",
        "ignore": "^5.2.0",
        "ioredis": "^5.3.2",
        "jsdom": "*",
        "mammoth": "^1.6.0",
        "mongodb": ">=5.2.0",
        "node-llama-cpp": "*",
        "notion-to-md": "^3.1.0",
        "officeparser": "^4.0.4",
        "pdf-parse": "1.1.1",
        "peggy": "^3.0.2",
        "playwright": "^1.32.1",
        "puppeteer": "^19.7.2",
        "pyodide": "^0.24.1",
        "redis": "^4.6.4",
        "sonix-speech-recognition": "^2.1.1",
        "srt-parser-2": "^1.2.3",
        "typeorm": "^0.3.12",
        "weaviate-ts-client": "*",
        "web-auth-library": "^1.0.3",
        "ws": "^8.14.2",
        "youtube-transcript": "^1.0.6",
        "youtubei.js": "^9.1.0"
      },
      "peerDependenciesMeta": {
        "@aws-sdk/client-s3": {
          "optional": true
        },
        "@aws-sdk/client-sagemaker-runtime": {
          "optional": true
        },
        "@aws-sdk/client-sfn": {
          "optional": true
        },
        "@aws-sdk/credential-provider-node": {
          "optional": true
        },
        "@azure/storage-blob": {
          "optional": true
        },
        "@browserbasehq/sdk": {
          "optional": true
        },
        "@gomomento/sdk": {
          "optional": true
        },
        "@gomomento/sdk-core": {
          "optional": true
        },
        "@gomomento/sdk-web": {
          "optional": true
        },
        "@google-ai/generativelanguage": {
          "optional": true
        },
        "@google-cloud/storage": {
          "optional": true
        },
        "@mendable/firecrawl-js": {
          "optional": true
        },
        "@notionhq/client": {
          "optional": true
        },
        "@pinecone-database/pinecone": {
          "optional": true
        },
        "@supabase/supabase-js": {
          "optional": true
        },
        "@vercel/kv": {
          "optional": true
        },
        "@xata.io/client": {
          "optional": true
        },
        "apify-client": {
          "optional": true
        },
        "assemblyai": {
          "optional": true
        },
        "axios": {
          "optional": true
        },
        "cheerio": {
          "optional": true
        },
        "chromadb": {
          "optional": true
        },
        "convex": {
          "optional": true
        },
        "couchbase": {
          "optional": true
        },
        "d3-dsv": {
          "optional": true
        },
        "epub2": {
          "optional": true
        },
        "faiss-node": {
          "optional": true
        },
        "fast-xml-parser": {
          "optional": true
        },
        "google-auth-library": {
          "optional": true
        },
        "handlebars": {
          "optional": true
        },
        "html-to-text": {
          "optional": true
        },
        "ignore": {
          "optional": true
        },
        "ioredis": {
          "optional": true
        },
        "jsdom": {
          "optional": true
        },
        "mammoth": {
          "optional": true
        },
        "mongodb": {
          "optional": true
        },
        "node-llama-cpp": {
          "optional": true
        },
        "notion-to-md": {
          "optional": true
        },
        "officeparser": {
          "optional": true
        },
        "pdf-parse": {
          "optional": true
        },
        "peggy": {
          "optional": true
        },
        "playwright": {
          "optional": true
        },
        "puppeteer": {
          "optional": true
        },
        "pyodide": {
          "optional": true
        },
        "redis": {
          "optional": true
        },
        "sonix-speech-recognition": {
          "optional": true
        },
        "srt-parser-2": {
          "optional": true
        },
        "typeorm": {
          "optional": true
        },
        "weaviate-ts-client": {
          "optional": true
        },
        "web-auth-library": {
          "optional": true
        },
        "ws": {
          "optional": true
        },
        "youtube-transcript": {
          "optional": true
        },
        "youtubei.js": {
          "optional": true
        }
      }
    },
    "node_modules/langchain/node_modules/@anthropic-ai/sdk": {
      "version": "0.9.1",
      "resolved": "https://registry.npmjs.org/@anthropic-ai/sdk/-/sdk-0.9.1.tgz",
      "integrity": "sha512-wa1meQ2WSfoY8Uor3EdrJq0jTiZJoKoSii2ZVWRY1oN4Tlr5s59pADg9T79FTbPe1/se5c3pBeZgJL63wmuoBA==",
      "license": "MIT",
      "dependencies": {
        "@types/node": "^18.11.18",
        "@types/node-fetch": "^2.6.4",
        "abort-controller": "^3.0.0",
        "agentkeepalive": "^4.2.1",
        "digest-fetch": "^1.3.0",
        "form-data-encoder": "1.7.2",
        "formdata-node": "^4.3.2",
        "node-fetch": "^2.6.7",
        "web-streams-polyfill": "^3.2.1"
      }
    },
    "node_modules/langchain/node_modules/@types/node": {
      "version": "18.19.80",
      "resolved": "https://registry.npmjs.org/@types/node/-/node-18.19.80.tgz",
      "integrity": "sha512-kEWeMwMeIvxYkeg1gTc01awpwLbfMRZXdIhwRcakd/KlK53jmRC26LqcbIt7fnAQTu5GzlnWmzA3H6+l1u6xxQ==",
      "license": "MIT",
      "dependencies": {
        "undici-types": "~5.26.4"
      }
    },
    "node_modules/langchain/node_modules/undici-types": {
      "version": "5.26.5",
      "resolved": "https://registry.npmjs.org/undici-types/-/undici-types-5.26.5.tgz",
      "integrity": "sha512-JlCMO+ehdEIKqlFxk6IfVoAUVmgz7cU7zD/h9XZ0qzeosSHmUJVOzSQvvYSYWXkFXC+IfLKSIffhv0sVZup6pA==",
      "license": "MIT"
    },
    "node_modules/langchainhub": {
      "version": "0.0.11",
      "resolved": "https://registry.npmjs.org/langchainhub/-/langchainhub-0.0.11.tgz",
      "integrity": "sha512-WnKI4g9kU2bHQP136orXr2bcRdgz9iiTBpTN0jWt9IlScUKnJBoD0aa2HOzHURQKeQDnt2JwqVmQ6Depf5uDLQ==",
      "license": "MIT"
    },
    "node_modules/langsmith": {
      "version": "0.1.68",
      "resolved": "https://registry.npmjs.org/langsmith/-/langsmith-0.1.68.tgz",
      "integrity": "sha512-otmiysWtVAqzMx3CJ4PrtUBhWRG5Co8Z4o7hSZENPjlit9/j3/vm3TSvbaxpDYakZxtMjhkcJTqrdYFipISEiQ==",
      "license": "MIT",
      "dependencies": {
        "@types/uuid": "^10.0.0",
        "commander": "^10.0.1",
        "p-queue": "^6.6.2",
        "p-retry": "4",
        "semver": "^7.6.3",
        "uuid": "^10.0.0"
      },
      "peerDependencies": {
        "openai": "*"
      },
      "peerDependenciesMeta": {
        "openai": {
          "optional": true
        }
      }
    },
    "node_modules/langsmith/node_modules/uuid": {
      "version": "10.0.0",
      "resolved": "https://registry.npmjs.org/uuid/-/uuid-10.0.0.tgz",
      "integrity": "sha512-8XkAphELsDnEGrDxUOHB3RGvXz6TeuYSGEZBOjtTtPm2lwhGBjLgOzLHB63IUWfBpNucQjND6d3AOudO+H3RWQ==",
      "funding": [
        "https://github.com/sponsors/broofa",
        "https://github.com/sponsors/ctavan"
      ],
      "license": "MIT",
      "bin": {
        "uuid": "dist/bin/uuid"
      }
    },
    "node_modules/language-subtag-registry": {
      "version": "0.3.23",
      "resolved": "https://registry.npmjs.org/language-subtag-registry/-/language-subtag-registry-0.3.23.tgz",
      "integrity": "sha512-0K65Lea881pHotoGEa5gDlMxt3pctLi2RplBb7Ezh4rRdLEOtgi7n4EwK9lamnUCkKBqaeKRVebTq6BAxSkpXQ==",
      "dev": true,
      "license": "CC0-1.0"
    },
    "node_modules/language-tags": {
      "version": "1.0.9",
      "resolved": "https://registry.npmjs.org/language-tags/-/language-tags-1.0.9.tgz",
      "integrity": "sha512-MbjN408fEndfiQXbFQ1vnd+1NoLDsnQW41410oQBXiyXDMYH5z505juWa4KUE1LqxRC7DgOgZDbKLxHIwm27hA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "language-subtag-registry": "^0.3.20"
      },
      "engines": {
        "node": ">=0.10"
      }
    },
    "node_modules/leven": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/leven/-/leven-3.1.0.tgz",
      "integrity": "sha512-qsda+H8jTaUaN/x5vzW2rzc+8Rw4TAQ/4KjB46IwK5VH+IlVeeeje/EoZRpiXvIqjFgK84QffqPztGI3VBLG1A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/levn": {
      "version": "0.4.1",
      "resolved": "https://registry.npmjs.org/levn/-/levn-0.4.1.tgz",
      "integrity": "sha512-+bT2uH4E5LGE7h/n3evcS/sQlJXCpIp6ym8OWJ5eV6+67Dsql/LaaT7qJBAt2rzfoa/5QBGBhxDix1dMt2kQKQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "prelude-ls": "^1.2.1",
        "type-check": "~0.4.0"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/lilconfig": {
      "version": "3.1.3",
      "resolved": "https://registry.npmjs.org/lilconfig/-/lilconfig-3.1.3.tgz",
      "integrity": "sha512-/vlFKAoH5Cgt3Ie+JLhRbwOsCQePABiU3tJ1egGvyQ+33R/vcwM2Zl2QR/LzjsBeItPt3oSVXapn+m4nQDvpzw==",
      "license": "MIT",
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/antonk52"
      }
    },
    "node_modules/lines-and-columns": {
      "version": "1.2.4",
      "resolved": "https://registry.npmjs.org/lines-and-columns/-/lines-and-columns-1.2.4.tgz",
      "integrity": "sha512-7ylylesZQ/PV29jhEDl3Ufjo6ZX7gCqJr5F7PKrqc93v7fzSymt1BpwEU8nAUXs8qzzvqhbjhK5QZg6Mt/HkBg==",
      "license": "MIT"
    },
    "node_modules/locate-path": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-6.0.0.tgz",
      "integrity": "sha512-iPZK6eYjbxRu3uB4/WZ3EsEIMJFMqAoopl3R+zuq0UjcAm/MO6KCweDgPfP3elTztoKP3KtnVHxTn2NHBSDVUw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-locate": "^5.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/lodash": {
      "version": "4.17.21",
      "resolved": "https://registry.npmjs.org/lodash/-/lodash-4.17.21.tgz",
      "integrity": "sha512-v2kDEe57lecTulaDIuNTPy3Ry4gLGJ6Z1O3vE1krgXZNrsQ+LFTGHVxVjcXPs17LhbZVGedAJv8XZ1tvj5FvSg==",
      "license": "MIT"
    },
    "node_modules/lodash.debounce": {
      "version": "4.0.8",
      "resolved": "https://registry.npmjs.org/lodash.debounce/-/lodash.debounce-4.0.8.tgz",
      "integrity": "sha512-FT1yDzDYEoYWhnSGnpE/4Kj1fLZkDFyqRb7fNt6FdYOSxlUWAtp42Eh6Wb0rGIv/m9Bgo7x4GhQbm5Ys4SG5ow==",
      "license": "MIT"
    },
    "node_modules/lodash.merge": {
      "version": "4.6.2",
      "resolved": "https://registry.npmjs.org/lodash.merge/-/lodash.merge-4.6.2.tgz",
      "integrity": "sha512-0KpjqXRVvrYyCsX1swR/XTK0va6VQkQM6MNo7PqW77ByjAhoARA8EfrP1N4+KlKj8YS0ZUCtRT/YUuhyYDujIQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/longest-streak": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/longest-streak/-/longest-streak-3.1.0.tgz",
      "integrity": "sha512-9Ri+o0JYgehTaVBBDoMqIl8GXtbWg711O3srftcHhZ0dqnETqLaoIK0x17fUw9rFSlK/0NlsKe0Ahhyl5pXE2g==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/loose-envify": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/loose-envify/-/loose-envify-1.4.0.tgz",
      "integrity": "sha512-lyuxPGr/Wfhrlem2CL/UcnUc1zcqKAImBDzukY7Y5F/yQiNdko6+fRLevlw1HgMySw7f611UIY408EtxRSoK3Q==",
      "license": "MIT",
      "dependencies": {
        "js-tokens": "^3.0.0 || ^4.0.0"
      },
      "bin": {
        "loose-envify": "cli.js"
      }
    },
    "node_modules/lowlight": {
      "version": "1.20.0",
      "resolved": "https://registry.npmjs.org/lowlight/-/lowlight-1.20.0.tgz",
      "integrity": "sha512-8Ktj+prEb1RoCPkEOrPMYUN/nCggB7qAWe3a7OpMjWQkh3l2RD5wKRQ+o8Q8YuI9RG/xs95waaI/E6ym/7NsTw==",
      "license": "MIT",
      "dependencies": {
        "fault": "^1.0.0",
        "highlight.js": "~10.7.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/lru-cache": {
      "version": "10.4.3",
      "resolved": "https://registry.npmjs.org/lru-cache/-/lru-cache-10.4.3.tgz",
      "integrity": "sha512-JNAzZcXrCt42VGLuYz0zfAzDfAvJWW6AfYlDBQyDV5DClI2m5sAmK+OIO7s59XfsRsWHp02jAJrRadPRGTt6SQ==",
      "license": "ISC"
    },
    "node_modules/lucide-react": {
      "version": "0.359.0",
      "resolved": "https://registry.npmjs.org/lucide-react/-/lucide-react-0.359.0.tgz",
      "integrity": "sha512-bxVL+rM/wacjpT0BKShA6r5IIKb6LCRg+ltFG9pnnIwaRX8kK3hq8v5JwMpT7RC6XeqB5cSaaV6GapPWWmtliw==",
      "license": "ISC",
      "peerDependencies": {
        "react": "^16.5.1 || ^17.0.0 || ^18.0.0"
      }
    },
    "node_modules/lz-string": {
      "version": "1.5.0",
      "resolved": "https://registry.npmjs.org/lz-string/-/lz-string-1.5.0.tgz",
      "integrity": "sha512-h5bgJWpxJNswbU7qCrV0tIKQCaS3blPDrqKWx+QxzuzL1zGUzij9XCWLrSLsJPu5t+eWA/ycetzYAO5IOMcWAQ==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "bin": {
        "lz-string": "bin/bin.js"
      }
    },
    "node_modules/make-dir": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/make-dir/-/make-dir-4.0.0.tgz",
      "integrity": "sha512-hXdUTZYIVOt1Ex//jAQi+wTZZpUpwBj/0QsOzqegb3rGMMeJiSEu5xLHnYfBrRV4RH2+OCSOO95Is/7x1WJ4bw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "semver": "^7.5.3"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/makeerror": {
      "version": "1.0.12",
      "resolved": "https://registry.npmjs.org/makeerror/-/makeerror-1.0.12.tgz",
      "integrity": "sha512-JmqCvUhmt43madlpFzG4BQzG2Z3m6tvQDNKdClZnO3VbIudJYmxsT0FNJMeiB2+JTSlTQTSbU8QdesVmwJcmLg==",
      "dev": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "tmpl": "1.0.5"
      }
    },
    "node_modules/markdown-table": {
      "version": "3.0.4",
      "resolved": "https://registry.npmjs.org/markdown-table/-/markdown-table-3.0.4.tgz",
      "integrity": "sha512-wiYz4+JrLyb/DqW2hkFJxP7Vd7JuTDm77fvbM8VfEQdmSMqcImWeeRbHwZjBjIFki/VaMK2BhFi7oUUZeM5bqw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/math-intrinsics": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/math-intrinsics/-/math-intrinsics-1.1.0.tgz",
      "integrity": "sha512-/IXtbwEk5HTPyEwyKX6hGkYXxM9nbj64B+ilVJnC/R6B0pH5G4V3b0pVbL7DBj4tkhBAppbQUlf6F6Xl9LHu1g==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/md5": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/md5/-/md5-2.3.0.tgz",
      "integrity": "sha512-T1GITYmFaKuO91vxyoQMFETst+O71VUPEU3ze5GNzDm0OWdP8v1ziTaAEPUr/3kLsY3Sftgz242A1SetQiDL7g==",
      "license": "BSD-3-Clause",
      "dependencies": {
        "charenc": "0.0.2",
        "crypt": "0.0.2",
        "is-buffer": "~1.1.6"
      }
    },
    "node_modules/mdast-util-find-and-replace": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/mdast-util-find-and-replace/-/mdast-util-find-and-replace-3.0.2.tgz",
      "integrity": "sha512-Tmd1Vg/m3Xz43afeNxDIhWRtFZgM2VLyaf4vSTYwudTyeuTneoL3qtWMA5jeLyz/O1vDJmmV4QuScFCA2tBPwg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "escape-string-regexp": "^5.0.0",
        "unist-util-is": "^6.0.0",
        "unist-util-visit-parents": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-find-and-replace/node_modules/escape-string-regexp": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-5.0.0.tgz",
      "integrity": "sha512-/veY75JbMK4j1yjvuUxuVsiS/hr/4iHs9FTT6cgTexxdE0Ly/glccBAkloH/DofkjRbZU3bnoj38mOmhkZ0lHw==",
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/mdast-util-from-markdown": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/mdast-util-from-markdown/-/mdast-util-from-markdown-2.0.2.tgz",
      "integrity": "sha512-uZhTV/8NBuw0WHkPTrCqDOl0zVe1BIng5ZtHoDk49ME1qqcjYmmLmOf0gELgcRMxN4w2iuIeVso5/6QymSrgmA==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "@types/unist": "^3.0.0",
        "decode-named-character-reference": "^1.0.0",
        "devlop": "^1.0.0",
        "mdast-util-to-string": "^4.0.0",
        "micromark": "^4.0.0",
        "micromark-util-decode-numeric-character-reference": "^2.0.0",
        "micromark-util-decode-string": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0",
        "unist-util-stringify-position": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm/-/mdast-util-gfm-3.1.0.tgz",
      "integrity": "sha512-0ulfdQOM3ysHhCJ1p06l0b0VKlhU0wuQs3thxZQagjcjPrlFRqY215uZGHHJan9GEAXd9MbfPjFJz+qMkVR6zQ==",
      "license": "MIT",
      "dependencies": {
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-gfm-autolink-literal": "^2.0.0",
        "mdast-util-gfm-footnote": "^2.0.0",
        "mdast-util-gfm-strikethrough": "^2.0.0",
        "mdast-util-gfm-table": "^2.0.0",
        "mdast-util-gfm-task-list-item": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-autolink-literal": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-autolink-literal/-/mdast-util-gfm-autolink-literal-2.0.1.tgz",
      "integrity": "sha512-5HVP2MKaP6L+G6YaxPNjuL0BPrq9orG3TsrZ9YXbA3vDw/ACI4MEsnoDpn6ZNm7GnZgtAcONJyPhOP8tNJQavQ==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "ccount": "^2.0.0",
        "devlop": "^1.0.0",
        "mdast-util-find-and-replace": "^3.0.0",
        "micromark-util-character": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-footnote": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-footnote/-/mdast-util-gfm-footnote-2.1.0.tgz",
      "integrity": "sha512-sqpDWlsHn7Ac9GNZQMeUzPQSMzR6Wv0WKRNvQRg0KqHh02fpTz69Qc1QSseNX29bhz1ROIyNyxExfawVKTm1GQ==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "devlop": "^1.1.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-strikethrough": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-strikethrough/-/mdast-util-gfm-strikethrough-2.0.0.tgz",
      "integrity": "sha512-mKKb915TF+OC5ptj5bJ7WFRPdYtuHv0yTRxK2tJvi+BDqbkiG7h7u/9SI89nRAYcmap2xHQL9D+QG/6wSrTtXg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-table": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-table/-/mdast-util-gfm-table-2.0.0.tgz",
      "integrity": "sha512-78UEvebzz/rJIxLvE7ZtDd/vIQ0RHv+3Mh5DR96p7cS7HsBhYIICDBCu8csTNWNO6tBWfqXPWekRuj2FNOGOZg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "markdown-table": "^3.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-gfm-task-list-item": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/mdast-util-gfm-task-list-item/-/mdast-util-gfm-task-list-item-2.0.0.tgz",
      "integrity": "sha512-IrtvNvjxC1o06taBAVJznEnkiHxLFTzgonUdy8hzFVeDun0uTjxxrRGVaNFqkU1wJR3RBPEfsxmU6jDWPofrTQ==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-mdx-expression": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/mdast-util-mdx-expression/-/mdast-util-mdx-expression-2.0.1.tgz",
      "integrity": "sha512-J6f+9hUp+ldTZqKRSg7Vw5V6MqjATc+3E4gf3CFNcuZNWD8XdyI6zQ8GqH7f8169MM6P7hMBRDVGnn7oHB9kXQ==",
      "license": "MIT",
      "dependencies": {
        "@types/estree-jsx": "^1.0.0",
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-mdx-jsx": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/mdast-util-mdx-jsx/-/mdast-util-mdx-jsx-3.2.0.tgz",
      "integrity": "sha512-lj/z8v0r6ZtsN/cGNNtemmmfoLAFZnjMbNyLzBafjzikOM+glrjNHPlf6lQDOTccj9n5b0PPihEBbhneMyGs1Q==",
      "license": "MIT",
      "dependencies": {
        "@types/estree-jsx": "^1.0.0",
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "@types/unist": "^3.0.0",
        "ccount": "^2.0.0",
        "devlop": "^1.1.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0",
        "parse-entities": "^4.0.0",
        "stringify-entities": "^4.0.0",
        "unist-util-stringify-position": "^4.0.0",
        "vfile-message": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-mdxjs-esm": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/mdast-util-mdxjs-esm/-/mdast-util-mdxjs-esm-2.0.1.tgz",
      "integrity": "sha512-EcmOpxsZ96CvlP03NghtH1EsLtr0n9Tm4lPUJUBccV9RwUOneqSycg19n5HGzCf+10LozMRSObtVr3ee1WoHtg==",
      "license": "MIT",
      "dependencies": {
        "@types/estree-jsx": "^1.0.0",
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "mdast-util-to-markdown": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-phrasing": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/mdast-util-phrasing/-/mdast-util-phrasing-4.1.0.tgz",
      "integrity": "sha512-TqICwyvJJpBwvGAMZjj4J2n0X8QWp21b9l0o7eXyVJ25YNWYbJDVIyD1bZXE6WtV6RmKJVYmQAKWa0zWOABz2w==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "unist-util-is": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-to-hast": {
      "version": "13.2.0",
      "resolved": "https://registry.npmjs.org/mdast-util-to-hast/-/mdast-util-to-hast-13.2.0.tgz",
      "integrity": "sha512-QGYKEuUsYT9ykKBCMOEDLsU5JRObWQusAolFMeko/tYPufNkRffBAQjIE+99jbA87xv6FgmjLtwjh9wBWajwAA==",
      "license": "MIT",
      "dependencies": {
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "@ungap/structured-clone": "^1.0.0",
        "devlop": "^1.0.0",
        "micromark-util-sanitize-uri": "^2.0.0",
        "trim-lines": "^3.0.0",
        "unist-util-position": "^5.0.0",
        "unist-util-visit": "^5.0.0",
        "vfile": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-to-markdown": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/mdast-util-to-markdown/-/mdast-util-to-markdown-2.1.2.tgz",
      "integrity": "sha512-xj68wMTvGXVOKonmog6LwyJKrYXZPvlwabaryTjLh9LuvovB/KAH+kvi8Gjj+7rJjsFi23nkUxRQv1KqSroMqA==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "@types/unist": "^3.0.0",
        "longest-streak": "^3.0.0",
        "mdast-util-phrasing": "^4.0.0",
        "mdast-util-to-string": "^4.0.0",
        "micromark-util-classify-character": "^2.0.0",
        "micromark-util-decode-string": "^2.0.0",
        "unist-util-visit": "^5.0.0",
        "zwitch": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/mdast-util-to-string": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/mdast-util-to-string/-/mdast-util-to-string-4.0.0.tgz",
      "integrity": "sha512-0H44vDimn51F0YwvxSJSm0eCDOJTRlmN0R1yBh4HLj9wiV1Dn0QoXGbvFAWj2hSItVTlCmBF1hqKlIyUBVFLPg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/merge-stream": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/merge-stream/-/merge-stream-2.0.0.tgz",
      "integrity": "sha512-abv/qOcuPfk3URPfDzmZU1LKmuw8kT+0nIHvKrKgFrwifol/doWcdA4ZqsWQ8ENrFKkd67Mfpo/LovbIUsbt3w==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/merge2": {
      "version": "1.4.1",
      "resolved": "https://registry.npmjs.org/merge2/-/merge2-1.4.1.tgz",
      "integrity": "sha512-8q7VEgMJW4J8tcfVPy8g09NcQwZdbwFEqhe/WZkoIzjn/3TGDwtOCYtXGxA3O8tPzpczCCDgv+P2P5y00ZJOOg==",
      "license": "MIT",
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/micromark": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/micromark/-/micromark-4.0.2.tgz",
      "integrity": "sha512-zpe98Q6kvavpCr1NPVSCMebCKfD7CA2NqZ+rykeNhONIJBpc1tFKt9hucLGwha3jNTNI8lHpctWJWoimVF4PfA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "@types/debug": "^4.0.0",
        "debug": "^4.0.0",
        "decode-named-character-reference": "^1.0.0",
        "devlop": "^1.0.0",
        "micromark-core-commonmark": "^2.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-combine-extensions": "^2.0.0",
        "micromark-util-decode-numeric-character-reference": "^2.0.0",
        "micromark-util-encode": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0",
        "micromark-util-resolve-all": "^2.0.0",
        "micromark-util-sanitize-uri": "^2.0.0",
        "micromark-util-subtokenize": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-core-commonmark": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/micromark-core-commonmark/-/micromark-core-commonmark-2.0.3.tgz",
      "integrity": "sha512-RDBrHEMSxVFLg6xvnXmb1Ayr2WzLAWjeSATAoxwKYJV94TeNavgoIdA0a9ytzDSVzBy2YKFK+emCPOEibLeCrg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "decode-named-character-reference": "^1.0.0",
        "devlop": "^1.0.0",
        "micromark-factory-destination": "^2.0.0",
        "micromark-factory-label": "^2.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-factory-title": "^2.0.0",
        "micromark-factory-whitespace": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-classify-character": "^2.0.0",
        "micromark-util-html-tag-name": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0",
        "micromark-util-resolve-all": "^2.0.0",
        "micromark-util-subtokenize": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-extension-gfm": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm/-/micromark-extension-gfm-3.0.0.tgz",
      "integrity": "sha512-vsKArQsicm7t0z2GugkCKtZehqUm31oeGBV/KVSorWSy8ZlNAv7ytjFhvaryUiCUJYqs+NoE6AFhpQvBTM6Q4w==",
      "license": "MIT",
      "dependencies": {
        "micromark-extension-gfm-autolink-literal": "^2.0.0",
        "micromark-extension-gfm-footnote": "^2.0.0",
        "micromark-extension-gfm-strikethrough": "^2.0.0",
        "micromark-extension-gfm-table": "^2.0.0",
        "micromark-extension-gfm-tagfilter": "^2.0.0",
        "micromark-extension-gfm-task-list-item": "^2.0.0",
        "micromark-util-combine-extensions": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-autolink-literal": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-autolink-literal/-/micromark-extension-gfm-autolink-literal-2.1.0.tgz",
      "integrity": "sha512-oOg7knzhicgQ3t4QCjCWgTmfNhvQbDDnJeVu9v81r7NltNCVmhPy1fJRX27pISafdjL+SVc4d3l48Gb6pbRypw==",
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-sanitize-uri": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-footnote": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-footnote/-/micromark-extension-gfm-footnote-2.1.0.tgz",
      "integrity": "sha512-/yPhxI1ntnDNsiHtzLKYnE3vf9JZ6cAisqVDauhp4CEHxlb4uoOTxOCJ+9s51bIB8U1N1FJ1RXOKTIlD5B/gqw==",
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-core-commonmark": "^2.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-normalize-identifier": "^2.0.0",
        "micromark-util-sanitize-uri": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-strikethrough": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-strikethrough/-/micromark-extension-gfm-strikethrough-2.1.0.tgz",
      "integrity": "sha512-ADVjpOOkjz1hhkZLlBiYA9cR2Anf8F4HqZUO6e5eDcPQd0Txw5fxLzzxnEkSkfnD0wziSGiv7sYhk/ktvbf1uw==",
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-classify-character": "^2.0.0",
        "micromark-util-resolve-all": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-table": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-table/-/micromark-extension-gfm-table-2.1.1.tgz",
      "integrity": "sha512-t2OU/dXXioARrC6yWfJ4hqB7rct14e8f7m0cbI5hUmDyyIlwv5vEtooptH8INkbLzOatzKuVbQmAYcbWoyz6Dg==",
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-tagfilter": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-tagfilter/-/micromark-extension-gfm-tagfilter-2.0.0.tgz",
      "integrity": "sha512-xHlTOmuCSotIA8TW1mDIM6X2O1SiX5P9IuDtqGonFhEK0qgRI4yeC6vMxEV2dgyr2TiD+2PQ10o+cOhdVAcwfg==",
      "license": "MIT",
      "dependencies": {
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-extension-gfm-task-list-item": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-extension-gfm-task-list-item/-/micromark-extension-gfm-task-list-item-2.1.0.tgz",
      "integrity": "sha512-qIBZhqxqI6fjLDYFTBIa4eivDMnP+OZqsNwmQ3xNLE4Cxwc+zfQEfbs6tzAo2Hjq+bh6q5F+Z8/cksrLFYWQQw==",
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/micromark-factory-destination": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-destination/-/micromark-factory-destination-2.0.1.tgz",
      "integrity": "sha512-Xe6rDdJlkmbFRExpTOmRj9N3MaWmbAgdpSrBQvCFqhezUn4AHqJHbaEnfbVYYiexVSs//tqOdY/DxhjdCiJnIA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-factory-label": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-label/-/micromark-factory-label-2.0.1.tgz",
      "integrity": "sha512-VFMekyQExqIW7xIChcXn4ok29YE3rnuyveW3wZQWWqF4Nv9Wk5rgJ99KzPvHjkmPXF93FXIbBp6YdW3t71/7Vg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-factory-space": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-space/-/micromark-factory-space-2.0.1.tgz",
      "integrity": "sha512-zRkxjtBxxLd2Sc0d+fbnEunsTj46SWXgXciZmHq0kDYGnck/ZSGj9/wULTV95uoeYiK5hRXP2mJ98Uo4cq/LQg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-factory-title": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-title/-/micromark-factory-title-2.0.1.tgz",
      "integrity": "sha512-5bZ+3CjhAd9eChYTHsjy6TGxpOFSKgKKJPJxr293jTbfry2KDoWkhBb6TcPVB4NmzaPhMs1Frm9AZH7OD4Cjzw==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-factory-whitespace": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-factory-whitespace/-/micromark-factory-whitespace-2.0.1.tgz",
      "integrity": "sha512-Ob0nuZ3PKt/n0hORHyvoD9uZhr+Za8sFoP+OnMcnWK5lngSzALgQYKMr9RJVOWLqQYuyn6ulqGWSXdwf6F80lQ==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-factory-space": "^2.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-character": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/micromark-util-character/-/micromark-util-character-2.1.1.tgz",
      "integrity": "sha512-wv8tdUTJ3thSFFFJKtpYKOYiGP2+v96Hvk4Tu8KpCAsTMs6yi+nVmGh1syvSCsaxz45J6Jbw+9DD6g97+NV67Q==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-chunked": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-chunked/-/micromark-util-chunked-2.0.1.tgz",
      "integrity": "sha512-QUNFEOPELfmvv+4xiNg2sRYeS/P84pTW0TCgP5zc9FpXetHY0ab7SxKyAQCNCc1eK0459uoLI1y5oO5Vc1dbhA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-classify-character": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-classify-character/-/micromark-util-classify-character-2.0.1.tgz",
      "integrity": "sha512-K0kHzM6afW/MbeWYWLjoHQv1sgg2Q9EccHEDzSkxiP/EaagNzCm7T/WMKZ3rjMbvIpvBiZgwR3dKMygtA4mG1Q==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-combine-extensions": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-combine-extensions/-/micromark-util-combine-extensions-2.0.1.tgz",
      "integrity": "sha512-OnAnH8Ujmy59JcyZw8JSbK9cGpdVY44NKgSM7E9Eh7DiLS2E9RNQf0dONaGDzEG9yjEl5hcqeIsj4hfRkLH/Bg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-decode-numeric-character-reference": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/micromark-util-decode-numeric-character-reference/-/micromark-util-decode-numeric-character-reference-2.0.2.tgz",
      "integrity": "sha512-ccUbYk6CwVdkmCQMyr64dXz42EfHGkPQlBj5p7YVGzq8I7CtjXZJrubAYezf7Rp+bjPseiROqe7G6foFd+lEuw==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-decode-string": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-decode-string/-/micromark-util-decode-string-2.0.1.tgz",
      "integrity": "sha512-nDV/77Fj6eH1ynwscYTOsbK7rR//Uj0bZXBwJZRfaLEJ1iGBR6kIfNmlNqaqJf649EP0F3NWNdeJi03elllNUQ==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "decode-named-character-reference": "^1.0.0",
        "micromark-util-character": "^2.0.0",
        "micromark-util-decode-numeric-character-reference": "^2.0.0",
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-encode": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-encode/-/micromark-util-encode-2.0.1.tgz",
      "integrity": "sha512-c3cVx2y4KqUnwopcO9b/SCdo2O67LwJJ/UyqGfbigahfegL9myoEFoDYZgkT7f36T0bLrM9hZTAaAyH+PCAXjw==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT"
    },
    "node_modules/micromark-util-html-tag-name": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-html-tag-name/-/micromark-util-html-tag-name-2.0.1.tgz",
      "integrity": "sha512-2cNEiYDhCWKI+Gs9T0Tiysk136SnR13hhO8yW6BGNyhOC4qYFnwF1nKfD3HFAIXA5c45RrIG1ub11GiXeYd1xA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT"
    },
    "node_modules/micromark-util-normalize-identifier": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-normalize-identifier/-/micromark-util-normalize-identifier-2.0.1.tgz",
      "integrity": "sha512-sxPqmo70LyARJs0w2UclACPUUEqltCkJ6PhKdMIDuJ3gSf/Q+/GIe3WKl0Ijb/GyH9lOpUkRAO2wp0GVkLvS9Q==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-resolve-all": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-resolve-all/-/micromark-util-resolve-all-2.0.1.tgz",
      "integrity": "sha512-VdQyxFWFT2/FGJgwQnJYbe1jjQoNTS4RjglmSjTUlpUMa95Htx9NHeYW4rGDJzbjvCsl9eLjMQwGeElsqmzcHg==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-sanitize-uri": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-sanitize-uri/-/micromark-util-sanitize-uri-2.0.1.tgz",
      "integrity": "sha512-9N9IomZ/YuGGZZmQec1MbgxtlgougxTodVwDzzEouPKo3qFWvymFHWcnDi2vzV1ff6kas9ucW+o3yzJK9YB1AQ==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "micromark-util-character": "^2.0.0",
        "micromark-util-encode": "^2.0.0",
        "micromark-util-symbol": "^2.0.0"
      }
    },
    "node_modules/micromark-util-subtokenize": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/micromark-util-subtokenize/-/micromark-util-subtokenize-2.1.0.tgz",
      "integrity": "sha512-XQLu552iSctvnEcgXw6+Sx75GflAPNED1qx7eBJ+wydBb2KCbRZe+NwvIEEMM83uml1+2WSXpBAcp9IUCgCYWA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "devlop": "^1.0.0",
        "micromark-util-chunked": "^2.0.0",
        "micromark-util-symbol": "^2.0.0",
        "micromark-util-types": "^2.0.0"
      }
    },
    "node_modules/micromark-util-symbol": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/micromark-util-symbol/-/micromark-util-symbol-2.0.1.tgz",
      "integrity": "sha512-vs5t8Apaud9N28kgCrRUdEed4UJ+wWNvicHLPxCa9ENlYuAY31M0ETy5y1vA33YoNPDFTghEbnh6efaE8h4x0Q==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT"
    },
    "node_modules/micromark-util-types": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/micromark-util-types/-/micromark-util-types-2.0.2.tgz",
      "integrity": "sha512-Yw0ECSpJoViF1qTU4DC6NwtC4aWGt1EkzaQB8KPPyCRR8z9TWeV0HbEFGTO+ZY1wB22zmxnJqhPyTpOVCpeHTA==",
      "funding": [
        {
          "type": "GitHub Sponsors",
          "url": "https://github.com/sponsors/unifiedjs"
        },
        {
          "type": "OpenCollective",
          "url": "https://opencollective.com/unified"
        }
      ],
      "license": "MIT"
    },
    "node_modules/micromatch": {
      "version": "4.0.8",
      "resolved": "https://registry.npmjs.org/micromatch/-/micromatch-4.0.8.tgz",
      "integrity": "sha512-PXwfBhYu0hBCPw8Dn0E+WDYb7af3dSLVWKi3HGv84IdF4TyFoC0ysxFd0Goxw7nSv4T/PzEJQxsYsEiFCKo2BA==",
      "license": "MIT",
      "dependencies": {
        "braces": "^3.0.3",
        "picomatch": "^2.3.1"
      },
      "engines": {
        "node": ">=8.6"
      }
    },
    "node_modules/mime-db": {
      "version": "1.52.0",
      "resolved": "https://registry.npmjs.org/mime-db/-/mime-db-1.52.0.tgz",
      "integrity": "sha512-sPU4uV7dYlvtWJxwwxHD0PuihVNiE7TyAbQ5SWxDCB9mUYvOgroQOwYQQOKPJ8CIbE+1ETVlOoK1UC2nU3gYvg==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/mime-types": {
      "version": "2.1.35",
      "resolved": "https://registry.npmjs.org/mime-types/-/mime-types-2.1.35.tgz",
      "integrity": "sha512-ZDY+bPm5zTTF+YpCrAU9nK0UgICYPT0QtT1NZWFv4s++TNkcgVaT0g6+4R2uI4MjQjzysHB1zxuWL50hzaeXiw==",
      "license": "MIT",
      "dependencies": {
        "mime-db": "1.52.0"
      },
      "engines": {
        "node": ">= 0.6"
      }
    },
    "node_modules/mimic-fn": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/mimic-fn/-/mimic-fn-2.1.0.tgz",
      "integrity": "sha512-OqbOk5oEQeAZ8WXWydlu9HJjz9WVdEIvamMCcXmuqUYjTknH/sqsWvhQ3vgwKFRR1HpjvNBKQ37nbJgYzGqGcg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/min-indent": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/min-indent/-/min-indent-1.0.1.tgz",
      "integrity": "sha512-I9jwMn07Sy/IwOj3zVkVik2JTvgpaykDZEigL6Rx6N9LbMywwUSMtxET+7lVoDLLd3O3IXwJwvuuns8UB/HeAg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/minimatch": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/minimatch/-/minimatch-3.1.2.tgz",
      "integrity": "sha512-J7p63hRiAjw1NDEww1W7i37+ByIrOWO5XQQAzZ3VOcL0PNybwpfmV/N05zFAzwQ9USyEcX6t3UO+K5aqBQOIHw==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "brace-expansion": "^1.1.7"
      },
      "engines": {
        "node": "*"
      }
    },
    "node_modules/minimist": {
      "version": "1.2.8",
      "resolved": "https://registry.npmjs.org/minimist/-/minimist-1.2.8.tgz",
      "integrity": "sha512-2yyAR8qBkN3YuheJanUpWC5U3bb5osDywNB8RzDVlDwDHbocAJveqqj1u8+SVD7jkWT4yvsHCpWqqWqAxb0zCA==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/minipass": {
      "version": "7.1.2",
      "resolved": "https://registry.npmjs.org/minipass/-/minipass-7.1.2.tgz",
      "integrity": "sha512-qOOzS1cBTWYF4BH8fVePDBOO9iptMnGUEZwNc/cMWnTV2nVLZ7VoNWEPHkYczZA0pdoA7dl6e7FL659nX9S2aw==",
      "license": "ISC",
      "engines": {
        "node": ">=16 || 14 >=14.17"
      }
    },
    "node_modules/ml-array-mean": {
      "version": "1.1.6",
      "resolved": "https://registry.npmjs.org/ml-array-mean/-/ml-array-mean-1.1.6.tgz",
      "integrity": "sha512-MIdf7Zc8HznwIisyiJGRH9tRigg3Yf4FldW8DxKxpCCv/g5CafTw0RRu51nojVEOXuCQC7DRVVu5c7XXO/5joQ==",
      "license": "MIT",
      "dependencies": {
        "ml-array-sum": "^1.1.6"
      }
    },
    "node_modules/ml-array-sum": {
      "version": "1.1.6",
      "resolved": "https://registry.npmjs.org/ml-array-sum/-/ml-array-sum-1.1.6.tgz",
      "integrity": "sha512-29mAh2GwH7ZmiRnup4UyibQZB9+ZLyMShvt4cH4eTK+cL2oEMIZFnSyB3SS8MlsTh6q/w/yh48KmqLxmovN4Dw==",
      "license": "MIT",
      "dependencies": {
        "is-any-array": "^2.0.0"
      }
    },
    "node_modules/ml-distance": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/ml-distance/-/ml-distance-4.0.1.tgz",
      "integrity": "sha512-feZ5ziXs01zhyFUUUeZV5hwc0f5JW0Sh0ckU1koZe/wdVkJdGxcP06KNQuF0WBTj8FttQUzcvQcpcrOp/XrlEw==",
      "license": "MIT",
      "dependencies": {
        "ml-array-mean": "^1.1.6",
        "ml-distance-euclidean": "^2.0.0",
        "ml-tree-similarity": "^1.0.0"
      }
    },
    "node_modules/ml-distance-euclidean": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/ml-distance-euclidean/-/ml-distance-euclidean-2.0.0.tgz",
      "integrity": "sha512-yC9/2o8QF0A3m/0IXqCTXCzz2pNEzvmcE/9HFKOZGnTjatvBbsn4lWYJkxENkA4Ug2fnYl7PXQxnPi21sgMy/Q==",
      "license": "MIT"
    },
    "node_modules/ml-tree-similarity": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/ml-tree-similarity/-/ml-tree-similarity-1.0.0.tgz",
      "integrity": "sha512-XJUyYqjSuUQkNQHMscr6tcjldsOoAekxADTplt40QKfwW6nd++1wHWV9AArl0Zvw/TIHgNaZZNvr8QGvE8wLRg==",
      "license": "MIT",
      "dependencies": {
        "binary-search": "^1.3.5",
        "num-sort": "^2.0.0"
      }
    },
    "node_modules/ms": {
      "version": "2.1.3",
      "resolved": "https://registry.npmjs.org/ms/-/ms-2.1.3.tgz",
      "integrity": "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA==",
      "license": "MIT"
    },
    "node_modules/mustache": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/mustache/-/mustache-4.2.0.tgz",
      "integrity": "sha512-71ippSywq5Yb7/tVYyGbkBggbU8H3u5Rz56fH60jGFgr8uHwxs+aSKeqmluIVzM0m0kB7xQjKS6qPfd0b2ZoqQ==",
      "license": "MIT",
      "bin": {
        "mustache": "bin/mustache"
      }
    },
    "node_modules/mz": {
      "version": "2.7.0",
      "resolved": "https://registry.npmjs.org/mz/-/mz-2.7.0.tgz",
      "integrity": "sha512-z81GNO7nnYMEhrGh9LeymoE4+Yr0Wn5McHIZMK5cfQCl+NDX08sCZgUc9/6MHni9IWuFLm1Z3HTCXu2z9fN62Q==",
      "license": "MIT",
      "dependencies": {
        "any-promise": "^1.0.0",
        "object-assign": "^4.0.1",
        "thenify-all": "^1.0.0"
      }
    },
    "node_modules/nanoid": {
      "version": "3.3.9",
      "resolved": "https://registry.npmjs.org/nanoid/-/nanoid-3.3.9.tgz",
      "integrity": "sha512-SppoicMGpZvbF1l3z4x7No3OlIjP7QJvC9XR7AhZr1kL133KHnKPztkKDc+Ir4aJ/1VhTySrtKhrsycmrMQfvg==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "bin": {
        "nanoid": "bin/nanoid.cjs"
      },
      "engines": {
        "node": "^10 || ^12 || ^13.7 || ^14 || >=15.0.1"
      }
    },
    "node_modules/natural-compare": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/natural-compare/-/natural-compare-1.4.0.tgz",
      "integrity": "sha512-OWND8ei3VtNC9h7V60qff3SVobHr996CTwgxubgyQYEpg290h9J0buyECNNJexkFm5sOajh5G116RYA1c8ZMSw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/next": {
      "version": "14.2.4",
      "resolved": "https://registry.npmjs.org/next/-/next-14.2.4.tgz",
      "integrity": "sha512-R8/V7vugY+822rsQGQCjoLhMuC9oFj9SOi4Cl4b2wjDrseD0LRZ10W7R6Czo4w9ZznVSshKjuIomsRjvm9EKJQ==",
      "license": "MIT",
      "dependencies": {
        "@next/env": "14.2.4",
        "@swc/helpers": "0.5.5",
        "busboy": "1.6.0",
        "caniuse-lite": "^1.0.30001579",
        "graceful-fs": "^4.2.11",
        "postcss": "8.4.31",
        "styled-jsx": "5.1.1"
      },
      "bin": {
        "next": "dist/bin/next"
      },
      "engines": {
        "node": ">=18.17.0"
      },
      "optionalDependencies": {
        "@next/swc-darwin-arm64": "14.2.4",
        "@next/swc-darwin-x64": "14.2.4",
        "@next/swc-linux-arm64-gnu": "14.2.4",
        "@next/swc-linux-arm64-musl": "14.2.4",
        "@next/swc-linux-x64-gnu": "14.2.4",
        "@next/swc-linux-x64-musl": "14.2.4",
        "@next/swc-win32-arm64-msvc": "14.2.4",
        "@next/swc-win32-ia32-msvc": "14.2.4",
        "@next/swc-win32-x64-msvc": "14.2.4"
      },
      "peerDependencies": {
        "@opentelemetry/api": "^1.1.0",
        "@playwright/test": "^1.41.2",
        "react": "^18.2.0",
        "react-dom": "^18.2.0",
        "sass": "^1.3.0"
      },
      "peerDependenciesMeta": {
        "@opentelemetry/api": {
          "optional": true
        },
        "@playwright/test": {
          "optional": true
        },
        "sass": {
          "optional": true
        }
      }
    },
    "node_modules/next/node_modules/postcss": {
      "version": "8.4.31",
      "resolved": "https://registry.npmjs.org/postcss/-/postcss-8.4.31.tgz",
      "integrity": "sha512-PS08Iboia9mts/2ygV3eLpY5ghnUcfLV/EXTOW1E2qYxJKGGBUtNjN76FYHnMs36RmARn41bC0AZmn+rR0OVpQ==",
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/postcss"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "nanoid": "^3.3.6",
        "picocolors": "^1.0.0",
        "source-map-js": "^1.0.2"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      }
    },
    "node_modules/node-domexception": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/node-domexception/-/node-domexception-1.0.0.tgz",
      "integrity": "sha512-/jKZoMpw0F8GRwl4/eLROPA3cfcXtLApP0QzLmUT/HuPCZWyB7IY9ZrMeKw2O/nFIqPQB3PVM9aYm0F312AXDQ==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/jimmywarting"
        },
        {
          "type": "github",
          "url": "https://paypal.me/jimmywarting"
        }
      ],
      "license": "MIT",
      "engines": {
        "node": ">=10.5.0"
      }
    },
    "node_modules/node-fetch": {
      "version": "2.7.0",
      "resolved": "https://registry.npmjs.org/node-fetch/-/node-fetch-2.7.0.tgz",
      "integrity": "sha512-c4FRfUm/dbcWZ7U+1Wq0AwCyFL+3nt2bEw05wfxSz+DWpWsitgmSgYmy2dQdWyKC1694ELPqMs/YzUSNozLt8A==",
      "license": "MIT",
      "dependencies": {
        "whatwg-url": "^5.0.0"
      },
      "engines": {
        "node": "4.x || >=6.0.0"
      },
      "peerDependencies": {
        "encoding": "^0.1.0"
      },
      "peerDependenciesMeta": {
        "encoding": {
          "optional": true
        }
      }
    },
    "node_modules/node-int64": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/node-int64/-/node-int64-0.4.0.tgz",
      "integrity": "sha512-O5lz91xSOeoXP6DulyHfllpq+Eg00MWitZIbtPfoSEvqIHdl5gfcY6hYzDWnj0qD5tz52PI08u9qUvSVeUBeHw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/node-releases": {
      "version": "2.0.19",
      "resolved": "https://registry.npmjs.org/node-releases/-/node-releases-2.0.19.tgz",
      "integrity": "sha512-xxOWJsBKtzAq7DY0J+DTzuz58K8e7sJbdgwkbMWQe8UYB6ekmsQ45q0M/tJDsGaZmbC+l7n57UV8Hl5tHxO9uw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/normalize-path": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/normalize-path/-/normalize-path-3.0.0.tgz",
      "integrity": "sha512-6eZs5Ls3WtCisHWp9S2GUy8dqkpGi4BVSz3GaqiE6ezub0512ESztXUwUB6C6IKbQkY2Pnb/mD4WYojCRwcwLA==",
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/normalize-range": {
      "version": "0.1.2",
      "resolved": "https://registry.npmjs.org/normalize-range/-/normalize-range-0.1.2.tgz",
      "integrity": "sha512-bdok/XvKII3nUpklnV6P2hxtMNrCboOjAcyBuQnWEhO665FwrSNRxU+AqpsyvO6LgGYPspN+lu5CLtw4jPRKNA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/npm-run-path": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/npm-run-path/-/npm-run-path-4.0.1.tgz",
      "integrity": "sha512-S48WzZW777zhNIrn7gxOlISNAqi9ZC/uQFnRdbeIHhZhCA6UqpkOT8T1G7BvfdgP4Er8gF4sUbaS0i7QvIfCWw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "path-key": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/num-sort": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/num-sort/-/num-sort-2.1.0.tgz",
      "integrity": "sha512-1MQz1Ed8z2yckoBeSfkQHHO9K1yDRxxtotKSJ9yvcTUUxSvfvzEq5GwBrjjHEpMlq/k5gvXdmJ1SbYxWtpNoVg==",
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/nwsapi": {
      "version": "2.2.19",
      "resolved": "https://registry.npmjs.org/nwsapi/-/nwsapi-2.2.19.tgz",
      "integrity": "sha512-94bcyI3RsqiZufXjkr3ltkI86iEl+I7uiHVDtcq9wJUTwYQJ5odHDeSzkkrRzi80jJ8MaeZgqKjH1bAWAFw9bA==",
      "devOptional": true,
      "license": "MIT"
    },
    "node_modules/object-assign": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/object-assign/-/object-assign-4.1.1.tgz",
      "integrity": "sha512-rJgTQnkUnH1sFw8yT6VSU3zD3sWmu6sZhIseY8VX+GRu3P6F7Fu+JNDoXfklElbLJSnc3FUQHVe4cU5hj+BcUg==",
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/object-hash": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/object-hash/-/object-hash-3.0.0.tgz",
      "integrity": "sha512-RSn9F68PjH9HqtltsSnqYC1XXoWe9Bju5+213R98cNGttag9q9yAOTzdbsqvIa7aNm5WffBZFpWYr2aWrklWAw==",
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/object-inspect": {
      "version": "1.13.4",
      "resolved": "https://registry.npmjs.org/object-inspect/-/object-inspect-1.13.4.tgz",
      "integrity": "sha512-W67iLl4J2EXEGTbfeHCffrjDfitvLANg0UlX3wFUUSTx92KXRFegMHUVgSqE+wvhAbi4WqjGg9czysTV2Epbew==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/object-keys": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/object-keys/-/object-keys-1.1.1.tgz",
      "integrity": "sha512-NuAESUOUMrlIXOfHKzD6bpPu3tYt3xvjNdRIQ+FeT0lNb4K8WR70CaDxhuNguS2XG+GjkyMwOzsN5ZktImfhLA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/object.assign": {
      "version": "4.1.7",
      "resolved": "https://registry.npmjs.org/object.assign/-/object.assign-4.1.7.tgz",
      "integrity": "sha512-nK28WOo+QIjBkDduTINE4JkF/UJJKyf2EJxvJKfblDpyg0Q+pkOHNTL0Qwy6NP6FhE/EnzV73BxxqcJaXY9anw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0",
        "has-symbols": "^1.1.0",
        "object-keys": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/object.entries": {
      "version": "1.1.8",
      "resolved": "https://registry.npmjs.org/object.entries/-/object.entries-1.1.8.tgz",
      "integrity": "sha512-cmopxi8VwRIAw/fkijJohSfpef5PdN0pMQJN6VC/ZKvn0LIknWD8KtgY6KlQdEc4tIjcQ3HxSMmnvtzIscdaYQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/object.fromentries": {
      "version": "2.0.8",
      "resolved": "https://registry.npmjs.org/object.fromentries/-/object.fromentries-2.0.8.tgz",
      "integrity": "sha512-k6E21FzySsSK5a21KRADBd/NGneRegFO5pLHfdQLpRDETUNJueLXs3WCzyQ3tFRDYgbq3KHGXfTbi2bs8WQ6rQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/object.groupby": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/object.groupby/-/object.groupby-1.0.3.tgz",
      "integrity": "sha512-+Lhy3TQTuzXI5hevh8sBGqbmurHbbIjAi0Z4S63nthVLmLxfbj4T54a4CfZrXIrt9iP4mVAPYMo/v99taj3wjQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/object.values": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/object.values/-/object.values-1.2.1.tgz",
      "integrity": "sha512-gXah6aZrcUxjWg2zR2MwouP2eHlCBzdV4pygudehaKXSGW4v2AsRQUK+lwwXhii6KFZcunEnmSUoYp5CXibxtA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/once": {
      "version": "1.4.0",
      "resolved": "https://registry.npmjs.org/once/-/once-1.4.0.tgz",
      "integrity": "sha512-lNaJgI+2Q5URQBkccEKHTQOPaXdUxnZZElQTZY0MFUAuaEqe1E+Nyvgdz/aIyNi6Z9MzO5dv1H8n58/GELp3+w==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "wrappy": "1"
      }
    },
    "node_modules/onetime": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/onetime/-/onetime-5.1.2.tgz",
      "integrity": "sha512-kbpaSSGJTWdAY5KPVeMOKXSrPtr8C8C7wodJbcsd51jRnmD+GZu8Y0VoU6Dm5Z4vWr0Ig/1NKuWRKf7j5aaYSg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "mimic-fn": "^2.1.0"
      },
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/openai": {
      "version": "4.87.3",
      "resolved": "https://registry.npmjs.org/openai/-/openai-4.87.3.tgz",
      "integrity": "sha512-d2D54fzMuBYTxMW8wcNmhT1rYKcTfMJ8t+4KjH2KtvYenygITiGBgHoIrzHwnDQWW+C5oCA+ikIR2jgPCFqcKQ==",
      "license": "Apache-2.0",
      "dependencies": {
        "@types/node": "^18.11.18",
        "@types/node-fetch": "^2.6.4",
        "abort-controller": "^3.0.0",
        "agentkeepalive": "^4.2.1",
        "form-data-encoder": "1.7.2",
        "formdata-node": "^4.3.2",
        "node-fetch": "^2.6.7"
      },
      "bin": {
        "openai": "bin/cli"
      },
      "peerDependencies": {
        "ws": "^8.18.0",
        "zod": "^3.23.8"
      },
      "peerDependenciesMeta": {
        "ws": {
          "optional": true
        },
        "zod": {
          "optional": true
        }
      }
    },
    "node_modules/openai/node_modules/@types/node": {
      "version": "18.19.80",
      "resolved": "https://registry.npmjs.org/@types/node/-/node-18.19.80.tgz",
      "integrity": "sha512-kEWeMwMeIvxYkeg1gTc01awpwLbfMRZXdIhwRcakd/KlK53jmRC26LqcbIt7fnAQTu5GzlnWmzA3H6+l1u6xxQ==",
      "license": "MIT",
      "dependencies": {
        "undici-types": "~5.26.4"
      }
    },
    "node_modules/openai/node_modules/undici-types": {
      "version": "5.26.5",
      "resolved": "https://registry.npmjs.org/undici-types/-/undici-types-5.26.5.tgz",
      "integrity": "sha512-JlCMO+ehdEIKqlFxk6IfVoAUVmgz7cU7zD/h9XZ0qzeosSHmUJVOzSQvvYSYWXkFXC+IfLKSIffhv0sVZup6pA==",
      "license": "MIT"
    },
    "node_modules/openapi-types": {
      "version": "12.1.3",
      "resolved": "https://registry.npmjs.org/openapi-types/-/openapi-types-12.1.3.tgz",
      "integrity": "sha512-N4YtSYJqghVu4iek2ZUvcN/0aqH1kRDuNqzcycDxhOUpg7GdvLa2F3DgS6yBNhInhv2r/6I0Flkn7CqL8+nIcw==",
      "license": "MIT"
    },
    "node_modules/optionator": {
      "version": "0.9.4",
      "resolved": "https://registry.npmjs.org/optionator/-/optionator-0.9.4.tgz",
      "integrity": "sha512-6IpQ7mKUxRcZNLIObR0hz7lxsapSSIYNZJwXPGeF0mTVqGKFIXj1DQcMoT22S3ROcLyY/rz0PWaWZ9ayWmad9g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "deep-is": "^0.1.3",
        "fast-levenshtein": "^2.0.6",
        "levn": "^0.4.1",
        "prelude-ls": "^1.2.1",
        "type-check": "^0.4.0",
        "word-wrap": "^1.2.5"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/own-keys": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/own-keys/-/own-keys-1.0.1.tgz",
      "integrity": "sha512-qFOyK5PjiWZd+QQIh+1jhdb9LpxTF0qs7Pm8o5QHYZ0M3vKqSqzsZaEB6oWlxZ+q2sJBMI/Ktgd2N5ZwQoRHfg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "get-intrinsic": "^1.2.6",
        "object-keys": "^1.1.1",
        "safe-push-apply": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/p-finally": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/p-finally/-/p-finally-1.0.0.tgz",
      "integrity": "sha512-LICb2p9CB7FS+0eR1oqWnHhp0FljGLZCWBE9aix0Uye9W8LTQPwMTYVGWQWIw9RdQiDg4+epXQODwIYJtSJaow==",
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/p-limit": {
      "version": "3.1.0",
      "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-3.1.0.tgz",
      "integrity": "sha512-TYOanM3wGwNGsZN2cVTYPArw454xnXj5qmWF1bEoAc4+cU/ol7GVh7odevjp1FNHduHc3KZMcFduxU5Xc6uJRQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "yocto-queue": "^0.1.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/p-locate": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-5.0.0.tgz",
      "integrity": "sha512-LaNjtRWUBY++zB5nE/NwcaoMylSPk+S+ZHNB1TzdbMJMny6dynpAGt7X/tl/QYq3TIeE6nxHppbo2LGymrG5Pw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-limit": "^3.0.2"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/p-queue": {
      "version": "6.6.2",
      "resolved": "https://registry.npmjs.org/p-queue/-/p-queue-6.6.2.tgz",
      "integrity": "sha512-RwFpb72c/BhQLEXIZ5K2e+AhgNVmIejGlTgiB9MzZ0e93GRvqZ7uSi0dvRF7/XIXDeNkra2fNHBxTyPDGySpjQ==",
      "license": "MIT",
      "dependencies": {
        "eventemitter3": "^4.0.4",
        "p-timeout": "^3.2.0"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/p-retry": {
      "version": "4.6.2",
      "resolved": "https://registry.npmjs.org/p-retry/-/p-retry-4.6.2.tgz",
      "integrity": "sha512-312Id396EbJdvRONlngUx0NydfrIQ5lsYu0znKVUzVvArzEIt08V1qhtyESbGVd1FGX7UKtiFp5uwKZdM8wIuQ==",
      "license": "MIT",
      "dependencies": {
        "@types/retry": "0.12.0",
        "retry": "^0.13.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/p-timeout": {
      "version": "3.2.0",
      "resolved": "https://registry.npmjs.org/p-timeout/-/p-timeout-3.2.0.tgz",
      "integrity": "sha512-rhIwUycgwwKcP9yTOOFK/AKsAopjjCakVqLHePO3CC6Mir1Z99xT+R63jZxAT5lFZLa2inS5h+ZS2GvR99/FBg==",
      "license": "MIT",
      "dependencies": {
        "p-finally": "^1.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/p-try": {
      "version": "2.2.0",
      "resolved": "https://registry.npmjs.org/p-try/-/p-try-2.2.0.tgz",
      "integrity": "sha512-R4nPAVTAU0B9D35/Gk3uJf/7XYbQcyohSKdvAxIRSNghFl4e71hVoGnBNQz9cWaXxO2I10KTC+3jMdvvoKw6dQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/parent-module": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/parent-module/-/parent-module-1.0.1.tgz",
      "integrity": "sha512-GQ2EWRpQV8/o+Aw8YqtfZZPfNRWZYkbidE9k5rpl/hC3vtHHBfGm2Ifi6qWV+coDGkrUKZAxE3Lot5kcsRlh+g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "callsites": "^3.0.0"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/parse-entities": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/parse-entities/-/parse-entities-4.0.2.tgz",
      "integrity": "sha512-GG2AQYWoLgL877gQIKeRPGO1xF9+eG1ujIb5soS5gPvLQ1y2o8FL90w2QWNdf9I361Mpp7726c+lj3U0qK1uGw==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^2.0.0",
        "character-entities-legacy": "^3.0.0",
        "character-reference-invalid": "^2.0.0",
        "decode-named-character-reference": "^1.0.0",
        "is-alphanumerical": "^2.0.0",
        "is-decimal": "^2.0.0",
        "is-hexadecimal": "^2.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/parse-entities/node_modules/@types/unist": {
      "version": "2.0.11",
      "resolved": "https://registry.npmjs.org/@types/unist/-/unist-2.0.11.tgz",
      "integrity": "sha512-CmBKiL6NNo/OqgmMn95Fk9Whlp2mtvIv+KNpQKN2F4SjvrEesubTRWGYSg+BnWZOnlCaSTU1sMpsBOzgbYhnsA==",
      "license": "MIT"
    },
    "node_modules/parse-json": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/parse-json/-/parse-json-5.2.0.tgz",
      "integrity": "sha512-ayCKvm/phCGxOkYRSCM82iDwct8/EonSEgCSxWxD7ve6jHggsFl4fZVQBPRNgQoKiuV/odhFrGzQXZwbifC8Rg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/code-frame": "^7.0.0",
        "error-ex": "^1.3.1",
        "json-parse-even-better-errors": "^2.3.0",
        "lines-and-columns": "^1.1.6"
      },
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/parse5": {
      "version": "7.2.1",
      "resolved": "https://registry.npmjs.org/parse5/-/parse5-7.2.1.tgz",
      "integrity": "sha512-BuBYQYlv1ckiPdQi/ohiivi9Sagc9JG+Ozs0r7b/0iK3sKmrb0b9FdWdBbOdx6hBCM/F9Ir82ofnBhtZOjCRPQ==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "entities": "^4.5.0"
      },
      "funding": {
        "url": "https://github.com/inikulin/parse5?sponsor=1"
      }
    },
    "node_modules/path-exists": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/path-exists/-/path-exists-4.0.0.tgz",
      "integrity": "sha512-ak9Qy5Q7jYb2Wwcey5Fpvg2KoAc/ZIhLSLOSBmRmygPsGwkVVt0fZa0qrtMz+m6tJTAHfZQ8FnmB4MG4LWy7/w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-is-absolute": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/path-is-absolute/-/path-is-absolute-1.0.1.tgz",
      "integrity": "sha512-AVbw3UJ2e9bq64vSaS9Am0fje1Pa8pbGqTTsmXfaIiMpnr5DlDhfJOuLj9Sf95ZPVDAUerDfEk88MPmPe7UCQg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/path-key": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/path-key/-/path-key-3.1.1.tgz",
      "integrity": "sha512-ojmeN0qd+y0jszEtoY48r0Peq5dwMEkIlCOu6Q5f41lfkswXuKtYrhgoTpLnyIcHm24Uhqx+5Tqm2InSwLhE6Q==",
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/path-parse": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/path-parse/-/path-parse-1.0.7.tgz",
      "integrity": "sha512-LDJzPVEEEPR+y48z93A0Ed0yXb8pAByGWo/k5YYdYgpY2/2EsOsksJrq7lOHxryrVOn1ejG6oAp8ahvOIQD8sw==",
      "license": "MIT"
    },
    "node_modules/path-scurry": {
      "version": "1.11.1",
      "resolved": "https://registry.npmjs.org/path-scurry/-/path-scurry-1.11.1.tgz",
      "integrity": "sha512-Xa4Nw17FS9ApQFJ9umLiJS4orGjm7ZzwUrwamcGQuHSzDyth9boKDaycYdDcZDuqYATXw4HFXgaqWTctW/v1HA==",
      "license": "BlueOak-1.0.0",
      "dependencies": {
        "lru-cache": "^10.2.0",
        "minipass": "^5.0.0 || ^6.0.2 || ^7.0.0"
      },
      "engines": {
        "node": ">=16 || 14 >=14.18"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/path-type": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/path-type/-/path-type-4.0.0.tgz",
      "integrity": "sha512-gDKb8aZMDeD/tZWs9P6+q0J9Mwkdl6xMV8TjnGP3qJVJ06bdMgkbBlLU8IdfOsIsFz2BW1rNVT3XuNEl8zPAvw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/pdfjs-dist": {
      "version": "4.10.38",
      "resolved": "https://registry.npmjs.org/pdfjs-dist/-/pdfjs-dist-4.10.38.tgz",
      "integrity": "sha512-/Y3fcFrXEAsMjJXeL9J8+ZG9U01LbuWaYypvDW2ycW1jL269L3js3DVBjDJ0Up9Np1uqDXsDrRihHANhZOlwdQ==",
      "license": "Apache-2.0",
      "engines": {
        "node": ">=20"
      },
      "optionalDependencies": {
        "@napi-rs/canvas": "^0.1.65"
      }
    },
    "node_modules/picocolors": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/picocolors/-/picocolors-1.1.1.tgz",
      "integrity": "sha512-xceH2snhtb5M9liqDsmEw56le376mTZkEX/jEb/RxNFyegNul7eNslCXP9FDj/Lcu0X8KEyMceP2ntpaHrDEVA==",
      "license": "ISC"
    },
    "node_modules/picomatch": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-2.3.1.tgz",
      "integrity": "sha512-JU3teHTNjmE2VCGFzuY8EXzCDVwEqB2a8fsIvwaStHhAWJEeVd1o1QD80CU6+ZdEXXSLbSsuLwJjkCBWqRQUVA==",
      "license": "MIT",
      "engines": {
        "node": ">=8.6"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/pify": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/pify/-/pify-2.3.0.tgz",
      "integrity": "sha512-udgsAY+fTnvv7kI7aaxbqwWNb0AHiB0qBO89PZKPkoTmGOgdbrHDKD+0B2X4uTfJ/FT1R09r9gTsjUjNJotuog==",
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/pirates": {
      "version": "4.0.6",
      "resolved": "https://registry.npmjs.org/pirates/-/pirates-4.0.6.tgz",
      "integrity": "sha512-saLsH7WeYYPiD25LDuLRRY/i+6HaPYr6G1OUlN39otzkSTxKnubR9RTxS3/Kk50s1g2JTgFwWQDQyplC5/SHZg==",
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/pkg-dir": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/pkg-dir/-/pkg-dir-4.2.0.tgz",
      "integrity": "sha512-HRDzbaKjC+AOWVXxAU/x54COGeIv9eb+6CkDSQoNTt4XyWoIJvuPsXizxu/Fr23EiekbtZwmh1IcIG/l/a10GQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "find-up": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/pkg-dir/node_modules/find-up": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/find-up/-/find-up-4.1.0.tgz",
      "integrity": "sha512-PpOwAdQ/YlXQ2vj8a3h8IipDuYRi3wceVQQGYWxNINccq40Anw7BlsEXCMbt1Zt+OLA6Fq9suIpIWD0OsnISlw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "locate-path": "^5.0.0",
        "path-exists": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/pkg-dir/node_modules/locate-path": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/locate-path/-/locate-path-5.0.0.tgz",
      "integrity": "sha512-t7hw9pI+WvuwNJXwk5zVHpyhIqzg2qTlklJOf0mVxGSbe3Fp2VieZcduNYjaLDoy6p9uGpQEGWG87WpMKlNq8g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-locate": "^4.1.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/pkg-dir/node_modules/p-limit": {
      "version": "2.3.0",
      "resolved": "https://registry.npmjs.org/p-limit/-/p-limit-2.3.0.tgz",
      "integrity": "sha512-//88mFWSJx8lxCzwdAABTJL2MyWB12+eIY7MDL2SqLmAkeKU9qxRvWuSyTjm3FUmpBEMuFfckAIqEaVGUDxb6w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-try": "^2.0.0"
      },
      "engines": {
        "node": ">=6"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/pkg-dir/node_modules/p-locate": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/p-locate/-/p-locate-4.1.0.tgz",
      "integrity": "sha512-R79ZZ/0wAxKGu3oYMlz8jy/kbhsNrS7SKZ7PxEHBgJ5+F2mtFW2fK2cOtBh1cHYkQsbzFV7I+EoRKe6Yt0oK7A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "p-limit": "^2.2.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/possible-typed-array-names": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/possible-typed-array-names/-/possible-typed-array-names-1.1.0.tgz",
      "integrity": "sha512-/+5VFTchJDoVj3bhoqi6UeymcD00DAwb1nJwamzPvHEszJ4FpF6SNNbUbOS8yI56qHzdV8eK0qEfOSiodkTdxg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/postcss": {
      "version": "8.5.3",
      "resolved": "https://registry.npmjs.org/postcss/-/postcss-8.5.3.tgz",
      "integrity": "sha512-dle9A3yYxlBSrt8Fu+IpjGT8SY8hN0mlaA6GY8t0P5PjIOZemULz/E2Bnm/2dcUOena75OTNkHI76uZBNUUq3A==",
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/postcss"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "nanoid": "^3.3.8",
        "picocolors": "^1.1.1",
        "source-map-js": "^1.2.1"
      },
      "engines": {
        "node": "^10 || ^12 || >=14"
      }
    },
    "node_modules/postcss-import": {
      "version": "15.1.0",
      "resolved": "https://registry.npmjs.org/postcss-import/-/postcss-import-15.1.0.tgz",
      "integrity": "sha512-hpr+J05B2FVYUAXHeK1YyI267J/dDDhMU6B6civm8hSY1jYJnBXxzKDKDswzJmtLHryrjhnDjqqp/49t8FALew==",
      "license": "MIT",
      "dependencies": {
        "postcss-value-parser": "^4.0.0",
        "read-cache": "^1.0.0",
        "resolve": "^1.1.7"
      },
      "engines": {
        "node": ">=14.0.0"
      },
      "peerDependencies": {
        "postcss": "^8.0.0"
      }
    },
    "node_modules/postcss-js": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/postcss-js/-/postcss-js-4.0.1.tgz",
      "integrity": "sha512-dDLF8pEO191hJMtlHFPRa8xsizHaM82MLfNkUHdUtVEV3tgTp5oj+8qbEqYM57SLfc74KSbw//4SeJma2LRVIw==",
      "license": "MIT",
      "dependencies": {
        "camelcase-css": "^2.0.1"
      },
      "engines": {
        "node": "^12 || ^14 || >= 16"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/postcss/"
      },
      "peerDependencies": {
        "postcss": "^8.4.21"
      }
    },
    "node_modules/postcss-load-config": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/postcss-load-config/-/postcss-load-config-4.0.2.tgz",
      "integrity": "sha512-bSVhyJGL00wMVoPUzAVAnbEoWyqRxkjv64tUl427SKnPrENtq6hJwUojroMz2VB+Q1edmi4IfrAPpami5VVgMQ==",
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "lilconfig": "^3.0.0",
        "yaml": "^2.3.4"
      },
      "engines": {
        "node": ">= 14"
      },
      "peerDependencies": {
        "postcss": ">=8.0.9",
        "ts-node": ">=9.0.0"
      },
      "peerDependenciesMeta": {
        "postcss": {
          "optional": true
        },
        "ts-node": {
          "optional": true
        }
      }
    },
    "node_modules/postcss-nested": {
      "version": "6.2.0",
      "resolved": "https://registry.npmjs.org/postcss-nested/-/postcss-nested-6.2.0.tgz",
      "integrity": "sha512-HQbt28KulC5AJzG+cZtj9kvKB93CFCdLvog1WFLf1D+xmMvPGlBstkpTEZfK5+AN9hfJocyBFCNiqyS48bpgzQ==",
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/postcss/"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "postcss-selector-parser": "^6.1.1"
      },
      "engines": {
        "node": ">=12.0"
      },
      "peerDependencies": {
        "postcss": "^8.2.14"
      }
    },
    "node_modules/postcss-selector-parser": {
      "version": "6.1.2",
      "resolved": "https://registry.npmjs.org/postcss-selector-parser/-/postcss-selector-parser-6.1.2.tgz",
      "integrity": "sha512-Q8qQfPiZ+THO/3ZrOrO0cJJKfpYCagtMUkXbnEfmgUjwXg6z/WBeOyS9APBBPCTSiDV+s4SwQGu8yFsiMRIudg==",
      "license": "MIT",
      "dependencies": {
        "cssesc": "^3.0.0",
        "util-deprecate": "^1.0.2"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/postcss-value-parser": {
      "version": "4.2.0",
      "resolved": "https://registry.npmjs.org/postcss-value-parser/-/postcss-value-parser-4.2.0.tgz",
      "integrity": "sha512-1NNCs6uurfkVbeXG4S8JFT9t19m45ICnif8zWLd5oPSZ50QnwMfK+H3jv408d4jw/7Bttv5axS5IiHoLaVNHeQ==",
      "license": "MIT"
    },
    "node_modules/prelude-ls": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/prelude-ls/-/prelude-ls-1.2.1.tgz",
      "integrity": "sha512-vkcDPrRZo1QZLbn5RLGPpg/WmIQ65qoWWhcGKf/b5eplkkarX0m9z8ppCat4mlOqUsWpyNuYgO3VRyrYHSzX5g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/pretty-format": {
      "version": "27.5.1",
      "resolved": "https://registry.npmjs.org/pretty-format/-/pretty-format-27.5.1.tgz",
      "integrity": "sha512-Qb1gy5OrP5+zDf2Bvnzdl3jsTf1qXVMazbvCoKhtKqVs4/YK4ozX4gKQJJVyNe+cajNPn0KoC0MC3FUmaHWEmQ==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "dependencies": {
        "ansi-regex": "^5.0.1",
        "ansi-styles": "^5.0.0",
        "react-is": "^17.0.1"
      },
      "engines": {
        "node": "^10.13.0 || ^12.13.0 || ^14.15.0 || >=15.0.0"
      }
    },
    "node_modules/pretty-format/node_modules/ansi-styles": {
      "version": "5.2.0",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-5.2.0.tgz",
      "integrity": "sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==",
      "dev": true,
      "license": "MIT",
      "peer": true,
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/pretty-format/node_modules/react-is": {
      "version": "17.0.2",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-17.0.2.tgz",
      "integrity": "sha512-w2GsyukL62IJnlaff/nRegPQR94C/XXamvMWmSHRJ4y7Ts/4ocGRmTHvOs8PSE6pB3dWOrD/nueuU5sduBsQ4w==",
      "dev": true,
      "license": "MIT",
      "peer": true
    },
    "node_modules/prismjs": {
      "version": "1.30.0",
      "resolved": "https://registry.npmjs.org/prismjs/-/prismjs-1.30.0.tgz",
      "integrity": "sha512-DEvV2ZF2r2/63V+tK8hQvrR2ZGn10srHbXviTlcv7Kpzw8jWiNTqbVgjO3IY8RxrrOUF8VPMQQFysYYYv0YZxw==",
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/prompts": {
      "version": "2.4.2",
      "resolved": "https://registry.npmjs.org/prompts/-/prompts-2.4.2.tgz",
      "integrity": "sha512-NxNv/kLguCA7p3jE8oL2aEBsrJWgAakBpgmgK6lpPWV+WuOmY6r2/zbAVnP+T8bQlA0nzHXSJSJW0Hq7ylaD2Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "kleur": "^3.0.3",
        "sisteransi": "^1.0.5"
      },
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/prop-types": {
      "version": "15.8.1",
      "resolved": "https://registry.npmjs.org/prop-types/-/prop-types-15.8.1.tgz",
      "integrity": "sha512-oj87CgZICdulUohogVAR7AjlC0327U4el4L6eAvOqCeudMDVU0NThNaV+b9Df4dXgSP1gXMTnPdhfe/2qDH5cg==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.4.0",
        "object-assign": "^4.1.1",
        "react-is": "^16.13.1"
      }
    },
    "node_modules/property-information": {
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/property-information/-/property-information-7.0.0.tgz",
      "integrity": "sha512-7D/qOz/+Y4X/rzSB6jKxKUsQnphO046ei8qxG59mtM3RG3DHgTK81HrxrmoDVINJb8NKT5ZsRbwHvQ6B68Iyhg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/psl": {
      "version": "1.15.0",
      "resolved": "https://registry.npmjs.org/psl/-/psl-1.15.0.tgz",
      "integrity": "sha512-JZd3gMVBAVQkSs6HdNZo9Sdo0LNcQeMNP3CozBJb3JYC/QUYZTnKxP+f8oWRX4rHP5EurWxqAHTSwUCjlNKa1w==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "punycode": "^2.3.1"
      },
      "funding": {
        "url": "https://github.com/sponsors/lupomontero"
      }
    },
    "node_modules/punycode": {
      "version": "2.3.1",
      "resolved": "https://registry.npmjs.org/punycode/-/punycode-2.3.1.tgz",
      "integrity": "sha512-vYt7UD1U9Wg6138shLtLOvdAu+8DsC/ilFtEVHcH+wydcSpNE20AfSOduf6MkRFahL5FY7X1oU7nKVZFtfq8Fg==",
      "devOptional": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/pure-rand": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/pure-rand/-/pure-rand-6.1.0.tgz",
      "integrity": "sha512-bVWawvoZoBYpp6yIoQtQXHZjmz35RSVHnUOTefl8Vcjr8snTPY1wnpSPMWekcFwbxI6gtmT7rSYPFvz71ldiOA==",
      "dev": true,
      "funding": [
        {
          "type": "individual",
          "url": "https://github.com/sponsors/dubzzz"
        },
        {
          "type": "opencollective",
          "url": "https://opencollective.com/fast-check"
        }
      ],
      "license": "MIT"
    },
    "node_modules/querystringify": {
      "version": "2.2.0",
      "resolved": "https://registry.npmjs.org/querystringify/-/querystringify-2.2.0.tgz",
      "integrity": "sha512-FIqgj2EUvTa7R50u0rGsyTftzjYmv/a3hO345bZNrqabNqjtgiDMgmo4mkUjd+nzU5oF3dClKqFIPUKybUyqoQ==",
      "devOptional": true,
      "license": "MIT"
    },
    "node_modules/queue-microtask": {
      "version": "1.2.3",
      "resolved": "https://registry.npmjs.org/queue-microtask/-/queue-microtask-1.2.3.tgz",
      "integrity": "sha512-NuaNSa6flKT5JaSYQzJok04JzTL1CA6aGhv5rfLW3PgqA+M2ChpZQnAC8h8i4ZFkBS8X5RqkDBHA7r4hej3K9A==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT"
    },
    "node_modules/re-resizable": {
      "version": "6.11.2",
      "resolved": "https://registry.npmjs.org/re-resizable/-/re-resizable-6.11.2.tgz",
      "integrity": "sha512-2xI2P3OHs5qw7K0Ud1aLILK6MQxW50TcO+DetD9eIV58j84TqYeHoZcL9H4GXFXXIh7afhH8mv5iUCXII7OW7A==",
      "license": "MIT",
      "peerDependencies": {
        "react": "^16.13.1 || ^17.0.0 || ^18.0.0 || ^19.0.0",
        "react-dom": "^16.13.1 || ^17.0.0 || ^18.0.0 || ^19.0.0"
      }
    },
    "node_modules/react": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react/-/react-18.3.1.tgz",
      "integrity": "sha512-wS+hAgJShR0KhEvPJArfuPVN1+Hz1t0Y6n5jLrGQbkb4urgPE/0Rve+1kMB1v/oWgHgm4WIcV+i7F2pTVj+2iQ==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.1.0"
      },
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/react-dom": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-dom/-/react-dom-18.3.1.tgz",
      "integrity": "sha512-5m4nQKp+rZRb09LNH59GM4BxTh9251/ylbKIbpe7TpGxfJ+9kv6BLkLBXIjjspbgbnIBNqlI23tRnTWT0snUIw==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.1.0",
        "scheduler": "^0.23.2"
      },
      "peerDependencies": {
        "react": "^18.3.1"
      }
    },
    "node_modules/react-draggable": {
      "version": "4.4.6",
      "resolved": "https://registry.npmjs.org/react-draggable/-/react-draggable-4.4.6.tgz",
      "integrity": "sha512-LtY5Xw1zTPqHkVmtM3X8MUOxNDOUhv/khTgBgrUvwaS064bwVvxT+q5El0uUFNx5IEPKXuRejr7UqLwBIg5pdw==",
      "license": "MIT",
      "dependencies": {
        "clsx": "^1.1.1",
        "prop-types": "^15.8.1"
      },
      "peerDependencies": {
        "react": ">= 16.3.0",
        "react-dom": ">= 16.3.0"
      }
    },
    "node_modules/react-draggable/node_modules/clsx": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/clsx/-/clsx-1.2.1.tgz",
      "integrity": "sha512-EcR6r5a8bj6pu3ycsa/E/cKVGuTgZJZdsyUYHOksG/UHIiKfjxzRxYJpyVBwYaQeOvghal9fcc4PidlgzugAQg==",
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/react-hook-form": {
      "version": "7.54.2",
      "resolved": "https://registry.npmjs.org/react-hook-form/-/react-hook-form-7.54.2.tgz",
      "integrity": "sha512-eHpAUgUjWbZocoQYUHposymRb4ZP6d0uwUnooL2uOybA9/3tPUvoAKqEWK1WaSiTxxOfTpffNZP7QwlnM3/gEg==",
      "license": "MIT",
      "engines": {
        "node": ">=18.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/react-hook-form"
      },
      "peerDependencies": {
        "react": "^16.8.0 || ^17 || ^18 || ^19"
      }
    },
    "node_modules/react-is": {
      "version": "16.13.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-16.13.1.tgz",
      "integrity": "sha512-24e6ynE2H+OKt4kqsOvNd8kBpV65zoxbA4BVsEOB3ARVWQki/DHzaUoC5KuON/BiccDaCCTZBuOcfZs70kR8bQ==",
      "license": "MIT"
    },
    "node_modules/react-markdown": {
      "version": "10.1.0",
      "resolved": "https://registry.npmjs.org/react-markdown/-/react-markdown-10.1.0.tgz",
      "integrity": "sha512-qKxVopLT/TyA6BX3Ue5NwabOsAzm0Q7kAPwq6L+wWDwisYs7R8vZ0nRXqq6rkueboxpkjvLGU9fWifiX/ZZFxQ==",
      "license": "MIT",
      "dependencies": {
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "devlop": "^1.0.0",
        "hast-util-to-jsx-runtime": "^2.0.0",
        "html-url-attributes": "^3.0.0",
        "mdast-util-to-hast": "^13.0.0",
        "remark-parse": "^11.0.0",
        "remark-rehype": "^11.0.0",
        "unified": "^11.0.0",
        "unist-util-visit": "^5.0.0",
        "vfile": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      },
      "peerDependencies": {
        "@types/react": ">=18",
        "react": ">=18"
      }
    },
    "node_modules/react-pdf-highlighter": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/react-pdf-highlighter/-/react-pdf-highlighter-6.1.0.tgz",
      "integrity": "sha512-PD7l+0q1v+pZahLA/2AeWIb0n8d1amL6o+mOKnldIqtyChBHSE3gfnY5ZNMSFrhWXdlM6l4Eet+aydnYo6Skow==",
      "license": "MIT",
      "dependencies": {
        "lodash.debounce": "^4.0.8",
        "pdfjs-dist": "2.16.105",
        "react-rnd": "^10.1.10"
      },
      "peerDependencies": {
        "react": ">=18.0.0",
        "react-dom": ">=18.0.0"
      }
    },
    "node_modules/react-pdf-highlighter/node_modules/pdfjs-dist": {
      "version": "2.16.105",
      "resolved": "https://registry.npmjs.org/pdfjs-dist/-/pdfjs-dist-2.16.105.tgz",
      "integrity": "sha512-J4dn41spsAwUxCpEoVf6GVoz908IAA3mYiLmNxg8J9kfRXc2jxpbUepcP0ocp0alVNLFthTAM8DZ1RaHh8sU0A==",
      "license": "Apache-2.0",
      "dependencies": {
        "dommatrix": "^1.0.3",
        "web-streams-polyfill": "^3.2.1"
      },
      "peerDependencies": {
        "worker-loader": "^3.0.8"
      },
      "peerDependenciesMeta": {
        "worker-loader": {
          "optional": true
        }
      }
    },
    "node_modules/react-remove-scroll": {
      "version": "2.6.3",
      "resolved": "https://registry.npmjs.org/react-remove-scroll/-/react-remove-scroll-2.6.3.tgz",
      "integrity": "sha512-pnAi91oOk8g8ABQKGF5/M9qxmmOPxaAnopyTHYfqYEwJhyFrbbBtHuSgtKEoH0jpcxx5o3hXqH1mNd9/Oi+8iQ==",
      "license": "MIT",
      "dependencies": {
        "react-remove-scroll-bar": "^2.3.7",
        "react-style-singleton": "^2.2.3",
        "tslib": "^2.1.0",
        "use-callback-ref": "^1.3.3",
        "use-sidecar": "^1.1.3"
      },
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/react-remove-scroll-bar": {
      "version": "2.3.8",
      "resolved": "https://registry.npmjs.org/react-remove-scroll-bar/-/react-remove-scroll-bar-2.3.8.tgz",
      "integrity": "sha512-9r+yi9+mgU33AKcj6IbT9oRCO78WriSj6t/cF8DWBZJ9aOGPOTEDvdUDz1FwKim7QXWwmHqtdHnRJfhAxEG46Q==",
      "license": "MIT",
      "dependencies": {
        "react-style-singleton": "^2.2.2",
        "tslib": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/react-rnd": {
      "version": "10.5.2",
      "resolved": "https://registry.npmjs.org/react-rnd/-/react-rnd-10.5.2.tgz",
      "integrity": "sha512-0Tm4x7k7pfHf2snewJA8x7Nwgt3LV+58MVEWOVsFjk51eYruFEa6Wy7BNdxt4/lH0wIRsu7Gm3KjSXY2w7YaNw==",
      "license": "MIT",
      "dependencies": {
        "re-resizable": "6.11.2",
        "react-draggable": "4.4.6",
        "tslib": "2.6.2"
      },
      "peerDependencies": {
        "react": ">=16.3.0",
        "react-dom": ">=16.3.0"
      }
    },
    "node_modules/react-rnd/node_modules/tslib": {
      "version": "2.6.2",
      "resolved": "https://registry.npmjs.org/tslib/-/tslib-2.6.2.tgz",
      "integrity": "sha512-AEYxH93jGFPn/a2iVAwW87VuUIkR1FVUKB77NwMF7nBTDkDrrT/Hpt/IrCJ0QXhW27jTBDcf5ZY7w6RiqTMw2Q==",
      "license": "0BSD"
    },
    "node_modules/react-smooth": {
      "version": "4.0.4",
      "resolved": "https://registry.npmjs.org/react-smooth/-/react-smooth-4.0.4.tgz",
      "integrity": "sha512-gnGKTpYwqL0Iii09gHobNolvX4Kiq4PKx6eWBCYYix+8cdw+cGo3do906l1NBPKkSWx1DghC1dlWG9L2uGd61Q==",
      "license": "MIT",
      "dependencies": {
        "fast-equals": "^5.0.1",
        "prop-types": "^15.8.1",
        "react-transition-group": "^4.4.5"
      },
      "peerDependencies": {
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0",
        "react-dom": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0"
      }
    },
    "node_modules/react-style-singleton": {
      "version": "2.2.3",
      "resolved": "https://registry.npmjs.org/react-style-singleton/-/react-style-singleton-2.2.3.tgz",
      "integrity": "sha512-b6jSvxvVnyptAiLjbkWLE/lOnR4lfTtDAl+eUC7RZy+QQWc6wRzIV2CE6xBuMmDxc2qIihtDCZD5NPOFl7fRBQ==",
      "license": "MIT",
      "dependencies": {
        "get-nonce": "^1.0.0",
        "tslib": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/react-syntax-highlighter": {
      "version": "15.6.1",
      "resolved": "https://registry.npmjs.org/react-syntax-highlighter/-/react-syntax-highlighter-15.6.1.tgz",
      "integrity": "sha512-OqJ2/vL7lEeV5zTJyG7kmARppUjiB9h9udl4qHQjjgEos66z00Ia0OckwYfRxCSFrW8RJIBnsBwQsHZbVPspqg==",
      "license": "MIT",
      "dependencies": {
        "@babel/runtime": "^7.3.1",
        "highlight.js": "^10.4.1",
        "highlightjs-vue": "^1.0.0",
        "lowlight": "^1.17.0",
        "prismjs": "^1.27.0",
        "refractor": "^3.6.0"
      },
      "peerDependencies": {
        "react": ">= 0.14.0"
      }
    },
    "node_modules/react-transition-group": {
      "version": "4.4.5",
      "resolved": "https://registry.npmjs.org/react-transition-group/-/react-transition-group-4.4.5.tgz",
      "integrity": "sha512-pZcd1MCJoiKiBR2NRxeCRg13uCXbydPnmB4EOeRrY7480qNWO8IIgQG6zlDkm6uRMsURXPuKq0GWtiM59a5Q6g==",
      "license": "BSD-3-Clause",
      "dependencies": {
        "@babel/runtime": "^7.5.5",
        "dom-helpers": "^5.0.1",
        "loose-envify": "^1.4.0",
        "prop-types": "^15.6.2"
      },
      "peerDependencies": {
        "react": ">=16.6.0",
        "react-dom": ">=16.6.0"
      }
    },
    "node_modules/read-cache": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/read-cache/-/read-cache-1.0.0.tgz",
      "integrity": "sha512-Owdv/Ft7IjOgm/i0xvNDZ1LrRANRfew4b2prF3OWMQLxLfu3bS8FVhCsrSCMK4lR56Y9ya+AThoTpDCTxCmpRA==",
      "license": "MIT",
      "dependencies": {
        "pify": "^2.3.0"
      }
    },
    "node_modules/readdirp": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/readdirp/-/readdirp-3.6.0.tgz",
      "integrity": "sha512-hOS089on8RduqdbhvQ5Z37A0ESjsqz6qnRcffsMU3495FuTdqSm+7bhJ29JvIOsBDEEnan5DPu9t3To9VRlMzA==",
      "license": "MIT",
      "dependencies": {
        "picomatch": "^2.2.1"
      },
      "engines": {
        "node": ">=8.10.0"
      }
    },
    "node_modules/recharts": {
      "version": "2.15.1",
      "resolved": "https://registry.npmjs.org/recharts/-/recharts-2.15.1.tgz",
      "integrity": "sha512-v8PUTUlyiDe56qUj82w/EDVuzEFXwEHp9/xOowGAZwfLjB9uAy3GllQVIYMWF6nU+qibx85WF75zD7AjqoT54Q==",
      "license": "MIT",
      "dependencies": {
        "clsx": "^2.0.0",
        "eventemitter3": "^4.0.1",
        "lodash": "^4.17.21",
        "react-is": "^18.3.1",
        "react-smooth": "^4.0.4",
        "recharts-scale": "^0.4.4",
        "tiny-invariant": "^1.3.1",
        "victory-vendor": "^36.6.8"
      },
      "engines": {
        "node": ">=14"
      },
      "peerDependencies": {
        "react": "^16.0.0 || ^17.0.0 || ^18.0.0 || ^19.0.0",
        "react-dom": "^16.0.0 || ^17.0.0 || ^18.0.0 || ^19.0.0"
      }
    },
    "node_modules/recharts-scale": {
      "version": "0.4.5",
      "resolved": "https://registry.npmjs.org/recharts-scale/-/recharts-scale-0.4.5.tgz",
      "integrity": "sha512-kivNFO+0OcUNu7jQquLXAxz1FIwZj8nrj+YkOKc5694NbjCvcT6aSZiIzNzd2Kul4o4rTto8QVR9lMNtxD4G1w==",
      "license": "MIT",
      "dependencies": {
        "decimal.js-light": "^2.4.1"
      }
    },
    "node_modules/recharts/node_modules/react-is": {
      "version": "18.3.1",
      "resolved": "https://registry.npmjs.org/react-is/-/react-is-18.3.1.tgz",
      "integrity": "sha512-/LLMVyas0ljjAtoYiPqYiL8VWXzUUdThrmU5+n20DZv+a+ClRoevUzw5JxU+Ieh5/c87ytoTBV9G1FiKfNJdmg==",
      "license": "MIT"
    },
    "node_modules/redent": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/redent/-/redent-3.0.0.tgz",
      "integrity": "sha512-6tDA8g98We0zd0GvVeMT9arEOnTw9qM03L9cJXaCjrip1OO764RDBLBfrB4cwzNGDj5OA5ioymC9GkizgWJDUg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "indent-string": "^4.0.0",
        "strip-indent": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/reflect.getprototypeof": {
      "version": "1.0.10",
      "resolved": "https://registry.npmjs.org/reflect.getprototypeof/-/reflect.getprototypeof-1.0.10.tgz",
      "integrity": "sha512-00o4I+DVrefhv+nX0ulyi3biSHCPDe+yLv5o/p6d/UVlirijB8E16FtfwSAi4g3tcqrQ4lRAqQSoFEZJehYEcw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.9",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "get-intrinsic": "^1.2.7",
        "get-proto": "^1.0.1",
        "which-builtin-type": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/refractor": {
      "version": "3.6.0",
      "resolved": "https://registry.npmjs.org/refractor/-/refractor-3.6.0.tgz",
      "integrity": "sha512-MY9W41IOWxxk31o+YvFCNyNzdkc9M20NoZK5vq6jkv4I/uh2zkWcfudj0Q1fovjUQJrNewS9NMzeTtqPf+n5EA==",
      "license": "MIT",
      "dependencies": {
        "hastscript": "^6.0.0",
        "parse-entities": "^2.0.0",
        "prismjs": "~1.27.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/refractor/node_modules/character-entities": {
      "version": "1.2.4",
      "resolved": "https://registry.npmjs.org/character-entities/-/character-entities-1.2.4.tgz",
      "integrity": "sha512-iBMyeEHxfVnIakwOuDXpVkc54HijNgCyQB2w0VfGQThle6NXn50zU6V/u+LDhxHcDUPojn6Kpga3PTAD8W1bQw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/refractor/node_modules/character-entities-legacy": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/character-entities-legacy/-/character-entities-legacy-1.1.4.tgz",
      "integrity": "sha512-3Xnr+7ZFS1uxeiUDvV02wQ+QDbc55o97tIV5zHScSPJpcLm/r0DFPcoY3tYRp+VZukxuMeKgXYmsXQHO05zQeA==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/refractor/node_modules/character-reference-invalid": {
      "version": "1.1.4",
      "resolved": "https://registry.npmjs.org/character-reference-invalid/-/character-reference-invalid-1.1.4.tgz",
      "integrity": "sha512-mKKUkUbhPpQlCOfIuZkvSEgktjPFIsZKRRbC6KWVEMvlzblj3i3asQv5ODsrwt0N3pHAEvjP8KTQPHkp0+6jOg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/refractor/node_modules/is-alphabetical": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/is-alphabetical/-/is-alphabetical-1.0.4.tgz",
      "integrity": "sha512-DwzsA04LQ10FHTZuL0/grVDk4rFoVH1pjAToYwBrHSxcrBIGQuXrQMtD5U1b0U2XVgKZCTLLP8u2Qxqhy3l2Vg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/refractor/node_modules/is-alphanumerical": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/is-alphanumerical/-/is-alphanumerical-1.0.4.tgz",
      "integrity": "sha512-UzoZUr+XfVz3t3v4KyGEniVL9BDRoQtY7tOyrRybkVNjDFWyo1yhXNGrrBTQxp3ib9BLAWs7k2YKBQsFRkZG9A==",
      "license": "MIT",
      "dependencies": {
        "is-alphabetical": "^1.0.0",
        "is-decimal": "^1.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/refractor/node_modules/is-decimal": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/is-decimal/-/is-decimal-1.0.4.tgz",
      "integrity": "sha512-RGdriMmQQvZ2aqaQq3awNA6dCGtKpiDFcOzrTWrDAT2MiWrKQVPmxLGHl7Y2nNu6led0kEyoX0enY0qXYsv9zw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/refractor/node_modules/is-hexadecimal": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/is-hexadecimal/-/is-hexadecimal-1.0.4.tgz",
      "integrity": "sha512-gyPJuv83bHMpocVYoqof5VDiZveEoGoFL8m3BXNb2VW8Xs+rz9kqO8LOQ5DH6EsuvilT1ApazU0pyl+ytbPtlw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/refractor/node_modules/parse-entities": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/parse-entities/-/parse-entities-2.0.0.tgz",
      "integrity": "sha512-kkywGpCcRYhqQIchaWqZ875wzpS/bMKhz5HnN3p7wveJTkTtyAB/AlnS0f8DFSqYW1T82t6yEAkEcB+A1I3MbQ==",
      "license": "MIT",
      "dependencies": {
        "character-entities": "^1.0.0",
        "character-entities-legacy": "^1.0.0",
        "character-reference-invalid": "^1.0.0",
        "is-alphanumerical": "^1.0.0",
        "is-decimal": "^1.0.0",
        "is-hexadecimal": "^1.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/refractor/node_modules/prismjs": {
      "version": "1.27.0",
      "resolved": "https://registry.npmjs.org/prismjs/-/prismjs-1.27.0.tgz",
      "integrity": "sha512-t13BGPUlFDR7wRB5kQDG4jjl7XeuH6jbJGt11JHPL96qwsEHNX2+68tFXqc1/k+/jALsbSWJKUOT/hcYAZ5LkA==",
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/regenerate": {
      "version": "1.4.2",
      "resolved": "https://registry.npmjs.org/regenerate/-/regenerate-1.4.2.tgz",
      "integrity": "sha512-zrceR/XhGYU/d/opr2EKO7aRHUeiBI8qjtfHqADTwZd6Szfy16la6kqD0MIUs5z5hx6AaKa+PixpPrR289+I0A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/regenerate-unicode-properties": {
      "version": "10.2.0",
      "resolved": "https://registry.npmjs.org/regenerate-unicode-properties/-/regenerate-unicode-properties-10.2.0.tgz",
      "integrity": "sha512-DqHn3DwbmmPVzeKj9woBadqmXxLvQoQIwu7nopMc72ztvxVmVk2SBhSnx67zuye5TP+lJsb/TBQsjLKhnDf3MA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "regenerate": "^1.4.2"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/regenerator-runtime": {
      "version": "0.14.1",
      "resolved": "https://registry.npmjs.org/regenerator-runtime/-/regenerator-runtime-0.14.1.tgz",
      "integrity": "sha512-dYnhHh0nJoMfnkZs6GmmhFknAGRrLznOu5nc9ML+EJxGvrx6H7teuevqVqCuPcPK//3eDrrjQhehXVx9cnkGdw==",
      "license": "MIT"
    },
    "node_modules/regenerator-transform": {
      "version": "0.15.2",
      "resolved": "https://registry.npmjs.org/regenerator-transform/-/regenerator-transform-0.15.2.tgz",
      "integrity": "sha512-hfMp2BoF0qOk3uc5V20ALGDS2ddjQaLrdl7xrGXvAIow7qeWRM2VA2HuCHkUKk9slq3VwEwLNK3DFBqDfPGYtg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@babel/runtime": "^7.8.4"
      }
    },
    "node_modules/regexp.prototype.flags": {
      "version": "1.5.4",
      "resolved": "https://registry.npmjs.org/regexp.prototype.flags/-/regexp.prototype.flags-1.5.4.tgz",
      "integrity": "sha512-dYqgNSZbDwkaJ2ceRd9ojCGjBq+mOm9LmtXnAnEGyHhN/5R7iDW2TRw3h+o/jCFxus3P2LfWIIiwowAjANm7IA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "define-properties": "^1.2.1",
        "es-errors": "^1.3.0",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "set-function-name": "^2.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/regexpu-core": {
      "version": "6.2.0",
      "resolved": "https://registry.npmjs.org/regexpu-core/-/regexpu-core-6.2.0.tgz",
      "integrity": "sha512-H66BPQMrv+V16t8xtmq+UC0CBpiTBA60V8ibS1QVReIp8T1z8hwFxqcGzm9K6lgsN7sB5edVH8a+ze6Fqm4weA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "regenerate": "^1.4.2",
        "regenerate-unicode-properties": "^10.2.0",
        "regjsgen": "^0.8.0",
        "regjsparser": "^0.12.0",
        "unicode-match-property-ecmascript": "^2.0.0",
        "unicode-match-property-value-ecmascript": "^2.1.0"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/regjsgen": {
      "version": "0.8.0",
      "resolved": "https://registry.npmjs.org/regjsgen/-/regjsgen-0.8.0.tgz",
      "integrity": "sha512-RvwtGe3d7LvWiDQXeQw8p5asZUmfU1G/l6WbUXeHta7Y2PEIvBTwH6E2EfmYUK8pxcxEdEmaomqyp0vZZ7C+3Q==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/regjsparser": {
      "version": "0.12.0",
      "resolved": "https://registry.npmjs.org/regjsparser/-/regjsparser-0.12.0.tgz",
      "integrity": "sha512-cnE+y8bz4NhMjISKbgeVJtqNbtf5QpjZP+Bslo+UqkIt9QPnX9q095eiRRASJG1/tz6dlNr6Z5NsBiWYokp6EQ==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "jsesc": "~3.0.2"
      },
      "bin": {
        "regjsparser": "bin/parser"
      }
    },
    "node_modules/regjsparser/node_modules/jsesc": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/jsesc/-/jsesc-3.0.2.tgz",
      "integrity": "sha512-xKqzzWXDttJuOcawBt4KnKHHIf5oQ/Cxax+0PWFG+DFDgHNAdi+TXECADI+RYiFUMmx8792xsMbbgXj4CwnP4g==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "jsesc": "bin/jsesc"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/remark-gfm": {
      "version": "4.0.1",
      "resolved": "https://registry.npmjs.org/remark-gfm/-/remark-gfm-4.0.1.tgz",
      "integrity": "sha512-1quofZ2RQ9EWdeN34S79+KExV1764+wCUGop5CPL1WGdD0ocPpu91lzPGbwWMECpEpd42kJGQwzRfyov9j4yNg==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "mdast-util-gfm": "^3.0.0",
        "micromark-extension-gfm": "^3.0.0",
        "remark-parse": "^11.0.0",
        "remark-stringify": "^11.0.0",
        "unified": "^11.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/remark-parse": {
      "version": "11.0.0",
      "resolved": "https://registry.npmjs.org/remark-parse/-/remark-parse-11.0.0.tgz",
      "integrity": "sha512-FCxlKLNGknS5ba/1lmpYijMUzX2esxW5xQqjWxw2eHFfS2MSdaHVINFmhjo+qN1WhZhNimq0dZATN9pH0IDrpA==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "mdast-util-from-markdown": "^2.0.0",
        "micromark-util-types": "^2.0.0",
        "unified": "^11.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/remark-rehype": {
      "version": "11.1.1",
      "resolved": "https://registry.npmjs.org/remark-rehype/-/remark-rehype-11.1.1.tgz",
      "integrity": "sha512-g/osARvjkBXb6Wo0XvAeXQohVta8i84ACbenPpoSsxTOQH/Ae0/RGP4WZgnMH5pMLpsj4FG7OHmcIcXxpza8eQ==",
      "license": "MIT",
      "dependencies": {
        "@types/hast": "^3.0.0",
        "@types/mdast": "^4.0.0",
        "mdast-util-to-hast": "^13.0.0",
        "unified": "^11.0.0",
        "vfile": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/remark-stringify": {
      "version": "11.0.0",
      "resolved": "https://registry.npmjs.org/remark-stringify/-/remark-stringify-11.0.0.tgz",
      "integrity": "sha512-1OSmLd3awB/t8qdoEOMazZkNsfVTeY4fTsgzcQFdXNq8ToTN4ZGwrMnlda4K6smTFKD+GRV6O48i6Z4iKgPPpw==",
      "license": "MIT",
      "dependencies": {
        "@types/mdast": "^4.0.0",
        "mdast-util-to-markdown": "^2.0.0",
        "unified": "^11.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/require-directory": {
      "version": "2.1.1",
      "resolved": "https://registry.npmjs.org/require-directory/-/require-directory-2.1.1.tgz",
      "integrity": "sha512-fGxEI7+wsG9xrvdjsrlmL22OMTTiHRwAMroiEeMgq8gzoLC/PQr7RsRDSTLUg/bZAZtF+TVIkHc6/4RIKrui+Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/requires-port": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/requires-port/-/requires-port-1.0.0.tgz",
      "integrity": "sha512-KigOCHcocU3XODJxsu8i/j8T9tzT4adHiecwORRQ0ZZFcp7ahwXuRU1m+yuO90C5ZUyGeGfocHDI14M3L3yDAQ==",
      "devOptional": true,
      "license": "MIT"
    },
    "node_modules/resolve": {
      "version": "1.22.10",
      "resolved": "https://registry.npmjs.org/resolve/-/resolve-1.22.10.tgz",
      "integrity": "sha512-NPRy+/ncIMeDlTAsuqwKIiferiawhefFJtkNSW0qZJEqMEb+qBt/77B/jGeeek+F0uOeN05CDa6HXbbIgtVX4w==",
      "license": "MIT",
      "dependencies": {
        "is-core-module": "^2.16.0",
        "path-parse": "^1.0.7",
        "supports-preserve-symlinks-flag": "^1.0.0"
      },
      "bin": {
        "resolve": "bin/resolve"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/resolve-cwd": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/resolve-cwd/-/resolve-cwd-3.0.0.tgz",
      "integrity": "sha512-OrZaX2Mb+rJCpH/6CpSqt9xFVpN++x01XnN2ie9g6P5/3xelLAkXWVADpdz1IHD/KFfEXyE6V0U01OQ3UO2rEg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "resolve-from": "^5.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/resolve-cwd/node_modules/resolve-from": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/resolve-from/-/resolve-from-5.0.0.tgz",
      "integrity": "sha512-qYg9KP24dD5qka9J47d0aVky0N+b4fTU89LN9iDnjB5waksiC49rvMB0PrUJQGoTmH50XPiqOvAjDfaijGxYZw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/resolve-from": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/resolve-from/-/resolve-from-4.0.0.tgz",
      "integrity": "sha512-pb/MYmXstAkysRFx8piNI1tGFNQIFA3vkE3Gq4EuA1dF6gHp/+vgZqsCGJapvy8N3Q+4o7FwvquPJcnZ7RYy4g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/resolve-pkg-maps": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/resolve-pkg-maps/-/resolve-pkg-maps-1.0.0.tgz",
      "integrity": "sha512-seS2Tj26TBVOC2NIc2rOe2y2ZO7efxITtLZcGSOnHHNOQ7CkiUBfw0Iw2ck6xkIhPwLhKNLS8BO+hEpngQlqzw==",
      "dev": true,
      "license": "MIT",
      "funding": {
        "url": "https://github.com/privatenumber/resolve-pkg-maps?sponsor=1"
      }
    },
    "node_modules/resolve.exports": {
      "version": "2.0.3",
      "resolved": "https://registry.npmjs.org/resolve.exports/-/resolve.exports-2.0.3.tgz",
      "integrity": "sha512-OcXjMsGdhL4XnbShKpAcSqPMzQoYkYyhbEaeSko47MjRP9NfEQMhZkXL1DoFlt9LWQn4YttrdnV6X2OiyzBi+A==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/retry": {
      "version": "0.13.1",
      "resolved": "https://registry.npmjs.org/retry/-/retry-0.13.1.tgz",
      "integrity": "sha512-XQBQ3I8W1Cge0Seh+6gjj03LbmRFWuoszgK9ooCpwYIrhhoO80pfq4cUkU5DkknwfOfFteRwlZ56PYOGYyFWdg==",
      "license": "MIT",
      "engines": {
        "node": ">= 4"
      }
    },
    "node_modules/reusify": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/reusify/-/reusify-1.1.0.tgz",
      "integrity": "sha512-g6QUff04oZpHs0eG5p83rFLhHeV00ug/Yf9nZM6fLeUrPguBTkTQOdpAWWspMh55TZfVQDPaN3NQJfbVRAxdIw==",
      "license": "MIT",
      "engines": {
        "iojs": ">=1.0.0",
        "node": ">=0.10.0"
      }
    },
    "node_modules/rimraf": {
      "version": "3.0.2",
      "resolved": "https://registry.npmjs.org/rimraf/-/rimraf-3.0.2.tgz",
      "integrity": "sha512-JZkJMZkAGFFPP2YqXZXPbMlMBgsxzE8ILs4lMIX/2o0L9UBw9O/Y3o6wFw/i9YLapcUJWwqbi3kdxIPdC62TIA==",
      "deprecated": "Rimraf versions prior to v4 are no longer supported",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "glob": "^7.1.3"
      },
      "bin": {
        "rimraf": "bin.js"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/rimraf/node_modules/glob": {
      "version": "7.2.3",
      "resolved": "https://registry.npmjs.org/glob/-/glob-7.2.3.tgz",
      "integrity": "sha512-nFR0zLpU2YCaRxwoCJvL6UvCH2JFyFVIvwTLsIf21AuHlMskA1hhTdk+LlYJtOlYt9v6dvszD2BGRqBL+iQK9Q==",
      "deprecated": "Glob versions prior to v9 are no longer supported",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "fs.realpath": "^1.0.0",
        "inflight": "^1.0.4",
        "inherits": "2",
        "minimatch": "^3.1.1",
        "once": "^1.3.0",
        "path-is-absolute": "^1.0.0"
      },
      "engines": {
        "node": "*"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/run-parallel": {
      "version": "1.2.0",
      "resolved": "https://registry.npmjs.org/run-parallel/-/run-parallel-1.2.0.tgz",
      "integrity": "sha512-5l4VyZR86LZ/lDxZTR6jqL8AFE2S0IFLMP26AbjsLVADxHdhB/c0GUsH+y39UfCi3dzz8OlQuPmnaJOMoDHQBA==",
      "funding": [
        {
          "type": "github",
          "url": "https://github.com/sponsors/feross"
        },
        {
          "type": "patreon",
          "url": "https://www.patreon.com/feross"
        },
        {
          "type": "consulting",
          "url": "https://feross.org/support"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "queue-microtask": "^1.2.2"
      }
    },
    "node_modules/safe-array-concat": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/safe-array-concat/-/safe-array-concat-1.1.3.tgz",
      "integrity": "sha512-AURm5f0jYEOydBj7VQlVvDrjeFgthDdEF5H1dP+6mNpoXOMo1quQqJ4wvJDyRZ9+pO3kGWoOdmV08cSv2aJV6Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.2",
        "get-intrinsic": "^1.2.6",
        "has-symbols": "^1.1.0",
        "isarray": "^2.0.5"
      },
      "engines": {
        "node": ">=0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/safe-push-apply": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/safe-push-apply/-/safe-push-apply-1.0.0.tgz",
      "integrity": "sha512-iKE9w/Z7xCzUMIZqdBsp6pEQvwuEebH4vdpjcDWnyzaI6yl6O9FHvVpmGelvEHNsoY6wGblkxR6Zty/h00WiSA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "isarray": "^2.0.5"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/safe-regex-test": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/safe-regex-test/-/safe-regex-test-1.1.0.tgz",
      "integrity": "sha512-x/+Cz4YrimQxQccJf5mKEbIa1NzeCRNI5Ecl/ekmlYaampdNLPalVyIcCZNNH3MvmqBugV5TMYZXv0ljslUlaw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "is-regex": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/safer-buffer": {
      "version": "2.1.2",
      "resolved": "https://registry.npmjs.org/safer-buffer/-/safer-buffer-2.1.2.tgz",
      "integrity": "sha512-YZo3K82SD7Riyi0E1EQPojLz7kpepnSQI9IyPbHHg1XXXevb5dJI7tpyN2ADxGcQbHG7vcyRHk0cbwqcQriUtg==",
      "devOptional": true,
      "license": "MIT"
    },
    "node_modules/saxes": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/saxes/-/saxes-6.0.0.tgz",
      "integrity": "sha512-xAg7SOnEhrm5zI3puOOKyy1OMcMlIJZYNJY7xLBwSze0UjhPLnWfj2GF2EpT0jmzaJKIWKHLsaSSajf35bcYnA==",
      "devOptional": true,
      "license": "ISC",
      "dependencies": {
        "xmlchars": "^2.2.0"
      },
      "engines": {
        "node": ">=v12.22.7"
      }
    },
    "node_modules/scheduler": {
      "version": "0.23.2",
      "resolved": "https://registry.npmjs.org/scheduler/-/scheduler-0.23.2.tgz",
      "integrity": "sha512-UOShsPwz7NrMUqhR6t0hWjFduvOzbtv7toDH1/hIrfRNIDBnnBWd0CwJTGvTpngVlmwGCdP9/Zl/tVrDqcuYzQ==",
      "license": "MIT",
      "dependencies": {
        "loose-envify": "^1.1.0"
      }
    },
    "node_modules/semver": {
      "version": "7.7.1",
      "resolved": "https://registry.npmjs.org/semver/-/semver-7.7.1.tgz",
      "integrity": "sha512-hlq8tAfn0m/61p4BVRcPzIGr6LKiMwo4VM6dGi6pt4qcRkmNzTcWq6eCEjEh+qXjkMDvPlOFFSGwQjoEa6gyMA==",
      "license": "ISC",
      "bin": {
        "semver": "bin/semver.js"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/set-function-length": {
      "version": "1.2.2",
      "resolved": "https://registry.npmjs.org/set-function-length/-/set-function-length-1.2.2.tgz",
      "integrity": "sha512-pgRc4hJ4/sNjWCSS9AmnS40x3bNMDTknHgL5UaMBTMyJnU90EgWh1Rz+MC9eFu4BuN/UwZjKQuY/1v3rM7HMfg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-data-property": "^1.1.4",
        "es-errors": "^1.3.0",
        "function-bind": "^1.1.2",
        "get-intrinsic": "^1.2.4",
        "gopd": "^1.0.1",
        "has-property-descriptors": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/set-function-name": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/set-function-name/-/set-function-name-2.0.2.tgz",
      "integrity": "sha512-7PGFlmtwsEADb0WYyvCMa1t+yke6daIG4Wirafur5kcf+MhUnPms1UeR0CKQdTZD81yESwMHbtn+TR+dMviakQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-data-property": "^1.1.4",
        "es-errors": "^1.3.0",
        "functions-have-names": "^1.2.3",
        "has-property-descriptors": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/set-proto": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/set-proto/-/set-proto-1.0.0.tgz",
      "integrity": "sha512-RJRdvCo6IAnPdsvP/7m6bsQqNnn1FCBX5ZNtFL98MmFF/4xAIJTIg1YbHW5DC2W5SKZanrC6i4HsJqlajw/dZw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "dunder-proto": "^1.0.1",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/shebang-command": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/shebang-command/-/shebang-command-2.0.0.tgz",
      "integrity": "sha512-kHxr2zZpYtdmrN1qDjrrX/Z1rR1kG8Dx+gkpK1G4eXmvXswmcE1hTWBWYUzlraYw1/yZp6YuDY77YtvbN0dmDA==",
      "license": "MIT",
      "dependencies": {
        "shebang-regex": "^3.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/shebang-regex": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/shebang-regex/-/shebang-regex-3.0.0.tgz",
      "integrity": "sha512-7++dFhtcx3353uBaq8DDR4NuxBetBzC7ZQOhmTQInHEd6bSrXdiEyzCvG07Z44UYdLShWUyXt5M/yhz8ekcb1A==",
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/side-channel": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/side-channel/-/side-channel-1.1.0.tgz",
      "integrity": "sha512-ZX99e6tRweoUXqR+VBrslhda51Nh5MTQwou5tnUDgbtyM0dBgmhEDtWGP/xbKn6hqfPRHujUNwz5fy/wbbhnpw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "object-inspect": "^1.13.3",
        "side-channel-list": "^1.0.0",
        "side-channel-map": "^1.0.1",
        "side-channel-weakmap": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-list": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/side-channel-list/-/side-channel-list-1.0.0.tgz",
      "integrity": "sha512-FCLHtRD/gnpCiCHEiJLOwdmFP+wzCmDEkc9y7NsYxeF4u7Btsn1ZuwgwJGxImImHicJArLP4R0yX4c2KCrMrTA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "es-errors": "^1.3.0",
        "object-inspect": "^1.13.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-map": {
      "version": "1.0.1",
      "resolved": "https://registry.npmjs.org/side-channel-map/-/side-channel-map-1.0.1.tgz",
      "integrity": "sha512-VCjCNfgMsby3tTdo02nbjtM/ewra6jPHmpThenkTYh8pG9ucZ/1P8So4u4FGBek/BjpOVsDCMoLA/iuBKIFXRA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.5",
        "object-inspect": "^1.13.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/side-channel-weakmap": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/side-channel-weakmap/-/side-channel-weakmap-1.0.2.tgz",
      "integrity": "sha512-WPS/HvHQTYnHisLo9McqBHOJk2FkHO/tlpvldyrnem4aeQp4hai3gythswg6p01oSoTl58rcpiFAjF2br2Ak2A==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "es-errors": "^1.3.0",
        "get-intrinsic": "^1.2.5",
        "object-inspect": "^1.13.3",
        "side-channel-map": "^1.0.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/signal-exit": {
      "version": "4.1.0",
      "resolved": "https://registry.npmjs.org/signal-exit/-/signal-exit-4.1.0.tgz",
      "integrity": "sha512-bzyZ1e88w9O1iNJbKnOlvYTrWPDl46O1bG0D3XInv+9tkPrxrN8jUUTiFlDkkmKWgn1M6CfIA13SuGqOa9Korw==",
      "license": "ISC",
      "engines": {
        "node": ">=14"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/sisteransi": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/sisteransi/-/sisteransi-1.0.5.tgz",
      "integrity": "sha512-bLGGlR1QxBcynn2d5YmDX4MGjlZvy2MRBDRNHLJ8VI6l6+9FUiyTFNJ0IveOSP0bcXgVDPRcfGqA0pjaqUpfVg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/slash": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/slash/-/slash-3.0.0.tgz",
      "integrity": "sha512-g9Q1haeby36OSStwb4ntCGGGaKsaVSjQ68fBxoQcutl5fS1vuY18H3wSt3jFyFtrkx+Kz0V1G85A4MyAdDMi2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/source-map": {
      "version": "0.6.1",
      "resolved": "https://registry.npmjs.org/source-map/-/source-map-0.6.1.tgz",
      "integrity": "sha512-UjgapumWlbMhkBgzT7Ykc5YXUT46F0iKu8SGXq0bcwP5dz/h0Plj6enJqjz1Zbq2l5WaqYnrVbwWOWMyF3F47g==",
      "dev": true,
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/source-map-js": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/source-map-js/-/source-map-js-1.2.1.tgz",
      "integrity": "sha512-UXWMKhLOwVKb728IUtQPXxfYU+usdybtUrK/8uGE8CQMvrhOpwvzDBwj0QhSL7MQc7vIsISBG8VQ8+IDQxpfQA==",
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/source-map-support": {
      "version": "0.5.13",
      "resolved": "https://registry.npmjs.org/source-map-support/-/source-map-support-0.5.13.tgz",
      "integrity": "sha512-SHSKFHadjVA5oR4PPqhtAVdcBWwRYVd6g6cAXnIbRiIwc2EhPrTuKUBdSLvlEKyIP3GCf89fltvcZiP9MMFA1w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "buffer-from": "^1.0.0",
        "source-map": "^0.6.0"
      }
    },
    "node_modules/space-separated-tokens": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/space-separated-tokens/-/space-separated-tokens-2.0.2.tgz",
      "integrity": "sha512-PEGlAwrG8yXGXRjW32fGbg66JAlOAwbObuqVoJpv/mRgoWDQfgH1wDPvtzWyUSNAXBGSk8h755YDbbcEy3SH2Q==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/sprintf-js": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/sprintf-js/-/sprintf-js-1.0.3.tgz",
      "integrity": "sha512-D9cPgkvLlV3t3IzL0D0YLvGA9Ahk4PcvVwUbN0dSGr1aP0Nrt4AEnTUbuGvquEC0mA64Gqt1fzirlRs5ibXx8g==",
      "dev": true,
      "license": "BSD-3-Clause"
    },
    "node_modules/stable-hash": {
      "version": "0.0.4",
      "resolved": "https://registry.npmjs.org/stable-hash/-/stable-hash-0.0.4.tgz",
      "integrity": "sha512-LjdcbuBeLcdETCrPn9i8AYAZ1eCtu4ECAWtP7UleOiZ9LzVxRzzUZEoZ8zB24nhkQnDWyET0I+3sWokSDS3E7g==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/stack-utils": {
      "version": "2.0.6",
      "resolved": "https://registry.npmjs.org/stack-utils/-/stack-utils-2.0.6.tgz",
      "integrity": "sha512-XlkWvfIm6RmsWtNJx+uqtKLS8eqFbxUg0ZzLXqY0caEy9l7hruX8IpiDnjsLavoBgqCCR71TqWO8MaXYheJ3RQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "escape-string-regexp": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/stack-utils/node_modules/escape-string-regexp": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/escape-string-regexp/-/escape-string-regexp-2.0.0.tgz",
      "integrity": "sha512-UpzcLCXolUWcNu5HtVMHYdXJjArjsF9C0aNnquZYY4uW/Vu0miy5YoWvbV345HauVvcAUnpRuhMMcqTcGOY2+w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/streamsearch": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/streamsearch/-/streamsearch-1.1.0.tgz",
      "integrity": "sha512-Mcc5wHehp9aXz1ax6bZUyY5afg9u2rv5cqQI3mRrYkGC8rW2hM02jWuwjtL++LS5qinSyhj2QfLyNsuc+VsExg==",
      "engines": {
        "node": ">=10.0.0"
      }
    },
    "node_modules/string-length": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/string-length/-/string-length-4.0.2.tgz",
      "integrity": "sha512-+l6rNN5fYHNhZZy41RXsYptCjA2Igmq4EG7kZAYFQI1E1VTXarr6ZPXBg6eq7Y6eK4FEhY6AJlyuFIb/v/S0VQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "char-regex": "^1.0.2",
        "strip-ansi": "^6.0.0"
      },
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/string-width": {
      "version": "5.1.2",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-5.1.2.tgz",
      "integrity": "sha512-HnLOCR3vjcY8beoNLtcjZ5/nxn2afmME6lhrDrebokqMap+XbeW8n9TXpPDOqdGK5qcI3oT0GKTW6wC7EMiVqA==",
      "license": "MIT",
      "dependencies": {
        "eastasianwidth": "^0.2.0",
        "emoji-regex": "^9.2.2",
        "strip-ansi": "^7.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/string-width-cjs": {
      "name": "string-width",
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
      "license": "MIT",
      "dependencies": {
        "emoji-regex": "^8.0.0",
        "is-fullwidth-code-point": "^3.0.0",
        "strip-ansi": "^6.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/string-width-cjs/node_modules/emoji-regex": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
      "license": "MIT"
    },
    "node_modules/string-width/node_modules/ansi-regex": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.1.0.tgz",
      "integrity": "sha512-7HSX4QQb4CspciLpVFwyRe79O3xsIZDDLER21kERQ71oaPodF8jL725AgJMFAYbooIqolJoRLuM81SpeUkpkvA==",
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
      }
    },
    "node_modules/string-width/node_modules/strip-ansi": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.0.tgz",
      "integrity": "sha512-iq6eVVI64nQQTRYq2KtEg2d2uU7LElhTJwsH4YzIHZshxlgZms/wIc4VoDQTlG/IvVIrBKG06CrZnp0qv7hkcQ==",
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^6.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
      }
    },
    "node_modules/string.prototype.includes": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/string.prototype.includes/-/string.prototype.includes-2.0.1.tgz",
      "integrity": "sha512-o7+c9bW6zpAdJHTtujeePODAhkuicdAryFsfVKwA+wGw89wJ4GTY484WTucM9hLtDEOpOvI+aHnzqnC5lHp4Rg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.3"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/string.prototype.matchall": {
      "version": "4.0.12",
      "resolved": "https://registry.npmjs.org/string.prototype.matchall/-/string.prototype.matchall-4.0.12.tgz",
      "integrity": "sha512-6CC9uyBL+/48dYizRf7H7VAYCMCNTBeM78x/VTUe9bFEaxBepPJDa1Ow99LqI/1yF7kuy7Q3cQsYMrcjGUcskA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.3",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.6",
        "es-errors": "^1.3.0",
        "es-object-atoms": "^1.0.0",
        "get-intrinsic": "^1.2.6",
        "gopd": "^1.2.0",
        "has-symbols": "^1.1.0",
        "internal-slot": "^1.1.0",
        "regexp.prototype.flags": "^1.5.3",
        "set-function-name": "^2.0.2",
        "side-channel": "^1.1.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/string.prototype.repeat": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/string.prototype.repeat/-/string.prototype.repeat-1.0.0.tgz",
      "integrity": "sha512-0u/TldDbKD8bFCQ/4f5+mNRrXwZ8hg2w7ZR8wa16e8z9XpePWl3eGEcUD0OXpEH/VJH/2G3gjUtR3ZOiBe2S/w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "define-properties": "^1.1.3",
        "es-abstract": "^1.17.5"
      }
    },
    "node_modules/string.prototype.trim": {
      "version": "1.2.10",
      "resolved": "https://registry.npmjs.org/string.prototype.trim/-/string.prototype.trim-1.2.10.tgz",
      "integrity": "sha512-Rs66F0P/1kedk5lyYyH9uBzuiI/kNRmwJAR9quK6VOtIpZ2G+hMZd+HQbbv25MgCA6gEffoMZYxlTod4WcdrKA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.2",
        "define-data-property": "^1.1.4",
        "define-properties": "^1.2.1",
        "es-abstract": "^1.23.5",
        "es-object-atoms": "^1.0.0",
        "has-property-descriptors": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/string.prototype.trimend": {
      "version": "1.0.9",
      "resolved": "https://registry.npmjs.org/string.prototype.trimend/-/string.prototype.trimend-1.0.9.tgz",
      "integrity": "sha512-G7Ok5C6E/j4SGfyLCloXTrngQIQU3PWtXGst3yM7Bea9FRURf1S42ZHlZZtsNque2FN2PoUhfZXYLNWwEr4dLQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.2",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/string.prototype.trimstart": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/string.prototype.trimstart/-/string.prototype.trimstart-1.0.8.tgz",
      "integrity": "sha512-UXSH262CSZY1tfu3G3Secr6uGLCFVPMhIqHjlgCUtCCcgihYc/xKs9djMTMUOb2j1mVSeU8EU6NWc/iQKU6Gfg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "define-properties": "^1.2.1",
        "es-object-atoms": "^1.0.0"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/stringify-entities": {
      "version": "4.0.4",
      "resolved": "https://registry.npmjs.org/stringify-entities/-/stringify-entities-4.0.4.tgz",
      "integrity": "sha512-IwfBptatlO+QCJUo19AqvrPNqlVMpW9YEL2LIVY+Rpv2qsjCGxaDLNRgeGsQWJhfItebuJhsGSLjaBbNSQ+ieg==",
      "license": "MIT",
      "dependencies": {
        "character-entities-html4": "^2.0.0",
        "character-entities-legacy": "^3.0.0"
      },
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/strip-ansi": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-ansi-cjs": {
      "name": "strip-ansi",
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-6.0.1.tgz",
      "integrity": "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A==",
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^5.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-bom": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/strip-bom/-/strip-bom-3.0.0.tgz",
      "integrity": "sha512-vavAMRXOgBVNF6nyEEmL3DBK19iRpDcoIwW+swQ+CbGiu7lju6t+JklA1MHweoWtadgt4ISVUsXLyDq34ddcwA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/strip-final-newline": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/strip-final-newline/-/strip-final-newline-2.0.0.tgz",
      "integrity": "sha512-BrpvfNAE3dcvq7ll3xVumzjKjZQ5tI1sEUIKr3Uoks0XUl45St3FlatVqef9prk4jRDzhW6WZg+3bk93y6pLjA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/strip-indent": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/strip-indent/-/strip-indent-3.0.0.tgz",
      "integrity": "sha512-laJTa3Jb+VQpaC6DseHhF7dXVqHTfJPCRDaEbid/drOhgitgYku/letMUqOXFoWV0zIIUbjpdH2t+tYj4bQMRQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "min-indent": "^1.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/strip-json-comments": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/strip-json-comments/-/strip-json-comments-3.1.1.tgz",
      "integrity": "sha512-6fPc+R4ihwqP6N/aIv2f1gMH8lOVtWQHoqC4yK6oSDVVocumAsfCqjkXnqiYMhmMwS/mEHLp7Vehlt3ql6lEig==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=8"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/style-to-js": {
      "version": "1.1.16",
      "resolved": "https://registry.npmjs.org/style-to-js/-/style-to-js-1.1.16.tgz",
      "integrity": "sha512-/Q6ld50hKYPH3d/r6nr117TZkHR0w0kGGIVfpG9N6D8NymRPM9RqCUv4pRpJ62E5DqOYx2AFpbZMyCPnjQCnOw==",
      "license": "MIT",
      "dependencies": {
        "style-to-object": "1.0.8"
      }
    },
    "node_modules/style-to-object": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/style-to-object/-/style-to-object-1.0.8.tgz",
      "integrity": "sha512-xT47I/Eo0rwJmaXC4oilDGDWLohVhR6o/xAQcPQN8q6QBuZVL8qMYL85kLmST5cPjAorwvqIA4qXTRQoYHaL6g==",
      "license": "MIT",
      "dependencies": {
        "inline-style-parser": "0.2.4"
      }
    },
    "node_modules/styled-jsx": {
      "version": "5.1.1",
      "resolved": "https://registry.npmjs.org/styled-jsx/-/styled-jsx-5.1.1.tgz",
      "integrity": "sha512-pW7uC1l4mBZ8ugbiZrcIsiIvVx1UmTfw7UkC3Um2tmfUq9Bhk8IiyEIPl6F8agHgjzku6j0xQEZbfA5uSgSaCw==",
      "license": "MIT",
      "dependencies": {
        "client-only": "0.0.1"
      },
      "engines": {
        "node": ">= 12.0.0"
      },
      "peerDependencies": {
        "react": ">= 16.8.0 || 17.x.x || ^18.0.0-0"
      },
      "peerDependenciesMeta": {
        "@babel/core": {
          "optional": true
        },
        "babel-plugin-macros": {
          "optional": true
        }
      }
    },
    "node_modules/sucrase": {
      "version": "3.35.0",
      "resolved": "https://registry.npmjs.org/sucrase/-/sucrase-3.35.0.tgz",
      "integrity": "sha512-8EbVDiu9iN/nESwxeSxDKe0dunta1GOlHufmSSXxMD2z2/tMZpDMpvXQGsc+ajGo8y2uYUmixaSRUc/QPoQ0GA==",
      "license": "MIT",
      "dependencies": {
        "@jridgewell/gen-mapping": "^0.3.2",
        "commander": "^4.0.0",
        "glob": "^10.3.10",
        "lines-and-columns": "^1.1.6",
        "mz": "^2.7.0",
        "pirates": "^4.0.1",
        "ts-interface-checker": "^0.1.9"
      },
      "bin": {
        "sucrase": "bin/sucrase",
        "sucrase-node": "bin/sucrase-node"
      },
      "engines": {
        "node": ">=16 || 14 >=14.17"
      }
    },
    "node_modules/sucrase/node_modules/commander": {
      "version": "4.1.1",
      "resolved": "https://registry.npmjs.org/commander/-/commander-4.1.1.tgz",
      "integrity": "sha512-NOKm8xhkzAjzFx8B2v5OAHT+u5pRQc2UCa2Vq9jYL/31o2wi9mxBA7LIFs3sV5VSC49z6pEhfbMULvShKj26WA==",
      "license": "MIT",
      "engines": {
        "node": ">= 6"
      }
    },
    "node_modules/supports-color": {
      "version": "7.2.0",
      "resolved": "https://registry.npmjs.org/supports-color/-/supports-color-7.2.0.tgz",
      "integrity": "sha512-qpCAvRl9stuOHveKsn7HncJRvv501qIacKzQlO/+Lwxc9+0q2wLyv4Dfvt80/DPn2pqOBsJdDiogXGR9+OvwRw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "has-flag": "^4.0.0"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/supports-preserve-symlinks-flag": {
      "version": "1.0.0",
      "resolved": "https://registry.npmjs.org/supports-preserve-symlinks-flag/-/supports-preserve-symlinks-flag-1.0.0.tgz",
      "integrity": "sha512-ot0WnXS9fgdkgIcePe6RHNk1WA8+muPa6cSjeR3V8K27q9BB1rTE3R1p7Hv0z1ZyAc8s6Vvv8DIyWf681MAt0w==",
      "license": "MIT",
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/symbol-tree": {
      "version": "3.2.4",
      "resolved": "https://registry.npmjs.org/symbol-tree/-/symbol-tree-3.2.4.tgz",
      "integrity": "sha512-9QNk5KwDF+Bvz+PyObkmSYjI5ksVUYtjW7AU22r2NKcfLJcXp96hkDWU3+XndOsUb+AQ9QhfzfCT2O+CNWT5Tw==",
      "devOptional": true,
      "license": "MIT"
    },
    "node_modules/tailwind-merge": {
      "version": "2.6.0",
      "resolved": "https://registry.npmjs.org/tailwind-merge/-/tailwind-merge-2.6.0.tgz",
      "integrity": "sha512-P+Vu1qXfzediirmHOC3xKGAYeZtPcV9g76X+xg2FD4tYgR71ewMA35Y3sCz3zhiN/dwefRpJX0yBcgwi1fXNQA==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/dcastil"
      }
    },
    "node_modules/tailwindcss": {
      "version": "3.4.17",
      "resolved": "https://registry.npmjs.org/tailwindcss/-/tailwindcss-3.4.17.tgz",
      "integrity": "sha512-w33E2aCvSDP0tW9RZuNXadXlkHXqFzSkQew/aIa2i/Sj8fThxwovwlXHSPXTbAHwEIhBFXAedUhP2tueAKP8Og==",
      "license": "MIT",
      "dependencies": {
        "@alloc/quick-lru": "^5.2.0",
        "arg": "^5.0.2",
        "chokidar": "^3.6.0",
        "didyoumean": "^1.2.2",
        "dlv": "^1.1.3",
        "fast-glob": "^3.3.2",
        "glob-parent": "^6.0.2",
        "is-glob": "^4.0.3",
        "jiti": "^1.21.6",
        "lilconfig": "^3.1.3",
        "micromatch": "^4.0.8",
        "normalize-path": "^3.0.0",
        "object-hash": "^3.0.0",
        "picocolors": "^1.1.1",
        "postcss": "^8.4.47",
        "postcss-import": "^15.1.0",
        "postcss-js": "^4.0.1",
        "postcss-load-config": "^4.0.2",
        "postcss-nested": "^6.2.0",
        "postcss-selector-parser": "^6.1.2",
        "resolve": "^1.22.8",
        "sucrase": "^3.35.0"
      },
      "bin": {
        "tailwind": "lib/cli.js",
        "tailwindcss": "lib/cli.js"
      },
      "engines": {
        "node": ">=14.0.0"
      }
    },
    "node_modules/tailwindcss-animate": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/tailwindcss-animate/-/tailwindcss-animate-1.0.7.tgz",
      "integrity": "sha512-bl6mpH3T7I3UFxuvDEXLxy/VuFxBk5bbzplh7tXI68mwMokNYd1t9qPBHlnyTwfa4JGC4zP516I1hYYtQ/vspA==",
      "license": "MIT",
      "peerDependencies": {
        "tailwindcss": ">=3.0.0 || insiders"
      }
    },
    "node_modules/tapable": {
      "version": "2.2.1",
      "resolved": "https://registry.npmjs.org/tapable/-/tapable-2.2.1.tgz",
      "integrity": "sha512-GNzQvQTOIP6RyTfE2Qxb8ZVlNmw0n88vp1szwWRimP02mnTsx3Wtn5qRdqY9w2XduFNUgvOwhNnQsjwCp+kqaQ==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/test-exclude": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/test-exclude/-/test-exclude-6.0.0.tgz",
      "integrity": "sha512-cAGWPIyOHU6zlmg88jwm7VRyXnMN7iV68OGAbYDk/Mh/xC/pzVPlQtY6ngoIH/5/tciuhGfvESU8GrHrcxD56w==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "@istanbuljs/schema": "^0.1.2",
        "glob": "^7.1.4",
        "minimatch": "^3.0.4"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/test-exclude/node_modules/glob": {
      "version": "7.2.3",
      "resolved": "https://registry.npmjs.org/glob/-/glob-7.2.3.tgz",
      "integrity": "sha512-nFR0zLpU2YCaRxwoCJvL6UvCH2JFyFVIvwTLsIf21AuHlMskA1hhTdk+LlYJtOlYt9v6dvszD2BGRqBL+iQK9Q==",
      "deprecated": "Glob versions prior to v9 are no longer supported",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "fs.realpath": "^1.0.0",
        "inflight": "^1.0.4",
        "inherits": "2",
        "minimatch": "^3.1.1",
        "once": "^1.3.0",
        "path-is-absolute": "^1.0.0"
      },
      "engines": {
        "node": "*"
      },
      "funding": {
        "url": "https://github.com/sponsors/isaacs"
      }
    },
    "node_modules/text-table": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/text-table/-/text-table-0.2.0.tgz",
      "integrity": "sha512-N+8UisAXDGk8PFXP4HAzVR9nbfmVJ3zYLAWiTIoqC5v5isinhr+r5uaO8+7r3BMfuNIufIsA7RdpVgacC2cSpw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/thenify": {
      "version": "3.3.1",
      "resolved": "https://registry.npmjs.org/thenify/-/thenify-3.3.1.tgz",
      "integrity": "sha512-RVZSIV5IG10Hk3enotrhvz0T9em6cyHBLkH/YAZuKqd8hRkKhSfCGIcP2KUY0EPxndzANBmNllzWPwak+bheSw==",
      "license": "MIT",
      "dependencies": {
        "any-promise": "^1.0.0"
      }
    },
    "node_modules/thenify-all": {
      "version": "1.6.0",
      "resolved": "https://registry.npmjs.org/thenify-all/-/thenify-all-1.6.0.tgz",
      "integrity": "sha512-RNxQH/qI8/t3thXJDwcstUO4zeqo64+Uy/+sNVRBx4Xn2OX+OZ9oP+iJnNFqplFra2ZUVeKCSa2oVWi3T4uVmA==",
      "license": "MIT",
      "dependencies": {
        "thenify": ">= 3.1.0 < 4"
      },
      "engines": {
        "node": ">=0.8"
      }
    },
    "node_modules/tiny-invariant": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/tiny-invariant/-/tiny-invariant-1.3.3.tgz",
      "integrity": "sha512-+FbBPE1o9QAYvviau/qC5SE3caw21q3xkvWKBtja5vgqOWIHHJ3ioaq1VPfn/Szqctz2bU/oYeKd9/z5BL+PVg==",
      "license": "MIT"
    },
    "node_modules/tinyglobby": {
      "version": "0.2.12",
      "resolved": "https://registry.npmjs.org/tinyglobby/-/tinyglobby-0.2.12.tgz",
      "integrity": "sha512-qkf4trmKSIiMTs/E63cxH+ojC2unam7rJ0WrauAzpT3ECNTxGRMlaXxVbfxMUC/w0LaYk6jQ4y/nGR9uBO3tww==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "fdir": "^6.4.3",
        "picomatch": "^4.0.2"
      },
      "engines": {
        "node": ">=12.0.0"
      },
      "funding": {
        "url": "https://github.com/sponsors/SuperchupuDev"
      }
    },
    "node_modules/tinyglobby/node_modules/fdir": {
      "version": "6.4.3",
      "resolved": "https://registry.npmjs.org/fdir/-/fdir-6.4.3.tgz",
      "integrity": "sha512-PMXmW2y1hDDfTSRc9gaXIuCCRpuoz3Kaz8cUelp3smouvfT632ozg2vrT6lJsHKKOF59YLbOGfAWGUcKEfRMQw==",
      "dev": true,
      "license": "MIT",
      "peerDependencies": {
        "picomatch": "^3 || ^4"
      },
      "peerDependenciesMeta": {
        "picomatch": {
          "optional": true
        }
      }
    },
    "node_modules/tinyglobby/node_modules/picomatch": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/picomatch/-/picomatch-4.0.2.tgz",
      "integrity": "sha512-M7BAV6Rlcy5u+m6oPhAPFgJTzAioX/6B0DxyvDlo9l8+T3nLKbrczg2WLUyzd45L8RqfUMyGPzekbMvX2Ldkwg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/sponsors/jonschlinkert"
      }
    },
    "node_modules/tmpl": {
      "version": "1.0.5",
      "resolved": "https://registry.npmjs.org/tmpl/-/tmpl-1.0.5.tgz",
      "integrity": "sha512-3f0uOEAQwIqGuWW2MVzYg8fV/QNnc/IpuJNG837rLuczAaLVHslWHZQj4IGiEl5Hs3kkbhwL9Ab7Hrsmuj+Smw==",
      "dev": true,
      "license": "BSD-3-Clause"
    },
    "node_modules/to-regex-range": {
      "version": "5.0.1",
      "resolved": "https://registry.npmjs.org/to-regex-range/-/to-regex-range-5.0.1.tgz",
      "integrity": "sha512-65P7iz6X5yEr1cwcgvQxbbIw7Uk3gOy5dIdtZ4rDveLqhrdJP+Li/Hx6tyK0NEb+2GCyneCMJiGqrADCSNk8sQ==",
      "license": "MIT",
      "dependencies": {
        "is-number": "^7.0.0"
      },
      "engines": {
        "node": ">=8.0"
      }
    },
    "node_modules/tough-cookie": {
      "version": "4.1.4",
      "resolved": "https://registry.npmjs.org/tough-cookie/-/tough-cookie-4.1.4.tgz",
      "integrity": "sha512-Loo5UUvLD9ScZ6jh8beX1T6sO1w2/MpCRpEP7V280GKMVUQ0Jzar2U3UJPsrdbziLEMMhu3Ujnq//rhiFuIeag==",
      "devOptional": true,
      "license": "BSD-3-Clause",
      "dependencies": {
        "psl": "^1.1.33",
        "punycode": "^2.1.1",
        "universalify": "^0.2.0",
        "url-parse": "^1.5.3"
      },
      "engines": {
        "node": ">=6"
      }
    },
    "node_modules/tr46": {
      "version": "0.0.3",
      "resolved": "https://registry.npmjs.org/tr46/-/tr46-0.0.3.tgz",
      "integrity": "sha512-N3WMsuqV66lT30CrXNbEjx4GEwlow3v6rr4mCcv6prnfwhS01rkgyFdjPNBYd9br7LpXV1+Emh01fHnq2Gdgrw==",
      "license": "MIT"
    },
    "node_modules/trim-lines": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/trim-lines/-/trim-lines-3.0.1.tgz",
      "integrity": "sha512-kRj8B+YHZCc9kQYdWfJB2/oUl9rA99qbowYYBtr4ui4mZyAQ2JpvVBd/6U2YloATfqBhBTSMhTpgBHtU0Mf3Rg==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/trough": {
      "version": "2.2.0",
      "resolved": "https://registry.npmjs.org/trough/-/trough-2.2.0.tgz",
      "integrity": "sha512-tmMpK00BjZiUyVyvrBK7knerNgmgvcV/KLVyuma/SC+TQN167GrMRciANTz09+k3zW8L8t60jWO1GpfkZdjTaw==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    },
    "node_modules/ts-api-utils": {
      "version": "1.4.3",
      "resolved": "https://registry.npmjs.org/ts-api-utils/-/ts-api-utils-1.4.3.tgz",
      "integrity": "sha512-i3eMG77UTMD0hZhgRS562pv83RC6ukSAC2GMNWc+9dieh/+jDM5u5YG+NHX6VNDRHQcHwmsTHctP9LhbC3WxVw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=16"
      },
      "peerDependencies": {
        "typescript": ">=4.2.0"
      }
    },
    "node_modules/ts-interface-checker": {
      "version": "0.1.13",
      "resolved": "https://registry.npmjs.org/ts-interface-checker/-/ts-interface-checker-0.1.13.tgz",
      "integrity": "sha512-Y/arvbn+rrz3JCKl9C4kVNfTfSm2/mEp5FSz5EsZSANGPSlQrpRI5M4PKF+mJnE52jOO90PnPSc3Ur3bTQw0gA==",
      "license": "Apache-2.0"
    },
    "node_modules/tsconfig-paths": {
      "version": "3.15.0",
      "resolved": "https://registry.npmjs.org/tsconfig-paths/-/tsconfig-paths-3.15.0.tgz",
      "integrity": "sha512-2Ac2RgzDe/cn48GvOe3M+o82pEFewD3UPbyoUHHdKasHwJKjds4fLXWf/Ux5kATBKN20oaFGu+jbElp1pos0mg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@types/json5": "^0.0.29",
        "json5": "^1.0.2",
        "minimist": "^1.2.6",
        "strip-bom": "^3.0.0"
      }
    },
    "node_modules/tslib": {
      "version": "2.8.1",
      "resolved": "https://registry.npmjs.org/tslib/-/tslib-2.8.1.tgz",
      "integrity": "sha512-oJFu94HQb+KVduSUQL7wnpmqnfmLsOA/nAh6b6EH0wCEoK0/mPeXU6c3wKDV83MkOuHPRHtSXKKU99IBazS/2w==",
      "license": "0BSD"
    },
    "node_modules/type-check": {
      "version": "0.4.0",
      "resolved": "https://registry.npmjs.org/type-check/-/type-check-0.4.0.tgz",
      "integrity": "sha512-XleUoc9uwGXqjWwXaUTZAmzMcFZ5858QA2vvx1Ur5xIcixXIP+8LnFDgRplU30us6teqdlskFfu+ae4K79Ooew==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "prelude-ls": "^1.2.1"
      },
      "engines": {
        "node": ">= 0.8.0"
      }
    },
    "node_modules/type-detect": {
      "version": "4.0.8",
      "resolved": "https://registry.npmjs.org/type-detect/-/type-detect-4.0.8.tgz",
      "integrity": "sha512-0fr/mIH1dlO+x7TlcMy+bIDqKPsw/70tVyeHW787goQjhmqaZe10uwLujubK9q9Lg6Fiho1KUKDYz0Z7k7g5/g==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/type-fest": {
      "version": "0.20.2",
      "resolved": "https://registry.npmjs.org/type-fest/-/type-fest-0.20.2.tgz",
      "integrity": "sha512-Ne+eE4r0/iWnpAxD852z3A+N0Bt5RN//NjJwRd2VFHEmrywxf5vsZlh4R6lixl6B+wz/8d+maTSAkN1FIkI3LQ==",
      "dev": true,
      "license": "(MIT OR CC0-1.0)",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/typed-array-buffer": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/typed-array-buffer/-/typed-array-buffer-1.0.3.tgz",
      "integrity": "sha512-nAYYwfY3qnzX30IkA6AQZjVbtK6duGontcQm1WSG1MD94YLqK0515GNApXkoxKOWMusVssAHWLh9SeaoefYFGw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "es-errors": "^1.3.0",
        "is-typed-array": "^1.1.14"
      },
      "engines": {
        "node": ">= 0.4"
      }
    },
    "node_modules/typed-array-byte-length": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/typed-array-byte-length/-/typed-array-byte-length-1.0.3.tgz",
      "integrity": "sha512-BaXgOuIxz8n8pIq3e7Atg/7s+DpiYrxn4vdot3w9KbnBhcRQq6o3xemQdIfynqSeXeDrF32x+WvfzmOjPiY9lg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.8",
        "for-each": "^0.3.3",
        "gopd": "^1.2.0",
        "has-proto": "^1.2.0",
        "is-typed-array": "^1.1.14"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/typed-array-byte-offset": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/typed-array-byte-offset/-/typed-array-byte-offset-1.0.4.tgz",
      "integrity": "sha512-bTlAFB/FBYMcuX81gbL4OcpH5PmlFHqlCCpAl8AlEzMz5k53oNDvN8p1PNOWLEmI2x4orp3raOFB51tv9X+MFQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "available-typed-arrays": "^1.0.7",
        "call-bind": "^1.0.8",
        "for-each": "^0.3.3",
        "gopd": "^1.2.0",
        "has-proto": "^1.2.0",
        "is-typed-array": "^1.1.15",
        "reflect.getprototypeof": "^1.0.9"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/typed-array-length": {
      "version": "1.0.7",
      "resolved": "https://registry.npmjs.org/typed-array-length/-/typed-array-length-1.0.7.tgz",
      "integrity": "sha512-3KS2b+kL7fsuk/eJZ7EQdnEmQoaho/r6KUef7hxvltNA5DR8NAUM+8wJMbJyZ4G9/7i3v5zPBIMN5aybAh2/Jg==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bind": "^1.0.7",
        "for-each": "^0.3.3",
        "gopd": "^1.0.1",
        "is-typed-array": "^1.1.13",
        "possible-typed-array-names": "^1.0.0",
        "reflect.getprototypeof": "^1.0.6"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/typescript": {
      "version": "5.8.2",
      "resolved": "https://registry.npmjs.org/typescript/-/typescript-5.8.2.tgz",
      "integrity": "sha512-aJn6wq13/afZp/jT9QZmwEjDqqvSGp1VT5GVg+f/t6/oVyrgXM6BY1h9BRh/O5p3PlUPAe+WuiEZOmb/49RqoQ==",
      "dev": true,
      "license": "Apache-2.0",
      "bin": {
        "tsc": "bin/tsc",
        "tsserver": "bin/tsserver"
      },
      "engines": {
        "node": ">=14.17"
      }
    },
    "node_modules/unbox-primitive": {
      "version": "1.1.0",
      "resolved": "https://registry.npmjs.org/unbox-primitive/-/unbox-primitive-1.1.0.tgz",
      "integrity": "sha512-nWJ91DjeOkej/TA8pXQ3myruKpKEYgqvpw9lz4OPHj/NWFNluYrjbz9j01CJ8yKQd2g4jFoOkINCTW2I5LEEyw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.3",
        "has-bigints": "^1.0.2",
        "has-symbols": "^1.1.0",
        "which-boxed-primitive": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/undici-types": {
      "version": "6.19.8",
      "resolved": "https://registry.npmjs.org/undici-types/-/undici-types-6.19.8.tgz",
      "integrity": "sha512-ve2KP6f/JnbPBFyobGHuerC9g1FYGn/F8n1LWTwNxCEzd6IfqTwUQcNXgEtmmQ6DlRrC1hrSrBnCZPokRrDHjw==",
      "license": "MIT"
    },
    "node_modules/unicode-canonical-property-names-ecmascript": {
      "version": "2.0.1",
      "resolved": "https://registry.npmjs.org/unicode-canonical-property-names-ecmascript/-/unicode-canonical-property-names-ecmascript-2.0.1.tgz",
      "integrity": "sha512-dA8WbNeb2a6oQzAQ55YlT5vQAWGV9WXOsi3SskE3bcCdM0P4SDd+24zS/OCacdRq5BkdsRj9q3Pg6YyQoxIGqg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/unicode-match-property-ecmascript": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/unicode-match-property-ecmascript/-/unicode-match-property-ecmascript-2.0.0.tgz",
      "integrity": "sha512-5kaZCrbp5mmbz5ulBkDkbY0SsPOjKqVS35VpL9ulMPfSl0J0Xsm+9Evphv9CoIZFwre7aJoa94AY6seMKGVN5Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "unicode-canonical-property-names-ecmascript": "^2.0.0",
        "unicode-property-aliases-ecmascript": "^2.0.0"
      },
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/unicode-match-property-value-ecmascript": {
      "version": "2.2.0",
      "resolved": "https://registry.npmjs.org/unicode-match-property-value-ecmascript/-/unicode-match-property-value-ecmascript-2.2.0.tgz",
      "integrity": "sha512-4IehN3V/+kkr5YeSSDDQG8QLqO26XpL2XP3GQtqwlT/QYSECAwFztxVHjlbh0+gjJ3XmNLS0zDsbgs9jWKExLg==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/unicode-property-aliases-ecmascript": {
      "version": "2.1.0",
      "resolved": "https://registry.npmjs.org/unicode-property-aliases-ecmascript/-/unicode-property-aliases-ecmascript-2.1.0.tgz",
      "integrity": "sha512-6t3foTQI9qne+OZoVQB/8x8rk2k1eVy1gRXhV3oFQ5T6R1dqQ1xtin3XqSlx3+ATBkliTaR/hHyJBm+LVPNM8w==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=4"
      }
    },
    "node_modules/unified": {
      "version": "11.0.5",
      "resolved": "https://registry.npmjs.org/unified/-/unified-11.0.5.tgz",
      "integrity": "sha512-xKvGhPWw3k84Qjh8bI3ZeJjqnyadK+GEFtazSfZv/rKeTkTjOJho6mFqh2SM96iIcZokxiOpg78GazTSg8+KHA==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "bail": "^2.0.0",
        "devlop": "^1.0.0",
        "extend": "^3.0.0",
        "is-plain-obj": "^4.0.0",
        "trough": "^2.0.0",
        "vfile": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-is": {
      "version": "6.0.0",
      "resolved": "https://registry.npmjs.org/unist-util-is/-/unist-util-is-6.0.0.tgz",
      "integrity": "sha512-2qCTHimwdxLfz+YzdGfkqNlH0tLi9xjTnHddPmJwtIG9MGsdbutfTc4P+haPD7l7Cjxf/WZj+we5qfVPvvxfYw==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-position": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/unist-util-position/-/unist-util-position-5.0.0.tgz",
      "integrity": "sha512-fucsC7HjXvkB5R3kTCO7kUjRdrS0BJt3M/FPxmHMBOm8JQi2BsHAHFsy27E0EolP8rp0NzXsJ+jNPyDWvOJZPA==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-stringify-position": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/unist-util-stringify-position/-/unist-util-stringify-position-4.0.0.tgz",
      "integrity": "sha512-0ASV06AAoKCDkS2+xw5RXJywruurpbC4JZSm7nr7MOt1ojAzvyyaO+UxZf18j8FCF6kmzCZKcAgN/yu2gm2XgQ==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-visit": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/unist-util-visit/-/unist-util-visit-5.0.0.tgz",
      "integrity": "sha512-MR04uvD+07cwl/yhVuVWAtw+3GOR/knlL55Nd/wAdblk27GCVt3lqpTivy/tkJcZoNPzTwS1Y+KMojlLDhoTzg==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "unist-util-is": "^6.0.0",
        "unist-util-visit-parents": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/unist-util-visit-parents": {
      "version": "6.0.1",
      "resolved": "https://registry.npmjs.org/unist-util-visit-parents/-/unist-util-visit-parents-6.0.1.tgz",
      "integrity": "sha512-L/PqWzfTP9lzzEa6CKs0k2nARxTdZduw3zyh8d2NVBnsyvHjSX4TWse388YrrQKbvI8w20fGjGlhgT96WwKykw==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "unist-util-is": "^6.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/universalify": {
      "version": "0.2.0",
      "resolved": "https://registry.npmjs.org/universalify/-/universalify-0.2.0.tgz",
      "integrity": "sha512-CJ1QgKmNg3CwvAv/kOFmtnEN05f0D/cn9QntgNOQlQF9dgvVTHj3t+8JPdjqawCHk7V/KA+fbUqzZ9XWhcqPUg==",
      "devOptional": true,
      "license": "MIT",
      "engines": {
        "node": ">= 4.0.0"
      }
    },
    "node_modules/update-browserslist-db": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/update-browserslist-db/-/update-browserslist-db-1.1.3.tgz",
      "integrity": "sha512-UxhIZQ+QInVdunkDAaiazvvT/+fXL5Osr0JZlJulepYu6Jd7qJtDZjlur0emRlT71EN3ScPoE7gvsuIKKNavKw==",
      "dev": true,
      "funding": [
        {
          "type": "opencollective",
          "url": "https://opencollective.com/browserslist"
        },
        {
          "type": "tidelift",
          "url": "https://tidelift.com/funding/github/npm/browserslist"
        },
        {
          "type": "github",
          "url": "https://github.com/sponsors/ai"
        }
      ],
      "license": "MIT",
      "dependencies": {
        "escalade": "^3.2.0",
        "picocolors": "^1.1.1"
      },
      "bin": {
        "update-browserslist-db": "cli.js"
      },
      "peerDependencies": {
        "browserslist": ">= 4.21.0"
      }
    },
    "node_modules/uri-js": {
      "version": "4.4.1",
      "resolved": "https://registry.npmjs.org/uri-js/-/uri-js-4.4.1.tgz",
      "integrity": "sha512-7rKUyy33Q1yc98pQ1DAmLtwX109F7TIfWlW1Ydo8Wl1ii1SeHieeh0HHfPeL2fMXK6z0s8ecKs9frCuLJvndBg==",
      "dev": true,
      "license": "BSD-2-Clause",
      "dependencies": {
        "punycode": "^2.1.0"
      }
    },
    "node_modules/url-parse": {
      "version": "1.5.10",
      "resolved": "https://registry.npmjs.org/url-parse/-/url-parse-1.5.10.tgz",
      "integrity": "sha512-WypcfiRhfeUP9vvF0j6rw0J3hrWrw6iZv3+22h6iRMJ/8z1Tj6XfLP4DsUix5MhMPnXpiHDoKyoZ/bdCkwBCiQ==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "querystringify": "^2.1.1",
        "requires-port": "^1.0.0"
      }
    },
    "node_modules/use-callback-ref": {
      "version": "1.3.3",
      "resolved": "https://registry.npmjs.org/use-callback-ref/-/use-callback-ref-1.3.3.tgz",
      "integrity": "sha512-jQL3lRnocaFtu3V00JToYz/4QkNWswxijDaCVNZRiRTO3HQDLsdu1ZtmIUvV4yPp+rvWm5j0y0TG/S61cuijTg==",
      "license": "MIT",
      "dependencies": {
        "tslib": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/use-sidecar": {
      "version": "1.1.3",
      "resolved": "https://registry.npmjs.org/use-sidecar/-/use-sidecar-1.1.3.tgz",
      "integrity": "sha512-Fedw0aZvkhynoPYlA5WXrMCAMm+nSWdZt6lzJQ7Ok8S6Q+VsHmHpRWndVRJ8Be0ZbkfPc5LRYH+5XrzXcEeLRQ==",
      "license": "MIT",
      "dependencies": {
        "detect-node-es": "^1.1.0",
        "tslib": "^2.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "peerDependencies": {
        "@types/react": "*",
        "react": "^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0 || ^19.0.0-rc"
      },
      "peerDependenciesMeta": {
        "@types/react": {
          "optional": true
        }
      }
    },
    "node_modules/util-deprecate": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/util-deprecate/-/util-deprecate-1.0.2.tgz",
      "integrity": "sha512-EPD5q1uXyFxJpCrLnCc1nHnq3gOa6DZBocAIiI2TaSCA7VCJ1UJDMagCzIkXNsUYfD1daK//LTEQ8xiIbrHtcw==",
      "license": "MIT"
    },
    "node_modules/uuid": {
      "version": "9.0.1",
      "resolved": "https://registry.npmjs.org/uuid/-/uuid-9.0.1.tgz",
      "integrity": "sha512-b+1eJOlsR9K8HJpow9Ok3fiWOWSIcIzXodvv0rQjVoOVNpWMpxf1wZNpt4y9h10odCNrqnYp1OBzRktckBe3sA==",
      "funding": [
        "https://github.com/sponsors/broofa",
        "https://github.com/sponsors/ctavan"
      ],
      "license": "MIT",
      "bin": {
        "uuid": "dist/bin/uuid"
      }
    },
    "node_modules/v8-to-istanbul": {
      "version": "9.3.0",
      "resolved": "https://registry.npmjs.org/v8-to-istanbul/-/v8-to-istanbul-9.3.0.tgz",
      "integrity": "sha512-kiGUalWN+rgBJ/1OHZsBtU4rXZOfj/7rKQxULKlIzwzQSvMJUUNgPwJEEh7gU6xEVxC0ahoOBvN2YI8GH6FNgA==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "@jridgewell/trace-mapping": "^0.3.12",
        "@types/istanbul-lib-coverage": "^2.0.1",
        "convert-source-map": "^2.0.0"
      },
      "engines": {
        "node": ">=10.12.0"
      }
    },
    "node_modules/vfile": {
      "version": "6.0.3",
      "resolved": "https://registry.npmjs.org/vfile/-/vfile-6.0.3.tgz",
      "integrity": "sha512-KzIbH/9tXat2u30jf+smMwFCsno4wHVdNmzFyL+T/L3UGqqk6JKfVqOFOZEpZSHADH1k40ab6NUIXZq422ov3Q==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "vfile-message": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/vfile-message": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/vfile-message/-/vfile-message-4.0.2.tgz",
      "integrity": "sha512-jRDZ1IMLttGj41KcZvlrYAaI3CfqpLpfpf+Mfig13viT6NKvRzWZ+lXz0Y5D60w6uJIBAOGq9mSHf0gktF0duw==",
      "license": "MIT",
      "dependencies": {
        "@types/unist": "^3.0.0",
        "unist-util-stringify-position": "^4.0.0"
      },
      "funding": {
        "type": "opencollective",
        "url": "https://opencollective.com/unified"
      }
    },
    "node_modules/victory-vendor": {
      "version": "36.9.2",
      "resolved": "https://registry.npmjs.org/victory-vendor/-/victory-vendor-36.9.2.tgz",
      "integrity": "sha512-PnpQQMuxlwYdocC8fIJqVXvkeViHYzotI+NJrCuav0ZYFoq912ZHBk3mCeuj+5/VpodOjPe1z0Fk2ihgzlXqjQ==",
      "license": "MIT AND ISC",
      "dependencies": {
        "@types/d3-array": "^3.0.3",
        "@types/d3-ease": "^3.0.0",
        "@types/d3-interpolate": "^3.0.1",
        "@types/d3-scale": "^4.0.2",
        "@types/d3-shape": "^3.1.0",
        "@types/d3-time": "^3.0.0",
        "@types/d3-timer": "^3.0.0",
        "d3-array": "^3.1.6",
        "d3-ease": "^3.0.1",
        "d3-interpolate": "^3.0.1",
        "d3-scale": "^4.0.2",
        "d3-shape": "^3.1.0",
        "d3-time": "^3.0.0",
        "d3-timer": "^3.0.1"
      }
    },
    "node_modules/w3c-xmlserializer": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/w3c-xmlserializer/-/w3c-xmlserializer-4.0.0.tgz",
      "integrity": "sha512-d+BFHzbiCx6zGfz0HyQ6Rg69w9k19nviJspaj4yNscGjrHu94sVP+aRm75yEbCh+r2/yR+7q6hux9LVtbuTGBw==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "xml-name-validator": "^4.0.0"
      },
      "engines": {
        "node": ">=14"
      }
    },
    "node_modules/walker": {
      "version": "1.0.8",
      "resolved": "https://registry.npmjs.org/walker/-/walker-1.0.8.tgz",
      "integrity": "sha512-ts/8E8l5b7kY0vlWLewOkDXMmPdLcVV4GmOQLyxuSswIJsweeFZtAsMF7k1Nszz+TYBQrlYRmzOnr398y1JemQ==",
      "dev": true,
      "license": "Apache-2.0",
      "dependencies": {
        "makeerror": "1.0.12"
      }
    },
    "node_modules/web-streams-polyfill": {
      "version": "3.3.3",
      "resolved": "https://registry.npmjs.org/web-streams-polyfill/-/web-streams-polyfill-3.3.3.tgz",
      "integrity": "sha512-d2JWLCivmZYTSIoge9MsgFCZrt571BikcWGYkjC1khllbTeDlGqZ2D8vD8E/lJa8WGWbb7Plm8/XJYV7IJHZZw==",
      "license": "MIT",
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/webidl-conversions": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/webidl-conversions/-/webidl-conversions-3.0.1.tgz",
      "integrity": "sha512-2JAn3z8AR6rjK8Sm8orRC0h/bcl/DqL7tRPdGZ4I1CjdF+EaMLmYxBHyXuKL849eucPFhvBoxMsflfOb8kxaeQ==",
      "license": "BSD-2-Clause"
    },
    "node_modules/whatwg-encoding": {
      "version": "2.0.0",
      "resolved": "https://registry.npmjs.org/whatwg-encoding/-/whatwg-encoding-2.0.0.tgz",
      "integrity": "sha512-p41ogyeMUrw3jWclHWTQg1k05DSVXPLcVxRTYsXUk+ZooOCZLcoYgPZ/HL/D/N+uQPOtcp1me1WhBEaX02mhWg==",
      "devOptional": true,
      "license": "MIT",
      "dependencies": {
        "iconv-lite": "0.6.3"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/whatwg-mimetype": {
      "version": "3.0.0",
      "resolved": "https://registry.npmjs.org/whatwg-mimetype/-/whatwg-mimetype-3.0.0.tgz",
      "integrity": "sha512-nt+N2dzIutVRxARx1nghPKGv1xHikU7HKdfafKkLNLindmPU/ch3U31NOCGGA/dmPcmb1VlofO0vnKAcsm0o/Q==",
      "devOptional": true,
      "license": "MIT",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/whatwg-url": {
      "version": "5.0.0",
      "resolved": "https://registry.npmjs.org/whatwg-url/-/whatwg-url-5.0.0.tgz",
      "integrity": "sha512-saE57nupxk6v3HY35+jzBwYa0rKSy0XR8JSxZPwgLr7ys0IBzhGviA1/TUGJLmSVqs8pb9AnvICXEuOHLprYTw==",
      "license": "MIT",
      "dependencies": {
        "tr46": "~0.0.3",
        "webidl-conversions": "^3.0.0"
      }
    },
    "node_modules/which": {
      "version": "2.0.2",
      "resolved": "https://registry.npmjs.org/which/-/which-2.0.2.tgz",
      "integrity": "sha512-BLI3Tl1TW3Pvl70l3yq3Y64i+awpwXqsGBYWkkqMtnbXgrMD+yj7rhW0kuEDxzJaYXGjEW5ogapKNMEKNMjibA==",
      "license": "ISC",
      "dependencies": {
        "isexe": "^2.0.0"
      },
      "bin": {
        "node-which": "bin/node-which"
      },
      "engines": {
        "node": ">= 8"
      }
    },
    "node_modules/which-boxed-primitive": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/which-boxed-primitive/-/which-boxed-primitive-1.1.1.tgz",
      "integrity": "sha512-TbX3mj8n0odCBFVlY8AxkqcHASw3L60jIuF8jFP78az3C2YhmGvqbHBpAjTRH2/xqYunrJ9g1jSyjCjpoWzIAA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-bigint": "^1.1.0",
        "is-boolean-object": "^1.2.1",
        "is-number-object": "^1.1.1",
        "is-string": "^1.1.1",
        "is-symbol": "^1.1.1"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/which-builtin-type": {
      "version": "1.2.1",
      "resolved": "https://registry.npmjs.org/which-builtin-type/-/which-builtin-type-1.2.1.tgz",
      "integrity": "sha512-6iBczoX+kDQ7a3+YJBnh3T+KZRxM/iYNPXicqk66/Qfm1b93iu+yOImkg0zHbj5LNOcNv1TEADiZ0xa34B4q6Q==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "call-bound": "^1.0.2",
        "function.prototype.name": "^1.1.6",
        "has-tostringtag": "^1.0.2",
        "is-async-function": "^2.0.0",
        "is-date-object": "^1.1.0",
        "is-finalizationregistry": "^1.1.0",
        "is-generator-function": "^1.0.10",
        "is-regex": "^1.2.1",
        "is-weakref": "^1.0.2",
        "isarray": "^2.0.5",
        "which-boxed-primitive": "^1.1.0",
        "which-collection": "^1.0.2",
        "which-typed-array": "^1.1.16"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/which-collection": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/which-collection/-/which-collection-1.0.2.tgz",
      "integrity": "sha512-K4jVyjnBdgvc86Y6BkaLZEN933SwYOuBFkdmBu9ZfkcAbdVbpITnDmjvZ/aQjRXQrv5EPkTnD1s39GiiqbngCw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "is-map": "^2.0.3",
        "is-set": "^2.0.3",
        "is-weakmap": "^2.0.2",
        "is-weakset": "^2.0.3"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/which-typed-array": {
      "version": "1.1.19",
      "resolved": "https://registry.npmjs.org/which-typed-array/-/which-typed-array-1.1.19.tgz",
      "integrity": "sha512-rEvr90Bck4WZt9HHFC4DJMsjvu7x+r6bImz0/BrbWb7A2djJ8hnZMrWnHo9F8ssv0OMErasDhftrfROTyqSDrw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "available-typed-arrays": "^1.0.7",
        "call-bind": "^1.0.8",
        "call-bound": "^1.0.4",
        "for-each": "^0.3.5",
        "get-proto": "^1.0.1",
        "gopd": "^1.2.0",
        "has-tostringtag": "^1.0.2"
      },
      "engines": {
        "node": ">= 0.4"
      },
      "funding": {
        "url": "https://github.com/sponsors/ljharb"
      }
    },
    "node_modules/word-wrap": {
      "version": "1.2.5",
      "resolved": "https://registry.npmjs.org/word-wrap/-/word-wrap-1.2.5.tgz",
      "integrity": "sha512-BN22B5eaMMI9UMtjrGd5g5eCYPpCPDUy0FJXbYsaT5zYxjFOckS53SQDE3pWkVoWpHXVb3BrYcEN4Twa55B5cA==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=0.10.0"
      }
    },
    "node_modules/wrap-ansi": {
      "version": "8.1.0",
      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-8.1.0.tgz",
      "integrity": "sha512-si7QWI6zUMq56bESFvagtmzMdGOtoxfR+Sez11Mobfc7tm+VkUckk9bW2UeffTGVUbOksxmSw0AA2gs8g71NCQ==",
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^6.1.0",
        "string-width": "^5.0.1",
        "strip-ansi": "^7.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
      }
    },
    "node_modules/wrap-ansi-cjs": {
      "name": "wrap-ansi",
      "version": "7.0.0",
      "resolved": "https://registry.npmjs.org/wrap-ansi/-/wrap-ansi-7.0.0.tgz",
      "integrity": "sha512-YVGIj2kamLSTxw6NsZjoBxfSwsn0ycdesmc4p+Q21c5zPuZ1pl+NfxVdxPtdHvmNVOQ6XSYG4AUtyt/Fi7D16Q==",
      "license": "MIT",
      "dependencies": {
        "ansi-styles": "^4.0.0",
        "string-width": "^4.1.0",
        "strip-ansi": "^6.0.0"
      },
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/chalk/wrap-ansi?sponsor=1"
      }
    },
    "node_modules/wrap-ansi-cjs/node_modules/emoji-regex": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
      "license": "MIT"
    },
    "node_modules/wrap-ansi-cjs/node_modules/string-width": {
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
      "license": "MIT",
      "dependencies": {
        "emoji-regex": "^8.0.0",
        "is-fullwidth-code-point": "^3.0.0",
        "strip-ansi": "^6.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/wrap-ansi/node_modules/ansi-regex": {
      "version": "6.1.0",
      "resolved": "https://registry.npmjs.org/ansi-regex/-/ansi-regex-6.1.0.tgz",
      "integrity": "sha512-7HSX4QQb4CspciLpVFwyRe79O3xsIZDDLER21kERQ71oaPodF8jL725AgJMFAYbooIqolJoRLuM81SpeUkpkvA==",
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-regex?sponsor=1"
      }
    },
    "node_modules/wrap-ansi/node_modules/ansi-styles": {
      "version": "6.2.1",
      "resolved": "https://registry.npmjs.org/ansi-styles/-/ansi-styles-6.2.1.tgz",
      "integrity": "sha512-bN798gFfQX+viw3R7yrGWRqnrN2oRkEkUjjl4JNn4E8GxxbjtG3FbrEIIY3l8/hrwUwIeCZvi4QuOTP4MErVug==",
      "license": "MIT",
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/ansi-styles?sponsor=1"
      }
    },
    "node_modules/wrap-ansi/node_modules/strip-ansi": {
      "version": "7.1.0",
      "resolved": "https://registry.npmjs.org/strip-ansi/-/strip-ansi-7.1.0.tgz",
      "integrity": "sha512-iq6eVVI64nQQTRYq2KtEg2d2uU7LElhTJwsH4YzIHZshxlgZms/wIc4VoDQTlG/IvVIrBKG06CrZnp0qv7hkcQ==",
      "license": "MIT",
      "dependencies": {
        "ansi-regex": "^6.0.1"
      },
      "engines": {
        "node": ">=12"
      },
      "funding": {
        "url": "https://github.com/chalk/strip-ansi?sponsor=1"
      }
    },
    "node_modules/wrappy": {
      "version": "1.0.2",
      "resolved": "https://registry.npmjs.org/wrappy/-/wrappy-1.0.2.tgz",
      "integrity": "sha512-l4Sp/DRseor9wL6EvV2+TuQn63dMkPjZ/sp9XkghTEbV9KlPS1xUsZ3u7/IQO4wxtcFB4bgpQPRcR3QCvezPcQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/write-file-atomic": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/write-file-atomic/-/write-file-atomic-4.0.2.tgz",
      "integrity": "sha512-7KxauUdBmSdWnmpaGFg+ppNjKF8uNLry8LyzjauQDOVONfFLNKrKvQOxZ/VuTIcS/gge/YNahf5RIIQWTSarlg==",
      "dev": true,
      "license": "ISC",
      "dependencies": {
        "imurmurhash": "^0.1.4",
        "signal-exit": "^3.0.7"
      },
      "engines": {
        "node": "^12.13.0 || ^14.15.0 || >=16.0.0"
      }
    },
    "node_modules/write-file-atomic/node_modules/signal-exit": {
      "version": "3.0.7",
      "resolved": "https://registry.npmjs.org/signal-exit/-/signal-exit-3.0.7.tgz",
      "integrity": "sha512-wnD2ZE+l+SPC/uoS0vXeE9L1+0wuaMqKlfz9AMUo38JsyLSBWSFcHR1Rri62LZc12vLr1gb3jl7iwQhgwpAbGQ==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/ws": {
      "version": "8.18.1",
      "resolved": "https://registry.npmjs.org/ws/-/ws-8.18.1.tgz",
      "integrity": "sha512-RKW2aJZMXeMxVpnZ6bck+RswznaxmzdULiBr6KY7XkTnW8uvt0iT9H5DkHUChXrc+uurzwa0rVI16n/Xzjdz1w==",
      "devOptional": true,
      "license": "MIT",
      "engines": {
        "node": ">=10.0.0"
      },
      "peerDependencies": {
        "bufferutil": "^4.0.1",
        "utf-8-validate": ">=5.0.2"
      },
      "peerDependenciesMeta": {
        "bufferutil": {
          "optional": true
        },
        "utf-8-validate": {
          "optional": true
        }
      }
    },
    "node_modules/xml-name-validator": {
      "version": "4.0.0",
      "resolved": "https://registry.npmjs.org/xml-name-validator/-/xml-name-validator-4.0.0.tgz",
      "integrity": "sha512-ICP2e+jsHvAj2E2lIHxa5tjXRlKDJo4IdvPvCXbXQGdzSfmSpNVyIKMvoZHjDY9DP0zV17iI85o90vRFXNccRw==",
      "devOptional": true,
      "license": "Apache-2.0",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/xmlchars": {
      "version": "2.2.0",
      "resolved": "https://registry.npmjs.org/xmlchars/-/xmlchars-2.2.0.tgz",
      "integrity": "sha512-JZnDKK8B0RCDw84FNdDAIpZK+JuJw+s7Lz8nksI7SIuU3UXJJslUthsi+uWBUYOwPFwW7W7PRLRfUKpxjtjFCw==",
      "devOptional": true,
      "license": "MIT"
    },
    "node_modules/xtend": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/xtend/-/xtend-4.0.2.tgz",
      "integrity": "sha512-LKYU1iAXJXUgAXn9URjiu+MWhyUXHsvfp7mcuYm9dSUKK0/CjtrUwFAxD82/mCWbtLsGjFIad0wIsod4zrTAEQ==",
      "license": "MIT",
      "engines": {
        "node": ">=0.4"
      }
    },
    "node_modules/y18n": {
      "version": "5.0.8",
      "resolved": "https://registry.npmjs.org/y18n/-/y18n-5.0.8.tgz",
      "integrity": "sha512-0pfFzegeDWJHJIAmTLRP2DwHjdF5s7jo9tuztdQxAhINCdvS+3nGINqPd00AphqJR/0LhANUS6/+7SCb98YOfA==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": ">=10"
      }
    },
    "node_modules/yallist": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/yallist/-/yallist-3.1.1.tgz",
      "integrity": "sha512-a4UGQaWPH59mOXUYnAG2ewncQS4i4F43Tv3JoAM+s2VDAmS9NsK8GpDMLrCHPksFT7h3K6TOoUNn2pb7RoXx4g==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/yaml": {
      "version": "2.7.0",
      "resolved": "https://registry.npmjs.org/yaml/-/yaml-2.7.0.tgz",
      "integrity": "sha512-+hSoy/QHluxmC9kCIJyL/uyFmLmc+e5CFR5Wa+bpIhIj85LVb9ZH2nVnqrHoSvKogwODv0ClqZkmiSSaIH5LTA==",
      "license": "ISC",
      "bin": {
        "yaml": "bin.mjs"
      },
      "engines": {
        "node": ">= 14"
      }
    },
    "node_modules/yargs": {
      "version": "17.7.2",
      "resolved": "https://registry.npmjs.org/yargs/-/yargs-17.7.2.tgz",
      "integrity": "sha512-7dSzzRQ++CKnNI/krKnYRV7JKKPUXMEh61soaHKg9mrWEhzFWhFnxPxGl+69cD1Ou63C13NUPCnmIcrvqCuM6w==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "cliui": "^8.0.1",
        "escalade": "^3.1.1",
        "get-caller-file": "^2.0.5",
        "require-directory": "^2.1.1",
        "string-width": "^4.2.3",
        "y18n": "^5.0.5",
        "yargs-parser": "^21.1.1"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/yargs-parser": {
      "version": "21.1.1",
      "resolved": "https://registry.npmjs.org/yargs-parser/-/yargs-parser-21.1.1.tgz",
      "integrity": "sha512-tVpsJW7DdjecAiFpbIB1e3qxIQsE6NoPc5/eTdrbbIC4h0LVsWhnoa3g+m2HclBIujHzsxZ4VJVA+GUuc2/LBw==",
      "dev": true,
      "license": "ISC",
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/yargs/node_modules/emoji-regex": {
      "version": "8.0.0",
      "resolved": "https://registry.npmjs.org/emoji-regex/-/emoji-regex-8.0.0.tgz",
      "integrity": "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/yargs/node_modules/string-width": {
      "version": "4.2.3",
      "resolved": "https://registry.npmjs.org/string-width/-/string-width-4.2.3.tgz",
      "integrity": "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "emoji-regex": "^8.0.0",
        "is-fullwidth-code-point": "^3.0.0",
        "strip-ansi": "^6.0.1"
      },
      "engines": {
        "node": ">=8"
      }
    },
    "node_modules/yocto-queue": {
      "version": "0.1.0",
      "resolved": "https://registry.npmjs.org/yocto-queue/-/yocto-queue-0.1.0.tgz",
      "integrity": "sha512-rVksvsnNCdJ/ohGc6xgPwyN8eheCxsiLM8mxuE/t/mOVqJewPuO1miLpTHQiRgTKCLexL4MeAFVagts7HmNZ2Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=10"
      },
      "funding": {
        "url": "https://github.com/sponsors/sindresorhus"
      }
    },
    "node_modules/zod": {
      "version": "3.24.2",
      "resolved": "https://registry.npmjs.org/zod/-/zod-3.24.2.tgz",
      "integrity": "sha512-lY7CDW43ECgW9u1TcT3IoXHflywfVqDYze4waEz812jR/bZ8FHDsl7pFQoSZTz5N+2NqRXs8GBwnAwo3ZNxqhQ==",
      "license": "MIT",
      "funding": {
        "url": "https://github.com/sponsors/colinhacks"
      }
    },
    "node_modules/zod-to-json-schema": {
      "version": "3.24.3",
      "resolved": "https://registry.npmjs.org/zod-to-json-schema/-/zod-to-json-schema-3.24.3.tgz",
      "integrity": "sha512-HIAfWdYIt1sssHfYZFCXp4rU1w2r8hVVXYIlmoa0r0gABLs5di3RCqPU5DDROogVz1pAdYBaz7HK5n9pSUNs3A==",
      "license": "ISC",
      "peerDependencies": {
        "zod": "^3.24.1"
      }
    },
    "node_modules/zwitch": {
      "version": "2.0.4",
      "resolved": "https://registry.npmjs.org/zwitch/-/zwitch-2.0.4.tgz",
      "integrity": "sha512-bXE4cR/kVZhKZX/RjPEflHaKVhUVl85noU3v6b8apfQEc1x4A+zBxjZ4lN8LqGd6WZ3dl98pY4o717VFmoPp+A==",
      "license": "MIT",
      "funding": {
        "type": "github",
        "url": "https://github.com/sponsors/wooorm"
      }
    }
  }
}
</file>
```

#### package\.json
*Size: 1.8 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/package.json">
{
  "name": "fdas-nextjs",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "test": "jest"
  },
  "dependencies": {
    "@anthropic-ai/sdk": "^0.16.1",
    "@radix-ui/react-avatar": "^1.0.4",
    "@radix-ui/react-collapsible": "^1.1.3",
    "@radix-ui/react-dialog": "^1.0.5",
    "@radix-ui/react-dropdown-menu": "^2.0.6",
    "@radix-ui/react-popover": "^1.0.7",
    "@radix-ui/react-select": "^2.0.0",
    "@radix-ui/react-slot": "^1.0.2",
    "@radix-ui/react-tabs": "^1.0.4",
    "@radix-ui/react-toast": "^1.1.5",
    "class-variance-authority": "^0.7.0",
    "clsx": "^2.1.0",
    "langchain": "^0.1.25",
    "langsmith": "^0.1.25",
    "lucide-react": "^0.359.0",
    "mdast-util-to-markdown": "^2.1.2",
    "next": "14.2.4",
    "pdfjs-dist": "^4.3.136",
    "react": "^18",
    "react-dom": "^18",
    "react-hook-form": "^7.51.1",
    "react-markdown": "^10.1.0",
    "react-pdf-highlighter": "^6.1.0",
    "react-syntax-highlighter": "^15.6.1",
    "recharts": "^2.15.1",
    "remark-gfm": "^4.0.1",
    "tailwind-merge": "^2.2.2",
    "tailwindcss-animate": "^1.0.7",
    "zod": "^3.22.4"
  },
  "devDependencies": {
    "@babel/core": "^7.26.10",
    "@babel/preset-env": "^7.26.9",
    "@babel/preset-react": "^7.26.3",
    "@babel/preset-typescript": "^7.27.0",
    "@testing-library/jest-dom": "^6.6.3",
    "@testing-library/react": "^16.2.0",
    "@types/jest": "^29.5.14",
    "@types/node": "^20",
    "@types/react": "^18",
    "@types/react-dom": "^18",
    "autoprefixer": "^10.0.1",
    "babel-jest": "^29.7.0",
    "eslint": "^8",
    "eslint-config-next": "14.2.4",
    "identity-obj-proxy": "^3.0.0",
    "jest": "^29.7.0",
    "jest-environment-jsdom": "^29.7.0",
    "postcss": "^8",
    "tailwindcss": "^3.3.0",
    "typescript": "^5"
  }
}
</file>
```

#### postcss\.config\.js
*Size: 83 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/postcss.config.js">
module.exports = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
}; 
</file>
```

#### src/app/dashboard/layout\.tsx
*Size: 323 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/app/dashboard/layout.tsx">
import Header from '@/components/layout/Header'

export default function DashboardLayout({
  children,
}: Readonly<{
  children: React.ReactNode
}>) {
  return (
    <div className="min-h-screen flex flex-col">
      <Header />
      <main className="flex-1 flex flex-col">
        {children}
      </main>
    </div>
  )
}
</file>
```

#### src/app/dashboard/page\.tsx
*Size: 7.8 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/app/dashboard/page.tsx">
'use client'

import Link from 'next/link'
import { useState } from 'react'
import { BarChart2, Calendar, FileText, Plus } from 'lucide-react'
import { UploadForm } from '../../components/UploadForm'
import { DocumentList } from '../../components/DocumentList'
import { ProcessedDocument } from '@/types'

export default function Dashboard() {
  // State to trigger document list refresh when uploading a new document
  const [refreshTrigger, setRefreshTrigger] = useState(0);
  const [lastUploadedDocument, setLastUploadedDocument] = useState<ProcessedDocument | null>(null);

  // Mock data for recent analyses (would come from API in production)
  const [analyses, setAnalyses] = useState([
    { id: '1', name: 'Revenue Trend Analysis', date: '2023-12-30', metrics: ['Revenue', 'COGS', 'Gross Margin'] },
    { id: '2', name: 'Liquidity Ratio Analysis', date: '2023-12-20', metrics: ['Current Ratio', 'Quick Ratio', 'Cash Ratio'] },
  ]);

  // Handle successful document upload
  const handleUploadSuccess = (document: ProcessedDocument) => {
    // Update the last uploaded document state
    setLastUploadedDocument(document);
    
    // Trigger a refresh of the document list
    setRefreshTrigger(prev => prev + 1);
  };

  // Handle selection of a document
  const handleSelectDocument = (documentId: string) => {
    // Navigate to the document viewer or workspace page
    window.location.href = `/workspace?document=${documentId}`;
  };

  // Handle analyze action for a document
  const handleAnalyzeDocument = (documentId: string) => {
    window.location.href = `/workspace?document=${documentId}&analyze=true`;
  };

  // Handle document deletion
  const handleDocumentDelete = (documentId: string) => {
    // The DocumentList component handles the deletion API call
    // Here we can add any additional logic if needed
    console.log(`Document ${documentId} has been deleted`);
  };

  return (
    <div className="container mx-auto px-4 py-8">
      <div className="flex justify-between items-center mb-8">
        <h1 className="text-2xl font-bold text-gray-900">Dashboard</h1>
        <Link 
          href="/workspace"
          className="bg-indigo-600 hover:bg-indigo-700 text-white px-4 py-2 rounded-md text-sm font-medium flex items-center transition-colors"
        >
          <Plus className="h-4 w-4 mr-2" />
          New Analysis
        </Link>
      </div>

      {/* Stats Overview */}
      <div className="grid grid-cols-1 md:grid-cols-3 gap-6 mb-8">
        <div className="bg-white p-6 rounded-lg shadow-sm border border-gray-200">
          <div className="flex items-center">
            <div className="bg-indigo-100 p-3 rounded-full mr-4">
              <FileText className="h-6 w-6 text-indigo-600" />
            </div>
            <div>
              <p className="text-sm text-gray-500">Documents</p>
              <p className="text-2xl font-semibold" id="document-count">-</p>
            </div>
          </div>
        </div>
        <div className="bg-white p-6 rounded-lg shadow-sm border border-gray-200">
          <div className="flex items-center">
            <div className="bg-indigo-100 p-3 rounded-full mr-4">
              <BarChart2 className="h-6 w-6 text-indigo-600" />
            </div>
            <div>
              <p className="text-sm text-gray-500">Analyses</p>
              <p className="text-2xl font-semibold">{analyses.length}</p>
            </div>
          </div>
        </div>
        <div className="bg-white p-6 rounded-lg shadow-sm border border-gray-200">
          <div className="flex items-center">
            <div className="bg-indigo-100 p-3 rounded-full mr-4">
              <Calendar className="h-6 w-6 text-indigo-600" />
            </div>
            <div>
              <p className="text-sm text-gray-500">Last Activity</p>
              <p className="text-2xl font-semibold">Today</p>
            </div>
          </div>
        </div>
      </div>

      {/* Main Content Area */}
      <div className="grid grid-cols-1 md:grid-cols-3 gap-6 mb-10">
        {/* Documents List */}
        <div className="md:col-span-2">
          <DocumentList 
            refreshTrigger={refreshTrigger}
            onSelectDocument={handleSelectDocument}
            onDelete={handleDocumentDelete}
            onAnalyze={handleAnalyzeDocument}
          />
        </div>
        
        {/* Upload Section */}
        <div className="space-y-4">
          <div className="bg-white p-6 rounded-lg shadow-sm border border-gray-200">
            <h2 className="text-lg font-semibold mb-4">Upload Document</h2>
            <UploadForm onUploadSuccess={handleUploadSuccess} />
            
            {lastUploadedDocument && (
              <div className="mt-4 p-3 bg-green-50 border border-green-200 rounded-md">
                <p className="text-sm text-green-800 font-medium">
                  Successfully uploaded: {lastUploadedDocument.metadata.filename}
                </p>
                <p className="text-xs text-green-600 mt-1">
                  {lastUploadedDocument.citations?.length || 0} citations extracted
                </p>
              </div>
            )}
            
            <div className="mt-6 pt-4 border-t border-gray-200">
              <h3 className="text-sm font-medium mb-2">Supported Formats</h3>
              <p className="text-sm text-gray-500">
                PDF documents containing financial statements, including:
                <ul className="list-disc pl-5 mt-1 space-y-1">
                  <li>Balance Sheets</li>
                  <li>Income Statements</li>
                  <li>Cash Flow Statements</li>
                  <li>Annual Reports</li>
                </ul>
              </p>
            </div>
          </div>
        </div>
      </div>

      {/* Recent Analyses Section */}
      <div>
        <div className="flex justify-between items-center mb-4">
          <h2 className="text-xl font-semibold text-gray-800">Recent Analyses</h2>
          <Link
            href="/workspace"
            className="text-indigo-600 hover:text-indigo-800 text-sm font-medium flex items-center"
          >
            View All
          </Link>
        </div>
        <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
          {analyses.map((analysis) => (
            <div key={analysis.id} className="bg-white p-6 rounded-lg shadow-sm border border-gray-200">
              <div className="flex justify-between items-start">
                <div>
                  <h3 className="text-lg font-semibold text-gray-900 mb-2">{analysis.name}</h3>
                  <p className="text-sm text-gray-500 mb-4">{new Date(analysis.date).toLocaleDateString()}</p>
                  <div className="flex flex-wrap gap-2">
                    {analysis.metrics.map((metric, index) => (
                      <span key={index} className="px-2 py-1 text-xs font-medium rounded-full bg-gray-100 text-gray-700">
                        {metric}
                      </span>
                    ))}
                  </div>
                </div>
                <div className="bg-indigo-100 p-2 rounded-full">
                  <BarChart2 className="h-6 w-6 text-indigo-600" />
                </div>
              </div>
              <div className="mt-6 flex justify-end">
                <Link 
                  href={`/workspace?analysis=${analysis.id}`}
                  className="text-indigo-600 hover:text-indigo-800 text-sm font-medium flex items-center"
                >
                  Open Analysis
                  <svg className="ml-1 h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                    <path strokeLinecap="round" strokeLinejoin="round" strokeWidth="2" d="M9 5l7 7-7 7"></path>
                  </svg>
                </Link>
              </div>
            </div>
          ))}
        </div>
      </div>
    </div>
  )
}
</file>
```

#### src/app/globals\.css
*Size: 5.8 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/app/globals.css">
@tailwind base;
@tailwind components;
@tailwind utilities;
 
@layer base {
  :root {
    --background: 0 0% 100%;
    --foreground: 222.2 84% 4.9%;
 
    --card: 0 0% 100%;
    --card-foreground: 222.2 84% 4.9%;
 
    --popover: 0 0% 100%;
    --popover-foreground: 222.2 84% 4.9%;
 
    --primary: 221.2 83.2% 53.3%;
    --primary-foreground: 210 40% 98%;
 
    --secondary: 210 40% 96.1%;
    --secondary-foreground: 222.2 47.4% 11.2%;
 
    --muted: 210 40% 96.1%;
    --muted-foreground: 215.4 16.3% 46.9%;
 
    --accent: 210 40% 96.1%;
    --accent-foreground: 222.2 47.4% 11.2%;
 
    --destructive: 0 84.2% 60.2%;
    --destructive-foreground: 210 40% 98%;
 
    --border: 214.3 31.8% 91.4%;
    --input: 214.3 31.8% 91.4%;
    --ring: 221.2 83.2% 53.3%;
 
    --radius: 0.5rem;

    /* Chart colors - needed for visualizations */
    --chart-1: 221.2 83.2% 53.3%;
    --chart-2: 15 100% 55%;
    --chart-3: 162 76.1% 46.5%;
    --chart-4: 291.1 91.1% 64.1%;
    --chart-5: 52.5 100% 50%;
    --chart-6: 245 58% 51%;
    --chart-7: 329.8 100% 56.3%;
    --chart-8: 194.7 100% 42.7%;
    --chart-up: 142.1 76.2% 36.3%;
    --chart-down: 0 84.2% 60.2%;
    --chart-neutral: 215.4 16.3% 46.9%;
  }
 
  .dark {
    --background: 222.2 84% 4.9%;
    --foreground: 210 40% 98%;
 
    --card: 222.2 84% 4.9%;
    --card-foreground: 210 40% 98%;
 
    --popover: 222.2 84% 4.9%;
    --popover-foreground: 210 40% 98%;
 
    --primary: 217.2 91.2% 59.8%;
    --primary-foreground: 222.2 47.4% 11.2%;
 
    --secondary: 217.2 32.6% 17.5%;
    --secondary-foreground: 210 40% 98%;
 
    --muted: 217.2 32.6% 17.5%;
    --muted-foreground: 215 20.2% 65.1%;
 
    --accent: 217.2 32.6% 17.5%;
    --accent-foreground: 210 40% 98%;
 
    --destructive: 0 62.8% 30.6%;
    --destructive-foreground: 210 40% 98%;
 
    --border: 217.2 32.6% 17.5%;
    --input: 217.2 32.6% 17.5%;
    --ring: 224.3 76.3% 48%;

    /* Chart colors - dark mode versions */
    --chart-1: 217.2 91.2% 59.8%;
    --chart-2: 20 90% 60%;
    --chart-3: 162 86% 55%;
    --chart-4: 291.1 96% 68%;
    --chart-5: 52.5 95% 58%;
    --chart-6: 245 70% 60%;
    --chart-7: 329.8 95% 62%;
    --chart-8: 194.7 95% 55%;
    --chart-up: 142.1 76.2% 45%;
    --chart-down: 0 84.2% 65%;
    --chart-neutral: 215 20.2% 65.1%;
  }
}
 
@layer base {
  * {
    @apply border-border;
  }
  body {
    @apply bg-background text-foreground;
  }
}

/* Chart component styles */
.chart-container {
  @apply w-full h-full mb-4 rounded-lg overflow-hidden p-2;
}

.chart-header {
  @apply mb-3;
}

.chart-title {
  @apply text-lg font-semibold;
}

.chart-description {
  @apply text-sm text-gray-500;
}

.chart-footer {
  @apply mt-2 text-xs text-gray-500 italic;
}

.recharts-responsive-container {
  @apply rounded-lg overflow-hidden;
}

.recharts-tooltip-wrapper {
  @apply !shadow-lg;
}

.recharts-default-tooltip {
  @apply !bg-white dark:!bg-gray-800 !border-gray-200 dark:!border-gray-600 !shadow-md !p-2;
}

/* Table component styles */
.data-table-container {
  @apply w-full overflow-hidden rounded-lg border border-gray-200 dark:border-gray-700;
}

.data-table {
  @apply w-full;
}

.data-table-header {
  @apply bg-gray-100 dark:bg-gray-800 text-left;
}

.data-table-header th {
  @apply px-4 py-2 font-medium text-gray-600 dark:text-gray-300;
}

.data-table-row {
  @apply border-b border-gray-200 dark:border-gray-700 hover:bg-gray-50 dark:hover:bg-gray-700;
}

.data-table-row:last-child {
  @apply border-b-0;
}

.data-table-cell {
  @apply px-4 py-2;
}

.data-table-footer {
  @apply text-xs text-gray-500 mt-2 italic;
}

/* PDF viewer styles */
.PdfHighlighter {
  @apply h-full w-full;
}

.Highlight {
  @apply cursor-pointer transition-colors;
}

.Highlight--ai {
  @apply bg-yellow-300 bg-opacity-40;
}

.Highlight--user {
  @apply bg-indigo-300 bg-opacity-40;
}

.Highlight__part {
  @apply transition-colors;
}

.Highlight--ai .Highlight__part {
  @apply bg-yellow-300 bg-opacity-40 hover:bg-yellow-400 hover:bg-opacity-50;
}

.Highlight--user .Highlight__part {
  @apply bg-indigo-300 bg-opacity-40 hover:bg-indigo-400 hover:bg-opacity-50;
}

.Highlight__popup {
  @apply absolute bg-white shadow-lg p-3 rounded-md border border-gray-200 max-w-xs z-50;
}

.Highlight__popup-comment {
  @apply text-sm;
}

.Highlight__popup-buttons {
  @apply flex justify-end mt-2 gap-2;
}

/* Typing indicator */
.typing-indicator {
  @apply flex items-center space-x-1;
}

.typing-indicator span {
  @apply bg-gray-400 rounded-full h-2 w-2 animate-pulse;
}

.typing-indicator span:nth-child(1) {
  animation-delay: 0ms;
}

.typing-indicator span:nth-child(2) {
  animation-delay: 200ms;
}

.typing-indicator span:nth-child(3) {
  animation-delay: 400ms;
}

/* Custom scrollbar */
::-webkit-scrollbar {
  @apply w-2 h-2;
}

::-webkit-scrollbar-track {
  @apply bg-gray-100 rounded-full;
}

::-webkit-scrollbar-thumb {
  @apply bg-gray-300 rounded-full hover:bg-gray-400 transition-colors;
}

/* Citation styles */
.citation-link {
  @apply inline-flex items-center px-1 py-0.5 rounded bg-yellow-200 text-yellow-800 hover:bg-yellow-300 
  hover:text-yellow-900 transition-colors cursor-pointer text-sm;
}

.citation-icon {
  @apply ml-0.5 h-3 w-3 shrink-0;
}

/* Analysis block styles */
.analysis-block {
  @apply bg-white rounded-lg shadow-sm border border-gray-200 mb-6 overflow-hidden;
}

.analysis-block-header {
  @apply px-4 py-3 border-b border-gray-200 flex justify-between items-center;
}

.analysis-block-content {
  @apply p-4;
}

.analysis-insight {
  @apply p-3 rounded-md mb-2;
}

.analysis-insight-high {
  @apply bg-blue-50 border-l-4 border-blue-500;
}

.analysis-insight-medium {
  @apply bg-indigo-50 border-l-4 border-indigo-400;
}

.analysis-insight-low {
  @apply bg-gray-50 border-l-4 border-gray-300;
}

.trend-indicator-up {
  @apply text-green-600;
}

.trend-indicator-down {
  @apply text-red-600;
}

.trend-indicator-stable {
  @apply text-gray-600;
}
</file>
```

#### src/app/layout\.tsx
*Size: 523 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/app/layout.tsx">
import type { Metadata } from 'next'
import { Inter } from 'next/font/google'
import './globals.css'

const inter = Inter({ subsets: ['latin'] })

export const metadata: Metadata = {
  title: 'Financial Document Analysis System',
  description: 'AI-powered application for analyzing financial PDFs',
}

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode
}>) {
  return (
    <html lang="en">
      <body className={inter.className}>
        {children}
      </body>
    </html>
  )
}
</file>
```

#### src/app/page\.tsx
*Size: 5.1 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/app/page.tsx">
import Link from 'next/link'
import { BarChart3, FileUp, FileSearch, Zap } from 'lucide-react'

export default function Home() {
  return (
    <main className="min-h-screen bg-gradient-to-b from-indigo-50 to-white">
      <div className="container mx-auto px-4 py-12">
        {/* Header */}
        <header className="text-center mb-16">
          <h1 className="text-4xl font-bold text-indigo-700 mb-4">
            Financial Document Analysis System
          </h1>
          <p className="text-xl text-gray-600 max-w-3xl mx-auto">
            AI-powered application that analyzes financial PDFs using an interactive chatbot 
            and advanced data visualization.
          </p>
        </header>

        {/* Main Features */}
        <div className="grid grid-cols-1 md:grid-cols-3 gap-8 mb-16">
          <div className="bg-white p-8 rounded-xl shadow-md hover:shadow-lg transition-shadow">
            <div className="flex items-center mb-4">
              <div className="bg-indigo-100 p-3 rounded-full mr-4">
                <FileUp className="h-6 w-6 text-indigo-600" />
              </div>
              <h2 className="text-xl font-semibold">Document Processing</h2>
            </div>
            <p className="text-gray-600 mb-4">
              Upload financial documents to extract structured data, tables, and citations using Claude API technology.
            </p>
            <ul className="space-y-2 text-gray-700">
              <li className="flex items-center">
                <Zap className="h-4 w-4 text-indigo-500 mr-2" />
                Intelligent PDF processing
              </li>
              <li className="flex items-center">
                <Zap className="h-4 w-4 text-indigo-500 mr-2" />
                Citation extraction and linking
              </li>
              <li className="flex items-center">
                <Zap className="h-4 w-4 text-indigo-500 mr-2" />
                Multi-document analysis
              </li>
            </ul>
          </div>

          <div className="bg-white p-8 rounded-xl shadow-md hover:shadow-lg transition-shadow">
            <div className="flex items-center mb-4">
              <div className="bg-indigo-100 p-3 rounded-full mr-4">
                <FileSearch className="h-6 w-6 text-indigo-600" />
              </div>
              <h2 className="text-xl font-semibold">Interactive Analysis</h2>
            </div>
            <p className="text-gray-600 mb-4">
              Engage with your financial data through a conversational interface with contextual understanding.
            </p>
            <ul className="space-y-2 text-gray-700">
              <li className="flex items-center">
                <Zap className="h-4 w-4 text-indigo-500 mr-2" />
                Multi-turn conversation
              </li>
              <li className="flex items-center">
                <Zap className="h-4 w-4 text-indigo-500 mr-2" />
                Contextual references to documents
              </li>
              <li className="flex items-center">
                <Zap className="h-4 w-4 text-indigo-500 mr-2" />
                Guided analysis prompts
              </li>
            </ul>
          </div>

          <div className="bg-white p-8 rounded-xl shadow-md hover:shadow-lg transition-shadow">
            <div className="flex items-center mb-4">
              <div className="bg-indigo-100 p-3 rounded-full mr-4">
                <BarChart3 className="h-6 w-6 text-indigo-600" />
              </div>
              <h2 className="text-xl font-semibold">Visual Insights</h2>
            </div>
            <p className="text-gray-600 mb-4">
              Transform financial data into interactive visualizations with citation linking.
            </p>
            <ul className="space-y-2 text-gray-700">
              <li className="flex items-center">
                <Zap className="h-4 w-4 text-indigo-500 mr-2" />
                Dynamic charts and graphs
              </li>
              <li className="flex items-center">
                <Zap className="h-4 w-4 text-indigo-500 mr-2" />
                Time series analysis
              </li>
              <li className="flex items-center">
                <Zap className="h-4 w-4 text-indigo-500 mr-2" />
                Comparative financial metrics
              </li>
            </ul>
          </div>
        </div>

        {/* Call to Action */}
        <div className="text-center">
          <Link 
            href="/workspace" 
            className="bg-indigo-600 hover:bg-indigo-700 text-white font-semibold py-3 px-8 rounded-lg inline-flex items-center transition-colors"
          >
            Get Started
            <svg xmlns="http://www.w3.org/2000/svg" className="h-5 w-5 ml-2" viewBox="0 0 20 20" fill="currentColor">
              <path fillRule="evenodd" d="M10.293 5.293a1 1 0 011.414 0l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414-1.414L12.586 11H5a1 1 0 110-2h7.586l-2.293-2.293a1 1 0 010-1.414z" clipRule="evenodd" />
            </svg>
          </Link>
          <p className="mt-4 text-gray-600">
            Or explore the <Link href="/dashboard" className="text-indigo-600 hover:underline">dashboard</Link>
          </p>
        </div>
      </div>
    </main>
  )
}
</file>
```

#### src/app/pdf\-viewer/\[documentId\]/page\.tsx
*Size: 2.6 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/app/pdf-viewer/[documentId]/page.tsx">
'use client';

import React, { useEffect, useState } from 'react';
import { useParams, useSearchParams } from 'next/navigation';

interface PageProps {
  params: {
    documentId: string;
  };
}

export default function PDFViewerPage({ params }: PageProps) {
  const { documentId } = params;
  const searchParams = useSearchParams();
  const highlightId = searchParams.get('highlightId');
  const page = searchParams.get('page');

  const [isLoading, setIsLoading] = useState(true);

  useEffect(() => {
    // In a real implementation, this would load the document and scroll to the highlight
    setIsLoading(false);
    
    if (highlightId) {
      console.log(`Navigate to highlight: ${highlightId} on page ${page}`);
    }
  }, [documentId, highlightId, page]);

  return (
    <div className="container mx-auto p-4">
      <div className="mb-4">
        <h1 className="text-2xl font-bold">PDF Viewer</h1>
        <p className="text-gray-600">
          Document ID: {documentId}
        </p>
        {highlightId && (
          <p className="text-indigo-600">
            Viewing highlight: {highlightId} {page && `on page ${page}`}
          </p>
        )}
      </div>

      {isLoading ? (
        <div className="flex justify-center items-center h-[600px]">
          <div className="animate-spin rounded-full h-12 w-12 border-t-2 border-b-2 border-indigo-500"></div>
        </div>
      ) : (
        <div className="border border-gray-300 rounded-lg">
          <div className="bg-gray-100 p-4 h-[600px] flex flex-col items-center justify-center">
            <p className="text-xl mb-4">PDF Viewer Placeholder</p>
            <p className="text-gray-600 mb-6">
              This is a placeholder for the PDF Viewer component that would load the document
              and navigate to the specific highlight.
            </p>
            <div className="bg-yellow-100 p-4 rounded-lg border border-yellow-300 max-w-lg">
              <p className="font-semibold mb-2">Selected Highlight:</p>
              <p>
                In a real implementation, the PDF viewer would:
              </p>
              <ul className="list-disc pl-5 mt-2">
                <li>Load the document with ID: <span className="font-mono">{documentId}</span></li>
                {highlightId && (
                  <li>Navigate to highlight: <span className="font-mono">{highlightId}</span></li>
                )}
                {page && (
                  <li>Scroll to page: <span className="font-mono">{page}</span></li>
                )}
                <li>Highlight the cited text in the document</li>
              </ul>
            </div>
          </div>
        </div>
      )}
    </div>
  );
}
</file>
```

#### src/app/test\-markdown/page\.tsx
*Size: 16.4 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/app/test-markdown/page.tsx">
'use client';

import React, { useState } from 'react';
import { MarkdownRenderer } from '@/components/chat/MarkdownRenderer';
import { Citation, Message } from '@/types';
import { EnhancedChart } from '@/components/visualization/EnhancedChart';
import { FinancialInsight, TrendAnalysis } from '@/types/enhanced';
import { Card } from '@/components/ui/card';
import { Tabs, TabsContent, TabsList, TabsTrigger } from '@/components/ui/tabs';
import { BarChart2 } from 'lucide-react';
import { ChartType } from '@/types/visualization';

export default function TestMarkdownPage() {
  const [selectedCitation, setSelectedCitation] = useState<Citation | null>(null);
  const [selectedChartType, setSelectedChartType] = useState<ChartType>('bar');
  const [navigationTarget, setNavigationTarget] = useState<string | null>(null);
  const [focusedMessageId, setFocusedMessageId] = useState<string | null>(null);
  
  // Example messages for reference linking
  const exampleMessages: Message[] = [
    {
      id: 'msg-1',
      role: 'user',
      content: 'Can you explain what EBITDA means in financial reporting?',
      timestamp: new Date().toISOString(),
      sessionId: 'demo-session',
      referencedDocuments: [],
      referencedAnalyses: []
    },
    {
      id: 'msg-2',
      role: 'assistant',
      content: 'EBITDA stands for Earnings Before Interest, Taxes, Depreciation, and Amortization. It\'s a measure used to evaluate a company\'s operating performance without the influence of financing decisions, accounting decisions, or tax environments.',
      timestamp: new Date().toISOString(),
      sessionId: 'demo-session',
      referencedDocuments: [],
      referencedAnalyses: []
    },
    {
      id: 'msg-3',
      role: 'user',
      content: 'How is the P/E Ratio calculated?',
      timestamp: new Date().toISOString(),
      sessionId: 'demo-session',
      referencedDocuments: [],
      referencedAnalyses: []
    },
    {
      id: 'msg-4',
      role: 'assistant',
      content: 'The P/E (Price-to-Earnings) Ratio is calculated by dividing a company\'s current share price by its earnings per share (EPS). It shows how much investors are willing to pay for each dollar of earnings.',
      timestamp: new Date().toISOString(),
      sessionId: 'demo-session',
      referencedDocuments: [],
      referencedAnalyses: []
    }
  ];
  
  // Example content with markdown, citation text, financial terms, and message references
  const content = `# Testing Enhanced Markdown Rendering

This is a test of the **markdown rendering** component that supports *formatting* and [links](https://example.com).

## Financial Terms Detection

The following text contains financial terms that should be automatically detected and explained:

EBITDA is a key performance indicator used by many companies to show their financial health. 
The P/E Ratio is commonly used by investors to determine if a stock is overvalued or undervalued.
Companies with high leverage or low liquidity often face financial challenges during economic downturns.
Understanding ROI and CAGR is essential for evaluating investment performance over time.

## Message References

You can reference previous messages using the syntax [ref:messageId] or [ref:messageId:custom text]:

Let's refer to the explanation of EBITDA [ref:msg-2:see EBITDA definition].

And here's a reference to the question about P/E Ratio [ref:msg-3].

## Code Blocks with Copy Functionality

Here's a code example that you can easily copy:

\`\`\`javascript
function calculateROI(initialInvestment, finalValue) {
  return ((finalValue - initialInvestment) / initialInvestment) * 100;
}

// Example usage
const investment = 10000;
const currentValue = 15000;
const roi = calculateROI(investment, currentValue);
console.log(\`ROI: \${roi}%\`); // Output: ROI: 50%
\`\`\`

## Citations

The Great Barrier Reef is the world's largest coral reef system. It is located off the coast of Queensland, Australia.

## Expandable Sections

The component supports expandable sections for displaying additional information like financial term explanations or long-form content.

## Lists

* Item 1
* Item 2
  * Nested item
* Item 3

1. Numbered item 1
2. Numbered item 2
3. Numbered item 3

## Tables

| Name | Type | Description |
|------|------|-------------|
| id | string | Unique identifier |
| name | string | User's name |
| email | string | User's email |

## Blockquotes

> This is a blockquote that demonstrates the styling of quoted text.
> It can span multiple lines and will be styled appropriately.

## Financial Data Visualization

Below are various chart types showing financial data:
`;

  // Example citations
  const citations: Citation[] = [
    {
      id: '1',
      text: "The Great Barrier Reef is the world's largest coral reef system",
      documentId: 'doc1',
      highlightId: 'highlight1',
      page: 1,
      rects: [
        {
          x1: 150,
          y1: 150,
          x2: 450,
          y2: 170,
          width: 300,
          height: 20
        }
      ]
    }
  ];

  // Example suggestions
  const suggestions = [
    {
      label: 'Tell me more about coral reefs',
      action: () => setNavigationTarget('Would search for information about coral reefs'),
      variant: 'primary' as const
    },
    {
      label: 'Show related marine life',
      action: () => setNavigationTarget('Would show information about related marine life'),
      variant: 'outline' as const
    },
    {
      label: 'Environmental impacts',
      action: () => setNavigationTarget('Would show information about environmental impacts'),
      variant: 'secondary' as const
    }
  ];

  // Example expandable content
  const expandableContent = [
    {
      summary: 'Learn more about coral reefs',
      content: `### Coral Reef Ecosystems
      
Coral reefs are underwater ecosystems characterized by reef-building corals. Corals are marine invertebrates that typically live in compact colonies of many identical individual polyps.

Coral reefs form some of the most diverse ecosystems on Earth. They occupy less than 0.1% of the world's ocean surface, yet they provide a home for at least 25% of all marine species.`,
      defaultExpanded: false
    },
    {
      summary: 'Climate change impacts',
      content: `### Climate Change and Coral Reefs
      
Climate change is the greatest global threat to coral reef ecosystems. Scientific evidence now clearly indicates that the Earth's atmosphere and ocean are warming due to human activities.

As temperatures rise, mass coral bleaching events and infectious disease outbreaks are becoming more frequent, compromising reef health and function.`,
      defaultExpanded: false
    }
  ];

  // Create helper function for creating citation objects with consistent format
  const createCitation = (highlightId: string, documentId: string, text: string, page: number): Citation => {
    return {
      id: `${highlightId}-id`,
      highlightId,
      documentId,
      text,
      page,
      rects: [
        {
          x1: 100,
          y1: 100,
          x2: 300,
          y2: 120,
          width: 200,
          height: 20
        }
      ]
    };
  };

  // Financial data for charts
  const financialData = [
    { 
      period: 'Q1 2023', 
      revenue: 120000, 
      expenses: 85000, 
      profit: 35000, 
      citation: createCitation('highlight2', 'doc1', 'Q1 2023 Financial Results', 2)
    },
    { 
      period: 'Q2 2023', 
      revenue: 150000, 
      expenses: 95000, 
      profit: 55000, 
      citation: createCitation('highlight3', 'doc1', 'Q2 2023 Financial Results', 2)
    },
    { 
      period: 'Q3 2023', 
      revenue: 170000, 
      expenses: 100000, 
      profit: 70000, 
      citation: createCitation('highlight4', 'doc1', 'Q3 2023 Financial Results', 3)
    },
    { 
      period: 'Q4 2023', 
      revenue: 190000, 
      expenses: 110000, 
      profit: 80000, 
      citation: createCitation('highlight5', 'doc1', 'Q4 2023 Financial Results', 3)
    },
    { 
      period: 'Q1 2024', 
      revenue: 210000, 
      expenses: 120000, 
      profit: 90000, 
      citation: createCitation('highlight6', 'doc1', 'Q1 2024 Financial Results', 4)
    }
  ];

  // Pie chart data
  const pieData = [
    { 
      name: 'Revenue', 
      value: 190000, 
      citation: createCitation('highlight7', 'doc1', 'Revenue Breakdown', 5)
    },
    { 
      name: 'Expenses', 
      value: 110000, 
      citation: createCitation('highlight8', 'doc1', 'Expense Breakdown', 5)
    },
    { 
      name: 'Profit', 
      value: 80000, 
      citation: createCitation('highlight9', 'doc1', 'Profit Margin', 5)
    }
  ];

  // Trend data for scatter plot
  const trendData: TrendAnalysis[] = [
    {
      metric: 'Revenue Growth',
      periods: ['Q1 2023', 'Q2 2023', 'Q3 2023', 'Q4 2023', 'Q1 2024'],
      values: [120000, 150000, 170000, 190000, 210000],
      trendDirection: 'up',
      growthRate: 0.15,
      citations: [createCitation('highlight10', 'doc1', 'Revenue Growth Trend', 6)]
    },
    {
      metric: 'Expense Growth',
      periods: ['Q1 2023', 'Q2 2023', 'Q3 2023', 'Q4 2023', 'Q1 2024'],
      values: [85000, 95000, 100000, 110000, 120000],
      trendDirection: 'up',
      growthRate: 0.09,
      citations: [createCitation('highlight11', 'doc1', 'Expense Growth Trend', 6)]
    },
    {
      metric: 'Profit Growth',
      periods: ['Q1 2023', 'Q2 2023', 'Q3 2023', 'Q4 2023', 'Q1 2024'],
      values: [35000, 55000, 70000, 80000, 90000],
      trendDirection: 'up',
      growthRate: 0.26,
      citations: [createCitation('highlight12', 'doc1', 'Profit Growth Trend', 7)]
    }
  ];

  // Financial insights
  const insights: FinancialInsight[] = [
    {
      id: '1',
      metric: 'Revenue Growth',
      value: 0.15,
      description: 'Revenue has shown consistent growth over the past 5 quarters, with an average quarterly growth rate of 15%.',
      importance: 'high',
      sentiment: 'positive',
      citations: [createCitation('highlight13', 'doc1', 'Revenue Growth Analysis', 8)]
    },
    {
      id: '2',
      metric: 'Expense Management',
      value: 0.09,
      description: 'Expenses have increased at a slower rate than revenue, indicating good cost management.',
      importance: 'medium',
      sentiment: 'positive',
      citations: [createCitation('highlight14', 'doc1', 'Expense Management', 8)]
    }
  ];

  const handleCitationClick = (citation: Citation) => {
    setSelectedCitation(citation);
    setNavigationTarget(`Would navigate to: /pdf-viewer/${citation.documentId}?highlightId=${citation.highlightId}&page=${citation.page}`);
  };

  const handleChartDataPointClick = (dataPoint: any) => {
    if (dataPoint && dataPoint.citation) {
      const citation = dataPoint.citation;
      const page = citation.page || 1;
      setNavigationTarget(`Would navigate to: /pdf-viewer/${citation.documentId}?highlightId=${citation.highlightId}&page=${page}`);
    }
  };
  
  const handleMessageReferenceClick = (messageId: string) => {
    setFocusedMessageId(messageId);
    const message = exampleMessages.find(msg => msg.id === messageId);
    if (message) {
      setNavigationTarget(`Scrolled to message: "${message.content.substring(0, 50)}..."`);
    }
  };

  const chartTypes: ChartType[] = ['bar', 'line', 'area', 'pie', 'scatter'];

  return (
    <div className="container mx-auto p-4">
      <h1 className="text-2xl font-bold mb-4">Enhanced Markdown Renderer Demo</h1>
      
      <div className="mb-6 p-4 border border-gray-200 rounded-lg">
        <div className="mb-6">
          <h2 className="text-xl font-semibold mb-2">Example Chat Messages</h2>
          <div className="space-y-4 p-4 bg-gray-50 rounded-lg">
            {exampleMessages.map(message => (
              <div 
                key={message.id} 
                id={message.id}
                className={`p-3 rounded-lg ${
                  message.role === 'user' 
                    ? 'bg-blue-100 ml-auto max-w-[80%]' 
                    : 'bg-white border border-gray-200 max-w-[80%]'
                } ${focusedMessageId === message.id ? 'ring-2 ring-blue-500' : ''}`}
              >
                <div className="text-xs text-gray-500 mb-1">
                  {message.role === 'user' ? 'You' : 'AI Assistant'}
                </div>
                <div>{message.content}</div>
              </div>
            ))}
          </div>
        </div>
      
        <div className="mb-6">
          <h2 className="text-xl font-semibold mb-2">Enhanced Markdown with Features</h2>
          <div className="p-4 bg-white border border-gray-200 rounded-lg">
            <MarkdownRenderer 
              content={content} 
              citations={citations}
              onCitationClick={handleCitationClick}
              suggestions={suggestions}
              expandableContent={expandableContent}
              parentMessages={exampleMessages}
              onMessageReferenceClick={handleMessageReferenceClick}
              enableFinancialTerms={true}
            />
          </div>
        </div>

        {/* Chart Type Selector */}
        <div className="mb-4 mt-6">
          <h3 className="text-lg font-semibold mb-2">Choose Chart Type:</h3>
          <div className="flex flex-wrap gap-2">
            {chartTypes.map(type => (
              <button
                key={type}
                onClick={() => setSelectedChartType(type)}
                className={`px-4 py-2 rounded-md ${
                  selectedChartType === type 
                    ? 'bg-indigo-600 text-white' 
                    : 'bg-gray-200 text-gray-800 hover:bg-gray-300'
                }`}
              >
                {type.charAt(0).toUpperCase() + type.slice(1)}
              </button>
            ))}
          </div>
        </div>

        {/* Chart Container */}
        <div className="mt-6 border border-gray-200 rounded-lg p-4">
          <h3 className="text-lg font-semibold mb-3">
            {selectedChartType.charAt(0).toUpperCase() + selectedChartType.slice(1)} Chart
          </h3>
          <div style={{ height: '400px' }}>
            <EnhancedChart 
              data={selectedChartType === 'pie' ? pieData : financialData}
              chartType={selectedChartType}
              onDataPointClick={handleChartDataPointClick}
              trendData={selectedChartType === 'scatter' ? trendData : undefined}
              insightData={insights}
              height={350}
            />
          </div>
          <p className="text-sm text-gray-500 mt-2">
            Click on data points to view associated citations.
          </p>
        </div>
      </div>

      {selectedCitation && (
        <div className="mt-4 p-4 bg-yellow-50 border border-yellow-200 rounded-lg">
          <h2 className="text-lg font-semibold">Selected Citation</h2>
          <p><strong>Text:</strong> {selectedCitation.text}</p>
          <p><strong>Document ID:</strong> {selectedCitation.documentId}</p>
          <p><strong>Highlight ID:</strong> {selectedCitation.highlightId}</p>
          <p><strong>Page:</strong> {selectedCitation.page}</p>
          <p><strong>Rectangle:</strong> ({selectedCitation.rects[0]?.x1}, {selectedCitation.rects[0]?.y1}) to ({selectedCitation.rects[0]?.x2}, {selectedCitation.rects[0]?.y2})</p>
        </div>
      )}

      {navigationTarget && (
        <div className="mt-4 p-4 bg-indigo-50 border border-indigo-200 rounded-lg">
          <h2 className="text-lg font-semibold">Navigation</h2>
          <p>{navigationTarget}</p>
          <button 
            onClick={() => {
              setNavigationTarget(null);
              setFocusedMessageId(null);
            }}
            className="mt-2 px-3 py-1 bg-indigo-600 text-white rounded-md hover:bg-indigo-700"
          >
            Clear
          </button>
        </div>
      )}
      
      <div className="mt-6 p-4 bg-gray-50 border border-gray-200 rounded-lg">
        <h2 className="text-lg font-semibold mb-2">Features Implemented</h2>
        <ul className="list-disc pl-5 space-y-2">
          <li><strong>Financial Terms Detection:</strong> Automatically identifies and explains financial terminology in messages.</li>
          <li><strong>Message Reference Links:</strong> Allow referring to previous messages with hoverable previews.</li>
          <li><strong>Citation Navigation:</strong> Click on citations to navigate directly to the source document and highlight.</li>
          <li><strong>Copy Functionality:</strong> Easily copy message content or code blocks.</li>
          <li><strong>Expandable Content:</strong> Collapsible sections for long-form content or additional information.</li>
        </ul>
      </div>
    </div>
  );
}
</file>
```

#### src/app/workspace/layout\.tsx
*Size: 323 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/app/workspace/layout.tsx">
import Header from '@/components/layout/Header'

export default function WorkspaceLayout({
  children,
}: Readonly<{
  children: React.ReactNode
}>) {
  return (
    <div className="min-h-screen flex flex-col">
      <Header />
      <main className="flex-1 flex flex-col">
        {children}
      </main>
    </div>
  )
}
</file>
```

#### src/app/workspace/page\.tsx
*Size: 18.5 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/app/workspace/page.tsx">
'use client'

import { useState, useEffect } from 'react'
import { Tabs, TabsContent, TabsList, TabsTrigger } from '../../components/ui/tabs'
import { FileText, BarChart2, Upload, FileUp, Zap, ChevronRight, FileSearch } from 'lucide-react'
import { ChatInterface } from '../../components/chat/ChatInterface'
import { UploadForm } from '../../components/document/UploadForm'
import dynamic from 'next/dynamic'
import { ProcessedDocument, AnalysisResult } from '@/types'
import { conversationApi } from '@/lib/api/conversation'
import { analysisApi } from '@/lib/api/analysis'
import Canvas from '@/components/visualization/Canvas'
import { AnalysisControls } from '@/components/analysis/AnalysisControls'

// Import PDFViewer component with dynamic import to avoid SSR issues
const PDFViewer = dynamic(
  () => import('../../components/document/PDFViewer').then(mod => mod.PDFViewer),
  { ssr: false }
)

export default function Workspace() {
  const [activeTab, setActiveTab] = useState<'document' | 'analysis'>('document')
  const [messages, setMessages] = useState([]);
  const [selectedDocument, setSelectedDocument] = useState<ProcessedDocument | null>(null);
  const [showUploadForm, setShowUploadForm] = useState(false);
  const [sessionId, setSessionId] = useState<string | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [analysisResults, setAnalysisResults] = useState<AnalysisResult[]>([]);
  const [analysisError, setAnalysisError] = useState<string | null>(null);
  const [analysisLoading, setAnalysisLoading] = useState<boolean>(false);
  const [highlightId, setHighlightId] = useState<string | null>(null);

  // Initialize conversation session when component mounts
  useEffect(() => {
    let mounted = true;
    let sessionInitialized = false;

    const initSession = async () => {
      // Only create a session if we don't have one and haven't tried to initialize yet
      if (!sessionId && !sessionInitialized) {
        sessionInitialized = true;
        try {
          setIsLoading(true);
          // Create a new conversation session
          const response = await conversationApi.createConversation('New Conversation');
          if (mounted) {
            setSessionId(response.session_id);
            console.log('Created conversation session:', response.session_id);
          }
        } catch (error) {
          console.error('Error initializing session:', error);
          if (mounted) {
            setMessages(prev => [...prev, {
              id: `system-${Date.now()}`,
              role: 'system',
              content: 'Error initializing chat session. Please refresh the page.',
              timestamp: new Date().toISOString(),
              metadata: {
                referencedDocuments: [],
                referencedAnalyses: []
              }
            }]);
          }
        } finally {
          if (mounted) {
            setIsLoading(false);
          }
        }
      }
    };

    initSession();

    return () => {
      mounted = false;
    };
  }, []); // Remove sessionId dependency to prevent multiple initializations

  // Run financial analysis when a document is selected
  useEffect(() => {
    const runAnalysis = async () => {
      if (!selectedDocument) return;
      
      // Check if we've already analyzed this document
      if (analysisResults.some(result => result.documentIds.includes(selectedDocument.metadata.id))) {
        console.log('Document already analyzed');
        return;
      }
      
      setAnalysisLoading(true);
      
      try {
        const result = await analysisApi.runAnalysis(
          [selectedDocument.metadata.id],
          'basic_financial',
          {}
        );
        
        setAnalysisResults(prev => [...prev, result]);
        
        let analysisMessage = '';
        // Check if this is a failed analysis (local ID, no metrics, has error insights)
        const isFailedAnalysis = (result.id.startsWith('analysis-') || result.id.startsWith('local-')) && 
                                (!result.metrics || result.metrics.length === 0) &&
                                result.insights.some(insight => 
                                  insight.includes('Unable to perform financial analysis') || 
                                  insight.includes('document does not contain structured financial data')
                                );
                                    
        if (isFailedAnalysis) {
          analysisMessage = `I attempted to analyze the financial data in "${selectedDocument.filename}" but ${result.insights[0].toLowerCase()}`;
        } else {
          analysisMessage = `I've completed the financial analysis for "${selectedDocument.filename}". You can see the results in the Analysis tab.`;
        }
        
        // Add system message about analysis completion
        setMessages(prev => {
          const newSystemMessage: Message = {
            id: `msg-${Date.now()}`,
            role: 'system',
            content: analysisMessage,
            timestamp: new Date().toISOString(),
            metadata: {
              referencedDocuments: [selectedDocument.metadata.id],
              // Only reference the analysis if it's not a failed analysis
              referencedAnalyses: isFailedAnalysis ? [] : [result.id],
            }
          };
          return [...prev, newSystemMessage];
        });
      } catch (error) {
        console.error('Error running analysis:', error);
        
        // Add error message to chat
        const errorMsg = error instanceof Error ? error.message : 'Unknown error occurred';
        setMessages(prev => {
          const newSystemMessage: Message = {
            id: `msg-${Date.now()}`,
            role: 'system',
            content: `Error performing analysis: ${errorMsg}`,
            timestamp: new Date().toISOString(),
            metadata: {
              referencedDocuments: [selectedDocument.metadata.id],
              referencedAnalyses: [],
            }
          };
          return [...prev, newSystemMessage];
        });
      } finally {
        setAnalysisLoading(false);
      }
    };
    
    if (selectedDocument && !analysisResults.some(result => 
      result.documentIds.includes(selectedDocument.metadata.id)
    )) {
      runAnalysis();
    }
  }, [selectedDocument, sessionId, analysisResults]);

  const handleSendMessage = async (messageText: string) => {
    if (!sessionId) {
      console.error("No valid session ID available");
      const errorMessage = {
        id: `system-${Date.now()}`,
        role: 'system',
        content: 'Error: No active session. Please refresh the page.',
        timestamp: new Date().toISOString(),
        metadata: {
          referencedDocuments: [],
          referencedAnalyses: []
        }
      };
      setMessages(prev => [...prev, errorMessage]);
      return;
    }

    try {
      // Show user message immediately
      const userMessage = {
        id: `user-${Date.now()}`,
        role: 'user',
        content: messageText,
        timestamp: new Date().toISOString(),
        metadata: {
          referencedDocuments: selectedDocument ? [selectedDocument.metadata.id] : [],
          referencedAnalyses: []
        }
      };
      
      // Add the user message
      setMessages(prev => [...prev, userMessage]);
      
      // Set loading state
      setIsLoading(true);
      
      const documentIds = selectedDocument ? [selectedDocument.metadata.id] : [];
      
      // Get response from the actual API
      const response = await conversationApi.sendMessage(
        sessionId,
        messageText,
        documentIds
      );
      
      // Add the AI response to messages
      setMessages(prev => [...prev, response]);
    } catch (error) {
      console.error("Error sending message:", error);
      // Add error message to chat
      const errorMessage = {
        id: `system-${Date.now()}`,
        role: 'system',
        content: `Error sending message: ${error instanceof Error ? error.message : 'Unknown error'}`,
        timestamp: new Date().toISOString(),
        metadata: {
          referencedDocuments: [],
          referencedAnalyses: []
        }
      };
      
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  };

  const handleUploadSuccess = (document: ProcessedDocument) => {
    setSelectedDocument(document);
    setShowUploadForm(false);
    
    // Add a system message about the successful upload
    const uploadSuccessMessage = {
      id: `system-${Date.now()}`,
      sessionId: sessionId || 'demo-session',
      timestamp: new Date().toISOString(),
      role: 'system',
      content: `Successfully uploaded: ${document.metadata.filename}`,
      referencedDocuments: [document.metadata.id],
      referencedAnalyses: []
    };
    
    setMessages((prev: any) => [...prev, uploadSuccessMessage]);
  };

  const handleUploadError = (error: Error) => {
    // Add an error message to the chat
    const errorMessage = {
      id: `system-${Date.now()}`,
      sessionId: sessionId || 'demo-session',
      timestamp: new Date().toISOString(),
      role: 'system',
      content: `Error uploading document: ${error.message}`,
      referencedDocuments: [],
      referencedAnalyses: []
    };
    
    setMessages((prev: any) => [...prev, errorMessage]);
  };

  // Handle citation clicks from analysis or chat
  const handleCitationClick = (highlightId: string) => {
    setHighlightId(highlightId);
    setActiveTab('document'); // Switch to document tab to show the citation
  };

  // Add this new function to run manual analysis
  const runManualAnalysis = async (documentId: string, analysisType: string, knowledgeBase?: string, userQuery?: string) => {
    if (!documentId) return;
    
    setAnalysisLoading(true);
    setAnalysisError(null);
    
    try {
      // Setup parameters with custom knowledge base and query if provided
      const parameters: Record<string, any> = {};
      if (knowledgeBase) parameters.knowledge_base = knowledgeBase;
      if (userQuery) parameters.user_query = userQuery;
      
      const result = await analysisApi.runAnalysis(
        [documentId],
        analysisType,
        parameters
      );
      
      // Add the new result and update messages
      setAnalysisResults(prev => {
        // If we already have a result for this analysis type and document,
        // replace it instead of adding a new one
        const existingIndex = prev.findIndex(r => 
          r.documentIds.includes(documentId) && r.analysisType === analysisType
        );
        
        if (existingIndex >= 0) {
          const newResults = [...prev];
          newResults[existingIndex] = result;
          return newResults;
        }
        
        // Otherwise add the new result
        return [...prev, result];
      });
      
      // Add system message about analysis completion
      setMessages(prev => {
        const newSystemMessage = {
          id: `msg-${Date.now()}`,
          role: 'system',
          content: `I've completed the ${analysisType} analysis${userQuery ? ' for: "' + userQuery + '"' : ''}. You can see the results in the Analysis tab.`,
          timestamp: new Date().toISOString(),
          metadata: {
            referencedDocuments: [documentId],
            referencedAnalyses: [result.id],
          }
        };
        return [...prev, newSystemMessage];
      });
      
      // Switch to analysis tab to show results
      setActiveTab('analysis');
    } catch (error) {
      console.error('Error running manual analysis:', error);
      setAnalysisError(error instanceof Error ? error.message : 'Unknown error occurred');
      
      // Add error message to chat
      const errorMsg = error instanceof Error ? error.message : 'Unknown error occurred';
      setMessages(prev => {
        const newSystemMessage = {
          id: `msg-${Date.now()}`,
          role: 'system',
          content: `Error performing analysis: ${errorMsg}`,
          timestamp: new Date().toISOString(),
          metadata: {
            referencedDocuments: [documentId],
            referencedAnalyses: [],
          }
        };
        return [...prev, newSystemMessage];
      });
    } finally {
      setAnalysisLoading(false);
    }
  };

  return (
    <div className="flex flex-col h-full bg-gradient-to-b from-indigo-50 to-white">
      <div className="container mx-auto px-4 py-6">
        <h1 className="text-2xl font-bold text-indigo-700 mb-2">Analysis Workspace</h1>
        <p className="text-gray-600 mb-6">
          Upload financial documents, ask questions, and analyze the data through interactive visualizations.
        </p>
      </div>

      {/* Main workspace area */}
      <div className="flex-1 grid grid-cols-1 md:grid-cols-2 gap-4 px-4 pb-6">
        {/* Left side: Chat Interface */}
        <div className="bg-white rounded-xl shadow-md flex flex-col h-[calc(100vh-180px)]">
          <div className="p-4 border-b border-gray-100 bg-indigo-50 rounded-t-xl">
            <h2 className="text-lg font-semibold text-indigo-700 flex items-center">
              <FileSearch className="h-5 w-5 mr-2" />
              Interactive Chat
            </h2>
            <p className="text-sm text-gray-600">Ask questions about your financial documents</p>
          </div>
          <div className="flex-1 overflow-hidden">
            <ChatInterface 
              messages={messages} 
              onSendMessage={handleSendMessage} 
              activeDocuments={selectedDocument ? [selectedDocument.metadata.id] : []}
              isLoading={isLoading}
            />
          </div>
        </div>

        {/* Right side: Document View / Analysis */}
        <div className="bg-white rounded-xl shadow-md flex flex-col h-[calc(100vh-180px)]">
          {/* Tab navigation */}
          <div className="border-b border-gray-100 bg-indigo-50 rounded-t-xl">
            <Tabs defaultValue="document" className="w-full">
              <TabsList className="grid grid-cols-2 p-2">
                <TabsTrigger 
                  value="document" 
                  onClick={() => setActiveTab('document')}
                  className="data-[state=active]:bg-white data-[state=active]:text-indigo-700"
                >
                  <div className="flex items-center">
                    <FileText className="h-4 w-4 mr-1.5" />
                    Document
                  </div>
                </TabsTrigger>
                <TabsTrigger 
                  value="analysis" 
                  onClick={() => setActiveTab('analysis')}
                  className="data-[state=active]:bg-white data-[state=active]:text-indigo-700"
                >
                  <div className="flex items-center">
                    <BarChart2 className="h-4 w-4 mr-1.5" />
                    Analysis
                  </div>
                </TabsTrigger>
              </TabsList>
              <TabsContent value="document" className="h-[calc(100vh-13rem)] p-0">
                {showUploadForm ? (
                  <div className="p-6">
                    <h2 className="text-xl font-semibold text-indigo-700 mb-4">Upload Document</h2>
                    <UploadForm 
                      onUploadSuccess={handleUploadSuccess}
                      onUploadError={handleUploadError}
                      sessionId={sessionId || undefined}
                    />
                    <button
                      onClick={() => setShowUploadForm(false)}
                      className="mt-4 text-sm text-indigo-500 hover:text-indigo-700"
                    >
                      Cancel
                    </button>
                  </div>
                ) : selectedDocument ? (
                  <div className="h-full">
                    <PDFViewer 
                      document={selectedDocument}
                      highlightId={highlightId}
                      onCitationCreate={(citation) => {
                        console.log('Citation created:', citation);
                        // You can add citation handling logic here
                      }}
                      onCitationClick={(citation) => {
                        console.log('Citation clicked:', citation);
                        // You can add citation click handling logic here
                      }}
                    />
                  </div>
                ) : (
                  <div className="h-full flex items-center justify-center">
                    <div className="text-center p-6 max-w-md">
                      <div className="bg-indigo-100 p-3 rounded-full w-16 h-16 flex items-center justify-center mx-auto mb-4">
                        <FileUp className="h-8 w-8 text-indigo-600" />
                      </div>
                      <h3 className="text-lg font-semibold text-indigo-700 mb-2">No document to display</h3>
                      <p className="text-gray-600 mb-6">
                        Upload a financial document to start analyzing it with our AI-powered tools.
                      </p>
                      <button
                        onClick={() => setShowUploadForm(true)}
                        className="inline-flex items-center bg-indigo-600 text-white px-6 py-3 rounded-lg text-sm font-medium hover:bg-indigo-700 transition-colors shadow-sm"
                      >
                        <Upload className="h-5 w-5 mr-2" />
                        Upload Document
                        <ChevronRight className="h-4 w-4 ml-1" />
                      </button>
                    </div>
                  </div>
                )}
              </TabsContent>
              <TabsContent value="analysis" className="h-[calc(100vh-13rem)] p-0 flex flex-col">
                {selectedDocument && (
                  <div className="p-4 border-b">
                    <AnalysisControls 
                      isLoading={analysisLoading}
                      onRunAnalysis={(analysisType, knowledgeBase, userQuery) => {
                        runManualAnalysis(
                          selectedDocument.metadata.id,
                          analysisType,
                          knowledgeBase,
                          userQuery
                        );
                      }}
                    />
                  </div>
                )}
                <div className="flex-1 overflow-hidden">
                  <Canvas 
                    analysisResults={analysisResults}
                    error={analysisError || undefined}
                    loading={analysisLoading}
                    onCitationClick={handleCitationClick}
                    messages={messages}
                  />
                </div>
              </TabsContent>
            </Tabs>
          </div>
        </div>
      </div>
    </div>
  )
}
</file>
```

#### src/components/DocumentList\.tsx
*Size: 7.3 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/DocumentList.tsx">
'use client';

import { useEffect, useState } from 'react';
import { File, Loader2, AlertCircle, Eye, Trash2, ChevronRight, BarChart } from 'lucide-react';
import { DocumentMetadata } from '@/types';
import { documentsApi } from '@/lib/api/documents';

interface DocumentListProps {
  refreshTrigger?: number;
  onSelectDocument?: (documentId: string) => void;
  onDelete?: (documentId: string) => void;
  onAnalyze?: (documentId: string) => void;
}

export function DocumentList({ 
  refreshTrigger = 0, 
  onSelectDocument,
  onDelete,
  onAnalyze
}: DocumentListProps) {
  const [documents, setDocuments] = useState<DocumentMetadata[]>([]);
  const [isLoading, setIsLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);
  const [page, setPage] = useState(1);
  const [hasMore, setHasMore] = useState(true);
  const [total, setTotal] = useState(0);
  const pageSize = 10;
  
  const fetchDocuments = async (currentPage: number = page) => {
    try {
      setIsLoading(true);
      setError(null);
      
      const response = await documentsApi.listDocuments(currentPage, pageSize);
      
      // If loading the first page, replace the list
      if (currentPage === 1) {
        setDocuments(response.documents);
      } else {
        // Otherwise append to the existing list
        setDocuments(prev => [...prev, ...response.documents]);
      }
      
      setTotal(response.total);
      setHasMore(response.total > currentPage * pageSize);
      setIsLoading(false);
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Failed to load documents');
      setIsLoading(false);
    }
  };
  
  useEffect(() => {
    // Reset to page 1 and fetch whenever the refresh trigger changes
    setPage(1);
    fetchDocuments(1);
  }, [refreshTrigger]);
  
  const handleLoadMore = () => {
    const nextPage = page + 1;
    setPage(nextPage);
    fetchDocuments(nextPage);
  };
  
  const handleSelectDocument = (documentId: string) => {
    if (onSelectDocument) {
      onSelectDocument(documentId);
    }
  };
  
  const handleDeleteDocument = async (documentId: string) => {
    if (confirm('Are you sure you want to delete this document?')) {
      try {
        await documentsApi.deleteDocument(documentId);
        // Remove from the local state
        setDocuments(prev => prev.filter(doc => doc.id !== documentId));
        setTotal(prev => prev - 1);
        // Call the parent callback if provided
        if (onDelete) {
          onDelete(documentId);
        }
      } catch (error) {
        setError('Failed to delete document');
      }
    }
  };
  
  const handleAnalyzeDocument = (documentId: string) => {
    if (onAnalyze) {
      onAnalyze(documentId);
    }
  };
  
  if (error) {
    return (
      <div className="p-4 border border-red-200 rounded-md flex items-center bg-red-50 text-red-800 mb-4">
        <AlertCircle className="h-4 w-4" />
        <div className="text-sm ml-2">{error}</div>
        <button 
          onClick={() => fetchDocuments(1)} 
          className="ml-auto text-sm py-1 px-3 border border-gray-300 rounded-md bg-white hover:bg-gray-50"
        >
          Try Again
        </button>
      </div>
    );
  }
  
  return (
    <div className="space-y-4">
      <div className="flex justify-between items-center mb-2">
        <h2 className="text-xl font-semibold">Your Documents</h2>
        <div className="text-sm text-gray-500">{total} documents</div>
      </div>
      
      {documents.length === 0 && !isLoading ? (
        <div className="text-center py-8 border rounded-md bg-gray-50">
          <File className="h-12 w-12 text-gray-400 mx-auto mb-3" />
          <p className="text-gray-500">No documents yet. Upload your first PDF to get started.</p>
        </div>
      ) : (
        <div className="space-y-3">
          {documents.map(doc => (
            <div 
              key={doc.id} 
              className="flex items-center justify-between p-4 border rounded-md hover:bg-gray-50 transition-colors"
            >
              <div className="flex items-center flex-1 min-w-0" onClick={() => handleSelectDocument(doc.id)} style={{cursor: 'pointer'}}>
                <File className="h-5 w-5 text-blue-500 flex-shrink-0 mr-3" />
                <div className="flex-1 min-w-0">
                  <div className="text-sm font-medium text-gray-900 truncate">{doc.filename}</div>
                  <div className="text-xs text-gray-500">
                    Uploaded {new Date(doc.uploadTimestamp).toLocaleString()}
                  </div>
                  {doc.citationLinks && doc.citationLinks.length > 0 && (
                    <div className="text-xs text-yellow-600 mt-1">
                      {doc.citationLinks.length} citations available
                    </div>
                  )}
                </div>
              </div>
              
              <div className="flex items-center space-x-2 ml-4">
                <button 
                  className="p-2 rounded-md text-gray-500 hover:bg-gray-100 hover:text-gray-700 transition-colors"
                  onClick={() => handleSelectDocument(doc.id)}
                  title="View document"
                >
                  <Eye className="h-4 w-4" />
                </button>
                {onAnalyze && (
                  <button
                    className="p-2 rounded-md text-gray-500 hover:bg-gray-100 hover:text-gray-700 transition-colors"
                    onClick={() => handleAnalyzeDocument(doc.id)}
                    title="Analyze document"
                  >
                    <BarChart className="h-4 w-4" />
                  </button>
                )}
                <button 
                  className="p-2 rounded-md text-red-500 hover:bg-red-50 hover:text-red-700 transition-colors"
                  onClick={() => handleDeleteDocument(doc.id)}
                  title="Delete document"
                >
                  <Trash2 className="h-4 w-4" />
                </button>
              </div>
            </div>
          ))}
          
          {isLoading && (
            <div className="space-y-3">
              {[...Array(3)].map((_, i) => (
                <div key={i} className="flex items-center p-4 border rounded-md">
                  <div className="h-5 w-5 rounded-full bg-gray-200 animate-pulse mr-3"></div>
                  <div className="flex-1">
                    <div className="h-4 w-2/3 bg-gray-200 animate-pulse mb-2"></div>
                    <div className="h-3 w-1/3 bg-gray-200 animate-pulse"></div>
                  </div>
                </div>
              ))}
            </div>
          )}
          
          {hasMore && (
            <button 
              className="w-full border border-gray-300 bg-white text-gray-700 hover:bg-gray-50 rounded-md font-medium transition-colors focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2 text-sm px-4 py-2 disabled:opacity-50 disabled:pointer-events-none"
              onClick={handleLoadMore} 
              disabled={isLoading}
            >
              {isLoading ? (
                <>
                  <Loader2 className="h-4 w-4 mr-2 animate-spin inline" />
                  Loading...
                </>
              ) : (
                <>
                  Load More <ChevronRight className="h-4 w-4 ml-2 inline" />
                </>
              )}
            </button>
          )}
        </div>
      )}
    </div>
  );
} 
</file>
```

#### src/components/UploadForm\.tsx
*Size: 12.5 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/UploadForm.tsx">
'use client';

import React, { useState, useRef, useCallback } from 'react';
import { Upload, Loader2, File, AlertCircle, CheckCircle2, RefreshCw } from 'lucide-react';
import { ProcessedDocument } from '@/types';
import { documentsApi } from '@/lib/api/documents';

interface UploadFormProps {
  onUploadSuccess?: (document: ProcessedDocument) => void;
  onUploadError?: (error: Error) => void;
}

export function UploadForm({ onUploadSuccess, onUploadError }: UploadFormProps) {
  const [file, setFile] = useState<File | null>(null);
  const [isUploading, setIsUploading] = useState(false);
  const [progress, setProgress] = useState(0);
  const [error, setError] = useState<string | null>(null);
  const [warning, setWarning] = useState<string | null>(null);
  const [isDragging, setIsDragging] = useState(false);
  const [uploadComplete, setUploadComplete] = useState(false);
  
  // Reference to the file input
  const fileInputRef = useRef<HTMLInputElement>(null);
  
  // Handle file selection from input
  const handleFileChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    const selectedFile = e.target.files?.[0];
    if (selectedFile) {
      validateAndSetFile(selectedFile);
    }
  };
  
  // Validate file and set it if valid
  const validateAndSetFile = (selectedFile: File) => {
    // Reset states
    setError(null);
    setWarning(null);
    
    // Check file type
    if (selectedFile.type !== 'application/pdf') {
      setError('Only PDF files are supported');
      return false;
    }
    
    // Check file size (10MB limit)
    if (selectedFile.size > 10 * 1024 * 1024) {
      setError('File size must be less than 10MB');
      return false;
    }
    
    // Optional additional checks for PDF content validity could go here
    
    // Set the file if validation passes
    setFile(selectedFile);
    return true;
  };
  
  // Handle drag events for drag-and-drop functionality
  const handleDragEnter = useCallback((e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
    setIsDragging(true);
  }, []);
  
  const handleDragLeave = useCallback((e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
    setIsDragging(false);
  }, []);
  
  const handleDragOver = useCallback((e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
  }, []);
  
  const handleDrop = useCallback((e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
    setIsDragging(false);
    
    const files = e.dataTransfer.files;
    if (files.length > 0) {
      validateAndSetFile(files[0]);
    }
  }, []);
  
  // Cancel the current upload
  const cancelUpload = () => {
    setIsUploading(false);
    setProgress(0);
    setError(null);
    setWarning(null);
    setUploadComplete(false);
    setFile(null);
  };
  
  // Retry upload after a failure
  const retryUpload = () => {
    setError(null);
    setProgress(0);
    handleUpload();
  };
  
  const handleUpload = async () => {
    if (!file) return;
    
    try {
      setIsUploading(true);
      setError(null);
      setWarning(null);
      setUploadComplete(false);
      
      // Instead of creating our own XMLHttpRequest, use the documentsApi's uploadAndVerifyDocumentWithProgress
      try {
        const document = await documentsApi.uploadAndVerifyDocumentWithProgress(
          file,
          (progress, stage) => {
            setProgress(progress);
            console.log(`Upload progress: ${progress}%, Stage: ${stage}`);
          }
        );
        
        // Document processing and verification complete
        setProgress(100);
        setUploadComplete(true);
        console.log("Document verification completed:", document);
        
        // Check if the document has financial data
        if (document.extractedData?.financialVerification) {
          const hasFinancialData = document.extractedData.financialVerification.hasFinancialData;
          const diagnosis = document.extractedData.financialVerification.diagnosis;
          
          if (!hasFinancialData) {
            // Document doesn't have ideal financial data - show warning but still allow
            console.warn("Document may not have ideal financial data:", diagnosis);
            setWarning(`The document was processed but may not contain structured financial data. You can still use it for analysis.`);
          }
        } else {
          // Even if no verification data, still allow document use
          console.log("No financial verification data available, but document can still be used");
        }
        
        // Notify parent component of successful upload
        onUploadSuccess?.(document);
        
        // Reset form after short delay to show 100% completion
        setTimeout(() => {
          setFile(null);
          setProgress(0);
          setIsUploading(false);
          setUploadComplete(false);
        }, 2000);
      } catch (err) {
        console.error("Document upload failed:", err);
        
        // Handle specific error types
        const errorMessage = err instanceof Error ? err.message : 'Failed to upload document';
        
        if (errorMessage.includes('Network error')) {
          setError('Network error. Please check your internet connection and try again.');
        } else if (errorMessage.includes('aborted')) {
          setError('Upload was cancelled.');
        } else if (errorMessage.includes('size limit exceeded')) {
          setError('The file exceeds the maximum size limit (10MB).');
        } else if (errorMessage.includes('unsupported file type')) {
          setError('The file type is not supported. Please upload a PDF document.');
        } else if (errorMessage.includes('processing')) {
          setError('Error processing the document. The PDF might be corrupted or password protected.');
        } else {
          setError(errorMessage);
        }
        
        setIsUploading(false);
        setProgress(0);
        onUploadError?.(err instanceof Error ? err : new Error('Unknown error'));
      }
    } catch (err) {
      console.error("Document upload failed:", err);
      
      // Handle specific error types
      const errorMessage = err instanceof Error ? err.message : 'Failed to upload document';
      
      if (errorMessage.includes('Network error')) {
        setError('Network error. Please check your internet connection and try again.');
      } else if (errorMessage.includes('aborted')) {
        setError('Upload was cancelled.');
      } else if (errorMessage.includes('size limit exceeded')) {
        setError('The file exceeds the maximum size limit (10MB).');
      } else if (errorMessage.includes('unsupported file type')) {
        setError('The file type is not supported. Please upload a PDF document.');
      } else if (errorMessage.includes('processing')) {
        setError('Error processing the document. The PDF might be corrupted or password protected.');
      } else {
        setError(errorMessage);
      }
      
      setIsUploading(false);
      setProgress(0);
      onUploadError?.(err instanceof Error ? err : new Error('Unknown error'));
    }
  };
  
  return (
    <div className="space-y-4">
      {error && (
        <div className="p-4 border border-red-200 rounded-md flex items-start space-x-2 bg-red-50 text-red-800">
          <AlertCircle className="h-5 w-5 flex-shrink-0 mt-0.5" />
          <div className="flex-1">
            <div className="text-sm font-medium">{error}</div>
            {isUploading === false && file && (
              <button 
                onClick={retryUpload}
                className="mt-2 inline-flex items-center text-xs font-medium text-red-700 hover:text-red-900"
              >
                <RefreshCw className="h-3 w-3 mr-1" /> Try again
              </button>
            )}
          </div>
        </div>
      )}
      
      {warning && !error && (
        <div className="p-4 border border-yellow-200 rounded-md flex items-start space-x-2 bg-yellow-50 text-yellow-800">
          <AlertCircle className="h-5 w-5 flex-shrink-0 mt-0.5" />
          <div className="text-sm">{warning}</div>
        </div>
      )}
      
      {uploadComplete && !error && !isUploading && (
        <div className="p-4 border border-green-200 rounded-md flex items-start space-x-2 bg-green-50 text-green-800">
          <CheckCircle2 className="h-5 w-5 flex-shrink-0 mt-0.5" />
          <div className="text-sm">Document uploaded and processed successfully!</div>
        </div>
      )}
      
      <div 
        className={`flex flex-col items-center p-6 border-2 ${isDragging ? 'border-blue-400 bg-blue-50' : 'border-dashed border-gray-300 bg-gray-50 hover:bg-gray-100'} rounded-md transition-colors`}
        onDragEnter={handleDragEnter}
        onDragOver={handleDragOver}
        onDragLeave={handleDragLeave}
        onDrop={handleDrop}
      >
        {!file ? (
          <>
            <File className="h-8 w-8 text-gray-400 mb-2" />
            <p className="text-sm text-gray-500 mb-4">Drag and drop your PDF or click to browse</p>
            <label className="cursor-pointer inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-blue-500 focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 bg-blue-500 text-white hover:bg-blue-600 h-10 px-4 py-2">
              <Upload className="mr-2 h-4 w-4" />
              Select PDF
              <input 
                ref={fileInputRef}
                type="file" 
                accept=".pdf,application/pdf" 
                onChange={handleFileChange} 
                disabled={isUploading}
                className="hidden"
              />
            </label>
          </>
        ) : (
          <div className="w-full space-y-4">
            <div className="flex items-center">
              <File className="h-6 w-6 text-blue-500 mr-2" />
              <div className="text-sm font-medium flex-1 truncate">{file.name}</div>
              <div className="text-xs text-gray-500">
                {(file.size / 1024 / 1024).toFixed(2)} MB
              </div>
            </div>
            
            {isUploading ? (
              <div className="space-y-2">
                <div className="w-full bg-gray-200 rounded-full h-2">
                  <div 
                    className="bg-blue-500 h-full rounded-full transition-all duration-300 ease-in-out" 
                    style={{ width: `${progress}%` }}
                  ></div>
                </div>
                <div className="flex justify-between text-xs text-gray-500">
                  <span>
                    {progress < 75 ? 'Uploading...' : 
                     progress < 90 ? 'Processing...' : 
                     'Verifying...'}
                  </span>
                  <span>{Math.round(progress)}%</span>
                </div>
              </div>
            ) : (
              <div className="flex space-x-2">
                <button
                  onClick={cancelUpload}
                  className="flex-1 border border-gray-300 bg-white text-gray-700 hover:bg-gray-50 rounded-md font-medium transition-colors focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2 text-sm px-4 py-2"
                >
                  Cancel
                </button>
                <button 
                  onClick={handleUpload}
                  disabled={isUploading}
                  className="flex-1 bg-blue-500 text-white hover:bg-blue-600 rounded-md font-medium transition-colors focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2 disabled:opacity-50 disabled:pointer-events-none text-sm px-4 py-2 flex items-center justify-center"
                >
                  {isUploading ? (
                    <>
                      <Loader2 className="h-4 w-4 mr-2 animate-spin" />
                      Processing...
                    </>
                  ) : 'Upload'}
                </button>
              </div>
            )}
          </div>
        )}
      </div>
      
      {isUploading && (
        <div className="text-xs text-gray-500">
          {progress < 75 ? (
            <div>Uploading your document... {Math.round(progress)}% complete</div>
          ) : progress < 90 ? (
            <div>Processing your document. This may take a minute...</div>
          ) : (
            <div className="text-blue-600 font-medium">
              Verifying financial data extraction...
            </div>
          )}
        </div>
      )}
      
      <div className="text-xs text-gray-500">
        <p>Supported file types: PDF (max size: 10MB)</p>
      </div>
    </div>
  );
}
</file>
```

#### src/components/analysis/AnalysisBlock\.tsx
*Size: 12.5 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/analysis/AnalysisBlock.tsx">
'use client';

import React from 'react';
import { DollarSign, ExternalLink, TrendingUp, Zap } from 'lucide-react';
import { EnhancedChart, ChartType as EnhancedChartType } from '../visualization/EnhancedChart';
import { FinancialInsight, TrendAnalysis } from '@/types/enhanced';
import { ChartType, FinancialMetric } from '@/types/visualization';
import { BarChart2, Clipboard, PieChart, Filter, History } from 'lucide-react';
import { Button } from '@/components/ui/button';
import MetricGrid from '../metrics/MetricGrid';
import ComparativePeriodDisplay from '../metrics/ComparativePeriodDisplay';

// Interface for period data used by ComparativePeriodDisplay
interface PeriodData {
  period: string;
  metrics: FinancialMetric[];
}

export interface AnalysisBlock {
  id: string;
  title: string;
  description?: string;
  chartType: ChartType | 'none';
  chartData: any[];
  insights: FinancialInsight[];
  trends?: TrendAnalysis[];
  metrics?: FinancialMetric[];
  comparativePeriods?: PeriodData[];
  citationReferences?: any[];
  timestamp: string;
  isLimitedAnalysis?: boolean;
  isEmptyAnalysis?: boolean;
  claudeCitations?: any[];
}

interface AnalysisBlockProps {
  block: AnalysisBlock;
  onCitationClick?: (highlightId: string) => void;
  showCitations?: boolean;
}

interface CitationsBlockProps {
  citations: any[];
  blockId: string;
  onCitationClick?: (highlightId: string) => void;
}

const CitationsBlock: React.FC<CitationsBlockProps> = ({ 
  citations, 
  blockId, 
  onCitationClick 
}) => {
  if (!citations || citations.length === 0) return null;
  
  return (
    <div className="mt-4 border-t pt-4">
      <h4 className="text-md font-medium flex items-center">
        <ExternalLink className="h-4 w-4 mr-1 text-indigo-600" />
        Document Citations
      </h4>
      <ul className="mt-2 space-y-2">
        {citations.map((citation, index) => {
          const citationId = `${blockId}-citation-${index}`;
          const location = citation.type === 'page_location' 
            ? `Page ${citation.start_page_number}` 
            : 'Document';
            
          return (
            <li 
              key={citationId}
              className="text-sm p-2 bg-gray-50 rounded border-l-2 border-indigo-300"
            >
              <div className="flex items-start gap-2">
                <div className="shrink-0 font-medium text-xs px-2 py-1 bg-indigo-100 rounded text-indigo-700 mt-0.5">
                  {location}
                </div>
                <div className="flex-1">
                  <div className="text-gray-700 italic">"{citation.cited_text}"</div>
                  <div className="text-gray-500 text-xs mt-1">
                    {citation.document_title || "Financial Document"}
                  </div>
                  
                  {onCitationClick && (
                    <button
                      onClick={() => onCitationClick(citationId)}
                      className="text-xs flex items-center text-indigo-600 hover:text-indigo-800 mt-2"
                    >
                      <ExternalLink className="h-3 w-3 mr-1" />
                      View in document
                    </button>
                  )}
                </div>
              </div>
            </li>
          );
        })}
      </ul>
    </div>
  );
};

export const AnalysisBlock: React.FC<AnalysisBlockProps> = ({ 
  block, 
  onCitationClick,
  showCitations = true
}) => {
  // Handle clicking on a data point with citation
  const handleDataPointClick = (dataPoint: any) => {
    if (dataPoint && dataPoint.citation && onCitationClick) {
      onCitationClick(dataPoint.citation.highlightId);
    }
  };

  // Add a utility function to convert Claude citations to the format needed by FinancialInsight citations
  const convertClaudeCitationsToInsightCitations = (claudeCitations: any[], blockId: string) => {
    if (!claudeCitations || claudeCitations.length === 0) return [];
    
    return claudeCitations.map((citation, index) => {
      // Create a unique ID for this citation
      const citationId = `${blockId}-citation-${index}`;
      
      // Create a citation with page number for PDF citations
      if (citation.type === 'page_location') {
        return {
          id: citationId,
          highlightId: citationId,
          text: citation.cited_text,
          pageNumber: citation.start_page_number,
          boundingBoxes: []
        };
      }
      
      // Handle text citations
      if (citation.type === 'char_location') {
        return {
          id: citationId,
          highlightId: citationId,
          text: citation.cited_text,
          // Use a default page number since we don't have one
          pageNumber: 1,
          boundingBoxes: []
        };
      }
      
      // Default case
      return {
        id: citationId,
        highlightId: citationId,
        text: citation.cited_text || "Citation from document",
        pageNumber: 1,
        boundingBoxes: []
      };
    });
  };

  // Determine if we have metrics to display
  const hasMetrics = block.metrics && block.metrics.length > 0;
  
  // Determine if we have comparative period data to display
  const hasComparativePeriods = block.comparativePeriods && block.comparativePeriods.length > 0;

  return (
    <div className="bg-white rounded-lg shadow p-4 mb-6 flex flex-col">
      {/* Block header */}
      <div className="mb-4">
        <h3 className="text-lg font-semibold text-gray-900">{block.title}</h3>
        {block.description && (
          <p className="text-sm text-gray-500 mt-1">{block.description}</p>
        )}
        <div className="text-xs text-gray-400 mt-1">
          {new Date(block.timestamp).toLocaleString()}
          {block.isLimitedAnalysis && (
            <span className="ml-2 bg-amber-100 text-amber-700 px-2 py-0.5 rounded-full text-xs">
              Limited Analysis
            </span>
          )}
          {block.isEmptyAnalysis && (
            <span className="ml-2 bg-gray-100 text-gray-700 px-2 py-0.5 rounded-full text-xs">
              No Financial Data
            </span>
          )}
        </div>
      </div>

      {/* Empty Analysis State */}
      {block.isEmptyAnalysis && (
        <div className="flex flex-col items-center justify-center py-8 px-4 mb-4 bg-gray-50 rounded-lg border border-gray-200">
          <DollarSign className="h-12 w-12 text-gray-300 mb-3" />
          <p className="text-gray-600 text-center mb-2 font-medium">No Financial Data Available</p>
          <p className="text-gray-500 text-sm text-center max-w-md">
            The document does not contain structured financial data that could be automatically extracted.
          </p>
        </div>
      )}

      {/* Key Metrics Section - Display metrics grid if available */}
      {!block.isEmptyAnalysis && hasMetrics && (
        <div className="mb-6">
          <h4 className="text-md font-medium flex items-center mb-3">
            <DollarSign className="h-4 w-4 mr-1 text-blue-600" />
            Key Financial Metrics
          </h4>
          <MetricGrid 
            metrics={block.metrics}
            onMetricClick={(metric) => {
              // Optional: Add any click handler for metrics
              console.log('Metric clicked:', metric);
            }}
          />
        </div>
      )}

      {/* Comparative Period Section - Display comparative metrics if available */}
      {!block.isEmptyAnalysis && hasComparativePeriods && (
        <div className="mb-6">
          <h4 className="text-md font-medium flex items-center mb-3">
            <History className="h-4 w-4 mr-1 text-blue-600" />
            Period-over-Period Comparison
          </h4>
          <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
            {block.comparativePeriods.map((periodData, index) => (
              <ComparativePeriodDisplay
                key={index}
                data={[periodData]}
                title={`${periodData.period} Metrics`}
              />
            ))}
          </div>
        </div>
      )}

      {/* Chart - only show if not an empty analysis */}
      {!block.isEmptyAnalysis && block.chartType !== 'none' && block.chartData && block.chartData.length > 0 && (
        <div className="mb-6">
          <h4 className="text-md font-medium flex items-center mb-3">
            <BarChart2 className="h-4 w-4 mr-1 text-blue-600" />
            Visualization
          </h4>
          <div className="h-64">
            <EnhancedChart
              data={block.chartData}
              chartType={block.chartType as EnhancedChartType}
              onDataPointClick={handleDataPointClick}
              insightData={block.insights}
              trendData={block.trends}
            />
          </div>
        </div>
      )}

      {/* Add a note at the top of insights section if this is limited analysis */}
      {block.isLimitedAnalysis && (
        <div className="mb-3 bg-amber-50 p-3 rounded-md text-sm text-amber-700 border border-amber-200">
          <p className="font-medium">Limited Analysis</p>
          <p>This analysis is based on text extraction and may not reflect complete financial data. Charts and metrics are derived from financial terms found in the document.</p>
        </div>
      )}

      {/* Insights and takeaways */}
      <div className="mt-4 border-t pt-4">
        <h4 className="text-md font-medium flex items-center">
          <DollarSign className="h-4 w-4 mr-1 text-indigo-600" />
          {block.isEmptyAnalysis ? 'Information' : 'Key Insights'}
        </h4>
        <ul className="mt-2 space-y-2">
          {block.insights.map((insight, index) => (
            <li 
              key={index} 
              className={`text-sm ${
                insight.importance === 'high' 
                  ? 'text-gray-800 font-medium' 
                  : insight.importance === 'medium'
                    ? 'text-gray-700' 
                    : 'text-gray-600'
              } p-2 rounded ${
                insight.importance === 'high' ? 'bg-yellow-50' : ''
              }`}
            >
              <div className="flex">
                {insight.importance === 'high' && <Zap className="h-4 w-4 mr-1 text-yellow-500 shrink-0" />}
                <span>{insight.description}</span>
              </div>
              
              {/* Citation links */}
              {insight.citations && insight.citations.length > 0 && showCitations && (
                <div className="mt-1">
                  {insight.citations.map((citation, citIndex) => (
                    <button
                      key={citIndex}
                      className="text-xs flex items-center text-indigo-600 hover:text-indigo-800 mt-1"
                      onClick={() => onCitationClick && onCitationClick(citation.highlightId)}
                    >
                      <ExternalLink className="h-3 w-3 mr-1" />
                      View source: {citation.text.substring(0, 30)}...
                    </button>
                  ))}
                </div>
              )}
            </li>
          ))}
        </ul>
        
        {/* Trends summary - only show if not an empty analysis */}
        {!block.isEmptyAnalysis && block.trends && block.trends.length > 0 && (
          <div className="mt-4">
            <h4 className="text-md font-medium flex items-center">
              <TrendingUp className="h-4 w-4 mr-1 text-indigo-600" />
              Key Trends
            </h4>
            <ul className="mt-2 space-y-1">
              {block.trends.map((trend, index) => (
                <li key={index} className="text-sm flex items-center">
                  <span 
                    className={`h-2 w-2 rounded-full mr-2 ${
                      trend.trendDirection === 'up' 
                        ? 'bg-green-500' 
                        : trend.trendDirection === 'down' 
                          ? 'bg-red-500' 
                          : 'bg-gray-500'
                    }`}
                  />
                  <span>
                    {trend.metric}: {trend.trendDirection === 'up' ? 'Increased' : trend.trendDirection === 'down' ? 'Decreased' : 'Stable'} 
                    {trend.growthRate !== undefined && ` by ${Math.abs(Number(trend.growthRate) * 100).toFixed(1)}%`}
                  </span>
                </li>
              ))}
            </ul>
          </div>
        )}
      </div>

      {/* Add a CitationsBlock component to display citations */}
      {block.citationReferences && block.citationReferences.length > 0 && (
        <CitationsBlock 
          citations={convertClaudeCitationsToInsightCitations(block.citationReferences, block.id)}
          blockId={block.id}
          onCitationClick={onCitationClick}
        />
      )}
    </div>
  );
}; 
</file>
```

#### src/components/analysis/AnalysisControls\.tsx
*Size: 4.5 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/analysis/AnalysisControls.tsx">
'use client';

import React, { useState } from 'react';
import { Button } from '@/components/ui/button';
import { Textarea } from '@/components/ui/textarea';
import { Input } from '@/components/ui/input';
import { Collapsible, CollapsibleContent, CollapsibleTrigger } from '@/components/ui/collapsible';
import { Settings, ChevronDown, ChevronUp } from 'lucide-react';

interface AnalysisControlsProps {
  onRunAnalysis: (
    analysisType: string, 
    knowledgeBase?: string, 
    userQuery?: string
  ) => void;
  isLoading: boolean;
}

export const AnalysisControls: React.FC<AnalysisControlsProps> = ({ 
  onRunAnalysis,
  isLoading 
}) => {
  const [analysisType, setAnalysisType] = useState<string>('basic_financial');
  const [isAdvancedOpen, setIsAdvancedOpen] = useState<boolean>(false);
  const [knowledgeBase, setKnowledgeBase] = useState<string>('');
  const [userQuery, setUserQuery] = useState<string>('');
  
  const handleRunAnalysis = () => {
    onRunAnalysis(
      analysisType,
      knowledgeBase.trim() || undefined,
      userQuery.trim() || undefined
    );
  };
  
  return (
    <div className="w-full p-4 border rounded-lg bg-white shadow-sm">
      <div className="flex flex-col space-y-4">
        <div className="flex justify-between items-center">
          <h2 className="text-lg font-medium">Analysis Controls</h2>
          
          <Button
            onClick={handleRunAnalysis}
            disabled={isLoading}
            className="bg-indigo-600 hover:bg-indigo-700 text-white"
          >
            {isLoading ? 'Running Analysis...' : 'Run Analysis'}
          </Button>
        </div>
        
        <div className="flex flex-wrap gap-4">
          <div className="w-full">
            <label className="block text-sm font-medium text-gray-700 mb-1">
              Analysis Type
            </label>
            <select
              className="w-full p-2 border rounded-md"
              value={analysisType}
              onChange={(e) => setAnalysisType(e.target.value)}
              disabled={isLoading}
            >
              <option value="basic_financial">Basic Financial Analysis</option>
              <option value="comprehensive">Comprehensive Analysis</option>
              <option value="ratio_analysis">Financial Ratios</option>
              <option value="trend_analysis">Trend Analysis</option>
              <option value="benchmarking">Industry Benchmarking</option>
            </select>
          </div>
        </div>
        
        <Collapsible 
          open={isAdvancedOpen} 
          onOpenChange={setIsAdvancedOpen}
          className="border rounded-md p-2"
        >
          <CollapsibleTrigger asChild>
            <Button variant="ghost" className="w-full flex justify-between items-center">
              <div className="flex items-center">
                <Settings className="h-4 w-4 mr-2" />
                <span>Advanced Options</span>
              </div>
              {isAdvancedOpen ? (
                <ChevronUp className="h-4 w-4" />
              ) : (
                <ChevronDown className="h-4 w-4" />
              )}
            </Button>
          </CollapsibleTrigger>
          <CollapsibleContent className="pt-2 space-y-4">
            <div>
              <label className="block text-sm font-medium text-gray-700 mb-1">
                Knowledge Base (Optional)
              </label>
              <Textarea
                placeholder="Enter custom knowledge base information..."
                value={knowledgeBase}
                onChange={(e) => setKnowledgeBase(e.target.value)}
                disabled={isLoading}
                className="min-h-[100px]"
              />
              <p className="text-xs text-gray-500 mt-1">
                Provide domain-specific knowledge to enhance the analysis.
              </p>
            </div>
            
            <div>
              <label className="block text-sm font-medium text-gray-700 mb-1">
                Custom Query (Optional)
              </label>
              <Textarea
                placeholder="Enter a specific query for the document..."
                value={userQuery}
                onChange={(e) => setUserQuery(e.target.value)}
                disabled={isLoading}
                className="min-h-[100px]"
              />
              <p className="text-xs text-gray-500 mt-1">
                Specify a custom question to analyze in the document.
              </p>
            </div>
          </CollapsibleContent>
        </Collapsible>
      </div>
    </div>
  );
}; 
</file>
```

#### src/components/charts/AreaChart\.tsx
*Size: 5.6 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/charts/AreaChart.tsx">
import React from 'react';
import {
  ResponsiveContainer,
  AreaChart as RechartsAreaChart,
  Area,
  XAxis,
  YAxis,
  CartesianGrid,
  Tooltip,
  Legend,
  Label,
  ReferenceLine
} from 'recharts';
import { ChartData } from '@/types/visualization';

interface AreaChartProps {
  data: ChartData;
  height?: number | string;
  width?: number | string;
}

const DEFAULT_COLORS = [
  { stroke: '#8884d8', fill: '#8884d8' },
  { stroke: '#82ca9d', fill: '#82ca9d' },
  { stroke: '#ffc658', fill: '#ffc658' },
  { stroke: '#ff7300', fill: '#ff7300' },
  { stroke: '#0088fe', fill: '#0088fe' },
  { stroke: '#00c49f', fill: '#00c49f' },
  { stroke: '#ffbb28', fill: '#ffbb28' },
  { stroke: '#ff8042', fill: '#ff8042' }
];

const AreaChart: React.FC<AreaChartProps> = ({ data, height = 400, width = '100%' }) => {
  const { config, data: chartData } = data;
  const dataKeys = chartData.length > 0 ? Object.keys(chartData[0]).filter(key => key !== 'name') : [];

  if (!chartData || chartData.length === 0) {
    return (
      <div role="status" aria-label="No data available" className="flex items-center justify-center p-4 bg-gray-50 rounded-lg min-h-[300px]">
        <p className="text-gray-500">No data available</p>
      </div>
    );
  }

  // Calculate min and max values for Y axis
  const allValues = chartData.flatMap(item => 
    dataKeys.map(key => Number(item[key]))
  ).filter(value => !isNaN(value));
  
  const minValue = Math.min(...allValues);
  const maxValue = Math.max(...allValues);
  const hasNegativeValues = minValue < 0;

  return (
    <div className="w-full">
      <div className="mb-4">
        {config.title && (
          <h3 role="heading" aria-level={3} className="text-lg font-semibold text-gray-900">
            {config.title}
          </h3>
        )}
        {config.subtitle && (
          <p role="doc-subtitle" className="text-sm text-gray-500">
            {config.subtitle}
          </p>
        )}
        {config.description && (
          <p role="doc-description" className="text-sm text-gray-500 mt-1">
            {config.description}
          </p>
        )}
      </div>

      <figure style={{ width, height }} role="figure" aria-label={config.title || 'Area Chart'}>
        <ResponsiveContainer>
          <RechartsAreaChart
            data={chartData}
            margin={{ top: 20, right: 30, left: 20, bottom: 20 }}
          >
            <defs>
              {dataKeys.map((key, index) => {
                const color = config.colors?.[index] || DEFAULT_COLORS[index % DEFAULT_COLORS.length].fill;
                return (
                  <linearGradient key={key} id={`color${key}`} x1="0" y1="0" x2="0" y2="1">
                    <stop offset="5%" stopColor={color} stopOpacity={0.8}/>
                    <stop offset="95%" stopColor={color} stopOpacity={0.1}/>
                  </linearGradient>
                );
              })}
            </defs>
            
            <CartesianGrid strokeDasharray="3 3" />
            <XAxis
              dataKey="name"
              height={60}
              tick={{ fill: '#666', fontSize: 12 }}
            >
              {config.xAxisLabel && (
                <Label
                  value={config.xAxisLabel}
                  position="bottom"
                  offset={0}
                  style={{ textAnchor: 'middle', fill: '#666' }}
                />
              )}
            </XAxis>
            <YAxis
              tick={{ fill: '#666', fontSize: 12 }}
              domain={[
                hasNegativeValues ? minValue * 1.1 : 0,
                maxValue * 1.1
              ]}
            >
              {config.yAxisLabel && (
                <Label
                  value={config.yAxisLabel}
                  angle={-90}
                  position="left"
                  style={{ textAnchor: 'middle', fill: '#666' }}
                />
              )}
            </YAxis>
            <Tooltip
              contentStyle={{
                backgroundColor: 'white',
                border: '1px solid #ccc',
                borderRadius: '4px'
              }}
              cursor={{ stroke: '#666', strokeWidth: 1 }}
            />
            {config.showLegend && (
              <Legend
                verticalAlign="top"
                height={36}
                wrapperStyle={{ paddingTop: '10px' }}
              />
            )}
            
            {/* Zero reference line for charts with negative values */}
            {hasNegativeValues && (
              <ReferenceLine y={0} stroke="#666" strokeDasharray="3 3" />
            )}

            {/* Dynamically render areas based on data structure */}
            {dataKeys.map((key, index) => {
              const color = config.colors?.[index] || DEFAULT_COLORS[index % DEFAULT_COLORS.length];
              return (
                <Area
                  key={key}
                  type="monotone"
                  dataKey={key}
                  stroke={color.stroke}
                  fill={`url(#color${key})`}
                  fillOpacity={1}
                  stackId={config.stacked ? 'stack' : undefined}
                  dot={config.showDots ?? false}
                  activeDot={{ r: 6, stroke: color.stroke, strokeWidth: 2 }}
                />
              );
            })}
          </RechartsAreaChart>
        </ResponsiveContainer>
      </figure>

      {config.footer && (
        <p role="doc-footnote" className="text-sm text-gray-500 mt-4">
          {config.footer}
        </p>
      )}
      {config.totalLabel && (
        <p role="doc-footnote" className="text-sm font-medium text-gray-700 mt-2">
          {config.totalLabel}
        </p>
      )}
    </div>
  );
};

export default AreaChart; 
</file>
```

#### src/components/charts/BarChart\.tsx
*Size: 5.0 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/charts/BarChart.tsx">
import React from 'react';
import {
  BarChart as RechartsBarChart,
  Bar,
  XAxis,
  YAxis,
  CartesianGrid,
  Tooltip,
  Legend,
  ResponsiveContainer,
  Label,
} from 'recharts';
import { ChartData, MetricConfig } from '@/types/visualization';
import { formatValue } from '@/utils/formatters';

interface BarChartProps {
  data: ChartData;
  height?: number | string;
  width?: number | string;
}

/**
 * BarChart component for rendering monetary values and comparing quantities
 * Uses Recharts library for rendering the chart
 */
export default function BarChart({ data, height = 400, width = '100%' }: BarChartProps) {
  const { config, chartConfig } = data;
  
  // Extract the keys that should be rendered as bars (all except the category axis)
  // Try different possible keys in order of preference
  const categoryKey = config.xAxisKey || 
                     (config.xAxisLabel ? config.xAxisLabel.toLowerCase() : 'category');
  
  const metricKeys = Object.keys(chartConfig).filter(key => key !== categoryKey);
  
  // Generate bars for each metric with their respective colors
  const bars = metricKeys.map((key) => {
    const metricConfig: MetricConfig = chartConfig[key];
    return (
      <Bar
        key={key}
        dataKey={key}
        name={metricConfig.label}
        fill={metricConfig.color || '#8884d8'}
        stroke={metricConfig.color ? undefined : '#7066bb'}
        strokeWidth={1}
        radius={[4, 4, 0, 0]}
      />
    );
  });

  // Custom tooltip formatter to use metric config for formatting
  const formatTooltip = (value: number, name: string) => {
    // Find the metric config for this bar
    const metricKey = metricKeys.find(key => chartConfig[key].label === name);
    if (metricKey && chartConfig[metricKey]) {
      const metric = chartConfig[metricKey];
      return [formatValue(value, metric.formatter, metric.precision), metric.unit || ''];
    }
    return [value, ''];
  };

  return (
    <div className="w-full overflow-hidden rounded-lg bg-white p-4 shadow-sm">
      {config.title && (
        <div className="mb-4">
          <h3 className="text-lg font-semibold text-gray-800">{config.title}</h3>
          {config.subtitle && <p className="text-sm text-gray-500">{config.subtitle}</p>}
          {config.description && !config.subtitle && (
            <p className="text-sm text-gray-500">{config.description}</p>
          )}
          {config.footer && (
            <p className="text-xs text-gray-400 mt-1">{config.footer}</p>
          )}
        </div>
      )}
      
      <ResponsiveContainer width={width} height={height}>
        <RechartsBarChart
          data={data.data}
          margin={{ top: 10, right: 30, left: 20, bottom: 30 }}
          barSize={config.stack ? 20 : 40}
          barGap={config.stack ? 0 : 4}
          barCategoryGap={config.stack ? '10%' : '20%'}
        >
          {config.showGrid !== false && <CartesianGrid strokeDasharray="3 3" vertical={false} />}
          
          <XAxis
            dataKey={categoryKey}
            scale="point"
            padding={{ left: 20, right: 20 }}
            tick={{ fontSize: 12 }}
            tickLine={true}
            axisLine={true}
          >
            {config.xAxisLabel && <Label value={config.xAxisLabel} offset={-10} position="insideBottom" />}
          </XAxis>
          
          <YAxis
            tick={{ fontSize: 12 }}
            tickLine={true}
            axisLine={true}
            tickFormatter={(value) => {
              // Format Y-axis ticks based on the first metric's config
              if (metricKeys.length > 0) {
                const firstMetric = chartConfig[metricKeys[0]];
                return formatValue(value, firstMetric.formatter, firstMetric.precision);
              }
              return value;
            }}
          >
            {config.yAxisLabel && <Label value={config.yAxisLabel} angle={-90} position="insideLeft" style={{ textAnchor: 'middle' }} />}
          </YAxis>
          
          <Tooltip
            formatter={formatTooltip}
            contentStyle={{
              backgroundColor: 'rgba(255, 255, 255, 0.95)',
              border: '1px solid #e2e8f0',
              borderRadius: '6px',
              boxShadow: '0 2px 4px rgba(0, 0, 0, 0.1)',
              padding: '8px 12px',
            }}
          />
          
          {config.showLegend && (
            <Legend
              verticalAlign={config.legendPosition === 'top' || config.legendPosition === 'bottom' ? config.legendPosition : 'bottom'}
              align={config.legendPosition === 'left' || config.legendPosition === 'right' ? config.legendPosition : 'center'}
              iconType="circle"
              iconSize={10}
              wrapperStyle={{ paddingTop: '10px' }}
            />
          )}
          
          {bars}
        </RechartsBarChart>
      </ResponsiveContainer>

      {/* Display totalLabel if provided */}
      {config.totalLabel && (
        <div className="mt-2 text-sm text-gray-500 text-center">
          {config.totalLabel}
        </div>
      )}
    </div>
  );
} 
</file>
```

#### src/components/charts/ChartRenderer\.tsx
*Size: 3.0 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/charts/ChartRenderer.tsx">
import React from 'react';
import type { ChartData, ChartSeries } from '@/types/visualization';
import { EnhancedChart } from '../visualization/EnhancedChart';

interface ChartRendererProps {
  data: ChartData;
  className?: string;
  onDataPointClick?: (dataPoint: any) => void;
}

/**
 * ChartRenderer component acts as a dispatcher for different chart types
 * It renders the appropriate chart component based on the chartType in the data
 * Supports both legacy format and tool-based chart format
 */
const ChartRenderer: React.FC<ChartRendererProps> = ({ 
  data, 
  className = '',
  onDataPointClick
}) => {
  // Extract data from chart data
  const { config, data: chartData, chartType, series } = data;

  // Handle different data formats
  // If we have series data from tool-based format, use it
  // Otherwise, use the original chart data format
  const formattedData = React.useMemo(() => {
    if (series && Array.isArray(series)) {
      // Tool-based format already contains properly formatted series data
      return series;
    } else if (chartData && Array.isArray(chartData)) {
      // Legacy format - we need to transform it for EnhancedChart
      // For bar and line charts, EnhancedChart expects series array
      if (data.chartType === 'bar' || data.chartType === 'line' || data.chartType === 'multiBar') {
        // Extract all keys except the xAxis key
        const xAxisKey = config.xAxisKey;
        if (!xAxisKey || !chartData.length) return chartData;
        
        // Get all data keys excluding the xAxis key
        const firstItem = chartData[0];
        const dataKeys = Object.keys(firstItem).filter(k => k !== xAxisKey);
        
        // Create a series for each data key
        return dataKeys.map(key => {
          const seriesConfig = data.chartConfig?.[key];
          return {
            name: seriesConfig?.label || key,
            color: seriesConfig?.color,
            data: chartData.map(item => ({
              x: item[xAxisKey],
              y: item[key],
              category: item[xAxisKey],
              value: item[key],
              // Include original item data for potential tooltips/interactions
              originalData: item
            }))
          };
        });
      }
    }
    
    // Default: return the original data
    return chartData;
  }, [chartData, config, data.chartType, series]);

  return (
    <div className={`bg-white rounded-lg shadow-sm p-4 ${className}`}>
      {config.title && (
        <div className="mb-4">
          <h3 className="text-lg font-semibold text-gray-900">{config.title}</h3>
          {config.description && (
            <p className="text-sm text-gray-500 mt-1">{config.description}</p>
          )}
        </div>
      )}
      <div className="relative h-[300px]">
        <EnhancedChart 
          data={formattedData}
          chartType={chartType}
          onDataPointClick={onDataPointClick}
          height={300}
          xAxisTitle={data.xAxisTitle}
          yAxisTitle={data.yAxisTitle}
        />
      </div>
    </div>
  );
};

export default ChartRenderer; 
</file>
```

#### src/components/charts/LineChart\.tsx
*Size: 4.9 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/charts/LineChart.tsx">
import React from 'react';
import {
  LineChart as RechartsLineChart,
  Line,
  XAxis,
  YAxis,
  CartesianGrid,
  Tooltip,
  Legend,
  ResponsiveContainer,
  Label,
} from 'recharts';
import { ChartData, MetricConfig } from '@/types/visualization';
import { formatValue } from '@/utils/formatters';

interface LineChartProps {
  data: ChartData;
  height?: number | string;
  width?: number | string;
}

/**
 * LineChart component for rendering trends and time series data
 * Uses Recharts library for rendering the chart
 */
export default function LineChart({ data, height = 400, width = '100%' }: LineChartProps) {
  const { config, chartConfig } = data;
  
  // Extract the keys that should be rendered as lines (all except the category axis)
  const categoryKey = config.xAxisLabel ? config.xAxisLabel.toLowerCase() : 'date';
  const metricKeys = Object.keys(chartConfig).filter(key => key !== categoryKey);
  
  // Generate lines for each metric with their respective colors
  const lines = metricKeys.map((key) => {
    const metricConfig: MetricConfig = chartConfig[key];
    return (
      <Line
        key={key}
        type="monotone"
        dataKey={key}
        name={metricConfig.label}
        stroke={metricConfig.color || '#8884d8'}
        strokeWidth={2}
        dot={{ r: 3, strokeWidth: 1 }}
        activeDot={{ r: 5, strokeWidth: 1 }}
      />
    );
  });

  // Custom tooltip formatter to use metric config for formatting
  const formatTooltip = (value: number, name: string) => {
    // Find the metric config for this line
    const metricKey = metricKeys.find(key => chartConfig[key].label === name);
    if (metricKey && chartConfig[metricKey]) {
      const metric = chartConfig[metricKey];
      return [formatValue(value, metric.formatter, metric.precision), metric.unit];
    }
    return [value, ''];
  };

  return (
    <div className="w-full overflow-hidden rounded-lg bg-white p-4 shadow-sm">
      {config.title && (
        <div className="mb-4">
          <h3 className="text-lg font-semibold text-gray-800">{config.title}</h3>
          {config.subtitle && <p className="text-sm text-gray-500">{config.subtitle}</p>}
        </div>
      )}
      
      <ResponsiveContainer width={width} height={height}>
        <RechartsLineChart
          data={data.data}
          margin={{ top: 10, right: 30, left: 20, bottom: 30 }}
        >
          {config.showGrid !== false && <CartesianGrid strokeDasharray="3 3" />}
          
          <XAxis
            dataKey={categoryKey}
            scale="auto"
            padding={{ left: 10, right: 10 }}
            tick={{ fontSize: 12 }}
            tickLine={true}
            axisLine={true}
          >
            {config.xAxisLabel && <Label value={config.xAxisLabel} offset={-10} position="insideBottom" />}
          </XAxis>
          
          <YAxis
            tick={{ fontSize: 12 }}
            tickLine={true}
            axisLine={true}
            tickFormatter={(value) => {
              // Format Y-axis ticks based on the first metric's config
              if (metricKeys.length > 0) {
                const firstMetric = chartConfig[metricKeys[0]];
                return formatValue(value, firstMetric.formatter, firstMetric.precision);
              }
              return value;
            }}
          >
            {config.yAxisLabel && <Label value={config.yAxisLabel} angle={-90} position="insideLeft" style={{ textAnchor: 'middle' }} />}
          </YAxis>
          
          <Tooltip
            formatter={formatTooltip}
            contentStyle={{
              backgroundColor: 'rgba(255, 255, 255, 0.95)',
              border: '1px solid #e2e8f0',
              borderRadius: '6px',
              boxShadow: '0 2px 4px rgba(0, 0, 0, 0.1)',
              padding: '8px 12px',
            }}
            labelFormatter={(label) => {
              // Format the X-axis label in the tooltip (usually a date)
              if (typeof label === 'string' && label.includes('-')) {
                // If it looks like a date string, format it
                try {
                  const date = new Date(label);
                  return date.toLocaleDateString('en-US', {
                    year: 'numeric',
                    month: 'short',
                    day: 'numeric',
                  });
                } catch (e) {
                  return label;
                }
              }
              return label;
            }}
          />
          
          {config.showLegend && (
            <Legend
              verticalAlign={config.legendPosition === 'top' || config.legendPosition === 'bottom' ? config.legendPosition : 'bottom'}
              align={config.legendPosition === 'left' || config.legendPosition === 'right' ? config.legendPosition : 'center'}
              iconType="line"
              iconSize={10}
              wrapperStyle={{ paddingTop: '10px' }}
            />
          )}
          
          {lines}
        </RechartsLineChart>
      </ResponsiveContainer>
    </div>
  );
} 
</file>
```

#### src/components/charts/MultiBarChart\.tsx
*Size: 4.6 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/charts/MultiBarChart.tsx">
import React from 'react';
import {
  ResponsiveContainer,
  BarChart,
  Bar,
  XAxis,
  YAxis,
  CartesianGrid,
  Tooltip,
  Legend,
  Label,
  ReferenceLine
} from 'recharts';
import { ChartData } from '@/types/visualization';

interface MultiBarChartProps {
  data: ChartData;
  height?: number | string;
  width?: number | string;
}

const DEFAULT_COLORS = [
  '#8884d8', '#82ca9d', '#ffc658', '#ff7300', '#0088fe', '#00c49f',
  '#ffbb28', '#ff8042', '#a4de6c', '#d0ed57'
];

const MultiBarChart: React.FC<MultiBarChartProps> = ({ data, height = 400, width = '100%' }) => {
  const { config, data: chartData } = data;
  const dataKeys = chartData.length > 0 ? Object.keys(chartData[0]).filter(key => key !== 'name') : [];

  if (!chartData || chartData.length === 0) {
    return (
      <div role="status" aria-label="No data available" className="flex items-center justify-center p-4 bg-gray-50 rounded-lg min-h-[300px]">
        <p className="text-gray-500">No data available</p>
      </div>
    );
  }

  // Calculate min and max values for Y axis
  const allValues = chartData.flatMap(item => 
    dataKeys.map(key => Number(item[key]))
  ).filter(value => !isNaN(value));
  
  const minValue = Math.min(...allValues);
  const maxValue = Math.max(...allValues);
  const hasNegativeValues = minValue < 0;

  return (
    <div className="w-full">
      <div className="mb-4">
        {config.title && (
          <h3 role="heading" aria-level={3} className="text-lg font-semibold text-gray-900">
            {config.title}
          </h3>
        )}
        {config.subtitle && (
          <p role="doc-subtitle" className="text-sm text-gray-500">
            {config.subtitle}
          </p>
        )}
        {config.description && (
          <p role="doc-description" className="text-sm text-gray-500 mt-1">
            {config.description}
          </p>
        )}
      </div>

      <figure style={{ width, height }} role="figure" aria-label={config.title || 'Multi Bar Chart'}>
        <ResponsiveContainer>
          <BarChart
            data={chartData}
            margin={{ top: 20, right: 30, left: 20, bottom: 20 }}
          >
            <CartesianGrid strokeDasharray="3 3" />
            <XAxis
              dataKey="name"
              height={60}
              tick={{ fill: '#666', fontSize: 12 }}
            >
              {config.xAxisLabel && (
                <Label
                  value={config.xAxisLabel}
                  position="bottom"
                  offset={0}
                  style={{ textAnchor: 'middle', fill: '#666' }}
                />
              )}
            </XAxis>
            <YAxis
              tick={{ fill: '#666', fontSize: 12 }}
              domain={[
                hasNegativeValues ? minValue * 1.1 : 0,
                maxValue * 1.1
              ]}
            >
              {config.yAxisLabel && (
                <Label
                  value={config.yAxisLabel}
                  angle={-90}
                  position="left"
                  style={{ textAnchor: 'middle', fill: '#666' }}
                />
              )}
            </YAxis>
            <Tooltip
              contentStyle={{
                backgroundColor: 'white',
                border: '1px solid #ccc',
                borderRadius: '4px'
              }}
              cursor={{ fill: 'rgba(0, 0, 0, 0.1)' }}
            />
            {config.showLegend && (
              <Legend
                verticalAlign="top"
                height={36}
                wrapperStyle={{ paddingTop: '10px' }}
              />
            )}
            
            {/* Zero reference line for charts with negative values */}
            {hasNegativeValues && (
              <ReferenceLine y={0} stroke="#666" strokeDasharray="3 3" />
            )}

            {/* Dynamically render bars based on data structure */}
            {dataKeys.map((key, index) => (
              <Bar
                key={key}
                dataKey={key}
                fill={config.colors?.[index] || DEFAULT_COLORS[index % DEFAULT_COLORS.length]}
                radius={[4, 4, 0, 0]}
                maxBarSize={60}
                stackId={config.stacked ? 'stack' : undefined}
              />
            ))}
          </BarChart>
        </ResponsiveContainer>
      </figure>

      {config.footer && (
        <p role="doc-footnote" className="text-sm text-gray-500 mt-4">
          {config.footer}
        </p>
      )}
      {config.totalLabel && (
        <p role="doc-footnote" className="text-sm font-medium text-gray-700 mt-2">
          {config.totalLabel}
        </p>
      )}
    </div>
  );
};

export default MultiBarChart; 
</file>
```

#### src/components/charts/PieChart\.tsx
*Size: 2.0 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/charts/PieChart.tsx">
import React from 'react';
import { PieChart as RechartsPieChart, Pie, Cell, ResponsiveContainer, Legend, Tooltip } from 'recharts';
import { ChartData } from '@/types/visualization';

const COLORS = ['#0088FE', '#00C49F', '#FFBB28', '#FF8042'];

interface PieChartProps {
  data: ChartData;
  height?: number | string;
  width?: number | string;
}

const PieChart: React.FC<PieChartProps> = ({ data, height = 400, width = '100%' }) => {
  const { config, data: chartData } = data;

  if (!chartData || chartData.length === 0) {
    return (
      <div className="flex items-center justify-center p-8 bg-gray-50 rounded-lg min-h-[300px]">
        <p role="status" className="text-gray-500">No pie chart data available</p>
      </div>
    );
  }

  return (
    <div className="w-full">
      <div className="mb-4">
        <h3 className="text-lg font-semibold text-gray-900">{config.title}</h3>
        {config.subtitle && (
          <p className="text-sm text-gray-500">{config.subtitle}</p>
        )}
        {config.description && (
          <p className="text-sm text-gray-500 mt-1">{config.description}</p>
        )}
      </div>

      <figure style={{ width, height }}>
        <ResponsiveContainer>
          <RechartsPieChart>
            <Pie
              data={chartData}
              dataKey="value"
              nameKey="name"
              cx="50%"
              cy="50%"
              outerRadius={80}
              label
            >
              {chartData.map((entry, index) => (
                <Cell key={`cell-${index}`} fill={COLORS[index % COLORS.length]} />
              ))}
            </Pie>
            {config.showLegend && <Legend />}
            <Tooltip />
          </RechartsPieChart>
        </ResponsiveContainer>
      </figure>

      {config.footer && (
        <p className="text-sm text-gray-500 mt-4">{config.footer}</p>
      )}
      {config.totalLabel && (
        <p className="text-sm font-medium text-gray-700 mt-2">{config.totalLabel}</p>
      )}
    </div>
  );
};

export default PieChart; 
</file>
```

#### src/components/charts/ScatterChart\.tsx
*Size: 4.3 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/charts/ScatterChart.tsx">
import React from 'react';
import {
  ResponsiveContainer,
  ScatterChart as RechartsScatterChart,
  Scatter,
  XAxis,
  YAxis,
  ZAxis,
  CartesianGrid,
  Tooltip,
  Legend,
  ReferenceLine
} from 'recharts';
import { ChartData } from '@/types/visualization';
import { formatValue } from '@/utils/formatters';

interface ScatterChartProps {
  data: ChartData;
  height?: number | string;
  width?: number | string;
}

/**
 * Scatter Chart component for visualizing correlation between two variables
 */
export default function ScatterChart({ data, height = 400, width = '100%' }: ScatterChartProps) {
  const { config, data: chartData, chartConfig } = data;
  
  if (!chartData || chartData.length === 0) {
    return (
      <div role="status" aria-label="No data available" className="flex items-center justify-center p-4 bg-gray-50 rounded-lg min-h-[300px]">
        <p className="text-gray-500">No data available</p>
      </div>
    );
  }

  // Determine x and y axis keys from config or use first two numeric properties
  const xAxisKey = config.xAxisKey || Object.keys(chartData[0]).find(
    key => typeof chartData[0][key] === 'number' && key !== 'z'
  ) || 'x';
  
  const yAxisKey = Object.keys(chartData[0]).find(
    key => typeof chartData[0][key] === 'number' && key !== xAxisKey && key !== 'z'
  ) || 'y';
  
  // Check if we have a z-axis value for bubble size
  const hasZValue = chartData.some(item => 'z' in item && typeof item.z === 'number');

  // Format tooltip value based on the metric config
  const formatTooltipValue = (value: any, name: string) => {
    const metricConfig = chartConfig[name];
    if (metricConfig) {
      return [formatValue(value, metricConfig.formatter, metricConfig.precision), metricConfig.unit || ''];
    }
    return [value, ''];
  };

  return (
    <div className="w-full">
      {/* Title section */}
      <div className="mb-4">
        {config.title && (
          <h3 role="heading" aria-level={3} className="text-lg font-semibold text-gray-900">{config.title}</h3>
        )}
        {config.subtitle && (
          <p role="doc-subtitle" className="text-sm text-gray-500">{config.subtitle}</p>
        )}
        {config.description && !config.subtitle && (
          <p role="doc-description" className="text-sm text-gray-500">{config.description}</p>
        )}
      </div>

      {/* Chart container */}
      <div role="figure" aria-label={`Scatter plot of ${config.title || 'data points'}`} style={{ width, height }}>
        <ResponsiveContainer>
          <RechartsScatterChart margin={{ top: 20, right: 30, left: 20, bottom: 20 }}>
            <CartesianGrid strokeDasharray="3 3" />
            <XAxis 
              dataKey={xAxisKey} 
              name={config.xAxisLabel || xAxisKey} 
              label={{ value: config.xAxisLabel || xAxisKey, position: 'insideBottom', offset: -5 }}
              aria-label={config.xAxisLabel || xAxisKey}
            />
            <YAxis 
              dataKey={yAxisKey} 
              name={config.yAxisLabel || yAxisKey}
              label={{ value: config.yAxisLabel || yAxisKey, angle: -90, position: 'insideLeft' }}
              aria-label={config.yAxisLabel || yAxisKey}
            />
            
            {hasZValue && <ZAxis dataKey="z" range={[50, 500]} />}
            
            <Tooltip 
              formatter={formatTooltipValue}
              labelFormatter={(label) => `${config.xAxisLabel || xAxisKey}: ${label}`}
            />
            
            {config.showLegend !== false && <Legend />}
            
            {/* Add reference lines at x=0 and y=0 if needed */}
            <ReferenceLine x={0} stroke="#666" />
            <ReferenceLine y={0} stroke="#666" />
            
            <Scatter 
              name={config.title || "Data"} 
              data={chartData} 
              fill="#4F46E5"
              aria-label={`Scatter plot points for ${config.title || 'data'}`}
            />
          </RechartsScatterChart>
        </ResponsiveContainer>
      </div>

      {/* Footer section */}
      {config.footer && (
        <p role="doc-footnote" className="mt-2 text-xs text-gray-500 italic">{config.footer}</p>
      )}

      {/* Total section */}
      {config.totalLabel && (
        <p role="doc-footnote" className="mt-4 text-sm font-medium text-gray-900">{config.totalLabel}</p>
      )}
    </div>
  );
} 
</file>
```

#### src/components/chat/ChatInterface\.tsx
*Size: 7.4 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/chat/ChatInterface.tsx">
'use client';

import { useState, useRef, useEffect } from 'react';
import { Message, Citation } from '@/types';
import { conversationApi } from '@/lib/api/conversation';
import { Loader2, Send, FileText } from 'lucide-react';
import { MessageRenderer } from './MessageRenderer';

interface ChatInterfaceProps {
  messages: Message[];
  onSendMessage: (message: string) => Promise<void>;
  activeDocuments?: string[];
  isLoading?: boolean;
  onCitationClick?: (citation: Citation) => void;
  onNavigateToHighlight?: (citation: Citation) => void;
}

export function ChatInterface({ 
  messages, 
  onSendMessage,
  activeDocuments = [],
  isLoading = false,
  onCitationClick,
  onNavigateToHighlight
}: ChatInterfaceProps) {
  const [inputValue, setInputValue] = useState('');
  const [isSubmitting, setIsSubmitting] = useState(false);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const textareaRef = useRef<HTMLTextAreaElement>(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  const handleSubmit = async (e?: React.FormEvent) => {
    if (e) e.preventDefault();
    
    if (!inputValue.trim() || isSubmitting) return;
    
    try {
      setIsSubmitting(true);
      await onSendMessage(inputValue);
      setInputValue('');
      // Resize textarea to default height after sending
      if (textareaRef.current) {
        textareaRef.current.style.height = 'auto';
      }
    } catch (error) {
      console.error('Error sending message:', error);
    } finally {
      setIsSubmitting(false);
    }
  };

  const handleKeyDown = (e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSubmit();
    }
  };

  const adjustTextareaHeight = () => {
    const textarea = textareaRef.current;
    if (textarea) {
      textarea.style.height = 'auto';
      textarea.style.height = `${Math.min(textarea.scrollHeight, 150)}px`;
    }
  };

  const handleCitationClick = (citation: Citation) => {
    if (!activeDocuments) return;
    
    // Navigate to the citation in the document
    if (onNavigateToHighlight && citation.rects && citation.rects.length > 0) {
      onNavigateToHighlight(citation);
    }
  };

  const renderMessage = (message: Message) => {
    // Special case for loading message
    if (message.role === 'system' && message.content === 'AI is thinking...') {
      return (
        <div key={message.id} className="flex justify-start">
          <div className="max-w-[80%] rounded-lg px-4 py-2 bg-gray-100 text-gray-900 flex items-center">
            <Loader2 className="h-5 w-5 text-indigo-600 animate-spin mr-2" />
            <span>Analyzing document...</span>
          </div>
        </div>
      );
    }

    return (
      <div 
        key={message.id} 
        className={`flex ${message.role === 'user' ? 'justify-end' : 'justify-start'} mb-4`}
      >
        <div 
          className={`max-w-[80%] rounded-lg px-4 py-3 ${
            message.role === 'user' 
              ? 'bg-indigo-600 text-white' 
              : message.role === 'system' 
                ? 'bg-gray-100 text-gray-900 italic' 
                : 'bg-white border border-gray-200 text-gray-900'
          }`}
        >
          <MessageRenderer 
            message={message} 
            onCitationClick={handleCitationClick}
          />
        </div>
      </div>
    );
  };

  return (
    <div className="flex flex-col h-full">
      <div className="p-4 border-b">
        <h2 className="text-lg font-semibold">Claude Assistant</h2>
        <p className="text-sm text-gray-600">
          Ask questions about your financial documents
        </p>
      </div>

      <div className="flex-1 overflow-y-auto p-4 space-y-4 bg-gray-50">
        {messages.length === 0 ? (
          <div className="flex flex-col items-center justify-center h-full text-center text-gray-500 p-6">
            <FileText className="h-12 w-12 mb-4 text-gray-400" />
            <h3 className="font-medium text-lg text-gray-900 mb-1">No messages yet</h3>
            <p className="mb-4">Start a conversation by sending a message below.</p>
            
            <div className="text-sm text-left w-full max-w-md space-y-2">
              <p className="font-medium">Try asking:</p>
              <button 
                onClick={() => setInputValue("What is the company's revenue for last quarter?")}
                className="p-2 bg-white border rounded-md text-left w-full hover:bg-gray-50"
              >
                What is the company's revenue for last quarter?
              </button>
              <button 
                onClick={() => setInputValue("Calculate the current ratio from the balance sheet.")}
                className="p-2 bg-white border rounded-md text-left w-full hover:bg-gray-50"
              >
                Calculate the current ratio from the balance sheet.
              </button>
              <button 
                onClick={() => setInputValue("How has the gross margin changed over time?")}
                className="p-2 bg-white border rounded-md text-left w-full hover:bg-gray-50"
              >
                How has the gross margin changed over time?
              </button>
            </div>
          </div>
        ) : (
          messages.map((message) => renderMessage(message))
        )}
        {isLoading && (
          <div className="flex justify-start">
            <div className="bg-white border rounded-lg rounded-bl-none p-4 max-w-[80%] flex items-center">
              <Loader2 className="h-4 w-4 animate-spin mr-2" />
              <span className="text-sm text-gray-500">Claude is thinking...</span>
            </div>
          </div>
        )}
        <div ref={messagesEndRef} />
      </div>

      <div className="p-4 border-t">
        <form onSubmit={handleSubmit} className="flex items-end space-x-2">
          <div className="flex-1 relative">
            <textarea
              ref={textareaRef}
              value={inputValue}
              onChange={(e) => {
                setInputValue(e.target.value);
                adjustTextareaHeight();
              }}
              onKeyDown={handleKeyDown}
              placeholder="Type your message..."
              className="w-full border rounded-md p-3 pr-10 max-h-[150px] min-h-[44px] resize-none focus:outline-none focus:ring-2 focus:ring-blue-500"
              disabled={isSubmitting}
            />
            {activeDocuments && activeDocuments.length > 0 && (
              <div className="absolute bottom-full mb-1 left-0 text-xs text-gray-500">
                <span className="bg-gray-100 px-1 py-0.5 rounded">
                  Using {activeDocuments.length} document{activeDocuments.length !== 1 ? 's' : ''}
                </span>
              </div>
            )}
          </div>
          <button
            type="submit"
            disabled={!inputValue.trim() || isSubmitting}
            className="bg-blue-500 text-white p-3 rounded-full hover:bg-blue-600 focus:outline-none focus:ring-2 focus:ring-blue-500 disabled:opacity-50 disabled:cursor-not-allowed h-[44px] w-[44px] flex items-center justify-center"
          >
            {isSubmitting ? (
              <Loader2 className="h-5 w-5 animate-spin" />
            ) : (
              <Send className="h-5 w-5" />
            )}
          </button>
        </form>
      </div>
    </div>
  );
}
</file>
```

#### src/components/chat/FinancialTerms\.tsx
*Size: 6.9 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/chat/FinancialTerms.tsx">
'use client';

import React, { useState, useEffect } from 'react';
import { Info } from 'lucide-react';
import { ExpandableContent } from './InteractiveElements';

// Financial terms with their explanations
interface FinancialTerm {
  term: string;
  explanation: string;
  category: 'basic' | 'intermediate' | 'advanced';
}

// Sample financial terms dictionary - in a production app, this would come from an API/database
const FINANCIAL_TERMS: FinancialTerm[] = [
  {
    term: 'EBITDA',
    explanation: 'Earnings Before Interest, Taxes, Depreciation, and Amortization. A measure of a company\'s overall financial performance and is used as an alternative to net income in some circumstances.',
    category: 'intermediate'
  },
  {
    term: 'ROI',
    explanation: 'Return on Investment. A performance measure used to evaluate the efficiency or profitability of an investment or compare the efficiency of several different investments.',
    category: 'basic'
  },
  {
    term: 'P/E Ratio',
    explanation: 'Price-to-Earnings Ratio. The ratio for valuing a company that measures its current share price relative to its per-share earnings (EPS).',
    category: 'intermediate'
  },
  {
    term: 'DCF',
    explanation: 'Discounted Cash Flow. A valuation method used to estimate the value of an investment based on its expected future cash flows.',
    category: 'advanced'
  },
  {
    term: 'CAGR',
    explanation: 'Compound Annual Growth Rate. The rate of return that would be required for an investment to grow from its beginning balance to its ending balance, assuming the profits were reinvested.',
    category: 'intermediate'
  },
  {
    term: 'Leverage',
    explanation: 'The use of borrowed money (debt) to finance assets. Companies with high leverage are considered riskier investments as they have higher debt levels compared to their assets or equity.',
    category: 'basic'
  },
  {
    term: 'Liquidity',
    explanation: 'The ease with which an asset can be converted into cash without significantly affecting its market price. High liquidity means assets can be quickly sold at fair market value.',
    category: 'basic'
  },
  {
    term: 'Market Cap',
    explanation: 'Market Capitalization. The total dollar value of a company\'s outstanding shares of stock. Calculated by multiplying the total number of shares by the current market price of one share.',
    category: 'basic'
  }
];

// Component for displaying detected financial terms
export interface FinancialTermsProps {
  content: string;
}

export const FinancialTermsDetector: React.FC<FinancialTermsProps> = ({ content }) => {
  const [detectedTerms, setDetectedTerms] = useState<FinancialTerm[]>([]);

  // Detect financial terms in the content
  useEffect(() => {
    const foundTerms: FinancialTerm[] = [];
    
    // Check for each term in the content
    FINANCIAL_TERMS.forEach(term => {
      // Create regex to find the term as a whole word
      const regex = new RegExp(`\\b${term.term}\\b`, 'gi');
      if (regex.test(content)) {
        // Only add unique terms
        if (!foundTerms.find(t => t.term === term.term)) {
          foundTerms.push(term);
        }
      }
    });
    
    setDetectedTerms(foundTerms);
  }, [content]);

  // If no terms detected, don't render anything
  if (detectedTerms.length === 0) {
    return null;
  }
  
  return (
    <div className="mt-4">
      <ExpandableContent 
        summary={
          <div className="flex items-center">
            <Info className="h-4 w-4 mr-2 text-blue-500" />
            <span>Financial Terms Explained ({detectedTerms.length})</span>
          </div>
        }
        defaultExpanded={false}
      >
        <div className="space-y-3">
          {detectedTerms.map((term, index) => (
            <div key={index} className="p-3 bg-blue-50 rounded-md">
              <h4 className="font-medium text-blue-700">{term.term}</h4>
              <p className="text-sm text-gray-700 mt-1">{term.explanation}</p>
              <div className="mt-1">
                <span className={`text-xs px-2 py-0.5 rounded-full ${
                  term.category === 'basic' 
                    ? 'bg-green-100 text-green-800' 
                    : term.category === 'intermediate'
                    ? 'bg-yellow-100 text-yellow-800'
                    : 'bg-red-100 text-red-800'
                }`}>
                  {term.category.charAt(0).toUpperCase() + term.category.slice(1)}
                </span>
              </div>
            </div>
          ))}
        </div>
      </ExpandableContent>
    </div>
  );
};

// Inline term highlighting component
export interface HighlightedTermProps {
  children: React.ReactNode;
  term: FinancialTerm;
}

export const HighlightedTerm: React.FC<HighlightedTermProps> = ({ children, term }) => {
  const [showTooltip, setShowTooltip] = useState(false);
  
  return (
    <span 
      className="relative inline-block text-blue-600 border-b border-dotted border-blue-400 cursor-help"
      onMouseEnter={() => setShowTooltip(true)}
      onMouseLeave={() => setShowTooltip(false)}
    >
      <span>{children}</span>
      {showTooltip && (
        <span className="absolute bottom-full left-0 mb-2 p-2 bg-white border border-gray-200 rounded shadow-lg z-10 max-w-xs block">
          <span className="font-medium text-blue-700 block">{term.term}</span>
          <span className="text-xs text-gray-700 mt-1 block">{term.explanation}</span>
        </span>
      )}
    </span>
  );
};

// Function to process text and highlight financial terms
export function processFinancialTerms(text: string): React.ReactNode {
  if (!text) return '';
  
  // Find all financial terms in the text with their positions
  const termMatches: Array<{
    term: FinancialTerm;
    index: number;
    length: number;
  }> = [];
  
  // Find all matches for each term
  FINANCIAL_TERMS.forEach(term => {
    const regex = new RegExp(`\\b${term.term}\\b`, 'gi');
    let match;
    
    while ((match = regex.exec(text)) !== null) {
      termMatches.push({
        term,
        index: match.index,
        length: match[0].length
      });
    }
  });
  
  // Sort matches by their position in the text
  termMatches.sort((a, b) => a.index - b.index);
  
  // If no matches, return the original text
  if (termMatches.length === 0) {
    return text;
  }
  
  // Build an array of text parts and highlighted terms
  const result: React.ReactNode[] = [];
  let lastIndex = 0;
  
  termMatches.forEach((match, i) => {
    // Add text before the current match
    if (match.index > lastIndex) {
      result.push(text.substring(lastIndex, match.index));
    }
    
    // Add the highlighted term
    result.push(
      <HighlightedTerm key={`term-${i}`} term={match.term}>
        {text.substring(match.index, match.index + match.length)}
      </HighlightedTerm>
    );
    
    // Update the last index
    lastIndex = match.index + match.length;
  });
  
  // Add any remaining text after the last match
  if (lastIndex < text.length) {
    result.push(text.substring(lastIndex));
  }
  
  return result;
};
</file>
```

#### src/components/chat/InteractiveElements\.tsx
*Size: 5.1 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/chat/InteractiveElements.tsx">
'use client';

import React, { useState } from 'react';
import { ChevronDown, ChevronUp, ThumbsUp, ThumbsDown, Copy, CheckCircle2, BarChart } from 'lucide-react';

// Types for the various interactive elements
export type SuggestionAction = {
  label: string;
  action: () => void;
  icon?: React.ReactNode;
  variant?: 'default' | 'primary' | 'outline' | 'secondary';
};

export type ExpandableContentProps = {
  summary: React.ReactNode;
  children: React.ReactNode;
  defaultExpanded?: boolean;
};

export type FeedbackProps = {
  messageId: string;
  onFeedback: (messageId: string, isPositive: boolean) => void;
};

export type AnalysisActionProps = {
  documentIds: string[];
  onRequestAnalysis: (documentIds: string[]) => void;
};

// Suggestion Chips component
export const SuggestionChips = ({ suggestions }: { suggestions: SuggestionAction[] }) => {
  return (
    <div className="flex flex-wrap gap-2 mt-3">
      {suggestions.map((suggestion, index) => (
        <button
          key={index}
          onClick={suggestion.action}
          className={`inline-flex items-center px-3 py-1 rounded-md text-sm transition-colors ${
            suggestion.variant === 'primary'
              ? 'bg-indigo-600 text-white hover:bg-indigo-700'
              : suggestion.variant === 'outline'
              ? 'border border-gray-300 text-gray-700 hover:bg-gray-50'
              : suggestion.variant === 'secondary'
              ? 'bg-gray-100 text-gray-800 hover:bg-gray-200'
              : 'bg-white border border-gray-200 text-gray-800 hover:bg-gray-50'
          }`}
        >
          {suggestion.icon && <span className="mr-1.5">{suggestion.icon}</span>}
          {suggestion.label}
        </button>
      ))}
    </div>
  );
};

// Expandable Content component
export const ExpandableContent = ({ summary, children, defaultExpanded = false }: ExpandableContentProps) => {
  const [isExpanded, setIsExpanded] = useState(defaultExpanded);

  return (
    <div className="mt-2 border border-gray-200 rounded-md overflow-hidden">
      <button
        onClick={() => setIsExpanded(!isExpanded)}
        className="w-full px-4 py-2 text-left bg-gray-50 hover:bg-gray-100 flex justify-between items-center"
      >
        <span className="font-medium">{summary}</span>
        {isExpanded ? (
          <ChevronUp className="h-4 w-4 text-gray-500" />
        ) : (
          <ChevronDown className="h-4 w-4 text-gray-500" />
        )}
      </button>
      {isExpanded && <div className="p-4 bg-white">{children}</div>}
    </div>
  );
};

// Message Feedback component
export const MessageFeedback = ({ messageId, onFeedback }: FeedbackProps) => {
  const [feedback, setFeedback] = useState<'positive' | 'negative' | null>(null);

  const handleFeedback = (isPositive: boolean) => {
    const feedbackType = isPositive ? 'positive' : 'negative';
    setFeedback(feedbackType);
    onFeedback(messageId, isPositive);
  };

  return (
    <div className="flex items-center space-x-2 mt-2">
      <span className="text-xs text-gray-500">Was this helpful?</span>
      <button
        onClick={() => handleFeedback(true)}
        className={`p-1 rounded-md ${
          feedback === 'positive' ? 'bg-green-100 text-green-600' : 'text-gray-400 hover:text-gray-600'
        }`}
        aria-label="Thumbs up"
      >
        <ThumbsUp className="h-4 w-4" />
      </button>
      <button
        onClick={() => handleFeedback(false)}
        className={`p-1 rounded-md ${
          feedback === 'negative' ? 'bg-red-100 text-red-600' : 'text-gray-400 hover:text-gray-600'
        }`}
        aria-label="Thumbs down"
      >
        <ThumbsDown className="h-4 w-4" />
      </button>
    </div>
  );
};

// Copy to Clipboard component
export const CopyToClipboard = ({ text }: { text: string }) => {
  const [copied, setCopied] = useState(false);

  const handleCopy = async () => {
    try {
      await navigator.clipboard.writeText(text);
      setCopied(true);
      setTimeout(() => setCopied(false), 2000);
    } catch (err) {
      console.error('Failed to copy text: ', err);
    }
  };

  return (
    <button
      onClick={handleCopy}
      className="p-1 rounded-md text-gray-400 hover:text-gray-600 hover:bg-gray-100"
      aria-label="Copy to clipboard"
    >
      {copied ? (
        <CheckCircle2 className="h-4 w-4 text-green-500" />
      ) : (
        <Copy className="h-4 w-4" />
      )}
    </button>
  );
};

// Analysis Request button
export const AnalysisAction = ({ documentIds, onRequestAnalysis }: AnalysisActionProps) => {
  return (
    <button
      onClick={() => onRequestAnalysis(documentIds)}
      className="mt-3 inline-flex items-center px-3 py-1.5 rounded-md text-sm bg-blue-50 text-blue-700 hover:bg-blue-100 border border-blue-200"
    >
      <BarChart className="h-4 w-4 mr-1.5" />
      Generate Financial Analysis
    </button>
  );
};

// Message Actions container
export const MessageActions = ({ 
  children,
  className = ""
}: { 
  children: React.ReactNode;
  className?: string;
}) => {
  return (
    <div className={`flex items-center justify-end space-x-2 mt-1 ${className}`}>
      {children}
    </div>
  );
};
</file>
```

#### src/components/chat/MarkdownRenderer\.tsx
*Size: 12.4 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/chat/MarkdownRenderer.tsx">
'use client';

import React, { useMemo } from 'react';
import ReactMarkdown from 'react-markdown';
import { Prism as SyntaxHighlighter } from 'react-syntax-highlighter';
import { nord } from 'react-syntax-highlighter/dist/esm/styles/prism';
import remarkGfm from 'remark-gfm';
import { ExternalLink } from 'lucide-react';
import { Citation, Message } from '@/types';
import { 
  CopyToClipboard, 
  MessageActions, 
  SuggestionChips, 
  ExpandableContent 
} from './InteractiveElements';
import type { ComponentPropsWithoutRef } from 'react';
import { Components } from 'react-markdown';
import { useRouter } from 'next/navigation';
import { FinancialTermsDetector, processFinancialTerms } from './FinancialTerms';
import { processMessageReferences } from './MessageReference';

interface MarkdownRendererProps {
  content: string;
  citations?: Citation[];
  onCitationClick?: (citation: Citation) => void;
  suggestions?: Array<{
    label: string;
    action: () => void;
    variant?: 'default' | 'primary' | 'outline' | 'secondary';
  }>;
  expandableContent?: {
    summary: string;
    content: string;
    defaultExpanded?: boolean;
  }[];
  parentMessages?: Message[];
  onMessageReferenceClick?: (messageId: string) => void;
  enableFinancialTerms?: boolean;
}

export function MarkdownRenderer({ 
  content, 
  citations = [], 
  onCitationClick,
  suggestions = [],
  expandableContent = [],
  parentMessages = [],
  onMessageReferenceClick = () => {},
  enableFinancialTerms = true
}: MarkdownRendererProps) {
  const router = useRouter();

  // Create a map of citation IDs to the actual citation objects
  const citationMap = useMemo(() => {
    return citations.reduce((map, citation) => {
      map[citation.id] = citation;
      return map;
    }, {} as Record<string, Citation>);
  }, [citations]);

  // Create a mapping of citation text to citation ID for highlighting
  const citationTextToId = useMemo(() => {
    return citations.reduce((map, citation) => {
      map[citation.text] = citation.id;
      return map;
    }, {} as Record<string, string>);
  }, [citations]);

  // Function to handle citation click and navigation
  const handleCitationClick = (citation: Citation) => {
    // Call the original onCitationClick callback if provided
    if (onCitationClick) {
      onCitationClick(citation);
    }

    // Navigate to the PDF viewer with the document and highlight information
    router.push(`/pdf-viewer/${citation.documentId}?highlightId=${citation.highlightId}&page=${citation.page}`);
  };

  // Function to find citations within a text node and also process financial terms
  const processCitations = (text: string) => {
    if (!citations.length && !enableFinancialTerms && !parentMessages.length) return text;

    // Sort citations by position in the text to ensure correct order
    const textCitations = citations
      .filter(citation => text.includes(citation.text))
      .sort((a, b) => text.indexOf(a.text) - text.indexOf(b.text));

    // If no citations, process financial terms only
    if (!textCitations.length) {
      // Process message references first
      const referencedParts = processMessageReferences(text, parentMessages, onMessageReferenceClick);
      
      // Process financial terms if enabled
      if (enableFinancialTerms) {
        // If referencedParts is just a single string, process it for financial terms
        if (referencedParts.length === 1 && typeof referencedParts[0] === 'string') {
          return <>{processFinancialTerms(referencedParts[0] as string)}</>;
        }
        
        // If we have multiple parts with references, process each string part for financial terms
        return (
          <>
            {referencedParts.map((part, index) => 
              typeof part === 'string' 
                ? <React.Fragment key={index}>{processFinancialTerms(part)}</React.Fragment>
                : <span key={index}>{part}</span>
            )}
          </>
        );
      }
      
      // If financial terms disabled, just return the referenced parts
      return (
        <>
          {referencedParts.map((part, index) => 
            typeof part === 'string' 
              ? part 
              : <span key={index}>{part}</span>
          )}
        </>
      );
    }

    // Split text and insert citation components
    const parts: React.ReactNode[] = [];
    let lastIndex = 0;

    textCitations.forEach(citation => {
      const index = text.indexOf(citation.text, lastIndex);
      if (index > lastIndex) {
        const beforeText = text.substring(lastIndex, index);
        // Process the text before citation
        if (enableFinancialTerms || parentMessages.length) {
          const referencedParts = processMessageReferences(beforeText, parentMessages, onMessageReferenceClick);
          
          if (enableFinancialTerms) {
            referencedParts.forEach((part, i) => {
              if (typeof part === 'string') {
                parts.push(<React.Fragment key={`before-${index}-${i}`}>{processFinancialTerms(part)}</React.Fragment>);
              } else {
                parts.push(<span key={`before-${index}-${i}`}>{part}</span>);
              }
            });
          } else {
            parts.push(...referencedParts.map((part, i) => 
              typeof part === 'string' 
                ? part 
                : <span key={`before-${index}-${i}`}>{part}</span>
            ));
          }
        } else {
          parts.push(beforeText);
        }
      }

      parts.push(
        <span
          key={citation.id}
          className="inline-flex items-center px-1 py-0.5 rounded bg-yellow-100 text-yellow-800 hover:bg-yellow-200 border border-yellow-200 cursor-pointer"
          onClick={() => handleCitationClick(citation)}
        >
          <span>{citation.text}</span>
          <ExternalLink className="ml-1 h-3 w-3" />
        </span>
      );

      lastIndex = index + citation.text.length;
    });

    if (lastIndex < text.length) {
      const afterText = text.substring(lastIndex);
      // Process the text after last citation
      if (enableFinancialTerms || parentMessages.length) {
        const referencedParts = processMessageReferences(afterText, parentMessages, onMessageReferenceClick);
        
        if (enableFinancialTerms) {
          referencedParts.forEach((part, i) => {
            if (typeof part === 'string') {
              parts.push(<React.Fragment key={`after-${i}`}>{processFinancialTerms(part)}</React.Fragment>);
            } else {
              parts.push(<span key={`after-${i}`}>{part}</span>);
            }
          });
        } else {
          parts.push(...referencedParts.map((part, i) => 
            typeof part === 'string' 
              ? part 
              : <span key={`after-${i}`}>{part}</span>
          ));
        }
      } else {
        parts.push(afterText);
      }
    }

    return <>{parts}</>;
  };

  // Define custom components for ReactMarkdown
  const components: Components = {
    // Override code block rendering to use syntax highlighting
    code({ className, children, node, ...props }) {
      const match = /language-(\w+)/.exec(className || '');
      const language = match ? match[1] : '';
      
      // Check if this is an inline code block
      const isInline = !node?.position?.start.line || 
        node.position.start.line === node.position.end.line;

      return !isInline && match ? (
        <div className="relative">
          <SyntaxHighlighter
            language={language}
            style={nord}
            customStyle={{ borderRadius: '0.375rem' }}
            PreTag="div"
            {...props}
          >
            {String(children).replace(/\n$/, '')}
          </SyntaxHighlighter>
          <MessageActions className="absolute top-2 right-2">
            <CopyToClipboard text={String(children)} />
          </MessageActions>
        </div>
      ) : (
        <code className={className} {...props}>
          {children}
        </code>
      );
    },
    // Process text nodes to find and highlight citations
    p({ children, ...props }) {
      // Check for potentially problematic children that would cause hydration errors
      const hasComplexContent = React.Children.toArray(children).some(child => 
        React.isValidElement(child) && 
        (child.type === 'div' || child.type === 'p' || 
         child.type === 'h1' || child.type === 'h2' || 
         child.type === 'h3' || child.type === 'h4' || 
         child.type === 'h5' || child.type === 'h6')
      );

      // If potentially problematic content is detected, use a div instead of p
      if (hasComplexContent) {
        return (
          <div {...props} className="mb-4">
            {React.Children.map(children, child => {
              if (typeof child === 'string') {
                return processCitations(child);
              }
              return child;
            })}
          </div>
        );
      }

      // Regular rendering if no hydration issues detected
      return (
        <p {...props}>
          {React.Children.map(children, child => {
            if (typeof child === 'string') {
              return processCitations(child);
            }
            return child;
          })}
        </p>
      );
    },
    // Process citations in list items
    li({ children, ...props }) {
      return (
        <li {...props}>
          {React.Children.map(children, child => {
            if (typeof child === 'string') {
              return processCitations(child);
            }
            return child;
          })}
        </li>
      );
    },
    // Process citations in headings
    h1({ children, ...props }) {
      return <h1 {...props}>{children}</h1>;
    },
    h2({ children, ...props }) {
      return <h2 {...props}>{children}</h2>;
    },
    h3({ children, ...props }) {
      return <h3 {...props}>{children}</h3>;
    },
    // Customize links
    a({ children, href, ...props }) {
      return (
        <a 
          href={href} 
          target="_blank" 
          rel="noopener noreferrer"
          className="text-blue-600 hover:text-blue-800 underline flex items-center"
          {...props}
        >
          {children}
          <ExternalLink className="inline-block ml-1 h-3 w-3" />
        </a>
      );
    },
    // Add styling to tables
    table({ children, ...props }) {
      return (
        <div className="overflow-x-auto">
          <table className="min-w-full border-collapse border border-gray-300" {...props}>
            {children}
          </table>
        </div>
      );
    },
    thead({ children, ...props }) {
      return <thead className="bg-gray-50" {...props}>{children}</thead>;
    },
    th({ children, ...props }) {
      return <th className="px-4 py-2 border border-gray-300 text-left" {...props}>{children}</th>;
    },
    td({ children, ...props }) {
      return <td className="px-4 py-2 border border-gray-300" {...props}>{children}</td>;
    },
    // Style blockquotes
    blockquote({ children, ...props }) {
      return (
        <blockquote 
          className="pl-4 border-l-4 border-gray-200 text-gray-700 italic"
          {...props}
        >
          {children}
        </blockquote>
      );
    }
  };

  return (
    <div className="markdown-content prose max-w-none break-words">
      <ReactMarkdown
        remarkPlugins={[remarkGfm]}
        components={components}
      >
        {content}
      </ReactMarkdown>
      
      {/* Add financial terms detector if enabled */}
      {enableFinancialTerms && <FinancialTermsDetector content={content} />}
      
      {/* Render suggestion chips if provided */}
      {suggestions.length > 0 && (
        <SuggestionChips 
          suggestions={suggestions.map(s => ({
            label: s.label,
            action: s.action,
            variant: s.variant
          }))} 
        />
      )}
      
      {/* Render expandable content sections if provided */}
      {expandableContent.map((item, index) => (
        <ExpandableContent 
          key={index}
          summary={item.summary}
          defaultExpanded={item.defaultExpanded}
        >
          <div className="prose max-w-none">
            <ReactMarkdown remarkPlugins={[remarkGfm]}>
              {item.content}
            </ReactMarkdown>
          </div>
        </ExpandableContent>
      ))}
      
      {/* Add message copy functionality */}
      <MessageActions className="mt-2 justify-start">
        <CopyToClipboard text={content} />
        <span className="text-xs text-gray-500 ml-2">Copy message</span>
      </MessageActions>
    </div>
  );
}
</file>
```

#### src/components/chat/MessageReference\.tsx
*Size: 3.2 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/chat/MessageReference.tsx">
'use client';

import React, { useState } from 'react';
import { ArrowUpRight, MessageSquare } from 'lucide-react';
import { Message } from '@/types';

// Component for displaying message references in chat
export interface MessageReferenceProps {
  messageId: string;
  referenceText: string;
  parentMessages?: Message[];
  onMessageReferenceClick: (messageId: string) => void;
}

export const MessageReference: React.FC<MessageReferenceProps> = ({
  messageId,
  referenceText,
  parentMessages = [],
  onMessageReferenceClick,
}) => {
  const [showPreview, setShowPreview] = useState(false);
  
  // Find the referenced message from the parent messages
  const referencedMessage = parentMessages.find(msg => msg.id === messageId);
  
  // If the message doesn't exist, just show text
  if (!referencedMessage) {
    return <span className="text-gray-600">{referenceText}</span>;
  }
  
  return (
    <span className="relative">
      <button
        className="inline-flex items-center px-2 py-1 rounded bg-gray-100 text-gray-700 hover:bg-gray-200 border border-gray-200 text-sm"
        onClick={() => onMessageReferenceClick(messageId)}
        onMouseEnter={() => setShowPreview(true)}
        onMouseLeave={() => setShowPreview(false)}
      >
        <MessageSquare className="h-3 w-3 mr-1" />
        {referenceText || 'See previous message'}
        <ArrowUpRight className="h-3 w-3 ml-1" />
      </button>
      
      {showPreview && (
        <div className="absolute z-10 bottom-full left-0 mb-2 p-3 bg-white border border-gray-200 rounded-md shadow-lg w-80 max-h-48 overflow-y-auto">
          <div className="text-xs text-gray-500 mb-1">
            {referencedMessage.role === 'assistant' ? 'AI Response' : 'Your Message'}
          </div>
          <div className="text-sm line-clamp-5">
            {referencedMessage.content.length > 200 
              ? `${referencedMessage.content.substring(0, 200)}...` 
              : referencedMessage.content}
          </div>
        </div>
      )}
    </span>
  );
};

// Process text to find message references with format [ref:messageId]
export const processMessageReferences = (
  text: string,
  parentMessages: Message[] = [],
  onMessageReferenceClick: (messageId: string) => void
): React.ReactNode[] => {
  const parts: React.ReactNode[] = [];
  
  // Regular expression for message references [ref:messageId]
  const refRegex = /\[ref:([a-zA-Z0-9-]+)(?::([^\]]+))?\]/g;
  
  let lastIndex = 0;
  let match;
  
  while ((match = refRegex.exec(text)) !== null) {
    // Add text before the match
    if (match.index > lastIndex) {
      parts.push(text.substring(lastIndex, match.index));
    }
    
    // Extract messageId and optional display text
    const messageId = match[1];
    const displayText = match[2] || 'See previous message';
    
    // Add the reference component
    parts.push(
      <MessageReference
        key={`ref-${match.index}`}
        messageId={messageId}
        referenceText={displayText}
        parentMessages={parentMessages}
        onMessageReferenceClick={onMessageReferenceClick}
      />
    );
    
    lastIndex = match.index + match[0].length;
  }
  
  // Add remaining text
  if (lastIndex < text.length) {
    parts.push(text.substring(lastIndex));
  }
  
  return parts.length > 0 ? parts : [text];
};
</file>
```

#### src/components/chat/MessageRenderer\.tsx
*Size: 1.3 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/chat/MessageRenderer.tsx">
'use client';

import React from 'react';
import { Message, Citation } from '@/types';
import { ExternalLink } from 'lucide-react';
import { MarkdownRenderer } from './MarkdownRenderer';

interface MessageRendererProps {
  message: Message;
  onCitationClick?: (citation: Citation) => void;
}

export function MessageRenderer({ message, onCitationClick }: MessageRendererProps) {
  // Return early if no content
  if (!message.content) {
    return null;
  }
  
  // For system messages, use simple line breaks without markdown
  if (message.role === 'system') {
    return (
      <div className="message-content">
        {message.content.split('\n').map((line, i) => (
          <div key={i} className={i > 0 ? 'mt-2' : ''}>
            {line}
          </div>
        ))}
      </div>
    );
  }

  // For user messages, use simple text with line breaks
  if (message.role === 'user') {
    return (
      <div className="message-content">
        {message.content.split('\n').map((line, i) => (
          <div key={i} className={i > 0 ? 'mt-2' : ''}>
            {line}
          </div>
        ))}
      </div>
    );
  }

  // For assistant messages, use rich markdown formatting with citation handling
  return (
    <MarkdownRenderer 
      content={message.content} 
      citations={message.citations}
      onCitationClick={onCitationClick}
    />
  );
}
</file>
```

#### src/components/document/PDFViewer\.tsx
*Size: 18.4 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/document/PDFViewer.tsx">
'use client';

import React, { useState, useCallback, useEffect, useRef } from 'react';
import { File, Loader2, AlertCircle } from 'lucide-react';
import { ProcessedDocument, Citation } from '@/types';
import {
  PdfLoader,
  PdfHighlighter,
  Highlight,
  Popup,
  AreaHighlight,
  IHighlight,
  LTWHP 
} from "react-pdf-highlighter";
import { documentsApi, cleanupBlobUrls } from '@/lib/api/documents';
import { convertCitationToHighlight, convertHighlightToCitation } from '@/lib/pdf/citationService';

// Add PDF.js type declaration
declare global {
  interface Window {
    pdfjsLib?: any;
  }
}

interface PDFViewerProps {
  document?: ProcessedDocument;
  isLoading?: boolean;
  error?: string;
  onCitationCreate?: (citation: Omit<Citation, 'id'>) => void;
  onCitationClick?: (citation: Citation | IHighlight) => void;
  aiHighlights?: IHighlight[];
  onCitationsLoaded?: (citations: IHighlight[]) => void;
  pdfUrl?: string;
  highlightId?: string | null;
  renderingQuality?: 'low' | 'medium' | 'high';
  pageBufferSize?: number;
}

export function PDFViewer({ 
  document, 
  isLoading, 
  error, 
  onCitationCreate, 
  onCitationClick,
  aiHighlights = [], 
  onCitationsLoaded,
  pdfUrl: propsPdfUrl,
  highlightId,
  renderingQuality = 'medium',
  pageBufferSize = 5
}: PDFViewerProps) {
  const [currentPage, setCurrentPage] = useState(1);
  const [userHighlights, setUserHighlights] = useState<IHighlight[]>([]);
  const [pdfUrl, setPdfUrl] = useState<string | null>(propsPdfUrl || null);
  const [errorState, setErrorState] = useState<string | null>(error || null);
  const [loadingState, setLoadingState] = useState<string | null>(null);
  const [documentCitations, setDocumentCitations] = useState<Citation[]>([]);
  const [totalPages, setTotalPages] = useState<number>(0);
  const [visiblePages, setVisiblePages] = useState<number[]>([]);
  const [loadedPages, setLoadedPages] = useState<Set<number>>(new Set());
  const [renderScale, setRenderScale] = useState<number>(
    renderingQuality === 'low' ? 1.0 : 
    renderingQuality === 'medium' ? 1.5 : 2.0
  );
  const [isBrowser, setIsBrowser] = useState(false);
  
  const [currentPdfDocument, setCurrentPdfDocument] = useState<any>(null);
  const scrollViewerRef = useRef<((highlight: IHighlight) => void) | null>(null);
  const cleanupRef = useRef<() => void>(() => {});
  
  // Convert citations to highlights format
  const citationHighlights = documentCitations.map(convertCitationToHighlight);
  
  // Combine AI-generated highlights with user highlights and citation highlights
  const allHighlights = [...userHighlights, ...aiHighlights, ...citationHighlights];
  
  // Memory management: Page visibility tracking
  const onVisiblePagesChanged = useCallback((pages: number[]) => {
    setVisiblePages(pages);
    
    // Only keep a buffer of pages in memory
    const pagesToKeep = new Set<number>();
    
    // Add currently visible pages
    pages.forEach(page => pagesToKeep.add(page));
    
    // Add buffer pages (before and after visible pages)
    const halfBuffer = Math.floor(pageBufferSize / 2);
    pages.forEach(page => {
      for (let i = 1; i <= halfBuffer; i++) {
        if (page - i > 0) pagesToKeep.add(page - i);
        if (page + i <= totalPages) pagesToKeep.add(page + i);
      }
    });
    
    // Update loaded pages state
    setLoadedPages(pagesToKeep);
    
  }, [pageBufferSize, totalPages]);
  
  // Handle PDF document loading completion
  const handleDocumentLoadSuccess = useCallback((pdfDocument: any) => {
    setTotalPages(pdfDocument.numPages);
    
    // Store cleanup function
    cleanupRef.current = () => {
      // Attempt to clean up PDF.js worker
      if (pdfDocument && typeof pdfDocument.cleanup === 'function') {
        pdfDocument.cleanup();
      }
      
      // Clear page caches and destroy document
      if (pdfDocument && typeof pdfDocument.destroy === 'function') {
        pdfDocument.destroy();
      }
      
      // Additional cleanup for any WebWorkers
      if (window.pdfjsLib && window.pdfjsLib.GlobalWorkerOptions) {
        // Force garbage collection on workers
        console.log('PDF.js workers scheduled for cleanup');
      }
    };
  }, []);
  
  // Define scrollToHighlight callback - IMPORTANT: must be defined before useEffect that uses it
  const scrollToHighlight = useCallback((highlightId: string) => {
    const highlight = allHighlights.find(h => h.id === highlightId);
    if (highlight && scrollViewerRef.current) {
      // Set current page to the highlight's page
      setCurrentPage(highlight.position.pageNumber);
      
      // Add a visual indicator by adding a temporary "focus" highlight
      const existingIndex = userHighlights.findIndex(h => h.id === highlightId + '-focus');
      if (existingIndex >= 0) {
        // Remove the previous focus highlight
        const updatedHighlights = [...userHighlights];
        updatedHighlights.splice(existingIndex, 1);
        setUserHighlights(updatedHighlights);
      }
      
      // Add a new focus highlight (larger than the original highlight)
      const focusHighlight = {
        ...highlight,
        id: highlightId + '-focus',
        comment: {
          text: "Focus highlight",
          emoji: "ğŸ”"
        },
        position: {
          ...highlight.position,
          rects: highlight.position.rects.map(rect => ({
            ...rect,
            x1: rect.x1 - 5,
            y1: rect.y1 - 5,
            x2: rect.x2 + 5,
            y2: rect.y2 + 5,
            width: rect.width + 10,
            height: rect.height + 10
          }))
        }
      };
      
      setUserHighlights(prev => [...prev, focusHighlight]);
      
      // Remove the focus highlight after a few seconds
      setTimeout(() => {
        setUserHighlights(prev => prev.filter(h => h.id !== highlightId + '-focus'));
      }, 3000);
      
      // Try to scroll to the highlight using PdfHighlighter's method
      if (scrollViewerRef.current) {
        scrollViewerRef.current(highlight);
      }
      
      return true;
    }
    return false;
  }, [allHighlights, userHighlights]);
  
  // Handler for adding highlights
  const addHighlight = useCallback((highlight: IHighlight) => {
    setUserHighlights(prev => [...prev, highlight]);
    
    // If onCitationCreate callback exists, create a citation object
    if (onCitationCreate && document) {
      const citation = convertHighlightToCitation(highlight, document.metadata.id);
      onCitationCreate(citation);
    }
  }, [document, onCitationCreate]);
  
  // Handler for highlight click
  const handleHighlightClick = useCallback((highlight: IHighlight) => {
    if (onCitationClick) {
      // Find the corresponding citation if it exists
      const citation = documentCitations.find(c => c.highlightId === highlight.id);
      if (citation) {
        onCitationClick(citation);
      } else {
        onCitationClick(highlight);
      }
    }
  }, [documentCitations, onCitationClick]);
  
  // Set isBrowser to true once component mounts - always declare hooks in the same order
  useEffect(() => {
    setIsBrowser(true);
  }, []);
  
  // Get document URL from props or fetch it when document changes
  useEffect(() => {
    if (!isBrowser) return;
    
    if (propsPdfUrl) {
      setPdfUrl(propsPdfUrl);
      setErrorState(null);
    } else if (document) {
      const fetchDocumentUrl = async () => {
        setLoadingState("Retrieving document URL...");
        try {
          const url = await documentsApi.getDocumentUrl(document.metadata.id);
          setPdfUrl(url);
          setErrorState(null);
          setLoadingState(null);
        } catch (error) {
          console.error("Error fetching document URL:", error);
          setErrorState("Failed to retrieve document URL. Please try again later.");
          setLoadingState(null);
        }
      };
      
      fetchDocumentUrl();
    } else {
      setPdfUrl(null);
    }
  }, [document, propsPdfUrl, isBrowser]);
  
  // Fetch citations when document changes
  useEffect(() => {
    if (!isBrowser || !document) return;
    
    const fetchCitations = async () => {
      try {
        setLoadingState("Loading document citations...");
        const citations = await documentsApi.getDocumentCitations(document.metadata.id);
        setDocumentCitations(citations);
        
        // Convert citations to highlights and notify parent
        const highlightsFromCitations = citations.map(convertCitationToHighlight);
        if (onCitationsLoaded) {
          onCitationsLoaded(highlightsFromCitations);
        }
        
        setLoadingState(null);
      } catch (error) {
        console.error("Error fetching document citations:", error);
        // Don't set error state here as we still want to show the document even if citations fail
        setLoadingState(null);
      }
    };
    
    fetchCitations();
  }, [document, onCitationsLoaded, isBrowser]);
  
  // Scroll to highlight when highlightId changes
  useEffect(() => {
    if (highlightId && allHighlights.length > 0) {
      const highlight = allHighlights.find(h => h.id === highlightId);
      if (highlight) {
        // Scroll to the highlight
        scrollToHighlight(highlightId);
      }
    }
  }, [highlightId, allHighlights, scrollToHighlight]);
  
  // Update render scale when renderingQuality changes
  useEffect(() => {
    if (!isBrowser) return;
    setRenderScale(
      renderingQuality === 'low' ? 1.0 : 
      renderingQuality === 'medium' ? 1.5 : 2.0
    );
  }, [renderingQuality, isBrowser]);
  
  // Cleanup on unmount
  useEffect(() => {
    return () => {
      console.log('PDFViewer unmounting, cleaning up resources');
      
      // Execute cleanup function
      cleanupRef.current();
      
      // Clean up blob URLs
      cleanupBlobUrls();
      
      // Clear memory
      setUserHighlights([]);
      setDocumentCitations([]);
      setPdfUrl(null);
    };
  }, []);
  
  // Handle when PDF document is set
  useEffect(() => {
    if (currentPdfDocument) {
      handleDocumentLoadSuccess(currentPdfDocument);
    }
  }, [currentPdfDocument, handleDocumentLoadSuccess]);
  
  // Skip rendering until we're in the browser
  if (!isBrowser) {
    return (
      <div className="h-full flex items-center justify-center">
        <div className="text-center">
          <Loader2 className="h-12 w-12 text-indigo-600 animate-spin mx-auto" />
          <p className="mt-2 text-sm text-gray-500">Loading PDF viewer...</p>
        </div>
      </div>
    );
  }

  if (isLoading || loadingState) {
    return (
      <div className="h-full flex items-center justify-center">
        <div className="text-center">
          <Loader2 className="h-12 w-12 text-indigo-600 animate-spin mx-auto" />
          <p className="mt-2 text-sm text-gray-500">{loadingState || "Loading document..."}</p>
        </div>
      </div>
    );
  }

  // Use the error prop if provided, otherwise use the internal error state
  if (errorState) {
    return (
      <div className="h-full flex items-center justify-center">
        <div className="text-center">
          <AlertCircle className="h-12 w-12 text-red-500 mx-auto" />
          <p className="mt-2 text-sm text-gray-500">{errorState}</p>
        </div>
      </div>
    );
  }

  if (!document || !pdfUrl) {
    return (
      <div className="h-full flex items-center justify-center">
        <div className="text-center">
          <File className="h-12 w-12 text-gray-400 mx-auto" />
          <h3 className="mt-2 text-sm font-medium text-gray-900">No document loaded</h3>
          <p className="mt-1 text-sm text-gray-500">Upload a document to view it here</p>
        </div>
      </div>
    );
  }

  // Render highlight element with popup
  const renderHighlight = (
    highlight: IHighlight,
    index: number,
    setTip: (highlight: IHighlight, callback: () => JSX.Element) => void,
    hideTip: () => void,
    viewportToScaled: (rect: LTWHP) => any,
    screenshot: (position: any) => string,
    isScrolledTo: boolean
  ) => {
    const isTextHighlight = !Boolean(highlight.content && highlight.content.image);
    
    // Determine highlight type and color
    const isAIHighlight = highlight.isAICitation || aiHighlights.some(h => h.id === highlight.id);
    const highlightColor = isAIHighlight ? 'bg-yellow-300' : 'bg-indigo-300';
    
    const triggerHighlightClick = () => handleHighlightClick(highlight);
    
    const popupContent = (
      <div 
        className={`${isAIHighlight ? 'bg-yellow-600' : 'bg-indigo-600'} text-white text-sm p-2 rounded shadow cursor-pointer`}
        onClick={triggerHighlightClick}
      >
        {isAIHighlight 
          ? "AI Citation: " + (highlight.comment?.text || "Referenced in conversation") 
          : (highlight.comment?.text || "User Highlight")}
      </div>
    );
    
    return (
      <Popup
        popupContent={popupContent}
        onMouseOver={popupContent => setTip(highlight, () => popupContent)}
        onMouseOut={hideTip}
        key={index}
      >
        <div onClick={triggerHighlightClick} className="cursor-pointer">
          {isTextHighlight ? (
            // Using any type to avoid type errors with the Highlight component
            <Highlight 
              isScrolledTo={isScrolledTo} 
              position={highlight.position as any}
              comment={highlight.comment}
            />
          ) : (
            // Using any type to avoid type errors with the AreaHighlight component
            <AreaHighlight
              isScrolledTo={isScrolledTo}
              highlight={highlight as any}
              onChange={() => {}}
            />
          )}
        </div>
      </Popup>
    );
  };

  return (
    <div className="h-full bg-gray-50 flex flex-col relative">
      {document && (
        <div className="p-4 border-b border-gray-200">
          <h2 className="text-lg font-medium text-gray-900">{document.metadata.filename}</h2>
          <div className="mt-1 flex flex-col sm:flex-row sm:flex-wrap sm:mt-0 sm:space-x-6">
            <div className="mt-2 flex items-center text-sm text-gray-500">
              <File className="flex-shrink-0 mr-1.5 h-5 w-5 text-gray-400" />
              {document.metadata.mimeType}
            </div>
            {document.confidenceScore !== undefined && (
              <div className="mt-2 flex items-center text-sm text-gray-500">
                <span className="mr-1.5">Confidence:</span>
                {Math.round(document.confidenceScore * 100)}%
              </div>
            )}
          </div>
        </div>
      )}
      
      {pdfUrl && (
        <div className="flex-1 overflow-auto">
          <PdfLoader 
            url={pdfUrl} 
            beforeLoad={<div className="p-4">Loading PDF...</div>}
            onError={(error) => {
              console.error("Error loading PDF:", error);
              setErrorState("Failed to load PDF. The file might be corrupted or password protected.");
            }}
            cMapUrl="https://unpkg.com/pdfjs-dist@2.16.105/cmaps/"
            cMapPacked={true}
            workerSrc="https://unpkg.com/pdfjs-dist@2.16.105/build/pdf.worker.min.js"
          >
            {(pdfDocument) => {
              // Update document in state after render without using hooks
              // This is a safe approach that doesn't violate hook rules
              // We use a regular function and setTimeout to defer the state update
              if (pdfDocument) {
                // Use setTimeout to move state update out of render phase
                setTimeout(() => {
                  setCurrentPdfDocument(pdfDocument);
                }, 0);
              }
              
              return (
                <PdfHighlighter
                  pdfDocument={pdfDocument}
                  enableAreaSelection={(event) => event.altKey}
                  onScrollChange={onVisiblePagesChanged as any}
                  scrollRef={(scrollTo: any) => {
                    scrollViewerRef.current = scrollTo;
                  }}
                  onSelectionFinished={(
                    position,
                    content,
                    hideTipAndSelection,
                    transformSelection
                  ) => {
                    return (
                      <div className="bg-white p-2 border border-gray-300 rounded shadow-md">
                        <div className="flex justify-between mb-2">
                          <div>Add Highlight</div>
                          <button 
                            className="text-indigo-600 hover:text-indigo-800 px-3 py-1 rounded text-sm" 
                            onClick={() => {
                              const highlightId = `highlight-${Date.now()}`;
                              addHighlight({
                                id: highlightId,
                                content,
                                position,
                                comment: {
                                  text: "User highlight",
                                  emoji: "âœï¸",
                                },
                              });
                              hideTipAndSelection();
                            }}
                          >
                            Save
                          </button>
                        </div>
                      </div>
                    );
                  }}
                  highlights={allHighlights}
                  highlightTransform={renderHighlight as any}
                  pdfScaleValue={renderScale.toString()}
                />
              );
            }}
          </PdfLoader>
        </div>
      )}
      
      {/* Performance controls for large PDFs */}
      {totalPages > 50 && (
        <div className="absolute bottom-4 right-4 bg-white rounded-md shadow p-2 text-xs z-10 border border-gray-200">
          <div className="mb-1 font-medium">Performance Options</div>
          <div className="flex space-x-2">
            <button 
              className={`px-2 py-1 rounded ${renderingQuality === 'low' ? 'bg-indigo-600 text-white' : 'bg-gray-200'}`}
              onClick={() => setRenderScale(1.0)}
            >
              Low
            </button>
            <button 
              className={`px-2 py-1 rounded ${renderingQuality === 'medium' ? 'bg-indigo-600 text-white' : 'bg-gray-200'}`}
              onClick={() => setRenderScale(1.5)}
            >
              Medium
            </button>
            <button 
              className={`px-2 py-1 rounded ${renderingQuality === 'high' ? 'bg-indigo-600 text-white' : 'bg-gray-200'}`}
              onClick={() => setRenderScale(2.0)}
            >
              High
            </button>
          </div>
        </div>
      )}
    </div>
  );
}
</file>
```

#### src/components/document/UploadForm\.tsx
*Size: 14.7 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/document/UploadForm.tsx">
'use client';

import React, { useState, useRef, useCallback } from 'react';
import { Upload, Loader2, File, AlertCircle, CheckCircle2, RefreshCw } from 'lucide-react';
import { ProcessedDocument } from '@/types';
import { documentsApi } from '@/lib/api/documents';
import { conversationApi } from '@/lib/api/conversation';

interface UploadFormProps {
  onUploadSuccess?: (document: ProcessedDocument) => void;
  onUploadError?: (error: Error) => void;
  sessionId?: string;
}

export function UploadForm({ onUploadSuccess, onUploadError, sessionId }: UploadFormProps) {
  const [file, setFile] = useState<File | null>(null);
  const [isUploading, setIsUploading] = useState(false);
  const [progress, setProgress] = useState(0);
  const [error, setError] = useState<string | null>(null);
  const [warning, setWarning] = useState<string | null>(null);
  const [isDragging, setIsDragging] = useState(false);
  const [uploadComplete, setUploadComplete] = useState(false);
  
  // Reference to the XMLHttpRequest for cancellation support
  const xhrRef = useRef<XMLHttpRequest | null>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);
  
  // Handle file selection from input
  const handleFileChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    const selectedFile = e.target.files?.[0];
    console.log("File selected:", selectedFile?.name);
    
    if (selectedFile) {
      validateAndSetFile(selectedFile);
    }
  };
  
  // Validate file and set it if valid
  const validateAndSetFile = (selectedFile: File) => {
    console.log("Validating file:", selectedFile.name);
    
    // Reset states
    setError(null);
    setWarning(null);
    setIsUploading(false); // Ensure we're not showing the loading state
    
    // Check file type
    if (selectedFile.type !== 'application/pdf') {
      console.error("Invalid file type:", selectedFile.type);
      setError('Only PDF files are supported');
      return false;
    }
    
    // Check file size (10MB limit)
    if (selectedFile.size > 10 * 1024 * 1024) {
      console.error("File too large:", selectedFile.size);
      setError('File size must be less than 10MB');
      return false;
    }
    
    console.log("File validation successful");
    
    // Set the file if validation passes
    setFile(selectedFile);
    return true;
  };
  
  // Handle drag events for drag-and-drop functionality
  const handleDragEnter = useCallback((e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
    setIsDragging(true);
  }, []);
  
  const handleDragLeave = useCallback((e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
    setIsDragging(false);
  }, []);
  
  const handleDragOver = useCallback((e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
  }, []);
  
  const handleDrop = useCallback((e: React.DragEvent) => {
    e.preventDefault();
    e.stopPropagation();
    setIsDragging(false);
    
    const files = e.dataTransfer.files;
    if (files.length > 0) {
      validateAndSetFile(files[0]);
    }
  }, []);
  
  // Cancel the current upload
  const cancelUpload = () => {
    if (xhrRef.current && isUploading) {
      xhrRef.current.abort();
      xhrRef.current = null;
      setIsUploading(false);
      setProgress(0);
      console.log('Upload cancelled');
    } else {
      // Just reset the form if not uploading
      setFile(null);
      setProgress(0);
      setError(null);
      setWarning(null);
      setUploadComplete(false);
    }
  };
  
  // Retry upload after a failure
  const retryUpload = () => {
    setError(null);
    setProgress(0);
    handleUpload();
  };
  
  const handleUpload = async () => {
    if (!file) return;
    
    try {
      setIsUploading(true);
      setError(null);
      setWarning(null);
      setUploadComplete(false);
      
      // Create FormData for upload
      const formData = new FormData();
      formData.append('file', file);
      
      // Create a new XMLHttpRequest for tracking real upload progress
      const xhr = new XMLHttpRequest();
      xhrRef.current = xhr;
      
      // Set up progress tracking
      xhr.upload.onprogress = (event) => {
        if (event.lengthComputable) {
          // Only go to 75% for upload - reserve 75-100% for processing & verification
          const uploadProgress = (event.loaded / event.total) * 75;
          setProgress(uploadProgress);
        }
      };
      
      // Create a promise to handle XHR response
      const uploadPromise = new Promise<{ document_id: string }>((resolve, reject) => {
        xhr.onload = () => {
          if (xhr.status >= 200 && xhr.status < 300) {
            try {
              const response = JSON.parse(xhr.responseText);
              resolve(response);
            } catch (error) {
              reject(new Error('Invalid response format'));
            }
          } else {
            // Try to parse error response
            try {
              const errorData = JSON.parse(xhr.responseText);
              reject(new Error(errorData.detail || `Upload failed with status ${xhr.status}`));
            } catch (e) {
              reject(new Error(`Upload failed with status ${xhr.status}`));
            }
          }
        };
        
        xhr.onerror = () => reject(new Error('Network error during upload'));
        xhr.onabort = () => reject(new Error('Upload was aborted'));
      });
      
      // Get the API base URL from environment or use default
      const API_BASE_URL = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8000';
      
      // Open and send the request
      xhr.open('POST', `${API_BASE_URL}/api/documents/upload`);
      xhr.send(formData);
      
      // Wait for upload to complete
      const uploadResponse = await uploadPromise;
      console.log('Upload complete, starting verification:', uploadResponse);
      
      // Update progress to indicate verification has started
      setProgress(80);
      
      // Use the document API to verify the upload and wait for processing
      console.log("Starting document processing and financial data verification...");
      const document = await documentsApi.uploadAndVerifyDocument(file);
      
      // Document processing and verification complete
      setProgress(100);
      setUploadComplete(true);
      console.log("Document verification completed:", document);
      
      // Check if the document has financial data
      if (document.extractedData?.financialVerification) {
        const hasFinancialData = document.extractedData.financialVerification.hasFinancialData;
        const diagnosis = document.extractedData.financialVerification.diagnosis;
        
        if (!hasFinancialData) {
          // Document doesn't have financial data - show warning but still allow
          console.warn("Document doesn't have valid financial data:", diagnosis);
          setWarning(`The document was processed but may not contain valid financial data: ${diagnosis}`);
        }
      }
      
      // Clear the XHR reference as it's complete
      xhrRef.current = null;
      
      // If we have a session ID, associate the document with the current conversation
      if (sessionId && document.metadata && document.metadata.id) {
        try {
          console.log(`Associating document ${document.metadata.id} with conversation ${sessionId}`);
          await conversationApi.addDocumentToConversation(sessionId, document.metadata.id);
          console.log("Document successfully associated with conversation");
        } catch (err) {
          console.error("Failed to associate document with conversation:", err);
          // We don't want to fail the upload process if this step fails
        }
      }
      
      // Notify parent component of successful upload
      onUploadSuccess?.(document);
      
      // Reset form after short delay to show 100% completion
      setTimeout(() => {
        setFile(null);
        setProgress(0);
        setIsUploading(false);
        setUploadComplete(false);
      }, 2000);
      
    } catch (err) {
      console.error("Document upload failed:", err);
      
      // Clear the XHR reference
      xhrRef.current = null;
      
      // Handle specific error types
      const errorMessage = err instanceof Error ? err.message : 'Failed to upload document';
      
      if (errorMessage.includes('Network error')) {
        setError('Network error. Please check your internet connection and try again.');
      } else if (errorMessage.includes('aborted')) {
        setError('Upload was cancelled.');
      } else if (errorMessage.includes('size limit exceeded')) {
        setError('The file exceeds the maximum size limit (10MB).');
      } else if (errorMessage.includes('unsupported file type')) {
        setError('The file type is not supported. Please upload a PDF document.');
      } else if (errorMessage.includes('processing')) {
        setError('Error processing the document. The PDF might be corrupted or password protected.');
      } else {
        setError(errorMessage);
      }
      
      setIsUploading(false);
      setProgress(0);
      onUploadError?.(err instanceof Error ? err : new Error('Unknown error'));
    }
  };
  
  return (
    <div className="space-y-4">
      {error && (
        <div className="p-4 border border-red-200 rounded-md flex items-start space-x-2 bg-red-50 text-red-800">
          <AlertCircle className="h-5 w-5 flex-shrink-0 mt-0.5" />
          <div className="flex-1">
            <div className="text-sm font-medium">{error}</div>
            {isUploading === false && file && (
              <button 
                onClick={retryUpload}
                className="mt-2 inline-flex items-center text-xs font-medium text-red-700 hover:text-red-900"
              >
                <RefreshCw className="h-3 w-3 mr-1" /> Try again
              </button>
            )}
          </div>
        </div>
      )}
      
      {warning && !error && (
        <div className="p-4 border border-yellow-200 rounded-md flex items-start space-x-2 bg-yellow-50 text-yellow-800">
          <AlertCircle className="h-5 w-5 flex-shrink-0 mt-0.5" />
          <div className="text-sm">{warning}</div>
        </div>
      )}
      
      {uploadComplete && !error && !isUploading && (
        <div className="p-4 border border-green-200 rounded-md flex items-start space-x-2 bg-green-50 text-green-800">
          <CheckCircle2 className="h-5 w-5 flex-shrink-0 mt-0.5" />
          <div className="text-sm">Document uploaded and processed successfully!</div>
        </div>
      )}
      
      <div 
        className={`flex flex-col items-center p-6 border-2 ${isDragging ? 'border-blue-400 bg-blue-50' : 'border-dashed border-gray-300 bg-gray-50 hover:bg-gray-100'} rounded-md transition-colors`}
        onDragEnter={handleDragEnter}
        onDragOver={handleDragOver}
        onDragLeave={handleDragLeave}
        onDrop={handleDrop}
      >
        {!file ? (
          <>
            <File className="h-8 w-8 text-gray-400 mb-2" />
            <p className="text-sm text-gray-500 mb-4">Drag and drop your PDF or click to browse</p>
            <label className="cursor-pointer inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-blue-500 focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 bg-blue-500 text-white hover:bg-blue-600 h-10 px-4 py-2">
              <Upload className="mr-2 h-4 w-4" />
              Select PDF
              <input 
                ref={fileInputRef}
                type="file" 
                accept=".pdf,application/pdf" 
                onChange={handleFileChange} 
                disabled={isUploading}
                className="hidden"
                key={`file-input-${isUploading ? 'uploading' : 'idle'}`}
              />
            </label>
          </>
        ) : (
          <div className="w-full space-y-4">
            <div className="flex items-center">
              <File className="h-6 w-6 text-blue-500 mr-2" />
              <div className="text-sm font-medium flex-1 truncate">{file.name}</div>
              <div className="text-xs text-gray-500">
                {(file.size / 1024 / 1024).toFixed(2)} MB
              </div>
            </div>
            
            {isUploading ? (
              <div className="space-y-2">
                <div className="w-full bg-gray-200 rounded-full h-2">
                  <div 
                    className="bg-blue-500 h-full rounded-full transition-all duration-300 ease-in-out" 
                    style={{ width: `${progress}%` }}
                  ></div>
                </div>
                <div className="flex justify-between text-xs text-gray-500">
                  <span>
                    {progress < 75 ? 'Uploading...' : 
                     progress < 90 ? 'Processing...' : 
                     'Verifying...'}
                  </span>
                  <span>{Math.round(progress)}%</span>
                </div>
              </div>
            ) : (
              <div className="flex space-x-2">
                <button
                  type="button"
                  onClick={cancelUpload}
                  className="flex-1 border border-gray-300 bg-white text-gray-700 hover:bg-gray-50 rounded-md font-medium transition-colors focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2 text-sm px-4 py-2"
                >
                  Cancel
                </button>
                <button 
                  type="button"
                  onClick={handleUpload}
                  disabled={isUploading}
                  className="flex-1 bg-blue-500 text-white hover:bg-blue-600 rounded-md font-medium transition-colors focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2 disabled:opacity-50 disabled:pointer-events-none text-sm px-4 py-2 flex items-center justify-center"
                >
                  {isUploading ? (
                    <>
                      <Loader2 className="h-4 w-4 mr-2 animate-spin" />
                      Processing...
                    </>
                  ) : 'Upload'}
                </button>
              </div>
            )}
          </div>
        )}
      </div>
      
      {isUploading && (
        <div className="text-xs text-gray-500 italic">
          {progress < 75 ? (
            <div>Uploading your document... {Math.round(progress)}% complete</div>
          ) : progress < 90 ? (
            <div>Processing your document. This may take a minute...</div>
          ) : (
            <div className="text-blue-600 font-medium">
              Verifying financial data extraction...
            </div>
          )}
        </div>
      )}
      
      <div className="text-xs text-gray-500">
        <p>Supported file types: PDF (max size: 10MB)</p>
      </div>
    </div>
  );
}
</file>
```

#### src/components/layout/Header\.tsx
*Size: 2.9 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/layout/Header.tsx">
'use client'

import Link from 'next/link'
import Image from 'next/image'
import { usePathname } from 'next/navigation'
import { BarChart, FileText, Home, Settings, User } from 'lucide-react'

export default function Header() {
  const pathname = usePathname()

  return (
    <header className="border-b border-gray-200 bg-white">
      <div className="container mx-auto px-4 py-3">
        <div className="flex justify-between items-center">
          {/* Logo and branding */}
          <div className="flex items-center">
            <Link href="/" className="flex items-center">
              <div className="bg-indigo-600 text-white p-1.5 rounded mr-2">
                <BarChart className="h-5 w-5" />
              </div>
              <span className="font-semibold text-xl text-gray-900">FDAS</span>
            </Link>
          </div>

          {/* Main navigation */}
          <nav className="hidden md:flex space-x-1">
            <Link 
              href="/" 
              className={`px-3 py-2 rounded-md text-sm font-medium ${
                pathname === '/' 
                  ? 'bg-indigo-100 text-indigo-700' 
                  : 'text-gray-700 hover:bg-gray-100'
              }`}
            >
              <div className="flex items-center">
                <Home className="h-4 w-4 mr-1.5" />
                Home
              </div>
            </Link>
            <Link 
              href="/dashboard" 
              className={`px-3 py-2 rounded-md text-sm font-medium ${
                pathname === '/dashboard' 
                  ? 'bg-indigo-100 text-indigo-700' 
                  : 'text-gray-700 hover:bg-gray-100'
              }`}
            >
              <div className="flex items-center">
                <BarChart className="h-4 w-4 mr-1.5" />
                Dashboard
              </div>
            </Link>
            <Link 
              href="/workspace" 
              className={`px-3 py-2 rounded-md text-sm font-medium ${
                pathname === '/workspace' 
                  ? 'bg-indigo-100 text-indigo-700' 
                  : 'text-gray-700 hover:bg-gray-100'
              }`}
            >
              <div className="flex items-center">
                <FileText className="h-4 w-4 mr-1.5" />
                Workspace
              </div>
            </Link>
          </nav>

          {/* User menu */}
          <div className="flex items-center space-x-3">
            <button className="p-2 text-gray-500 rounded-full hover:bg-gray-100">
              <Settings className="h-5 w-5" />
            </button>
            <div className="flex items-center">
              <button className="flex items-center">
                <div className="bg-gray-200 rounded-full p-0.5">
                  <User className="h-6 w-6 text-gray-600" />
                </div>
              </button>
            </div>
          </div>
        </div>
      </div>
    </header>
  )
}
</file>
```

#### src/components/metrics/ComparativePeriodDisplay\.tsx
*Size: 7.1 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/metrics/ComparativePeriodDisplay.tsx">
import React, { useState } from 'react';
import { FinancialMetric } from '@/types/visualization';
import { formatValue, formatChange, getTrend } from '@/utils/formatters';

interface PeriodData {
  period: string;
  metrics: FinancialMetric[];
}

interface ComparativePeriodDisplayProps {
  data: PeriodData[];
  title?: string;
  subtitle?: string;
  defaultMetric?: string;
}

/**
 * ComparativePeriodDisplay component
 * Shows how financial metrics change over multiple time periods
 */
export default function ComparativePeriodDisplay({
  data,
  title,
  subtitle,
  defaultMetric
}: ComparativePeriodDisplayProps) {
  // Get all unique metric names across all periods
  const allMetricNames = [...new Set(
    data.flatMap(period => period.metrics.map(metric => metric.name))
  )];
  
  // Set default selected metric or use the first one
  const [selectedMetric, setSelectedMetric] = useState<string>(
    defaultMetric || (allMetricNames.length > 0 ? allMetricNames[0] : '')
  );
  
  // No data to display
  if (data.length === 0 || allMetricNames.length === 0) {
    return (
      <div className="bg-white rounded-lg shadow-sm p-4 border border-gray-100">
        <h2 className="text-lg font-semibold text-gray-800">{title || 'Comparative Analysis'}</h2>
        {subtitle && <p className="text-sm text-gray-500 mt-1">{subtitle}</p>}
        <div className="text-center py-6">
          <p className="text-gray-500">No comparative data available</p>
        </div>
      </div>
    );
  }
  
  return (
    <div className="bg-white rounded-lg shadow-sm p-4 border border-gray-100">
      {/* Header section */}
      <div className="mb-4">
        <h2 className="text-lg font-semibold text-gray-800">{title || 'Comparative Analysis'}</h2>
        {subtitle && <p className="text-sm text-gray-500 mt-1">{subtitle}</p>}
        
        {/* Metric selector dropdown */}
        <div className="mt-3">
          <label htmlFor="metric-select" className="block text-sm font-medium text-gray-700">
            Select metric
          </label>
          <select
            id="metric-select"
            className="mt-1 block w-full pl-3 pr-10 py-2 text-base border-gray-300 focus:outline-none focus:ring-blue-500 focus:border-blue-500 sm:text-sm rounded-md"
            value={selectedMetric}
            onChange={(e) => setSelectedMetric(e.target.value)}
          >
            {allMetricNames.map(name => (
              <option key={name} value={name}>
                {name}
              </option>
            ))}
          </select>
        </div>
      </div>
      
      {/* Comparison table */}
      <div className="overflow-x-auto">
        <table className="min-w-full divide-y divide-gray-200">
          <thead className="bg-gray-50">
            <tr>
              <th scope="col" className="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                Period
              </th>
              <th scope="col" className="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                Value
              </th>
              <th scope="col" className="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                Change
              </th>
              <th scope="col" className="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">
                % Change
              </th>
            </tr>
          </thead>
          <tbody className="bg-white divide-y divide-gray-200">
            {data.map((periodData, index) => {
              // Find the selected metric in this period
              const metric = periodData.metrics.find(m => m.name === selectedMetric);
              
              // Calculate change from previous period
              let change = 0;
              let percentChange = 0;
              let trend: 'up' | 'down' | 'neutral' = 'neutral';
              
              if (metric && index > 0) {
                const prevPeriod = data[index - 1];
                const prevMetric = prevPeriod.metrics.find(m => m.name === selectedMetric);
                
                if (prevMetric) {
                  change = metric.value - prevMetric.value;
                  percentChange = prevMetric.value !== 0 
                    ? change / Math.abs(prevMetric.value)
                    : 0;
                  trend = getTrend(percentChange);
                }
              }
              
              // Determine color based on trend
              const trendColors = {
                up: 'text-green-600',
                down: 'text-red-600',
                neutral: 'text-gray-600'
              };
              const trendColor = trendColors[trend];
              
              return (
                <tr key={periodData.period}>
                  <td className="px-6 py-4 whitespace-nowrap text-sm font-medium text-gray-900">
                    {periodData.period}
                  </td>
                  <td className="px-6 py-4 whitespace-nowrap text-sm text-gray-500">
                    {metric 
                      ? `${formatValue(metric.value, 'currency')} ${metric.unit}`
                      : 'N/A'}
                  </td>
                  <td className="px-6 py-4 whitespace-nowrap text-sm text-gray-500">
                    {index > 0 && metric
                      ? <span className={trendColor}>
                          {formatChange(change, 'currency')} {metric.unit}
                        </span>
                      : 'â€”'}
                  </td>
                  <td className="px-6 py-4 whitespace-nowrap text-sm">
                    {index > 0 && metric
                      ? <div className="flex items-center">
                          {trend === 'up' ? (
                            <svg className={`h-4 w-4 ${trendColor} mr-1`} fill="currentColor" viewBox="0 0 20 20">
                              <path fillRule="evenodd" d="M5.293 9.707a1 1 0 010-1.414l4-4a1 1 0 011.414 0l4 4a1 1 0 01-1.414 1.414L11 7.414V15a1 1 0 11-2 0V7.414L6.707 9.707a1 1 0 01-1.414 0z" clipRule="evenodd" />
                            </svg>
                          ) : trend === 'down' ? (
                            <svg className={`h-4 w-4 ${trendColor} mr-1`} fill="currentColor" viewBox="0 0 20 20">
                              <path fillRule="evenodd" d="M14.707 10.293a1 1 0 010 1.414l-4 4a1 1 0 01-1.414 0l-4-4a1 1 0 111.414-1.414L9 12.586V5a1 1 0 012 0v7.586l2.293-2.293a1 1 0 011.414 0z" clipRule="evenodd" />
                            </svg>
                          ) : (
                            <svg className={`h-4 w-4 ${trendColor} mr-1`} fill="currentColor" viewBox="0 0 20 20">
                              <path fillRule="evenodd" d="M5 10a1 1 0 011-1h8a1 1 0 110 2H6a1 1 0 01-1-1z" clipRule="evenodd" />
                            </svg>
                          )}
                          <span className={trendColor}>
                            {formatChange(percentChange, 'percent')}
                          </span>
                        </div>
                      : 'â€”'}
                  </td>
                </tr>
              );
            })}
          </tbody>
        </table>
      </div>
    </div>
  );
} 
</file>
```

#### src/components/metrics/MetricCard\.tsx
*Size: 4.2 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/metrics/MetricCard.tsx">
import React from 'react';
import { FinancialMetric } from '@/types/visualization';
import { formatValue, formatChange, getTrend } from '@/utils/formatters';

interface MetricCardProps {
  metric: FinancialMetric;
  className?: string;
  onClick?: () => void;
}

/**
 * MetricCard component for displaying individual financial metrics
 * Includes trend indicators and formatted values
 */
export default function MetricCard({ metric, className = '', onClick }: MetricCardProps) {
  // Calculate trend if not provided
  const trend = metric.trend || 
    (metric.percentChange !== undefined ? getTrend(metric.percentChange) : 'neutral');
  
  // Determine color based on trend or provided color
  const colorMap = {
    up: 'text-green-600',
    down: 'text-red-600',
    neutral: 'text-gray-600'
  };
  
  const bgColorMap = {
    up: 'bg-green-50',
    down: 'bg-red-50',
    neutral: 'bg-gray-50'
  };
  
  const trendColor = colorMap[trend];
  const trendBgColor = bgColorMap[trend];
  
  // Icon based on trend
  const TrendIcon = () => {
    if (trend === 'up') {
      return (
        <svg 
          xmlns="http://www.w3.org/2000/svg" 
          viewBox="0 0 20 20" 
          fill="currentColor" 
          className="w-5 h-5"
        >
          <path 
            fillRule="evenodd" 
            d="M10 17a.75.75 0 01-.75-.75V5.612L5.29 9.77a.75.75 0 01-1.08-1.04l5.25-5.5a.75.75 0 011.08 0l5.25 5.5a.75.75 0 11-1.08 1.04l-3.96-4.158V16.25A.75.75 0 0110 17z" 
            clipRule="evenodd" 
          />
        </svg>
      );
    } else if (trend === 'down') {
      return (
        <svg 
          xmlns="http://www.w3.org/2000/svg" 
          viewBox="0 0 20 20" 
          fill="currentColor" 
          className="w-5 h-5"
        >
          <path 
            fillRule="evenodd" 
            d="M10 3a.75.75 0 01.75.75v10.638l3.96-4.158a.75.75 0 111.08 1.04l-5.25 5.5a.75.75 0 01-1.08 0l-5.25-5.5a.75.75 0 111.08-1.04l3.96 4.158V3.75A.75.75 0 0110 3z" 
            clipRule="evenodd" 
          />
        </svg>
      );
    } else {
      return (
        <svg 
          xmlns="http://www.w3.org/2000/svg" 
          viewBox="0 0 20 20" 
          fill="currentColor" 
          className="w-5 h-5"
        >
          <path 
            fillRule="evenodd" 
            d="M4 10a.75.75 0 01.75-.75h10.5a.75.75 0 010 1.5H4.75A.75.75 0 014 10z" 
            clipRule="evenodd" 
          />
        </svg>
      );
    }
  };
  
  return (
    <div 
      className={`bg-white rounded-lg shadow-sm p-4 border border-gray-100 ${className} ${onClick ? 'cursor-pointer hover:shadow-md transition-shadow' : ''}`}
      onClick={onClick}
    >
      <div className="flex justify-between items-start">
        <h3 className="text-sm font-medium text-gray-500 truncate">{metric.name}</h3>
        
        {/* Display category label if provided */}
        {metric.category && (
          <span className="px-2 py-1 text-xs rounded-full bg-gray-100 text-gray-600">
            {metric.category}
          </span>
        )}
      </div>
      
      <div className="mt-2 flex items-baseline">
        <div className="text-2xl font-semibold">
          {formatValue(metric.value, 'currency', 0)}
        </div>
        <div className="ml-1 text-sm text-gray-500">
          {metric.unit}
        </div>
      </div>
      
      {/* Trend indicator */}
      {metric.percentChange !== undefined && (
        <div className="mt-2 flex items-center">
          <div className={`flex items-center ${trendColor}`}>
            <span className={`p-1 rounded-full ${trendBgColor} mr-1`}>
              <TrendIcon />
            </span>
            <span className="text-sm font-medium">
              {formatChange(metric.percentChange, 'percent')}
            </span>
          </div>
          
          {metric.previousValue !== undefined && (
            <span className="ml-2 text-xs text-gray-500">
              vs {formatValue(metric.previousValue, 'currency', 0)}
            </span>
          )}
        </div>
      )}
      
      {/* Description if provided */}
      {metric.description && (
        <p className="mt-2 text-xs text-gray-500 line-clamp-2">
          {metric.description}
        </p>
      )}
    </div>
  );
} 
</file>
```

#### src/components/metrics/MetricGrid\.tsx
*Size: 2.8 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/metrics/MetricGrid.tsx">
import React, { useState } from 'react';
import { FinancialMetric } from '@/types/visualization';
import MetricCard from './MetricCard';

interface MetricGridProps {
  metrics: FinancialMetric[];
  title?: string;
  subtitle?: string;
  onMetricClick?: (metric: FinancialMetric) => void;
}

/**
 * MetricGrid component for organizing multiple metrics in a responsive grid layout
 * Includes filtering by category
 */
export default function MetricGrid({ metrics, title, subtitle, onMetricClick }: MetricGridProps) {
  const [selectedCategory, setSelectedCategory] = useState<string | null>(null);
  
  // Extract unique categories from metrics
  const categories = [...new Set(metrics.map(m => m.category).filter(Boolean))] as string[];
  
  // Filter metrics by selected category
  const filteredMetrics = selectedCategory
    ? metrics.filter(m => m.category === selectedCategory)
    : metrics;
  
  return (
    <div className="bg-white rounded-lg shadow-sm p-4 border border-gray-100">
      {/* Header section with title and category filter */}
      <div className="mb-4">
        {title && <h2 className="text-lg font-semibold text-gray-800">{title}</h2>}
        {subtitle && <p className="text-sm text-gray-500 mt-1">{subtitle}</p>}
        
        {/* Category filter tabs (only show if we have categories) */}
        {categories.length > 0 && (
          <div className="flex flex-wrap gap-2 mt-3">
            <button
              className={`px-3 py-1 text-xs rounded-full ${
                selectedCategory === null
                  ? 'bg-blue-100 text-blue-700'
                  : 'bg-gray-100 text-gray-700 hover:bg-gray-200'
              }`}
              onClick={() => setSelectedCategory(null)}
            >
              All
            </button>
            
            {categories.map(category => (
              <button
                key={category}
                className={`px-3 py-1 text-xs rounded-full ${
                  selectedCategory === category
                    ? 'bg-blue-100 text-blue-700'
                    : 'bg-gray-100 text-gray-700 hover:bg-gray-200'
                }`}
                onClick={() => setSelectedCategory(category)}
              >
                {category}
              </button>
            ))}
          </div>
        )}
      </div>
      
      {/* Metrics grid */}
      {filteredMetrics.length > 0 ? (
        <div className="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-3 gap-4">
          {filteredMetrics.map((metric, index) => (
            <MetricCard
              key={`${metric.name}-${index}`}
              metric={metric}
              onClick={onMetricClick ? () => onMetricClick(metric) : undefined}
            />
          ))}
        </div>
      ) : (
        <div className="text-center py-6">
          <p className="text-gray-500">No metrics available</p>
        </div>
      )}
    </div>
  );
} 
</file>
```

#### src/components/tables/TableRenderer\.tsx
*Size: 12.1 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/tables/TableRenderer.tsx">
import React, { useState } from 'react';
import { TableData, TableColumn } from '@/types/visualization';
import { formatValue } from '@/utils/formatters';

interface TableRendererProps {
  data: TableData;
  height?: number | string;
  width?: number | string;
  loading?: boolean;
  error?: Error | null;
  className?: string;
}

/**
 * TableRenderer component for displaying tabular data
 */
export default function TableRenderer({
  data,
  height,
  width = '100%',
  loading,
  error,
  className = ''
}: TableRendererProps) {
  const [currentPage, setCurrentPage] = useState(0);
  
  // Handle loading state
  if (loading) {
    return (
      <div className={`w-full overflow-hidden rounded-lg bg-white p-4 shadow-sm ${className}`}>
        <div className="animate-pulse">
          <div className="h-6 w-40 bg-gray-200 rounded mb-4"></div>
          <div className="h-4 w-full bg-gray-200 rounded mb-2"></div>
          <div className="h-4 w-full bg-gray-200 rounded mb-2"></div>
          <div className="h-4 w-full bg-gray-200 rounded mb-2"></div>
          <div className="h-4 w-3/4 bg-gray-200 rounded"></div>
        </div>
      </div>
    );
  }
  
  // Handle error state
  if (error) {
    return (
      <div className={`w-full overflow-hidden rounded-lg bg-red-50 p-4 shadow-sm ${className}`}>
        <div className="text-red-500 text-center">
          <h3 className="font-semibold mb-2">Error loading table</h3>
          <p className="text-sm">{error.message}</p>
        </div>
      </div>
    );
  }
  
  // If no data is provided, show placeholder
  if (!data) {
    return (
      <div className={`w-full overflow-hidden rounded-lg bg-white p-4 shadow-sm ${className}`}>
        <p className="text-gray-500 text-center">No table data available</p>
      </div>
    );
  }
  
  const { config, data: tableData } = data;
  
  // Use columns from TableData or from TableConfig if provided there
  const columns = data.columns || config.columns || [];
  
  // Calculate pagination if enabled
  const rowsPerPage = config.pageSize || 10;
  const totalPages = config.pagination !== false ? Math.ceil(tableData.length / rowsPerPage) : 1;
  
  // Get the rows for the current page
  const currentRows = config.pagination !== false
    ? tableData.slice(currentPage * rowsPerPage, (currentPage + 1) * rowsPerPage)
    : tableData;
  
  // Handle page navigation
  const goToNextPage = () => {
    if (currentPage < totalPages - 1) {
      setCurrentPage(currentPage + 1);
    }
  };
  
  const goToPrevPage = () => {
    if (currentPage > 0) {
      setCurrentPage(currentPage - 1);
    }
  };
  
  // Format cell value based on column formatter or format
  const formatCell = (value: any, column: TableColumn) => {
    if (value === undefined || value === null) {
      return 'â€”';
    }
    
    if (typeof value === 'number') {
      // First try formatter (frontend style), then try format (backend style)
      if (column.formatter) {
        return formatValue(value, column.formatter);
      } else if (column.format) {
        // Map backend format to frontend formatter
        const formatMap: Record<string, string> = {
          'number': 'number',
          'currency': 'currency',
          'percentage': 'percent',
          'text': 'text'
        };
        return formatValue(value, formatMap[column.format] || 'number');
      }
    }
    
    return value.toString();
  };
  
  return (
    <div 
      className={`w-full overflow-hidden rounded-lg bg-white p-4 shadow-sm ${className}`}
      style={{ width, height: height || 'auto' }}
    >
      {/* Table title and subtitle/description */}
      {config.title && (
        <div className="mb-4">
          <h3 className="text-lg font-semibold text-gray-800">{config.title}</h3>
          {config.subtitle && <p className="text-sm text-gray-500">{config.subtitle}</p>}
          {config.description && !config.subtitle && (
            <p className="text-sm text-gray-500">{config.description}</p>
          )}
        </div>
      )}
      
      {/* Table */}
      <div className="overflow-x-auto">
        <table className="min-w-full divide-y divide-gray-200">
          <thead className="bg-gray-50">
            <tr>
              {/* Row numbers column if enabled */}
              {config.showRowNumbers && (
                <th scope="col" className="px-3 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">#</th>
              )}
              
              {/* Column headers */}
              {columns.map((column, colIndex) => (
                <th
                  key={`col-${colIndex}`}
                  scope="col"
                  className={`px-3 py-3 text-xs font-medium text-gray-500 uppercase tracking-wider ${
                    column.align ? `text-${column.align}` : 'text-left'
                  }`}
                  style={{ width: column.width ? `${column.width}px` : 'auto' }}
                >
                  {/* Use header or label property, depending on which is available */}
                  {column.header || column.label}
                </th>
              ))}
            </tr>
          </thead>
          <tbody className="bg-white divide-y divide-gray-200">
            {currentRows.map((row, rowIndex) => (
              <tr key={`row-${rowIndex}`} className={rowIndex % 2 === 0 ? 'bg-white' : 'bg-gray-50'}>
                {/* Row number if enabled */}
                {config.showRowNumbers && (
                  <td className="px-3 py-4 whitespace-nowrap text-sm text-gray-500">
                    {currentPage * rowsPerPage + rowIndex + 1}
                  </td>
                )}
                
                {/* Cell data */}
                {columns.map((column, colIndex) => (
                  <td
                    key={`cell-${rowIndex}-${colIndex}`}
                    className={`px-3 py-4 whitespace-nowrap text-sm text-gray-500 ${
                      column.align ? `text-${column.align}` : ''
                    }`}
                  >
                    {formatCell(row[column.key], column)}
                  </td>
                ))}
              </tr>
            ))}
            
            {/* Empty state for no rows */}
            {currentRows.length === 0 && (
              <tr>
                <td
                  colSpan={columns.length + (config.showRowNumbers ? 1 : 0)}
                  className="px-3 py-4 text-center text-sm text-gray-500"
                >
                  No data available
                </td>
              </tr>
            )}
          </tbody>
        </table>
      </div>
      
      {/* Footer if provided */}
      {config.footer && (
        <div className="mt-2 text-sm text-gray-500">
          {config.footer}
        </div>
      )}
      
      {/* Pagination controls */}
      {config.pagination !== false && totalPages > 1 && (
        <div className="flex items-center justify-between border-t border-gray-200 px-4 py-3 sm:px-6 mt-4">
          <div className="flex flex-1 justify-between sm:hidden">
            <button
              onClick={goToPrevPage}
              disabled={currentPage === 0}
              className={`relative inline-flex items-center rounded-md px-4 py-2 text-sm font-medium ${
                currentPage === 0
                  ? 'text-gray-300 cursor-not-allowed'
                  : 'text-gray-700 hover:bg-gray-50'
              }`}
            >
              Previous
            </button>
            <button
              onClick={goToNextPage}
              disabled={currentPage === totalPages - 1}
              className={`relative ml-3 inline-flex items-center rounded-md px-4 py-2 text-sm font-medium ${
                currentPage === totalPages - 1
                  ? 'text-gray-300 cursor-not-allowed'
                  : 'text-gray-700 hover:bg-gray-50'
              }`}
            >
              Next
            </button>
          </div>
          <div className="hidden sm:flex sm:flex-1 sm:items-center sm:justify-between">
            <div>
              <p className="text-sm text-gray-700">
                Showing <span className="font-medium">{currentPage * rowsPerPage + 1}</span> to{' '}
                <span className="font-medium">
                  {Math.min((currentPage + 1) * rowsPerPage, tableData.length)}
                </span>{' '}
                of <span className="font-medium">{tableData.length}</span> results
              </p>
            </div>
            <div>
              <nav
                className="isolate inline-flex -space-x-px rounded-md shadow-sm"
                aria-label="Pagination"
              >
                <button
                  onClick={goToPrevPage}
                  disabled={currentPage === 0}
                  className={`relative inline-flex items-center rounded-l-md px-2 py-2 text-gray-400 ${
                    currentPage === 0
                      ? 'cursor-not-allowed'
                      : 'hover:bg-gray-50'
                  }`}
                >
                  <span className="sr-only">Previous</span>
                  {/* Heroicon: chevron-left */}
                  <svg
                    className="h-5 w-5"
                    xmlns="http://www.w3.org/2000/svg"
                    viewBox="0 0 20 20"
                    fill="currentColor"
                    aria-hidden="true"
                  >
                    <path
                      fillRule="evenodd"
                      d="M12.79 5.23a.75.75 0 01-.02 1.06L8.832 10l3.938 3.71a.75.75 0 11-1.04 1.08l-4.5-4.25a.75.75 0 010-1.08l4.5-4.25a.75.75 0 011.06.02z"
                      clipRule="evenodd"
                    />
                  </svg>
                </button>
                
                {/* Page numbers (limit to 5 pages for UI clarity) */}
                {Array.from({ length: Math.min(5, totalPages) }).map((_, i) => {
                  // For more than 5 pages, show first 2, current, and last 2
                  let pageNumber = i;
                  if (totalPages > 5) {
                    if (currentPage < 2) {
                      pageNumber = i;
                    } else if (currentPage > totalPages - 3) {
                      pageNumber = totalPages - 5 + i;
                    } else {
                      pageNumber = currentPage - 2 + i;
                    }
                  }
                  
                  return (
                    <button
                      key={pageNumber}
                      onClick={() => setCurrentPage(pageNumber)}
                      aria-current={currentPage === pageNumber ? 'page' : undefined}
                      className={`relative inline-flex items-center px-4 py-2 text-sm font-medium ${
                        currentPage === pageNumber
                          ? 'z-10 bg-blue-50 border-blue-500 text-blue-600'
                          : 'text-gray-500 hover:bg-gray-50'
                      }`}
                    >
                      {pageNumber + 1}
                    </button>
                  );
                })}
                
                <button
                  onClick={goToNextPage}
                  disabled={currentPage === totalPages - 1}
                  className={`relative inline-flex items-center rounded-r-md px-2 py-2 text-gray-400 ${
                    currentPage === totalPages - 1
                      ? 'cursor-not-allowed'
                      : 'hover:bg-gray-50'
                  }`}
                >
                  <span className="sr-only">Next</span>
                  {/* Heroicon: chevron-right */}
                  <svg
                    className="h-5 w-5"
                    xmlns="http://www.w3.org/2000/svg"
                    viewBox="0 0 20 20"
                    fill="currentColor"
                    aria-hidden="true"
                  >
                    <path
                      fillRule="evenodd"
                      d="M7.21 14.77a.75.75 0 01.02-1.06L11.168 10 7.23 6.29a.75.75 0 111.04-1.08l4.5 4.25a.75.75 0 010 1.08l-4.5 4.25a.75.75 0 01-1.06-.02z"
                      clipRule="evenodd"
                    />
                  </svg>
                </button>
              </nav>
            </div>
          </div>
        </div>
      )}
    </div>
  );
} 
</file>
```

#### src/components/ui/button\.tsx
*Size: 1.6 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/ui/button.tsx">
import * as React from "react"
import { cn } from "@/lib/utils"

export interface ButtonProps extends React.ButtonHTMLAttributes<HTMLButtonElement> {
  variant?: 'default' | 'destructive' | 'outline' | 'secondary' | 'ghost' | 'link'
  size?: 'default' | 'sm' | 'lg' | 'icon'
}

const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(
  ({ className, variant = 'default', size = 'default', ...props }, ref) => {
    const baseStyles = "inline-flex items-center justify-center rounded-md font-medium transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:opacity-50 disabled:pointer-events-none ring-offset-background"
    
    const variantStyles = {
      default: "bg-primary text-primary-foreground hover:bg-primary/90",
      destructive: "bg-destructive text-destructive-foreground hover:bg-destructive/90",
      outline: "border border-input hover:bg-accent hover:text-accent-foreground",
      secondary: "bg-secondary text-secondary-foreground hover:bg-secondary/80",
      ghost: "hover:bg-accent hover:text-accent-foreground",
      link: "underline-offset-4 hover:underline text-primary"
    }
    
    const sizeStyles = {
      default: "h-10 py-2 px-4",
      sm: "h-9 px-3 rounded-md",
      lg: "h-11 px-8 rounded-md",
      icon: "h-10 w-10"
    }
    
    return (
      <button
        className={cn(
          baseStyles,
          variantStyles[variant],
          sizeStyles[size],
          className
        )}
        ref={ref}
        {...props}
      />
    )
  }
)
Button.displayName = "Button"

export { Button } 
</file>
```

#### src/components/ui/collapsible\.tsx
*Size: 860 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/ui/collapsible.tsx">
import * as React from "react"
import * as CollapsiblePrimitive from "@radix-ui/react-collapsible"
import { cn } from "@/lib/utils"

const Collapsible = CollapsiblePrimitive.Root

const CollapsibleTrigger = CollapsiblePrimitive.Trigger

const CollapsibleContent = React.forwardRef<
  React.ElementRef<typeof CollapsiblePrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof CollapsiblePrimitive.Content>
>(({ className, children, ...props }, ref) => (
  <CollapsiblePrimitive.Content
    ref={ref}
    className={cn(
      "data-[state=closed]:animate-collapsible-up data-[state=open]:animate-collapsible-down overflow-hidden transition-all",
      className
    )}
    {...props}
  >
    {children}
  </CollapsiblePrimitive.Content>
))
CollapsibleContent.displayName = "CollapsibleContent"

export { Collapsible, CollapsibleTrigger, CollapsibleContent } 
</file>
```

#### src/components/ui/input\.tsx
*Size: 821 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/ui/input.tsx">
import * as React from "react"
import { cn } from "@/lib/utils"

export interface InputProps extends React.InputHTMLAttributes<HTMLInputElement> {}

const Input = React.forwardRef<HTMLInputElement, InputProps>(
  ({ className, type, ...props }, ref) => {
    return (
      <input
        type={type}
        className={cn(
          "flex h-10 w-full rounded-md border border-input bg-background px-3 py-2 text-sm ring-offset-background file:border-0 file:bg-transparent file:text-sm file:font-medium placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50",
          className
        )}
        ref={ref}
        {...props}
      />
    )
  }
)
Input.displayName = "Input"

export { Input } 
</file>
```

#### src/components/ui/tabs\.tsx
*Size: 1.8 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/ui/tabs.tsx">
"use client"

import * as React from "react"
import * as TabsPrimitive from "@radix-ui/react-tabs"

import { cn } from "@/lib/utils"

const Tabs = TabsPrimitive.Root

const TabsList = React.forwardRef<
  React.ElementRef<typeof TabsPrimitive.List>,
  React.ComponentPropsWithoutRef<typeof TabsPrimitive.List>
>(({ className, ...props }, ref) => (
  <TabsPrimitive.List
    ref={ref}
    className={cn(
      "inline-flex h-10 items-center justify-center rounded-md bg-gray-100 p-1 text-gray-500",
      className
    )}
    {...props}
  />
))
TabsList.displayName = TabsPrimitive.List.displayName

const TabsTrigger = React.forwardRef<
  React.ElementRef<typeof TabsPrimitive.Trigger>,
  React.ComponentPropsWithoutRef<typeof TabsPrimitive.Trigger>
>(({ className, ...props }, ref) => (
  <TabsPrimitive.Trigger
    ref={ref}
    className={cn(
      "inline-flex items-center justify-center whitespace-nowrap rounded-sm px-3 py-1.5 text-sm font-medium transition-all focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-indigo-500 focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 data-[state=active]:bg-white data-[state=active]:text-indigo-600 data-[state=active]:shadow-sm",
      className
    )}
    {...props}
  />
))
TabsTrigger.displayName = TabsPrimitive.Trigger.displayName

const TabsContent = React.forwardRef<
  React.ElementRef<typeof TabsPrimitive.Content>,
  React.ComponentPropsWithoutRef<typeof TabsPrimitive.Content>
>(({ className, ...props }, ref) => (
  <TabsPrimitive.Content
    ref={ref}
    className={cn(
      "mt-2 ring-offset-white focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-indigo-500 focus-visible:ring-offset-2",
      className
    )}
    {...props}
  />
))
TabsContent.displayName = TabsPrimitive.Content.displayName

export { Tabs, TabsList, TabsTrigger, TabsContent }
</file>
```

#### src/components/ui/textarea\.tsx
*Size: 769 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/ui/textarea.tsx">
import * as React from "react"
import { cn } from "@/lib/utils"

export interface TextareaProps extends React.TextareaHTMLAttributes<HTMLTextAreaElement> {}

const Textarea = React.forwardRef<HTMLTextAreaElement, TextareaProps>(
  ({ className, ...props }, ref) => {
    return (
      <textarea
        className={cn(
          "flex min-h-[80px] w-full rounded-md border border-input bg-background px-3 py-2 text-sm ring-offset-background placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50",
          className
        )}
        ref={ref}
        {...props}
      />
    )
  }
)
Textarea.displayName = "Textarea"

export { Textarea } 
</file>
```

#### src/components/visualization/Canvas\.tsx
*Size: 42.7 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/visualization/Canvas.tsx">
'use client';

import React, { useState, useCallback } from 'react';
import { AnalysisResult } from '@/types';
import { ChartData, TableData, VisualizationData, FinancialMetric } from '@/types/visualization';
import ChartRenderer from '../charts/ChartRenderer';
import TableRenderer from '../tables/TableRenderer';
import MetricCard from '../metrics/MetricCard';
import MetricGrid from '../metrics/MetricGrid';

interface CanvasProps {
  analysisResults: AnalysisResult[];
  messages?: any[]; // Add messages prop
  loading?: boolean;
  error?: Error | string;
  onCitationClick?: (highlightId: string) => void;
}

/**
 * Canvas component for managing the layout and navigation of multiple visualizations
 */
const Canvas: React.FC<CanvasProps> = ({ analysisResults, messages = [], loading, error, onCitationClick }) => {
  const [currentTab, setCurrentTab] = useState<'overview' | 'charts' | 'tables'>('overview');

  // Parse financial data from text messages
  const extractFinancialDataFromMessages = useCallback((msgs: any[]) => {
    // Only use assistant messages
    const assistantMessages = msgs.filter(msg => msg.role === 'assistant');
    if (assistantMessages.length === 0) return null;

    // Get the latest message content
    const latestContent = assistantMessages[assistantMessages.length - 1].content;
    
    // First, try to find what type of financial statement is being discussed
    const hasBalanceSheetContent = /balance sheet|assets|liabilities|equity|stockholders|cash and cash equivalents/i.test(latestContent);
    const hasIncomeStatementContent = /income statement|revenue|sales|earnings|profit|net income|operating income|expenses|cost of|gross margin|ebitda/i.test(latestContent);
    
    if (!hasBalanceSheetContent && !hasIncomeStatementContent) return null;
    
    console.log("Found financial content in message:", { 
      isBalanceSheet: hasBalanceSheetContent, 
      isIncomeStatement: hasIncomeStatementContent 
    });
    
    // Process income statement data
    if (hasIncomeStatementContent) {
      return extractIncomeStatementData(latestContent);
    }
    
    // Extract balance sheet data using existing patterns
    // ... existing balance sheet extraction code ...
    
    // Extract financial data using various patterns - including full dollar amount formats
    const financialData = {};
    
    // Extract asset values
    const assetMatch = latestContent.match(/cash and cash equivalents\s+(?:increased|decreased)\s+(?:from|to)\s+\$?([\d,]+(?:\.\d+)?)\s+(?:from|to)\s+\$?([\d,]+(?:\.\d+)?)/i) || 
                    latestContent.match(/total current assets\s+(?:increased|decreased)\s+(?:from|to)\s+\$?([\d,]+(?:\.\d+)?)\s+(?:from|to)\s+\$?([\d,]+(?:\.\d+)?)/i) ||
                    latestContent.match(/total assets\s+(?:increased|decreased)\s+(?:from|to)\s+\$?([\d,]+(?:\.\d+)?)\s+(?:from|to)\s+\$?([\d,]+(?:\.\d+)?)/i) ||
                    latestContent.match(/assets:.*total assets.*?\$?([\d,]+(?:\.\d+)?).*?\$?([\d,]+(?:\.\d+)?)/is);
                    
    // Extract liability values
    const liabMatch = latestContent.match(/total (?:current )?liabilities\s+(?:increased|decreased)\s+(?:from|to)\s+\$?([\d,]+(?:\.\d+)?)\s+(?:from|to)\s+\$?([\d,]+(?:\.\d+)?)/i) ||
                  latestContent.match(/liabilities:.*total liabilities.*?\$?([\d,]+(?:\.\d+)?).*?\$?([\d,]+(?:\.\d+)?)/is);
    
    // Extract equity values
    const equityMatch = latestContent.match(/total stockholders.*?(?:deficit|equity)\s+(?:improved|increased|decreased)\s+(?:from|to)\s+\$?\(?([\d,]+(?:\.\d+)?)\)?\s+(?:from|to)\s+\$?\(?([\d,]+(?:\.\d+)?)\)?/i) ||
                     latestContent.match(/total equity\s+(?:increased|decreased)\s+(?:from|to)\s+\$?([\d,]+(?:\.\d+)?)\s+(?:from|to)\s+\$?([\d,]+(?:\.\d+)?)/i);
    
    console.log("Balance sheet extraction results:", { 
      assetMatch: assetMatch ? assetMatch[0] : 'No match', 
      liabMatch: liabMatch ? liabMatch[0] : 'No match',
      equityMatch: equityMatch ? equityMatch[0] : 'No match'
    });
    
    // If we couldn't extract using standard patterns, try to find full balance sheet items
    if (!assetMatch && !liabMatch && !equityMatch) {
      // Try to find full numbers with commas for specific balance sheet items
      const fullNumberRegex = /(?:Cash and cash equivalents|Accounts receivable|Inventories|Total current assets|Property, plant|Total assets|Accounts payable|Total current liabilities|Total liabilities|Total equity|Total Mueller Industries stockholders' equity)\s+(?:increased|decreased)\s+(?:from|to)\s+\$?([\d,]+,\d+)\s+(?:from|to)\s+\$?([\d,]+,\d+)/gi;
      
      const allMatches = [...latestContent.matchAll(fullNumberRegex)];
      
      console.log("Alternative extraction found items:", {
        fullNumberMatches: allMatches.length,
        matches: allMatches.map(m => m[0])
      });
      
      if (allMatches.length > 0) {
        // Group matches by type
        const assetItems = allMatches.filter(item => 
          /cash|receivable|inventories|current assets|property|total assets/i.test(item[0])
        );
        
        const liabItems = allMatches.filter(item => 
          /payable|current liabilities|total liabilities/i.test(item[0]) && 
          !/equity|stockholders/i.test(item[0])
        );
        
        const equityItems = allMatches.filter(item => 
          /equity|stockholders/i.test(item[0])
        );
        
        return createVisualizationFromDetailedItems(assetItems, liabItems, equityItems, latestContent);
      }
      
      // Try a different approach - extract balance sheet items and their values directly
      // These regexes look for patterns like: "Cash decreased from $1,170,893,000 to $825,655,000"
      const directExtractionRegex = /([\w\s,]+)\s+(?:increased|decreased)\s+from\s+\$?([\d,]+(?:,\d+)?)\s+to\s+\$?([\d,]+(?:,\d+)?)/g;
      const directMatches = [...latestContent.matchAll(directExtractionRegex)];
      
      if (directMatches.length > 0) {
        // Process direct matches
        const processedItems = directMatches.map(match => ({
          name: match[1].trim(),
          oldValue: match[2].replace(/,/g, ''),
          newValue: match[3].replace(/,/g, '')
        }));
        
        // Create visualizations from these extracted items
        return createVisualizationFromDirectMatches(processedItems, latestContent);
      }
      
      return null;
    }
    
    // Create visualization data
    const visualizationData: VisualizationData = {
      charts: [],
      tables: [],
      metrics: []
    };
    
    // Extract period labels from the text
    const periodRegex = /(\w+\s+\d{1,2},?\s+\d{4})\s+(?:and|vs\.?|to|from|compared to)\s+(\w+\s+\d{1,2},?\s+\d{4})/i;
    const periodMatch = latestContent.match(periodRegex);
    const period1 = periodMatch?.[2] || 'December 30, 2023';
    const period2 = periodMatch?.[1] || 'June 29, 2024';
    
    // Determine if we're dealing with a deficit (negative equity)
    const isDeficit = latestContent.includes('deficit') || (equityMatch && latestContent.match(/\(.*?\)/));
    
    // Helper to normalize values to millions for display
    const normalizeToMillions = (value: string): number => {
      // Remove commas and convert to number
      let num = parseFloat(value.replace(/,/g, ''));
      
      // If the number is very large (over a million), convert to millions
      if (num > 1000000) {
        num = num / 1000000;
      }
      
      return num;
    };
    
    // Create metrics
    if (assetMatch) {
      const oldValue = normalizeToMillions(assetMatch[2]);
      const newValue = normalizeToMillions(assetMatch[1]);
      
      visualizationData.metrics.push({
        name: 'Total Assets',
        value: newValue,
        previousValue: oldValue,
        percentChange: calculatePercentChange(oldValue.toString(), newValue.toString()),
        unit: 'M',
        trend: newValue > oldValue ? 'up' : 'down'
      });
    }
    
    if (liabMatch) {
      const oldValue = normalizeToMillions(liabMatch[2]);
      const newValue = normalizeToMillions(liabMatch[1]);
      
      visualizationData.metrics.push({
        name: 'Total Liabilities',
        value: newValue,
        previousValue: oldValue,
        percentChange: calculatePercentChange(oldValue.toString(), newValue.toString()),
        unit: 'M',
        trend: newValue > oldValue ? 'up' : 'down'
      });
    }
    
    if (equityMatch) {
      // Handle cases where equity is shown as negative (deficit)
      const oldValue = normalizeToMillions(equityMatch[2]);
      const newValue = normalizeToMillions(equityMatch[1]);
      
      visualizationData.metrics.push({
        name: isDeficit ? 'Stockholders Deficit' : 'Total Equity',
        value: isDeficit ? -newValue : newValue,
        previousValue: isDeficit ? -oldValue : oldValue,
        percentChange: calculatePercentChange(
          isDeficit ? (-oldValue).toString() : oldValue.toString(), 
          isDeficit ? (-newValue).toString() : newValue.toString()
        ),
        unit: 'M',
        trend: isDeficit ? 
          (newValue < oldValue ? 'up' : 'down') : 
          (newValue > oldValue ? 'up' : 'down')
      });
    }
    
    // Create bar chart for balance sheet comparison
    if (visualizationData.metrics.length > 0) {
      const chartData = [];
      
      // Add each metric as a data point
      visualizationData.metrics.forEach(metric => {
        chartData.push({
          category: metric.name,
          [period1]: metric.previousValue,
          [period2]: metric.value
        });
      });
      
      visualizationData.charts.push({
        chartType: 'bar',
        config: {
          title: 'Balance Sheet Comparison',
          description: `${period1} vs ${period2}`,
          xAxisKey: 'category'
        },
        data: chartData,
        chartConfig: {
          [period1]: { label: period1 },
          [period2]: { label: period2 }
        }
      });
      
      // Create a detailed table with the extracted data
      const tableData = visualizationData.metrics.map(metric => ({
        metric: metric.name,
        prior: metric.previousValue,
        current: metric.value,
        change: metric.value - metric.previousValue,
        percentChange: metric.percentChange
      }));
      
      visualizationData.tables.push({
        tableType: 'comparison',
        config: {
          title: 'Balance Sheet Analysis',
          description: `${period1} vs ${period2}`,
          columns: [
            { key: 'metric', label: 'Metric', format: 'text' },
            { key: 'prior', label: period1, format: 'currency' },
            { key: 'current', label: period2, format: 'currency' },
            { key: 'change', label: 'Change', format: 'currency' },
            { key: 'percentChange', label: '% Change', format: 'percentage' }
          ]
        },
        data: tableData
      });
    }
    
    return visualizationData;
  }, []);
  
  // New function to extract income statement data
  const extractIncomeStatementData = (text) => {
    console.log("Extracting income statement data...");
    
    const visualizationData: VisualizationData = {
      charts: [],
      tables: [],
      metrics: []
    };
    
    // Extract quarter/year labels
    const periodRegex = /Q(\d)\s+(\d{4})/gi;
    const periods = [...text.matchAll(periodRegex)];
    const uniquePeriods = Array.from(new Set(periods.map(p => p[0])));
    
    console.log("Detected periods:", uniquePeriods);
    
    // Default periods if not found
    const period1 = uniquePeriods[1] || 'Q2 2023';
    const period2 = uniquePeriods[0] || 'Q2 2024';
    
    // 1. Extract revenue data
    const revenueMatches = [
      // Total revenue - try multiple patterns
      ...extractFinancialMetric(text, /(?:total|net)\s+revenue.*?\$([\d,.]+)\s+(?:million|M).*?(?:from|compared to).*?\$([\d,.]+)\s+(?:million|M)/gi),
      ...extractFinancialMetric(text, /(?:total|net)\s+revenue.*?\$([\d,.]+).*?(?:from|compared to).*?\$([\d,.]+)/gi),
      ...extractFinancialMetric(text, /revenue.*?(?:grew|increased|reached).*?\$([\d,.]+).*?(?:from|compared to).*?\$([\d,.]+)/gi),
      ...extractFinancialMetric(text, /revenue:.*?\$([\d,.]+).*?(?:vs|compared to).*?\$([\d,.]+)/gi)
    ];
    
    // 2. Extract net income data
    const netIncomeMatches = [
      ...extractFinancialMetric(text, /net\s+income.*?\$([\d,.]+)\s+(?:million|M).*?(?:from|compared to).*?\$([\d,.]+)\s+(?:million|M)/gi),
      ...extractFinancialMetric(text, /net\s+income.*?\$([\d,.]+).*?(?:from|compared to|vs\.?).*?\$([\d,.]+)/gi),
      ...extractFinancialMetric(text, /net\s+income\s+of.*?\$([\d,.]+).*?(?:compared to|vs\.?).*?\$([\d,.]+)/gi)
    ];
    
    // 3. Extract operating income data
    const operatingIncomeMatches = [
      ...extractFinancialMetric(text, /operating\s+income.*?\$([\d,.]+)\s+(?:million|M).*?(?:from|compared to).*?\$([\d,.]+)\s+(?:million|M)/gi),
      ...extractFinancialMetric(text, /operating\s+income.*?\$([\d,.]+).*?(?:from|compared to|vs\.?).*?\$([\d,.]+)/gi)
    ];
    
    // 4. Extract segment revenues
    const segmentRevenues = [];
    const segmentMatches = [
      ...extractNamedFinancialMetric(text, /([\w\s]+)\s+revenue:.*?\$([\d,.]+).*?(?:grew|increased).*?(?:\d+\.?\d*%)/gi),
      ...extractNamedFinancialMetric(text, /([\w\s]+)\s+revenue:.*?\$([\d,.]+).*?(?:vs|compared to|from).*?\$([\d,.]+)/gi)
    ];
    
    // Process segment revenue data
    segmentMatches.forEach(match => {
      if (match.name && match.currentValue) {
        segmentRevenues.push({
          name: match.name.trim(),
          currentValue: parseFloat(match.currentValue.replace(/,/g, '')),
          previousValue: match.previousValue ? parseFloat(match.previousValue.replace(/,/g, '')) : null,
          percentChange: match.percentChange || null
        });
      }
    });
    
    console.log("Extracted metrics:", {
      revenue: revenueMatches,
      netIncome: netIncomeMatches,
      operatingIncome: operatingIncomeMatches,
      segments: segmentRevenues
    });
    
    // Process and normalize values
    const processValue = (match) => {
      if (!match || !match.currentValue) return null;
      
      // Convert to number and normalize to millions if needed
      let currentValue = parseFloat(match.currentValue.replace(/,/g, ''));
      let previousValue = match.previousValue ? parseFloat(match.previousValue.replace(/,/g, '')) : 0;
      
      // Check if values need to be converted to millions
      if (currentValue > 100 && !text.includes('million') && !text.includes('M')) {
        currentValue = currentValue / 1000000;
        previousValue = previousValue / 1000000;
      }
      
      return {
        currentValue,
        previousValue,
        percentChange: calculatePercentChange(previousValue.toString(), currentValue.toString())
      };
    };
    
    // Add metrics for key financial data
    const revenueData = processValue(revenueMatches[0]);
    const netIncomeData = processValue(netIncomeMatches[0]);
    const operatingIncomeData = processValue(operatingIncomeMatches[0]);
    
    if (revenueData) {
      visualizationData.metrics.push({
        name: 'Total Revenue',
        value: revenueData.currentValue,
        previousValue: revenueData.previousValue,
        percentChange: revenueData.percentChange,
        unit: 'M',
        trend: revenueData.currentValue > revenueData.previousValue ? 'up' : 'down'
      });
    }
    
    if (netIncomeData) {
      visualizationData.metrics.push({
        name: 'Net Income',
        value: netIncomeData.currentValue,
        previousValue: netIncomeData.previousValue,
        percentChange: netIncomeData.percentChange,
        unit: 'M',
        trend: netIncomeData.currentValue > netIncomeData.previousValue ? 'up' : 'down'
      });
    }
    
    if (operatingIncomeData) {
      visualizationData.metrics.push({
        name: 'Operating Income',
        value: operatingIncomeData.currentValue,
        previousValue: operatingIncomeData.previousValue,
        percentChange: operatingIncomeData.percentChange,
        unit: 'M',
        trend: operatingIncomeData.currentValue > operatingIncomeData.previousValue ? 'up' : 'down'
      });
    }
    
    // Create visualization charts
    
    // 1. Revenue comparison chart
    if (revenueData || segmentRevenues.length > 0) {
      const chartData = [];
      
      // Add total revenue if available
      if (revenueData) {
        chartData.push({
          category: 'Total Revenue',
          [period1]: revenueData.previousValue,
          [period2]: revenueData.currentValue
        });
      }
      
      // Add segment revenues if available
      segmentRevenues.forEach(segment => {
        chartData.push({
          category: segment.name,
          [period1]: segment.previousValue || 0,
          [period2]: segment.currentValue || 0
        });
      });
      
      if (chartData.length > 0) {
        visualizationData.charts.push({
          chartType: 'bar',
          config: {
            title: 'Revenue by Segment',
            description: `${period1} vs ${period2} Revenue Comparison`,
            xAxisKey: 'category'
          },
          data: chartData,
          chartConfig: {
            [period1]: { label: period1 },
            [period2]: { label: period2 }
          }
        });
      }
    }
    
    // 2. Income metrics chart
    if (netIncomeData || operatingIncomeData) {
      const incomeChartData = [];
      
      if (operatingIncomeData) {
        incomeChartData.push({
          category: 'Operating Income',
          [period1]: operatingIncomeData.previousValue,
          [period2]: operatingIncomeData.currentValue
        });
      }
      
      if (netIncomeData) {
        incomeChartData.push({
          category: 'Net Income',
          [period1]: netIncomeData.previousValue,
          [period2]: netIncomeData.currentValue
        });
      }
      
      if (incomeChartData.length > 0) {
        visualizationData.charts.push({
          chartType: 'bar',
          config: {
            title: 'Operating Income by Segment',
            description: `${period1} vs ${period2} Operating Income`,
            xAxisKey: 'category'
          },
          data: incomeChartData,
          chartConfig: {
            [period1]: { label: period1 },
            [period2]: { label: period2 }
          }
        });
      }
    }
    
    // Create a detailed table with the extracted data
    const tableData = [];
    
    if (revenueData) {
      tableData.push({
        metric: 'Net Sales',
        prior: revenueData.previousValue,
        current: revenueData.currentValue,
        change: revenueData.currentValue - revenueData.previousValue,
        percentChange: revenueData.percentChange
      });
    }
    
    if (operatingIncomeData) {
      tableData.push({
        metric: 'Operating Income',
        prior: operatingIncomeData.previousValue,
        current: operatingIncomeData.currentValue,
        change: operatingIncomeData.currentValue - operatingIncomeData.previousValue,
        percentChange: operatingIncomeData.percentChange
      });
    }
    
    if (netIncomeData) {
      tableData.push({
        metric: 'Net Income',
        prior: netIncomeData.previousValue,
        current: netIncomeData.currentValue,
        change: netIncomeData.currentValue - netIncomeData.previousValue,
        percentChange: netIncomeData.percentChange
      });
    }
    
    if (tableData.length > 0) {
      visualizationData.tables.push({
        tableType: 'comparison',
        config: {
          title: 'Key Financial Metrics',
          description: `${period1} vs ${period2} Performance`,
          columns: [
            { key: 'metric', label: 'Metric', format: 'text' },
            { key: 'prior', label: period1, format: 'currency' },
            { key: 'current', label: period2, format: 'currency' },
            { key: 'change', label: 'Change', format: 'currency' },
            { key: 'percentChange', label: '% Change', format: 'percentage' }
          ]
        },
        data: tableData
      });
    }
    
    return visualizationData;
  };

  // Helper function to extract financial metrics with current and previous values
  const extractFinancialMetric = (text, pattern) => {
    try {
      // Ensure the pattern has the global flag
      if (!pattern.flags.includes('g')) {
        console.log("Warning: Adding missing global flag to regex pattern");
        pattern = new RegExp(pattern.source, pattern.flags + 'g');
      }
      
      const matches = [...text.matchAll(pattern)];
      return matches.map(match => ({
        currentValue: match[1],
        previousValue: match[2],
        percentChange: null // Will calculate later
      }));
    } catch (error) {
      console.error("Error in extractFinancialMetric:", error);
      return [];
    }
  };

  // Helper function to extract named financial metrics
  const extractNamedFinancialMetric = (text, pattern) => {
    try {
      // Ensure the pattern has the global flag
      if (!pattern.flags.includes('g')) {
        console.log("Warning: Adding missing global flag to regex pattern");
        pattern = new RegExp(pattern.source, pattern.flags + 'g');
      }
      
      const matches = [...text.matchAll(pattern)];
      return matches.map(match => ({
        name: match[1],
        currentValue: match[2],
        previousValue: match[3] || null,
        percentChange: null // Will calculate later
      }));
    } catch (error) {
      console.error("Error in extractNamedFinancialMetric:", error);
      return [];
    }
  };

  // Helper function to create visualizations from detailed balance sheet items
  const createVisualizationFromDetailedItems = (assetItems, liabItems, equityItems, text) => {
    const visualizationData: VisualizationData = {
      charts: [],
      tables: [],
      metrics: []
    };
    
    // Extract period labels from the text
    const periodRegex = /(\w+\s+\d{1,2},?\s+\d{4})\s+(?:and|vs\.?|to|from)\s+(\w+\s+\d{1,2},?\s+\d{4})/i;
    const periodMatch = text.match(periodRegex);
    const period1 = periodMatch?.[2] || 'December 31, 2023';
    const period2 = periodMatch?.[1] || 'June 30, 2024';
    
    // Determine if we're dealing with a deficit (negative equity)
    const isDeficit = text.includes('deficit') || text.includes('stockholders') && text.match(/\(.*?\)/);
    
    // Create asset metrics
    if (assetItems.length > 0) {
      const cashMatch = assetItems.find(item => item[0].includes('Cash and cash equivalents'));
      if (cashMatch) {
        visualizationData.metrics.push({
          name: 'Cash and Equivalents',
          value: parseFloat(cashMatch[1].replace(/,/g, '')),
          previousValue: parseFloat(cashMatch[2].replace(/,/g, '')),
          percentChange: calculatePercentChange(cashMatch[2], cashMatch[1]),
          unit: 'M',
          trend: parseFloat(cashMatch[1]) > parseFloat(cashMatch[2]) ? 'up' : 'down'
        });
      }
      
      const totalAssetsMatch = assetItems.find(item => item[0].includes('Total assets'));
      if (totalAssetsMatch) {
        visualizationData.metrics.push({
          name: 'Total Assets',
          value: parseFloat(totalAssetsMatch[1].replace(/,/g, '')),
          previousValue: parseFloat(totalAssetsMatch[2].replace(/,/g, '')),
          percentChange: calculatePercentChange(totalAssetsMatch[2], totalAssetsMatch[1]),
          unit: 'M',
          trend: parseFloat(totalAssetsMatch[1]) > parseFloat(totalAssetsMatch[2]) ? 'up' : 'down'
        });
      }
    } else {
      // Try to extract total assets directly from the text
      const totalAssetsRegex = /Total assets.*?(\$?[\d,.]+M?).*?(\$?[\d,.]+M?)/i;
      const totalAssetsMatch = text.match(totalAssetsRegex);
      if (totalAssetsMatch) {
        const currentValue = parseFloat(totalAssetsMatch[1].replace(/[^\d.]/g, ''));
        const previousValue = parseFloat(totalAssetsMatch[2].replace(/[^\d.]/g, ''));
        
        visualizationData.metrics.push({
          name: 'Total Assets',
          value: currentValue,
          previousValue: previousValue,
          percentChange: calculatePercentChange(previousValue.toString(), currentValue.toString()),
          unit: 'M',
          trend: currentValue > previousValue ? 'up' : 'down'
        });
      }
    }
    
    // Create liability metrics
    if (liabItems.length > 0) {
      const totalLiabMatch = liabItems.find(item => item[0].includes('Total liabilities'));
      if (totalLiabMatch) {
        visualizationData.metrics.push({
          name: 'Total Liabilities',
          value: parseFloat(totalLiabMatch[1].replace(/,/g, '')),
          previousValue: parseFloat(totalLiabMatch[2].replace(/,/g, '')),
          percentChange: calculatePercentChange(totalLiabMatch[2], totalLiabMatch[1]),
          unit: 'M',
          trend: parseFloat(totalLiabMatch[1]) > parseFloat(totalLiabMatch[2]) ? 'up' : 'down'
        });
      }
    } else {
      // Try direct extraction
      const totalLiabRegex = /Total liabilities.*?(\$?[\d,.]+M?).*?(\$?[\d,.]+M?)/i;
      const totalLiabMatch = text.match(totalLiabRegex);
      if (totalLiabMatch) {
        const currentValue = parseFloat(totalLiabMatch[1].replace(/[^\d.]/g, ''));
        const previousValue = parseFloat(totalLiabMatch[2].replace(/[^\d.]/g, ''));
        
        visualizationData.metrics.push({
          name: 'Total Liabilities',
          value: currentValue,
          previousValue: previousValue,
          percentChange: calculatePercentChange(previousValue.toString(), currentValue.toString()),
          unit: 'M',
          trend: currentValue > previousValue ? 'up' : 'down'
        });
      }
    }
    
    // Create equity metrics
    if (equityItems.length > 0) {
      const equityMatch = equityItems[0];
      const localIsDeficit = equityMatch[0].includes('deficit');
      
      visualizationData.metrics.push({
        name: localIsDeficit ? 'Stockholders Deficit' : 'Total Equity',
        value: localIsDeficit ? -parseFloat(equityMatch[1].replace(/,/g, '')) : parseFloat(equityMatch[1].replace(/,/g, '')),
        previousValue: localIsDeficit ? -parseFloat(equityMatch[2].replace(/,/g, '')) : parseFloat(equityMatch[2].replace(/,/g, '')),
        percentChange: calculatePercentChange(
          localIsDeficit ? (-parseFloat(equityMatch[2].replace(/,/g, ''))).toString() : equityMatch[2], 
          localIsDeficit ? (-parseFloat(equityMatch[1].replace(/,/g, ''))).toString() : equityMatch[1]
        ),
        unit: 'M',
        trend: localIsDeficit ? 
          (parseFloat(equityMatch[1]) < parseFloat(equityMatch[2]) ? 'up' : 'down') : 
          (parseFloat(equityMatch[1]) > parseFloat(equityMatch[2]) ? 'up' : 'down')
      });
    } else {
      // Try direct extraction
      const equityRegex = /Total (?:stockholders.*?deficit|equity).*?(?:\$?\()([\d,.]+)(?:\)M?).*?(?:\$?\()([\d,.]+)(?:\)M?)/i;
      const equityMatch = text.match(equityRegex);
      if (equityMatch) {
        const currentValue = -parseFloat(equityMatch[1].replace(/[^\d.]/g, ''));
        const previousValue = -parseFloat(equityMatch[2].replace(/[^\d.]/g, ''));
        
        visualizationData.metrics.push({
          name: 'Stockholders Deficit',
          value: currentValue,
          previousValue: previousValue,
          percentChange: calculatePercentChange(previousValue.toString(), currentValue.toString()),
          unit: 'M',
          trend: currentValue > previousValue ? 'up' : 'down'
        });
      }
    }
    
    // Only proceed if we have at least some data
    if (visualizationData.metrics.length === 0) {
      return null;
    }
    
    // Create bar chart for balance sheet comparison
    const chartData = [];
    visualizationData.metrics.forEach(metric => {
      chartData.push({
        category: metric.name,
        [period1]: metric.previousValue || 0,
        [period2]: metric.value || 0
      });
    });
    
    visualizationData.charts.push({
      chartType: 'bar',
      config: {
        title: 'Balance Sheet Comparison',
        description: `${period1} vs ${period2}`,
        xAxisKey: 'category'
      },
      data: chartData,
      chartConfig: {
        [period1]: { label: period1 },
        [period2]: { label: period2 }
      }
    });
    
    // Create a detailed table
    const tableData = visualizationData.metrics.map(metric => ({
      metric: metric.name,
      prior: metric.previousValue || 0,
      current: metric.value || 0,
      change: (metric.value || 0) - (metric.previousValue || 0),
      percentChange: metric.percentChange || 0
    }));
    
    visualizationData.tables.push({
      tableType: 'comparison',
      config: {
        title: 'Balance Sheet Analysis',
        description: `${period1} vs ${period2}`,
        columns: [
          { key: 'metric', label: 'Metric', format: 'text' },
          { key: 'prior', label: period1, format: 'currency' },
          { key: 'current', label: period2, format: 'currency' },
          { key: 'change', label: 'Change', format: 'currency' },
          { key: 'percentChange', label: '% Change', format: 'percentage' }
        ]
      },
      data: tableData
    });
    
    return visualizationData;
  };

  // Helper function to create visualizations from directly extracted balance sheet items
  const createVisualizationFromDirectMatches = (items, text) => {
    if (!items || items.length === 0) return null;
    
    const visualizationData: VisualizationData = {
      charts: [],
      tables: [],
      metrics: []
    };
    
    // Extract period labels from the text
    const periodRegex = /(\w+\s+\d{1,2},?\s+\d{4})\s+(?:and|vs\.?|to|from|compared to)\s+(\w+\s+\d{1,2},?\s+\d{4})/i;
    const periodMatch = text.match(periodRegex);
    const period1 = periodMatch?.[2] || 'December 30, 2023';
    const period2 = periodMatch?.[1] || 'June 29, 2024';
    
    // Helper to normalize values to millions for display
    const normalizeToMillions = (value: string): number => {
      // Remove commas and convert to number
      let num = parseFloat(value.replace(/,/g, ''));
      
      // If the number is very large (over a million), convert to millions
      if (num > 1000000) {
        num = num / 1000000;
      }
      
      return num;
    };
    
    // Process each item into metrics
    items.forEach(item => {
      const oldValue = normalizeToMillions(item.oldValue);
      const newValue = normalizeToMillions(item.newValue);
      const isAsset = /cash|receivable|inventories|assets|property/i.test(item.name);
      const isLiability = /payable|liabilities/i.test(item.name) && !/equity|stockholders/i.test(item.name);
      const isEquity = /equity|stockholders/i.test(item.name);
      const isDeficit = /deficit/i.test(item.name) || item.name.includes('(');
      
      // Only include balance sheet items
      if (isAsset || isLiability || isEquity) {
        visualizationData.metrics.push({
          name: item.name,
          value: isDeficit ? -newValue : newValue,
          previousValue: isDeficit ? -oldValue : oldValue,
          percentChange: calculatePercentChange(oldValue.toString(), newValue.toString()),
          unit: 'M',
          trend: newValue > oldValue ? 'up' : 'down'
        });
      }
    });
    
    // Only create charts if we have metrics
    if (visualizationData.metrics.length > 0) {
      // Create bar chart
      const chartData = visualizationData.metrics.map(metric => ({
        category: metric.name,
        [period1]: metric.previousValue,
        [period2]: metric.value
      }));
      
      visualizationData.charts.push({
        chartType: 'bar',
        config: {
          title: 'Balance Sheet Comparison',
          description: `${period1} vs ${period2}`,
          xAxisKey: 'category'
        },
        data: chartData,
        chartConfig: {
          [period1]: { label: period1 },
          [period2]: { label: period2 }
        }
      });
      
      // Create table
      const tableData = visualizationData.metrics.map(metric => ({
        metric: metric.name,
        prior: metric.previousValue,
        current: metric.value,
        change: metric.value - metric.previousValue,
        percentChange: metric.percentChange
      }));
      
      visualizationData.tables.push({
        tableType: 'comparison',
        config: {
          title: 'Balance Sheet Analysis',
          description: `${period1} vs ${period2}`,
          columns: [
            { key: 'metric', label: 'Metric', format: 'text' },
            { key: 'prior', label: period1, format: 'currency' },
            { key: 'current', label: period2, format: 'currency' },
            { key: 'change', label: 'Change', format: 'currency' },
            { key: 'percentChange', label: '% Change', format: 'percentage' }
          ]
        },
        data: tableData
      });
    }
    
    return visualizationData;
  };

  // Helper function to calculate percent change
  const calculatePercentChange = (oldValue: string, newValue: string): number => {
    const oldNum = parseFloat(oldValue.replace(/,/g, ''));
    const newNum = parseFloat(newValue.replace(/,/g, ''));
    
    // Safety checks to avoid division by zero or invalid values
    if (isNaN(oldNum) || isNaN(newNum) || oldNum === 0) return 0;
    
    return ((newNum - oldNum) / Math.abs(oldNum)) * 100;
  };

  // Process analysis results into visualization data
  const processAnalysisResults = useCallback((results: AnalysisResult[], msgs: any[] = []) => {
    // If we have analysis results with visualization data, use them
    if (results.length) {
      const latestResult = results[results.length - 1];
      
      // Add safety check for latestResult.data
      if (latestResult && latestResult.data) {
        // First, check if we have the new tool-based visualization format
        // Tool-based format has a visualizationData property directly in the result
        if (latestResult.visualizationData && (
          Array.isArray(latestResult.visualizationData.charts) || 
          Array.isArray(latestResult.visualizationData.tables)
        )) {
          console.log('Using tool-based visualization format from analysis result');
          return {
            charts: latestResult.visualizationData.charts || [],
            tables: latestResult.visualizationData.tables || [],
            metrics: latestResult.data.metrics || [],
            // Keep any legacy properties for backwards compatibility
            monetaryValues: latestResult.visualizationData.monetaryValues,
            percentages: latestResult.visualizationData.percentages,
            keywordFrequency: latestResult.visualizationData.keywordFrequency
          };
        }
        
        // Check if we have real visualization data from analysis results (legacy format)
        if (latestResult.data.charts?.length || latestResult.data.tables?.length || latestResult.data.metrics?.length) {
          const visualizationData: VisualizationData = {
            charts: latestResult.data.charts || [],
            tables: latestResult.data.tables || [],
            metrics: latestResult.data.metrics || []
          };
          
          // If we have real data, return it
          if (visualizationData.charts.length || visualizationData.tables.length || visualizationData.metrics.length) {
            console.log('Using legacy visualization format from analysis result');
            return visualizationData;
          }
        }
      }
    }
    
    // If we don't have real data from analysis results, try to extract from messages
    const messageVisualizationData = extractFinancialDataFromMessages(msgs);
    if (messageVisualizationData) {
      console.log('Using visualization data extracted from messages');
      return messageVisualizationData;
    }
    
    // If we couldn't extract from messages either, use fallback demo data
    console.log('Using fallback demo visualization data');
    const visualizationData: VisualizationData = {
      charts: [],
      tables: [],
      metrics: []
    };

    // Process metrics
    const metrics: FinancialMetric[] = [
      {
        name: 'Net Sales',
        value: 997.7,
        previousValue: 897.0,
        percentChange: 11.2,
        unit: 'M',
        trend: 'up'
      },
      {
        name: 'Operating Income',
        value: 210.0,
        previousValue: 210.7,
        percentChange: -0.3,
        unit: 'M',
        trend: 'down'
      },
      {
        name: 'Net Income',
        value: 160.2,
        previousValue: 177.7,
        percentChange: -9.8,
        unit: 'M',
        trend: 'down'
      },
      {
        name: 'Current Ratio',
        value: 4.7,
        unit: 'x',
        highlight: true
      }
    ];

    visualizationData.metrics = metrics;

    // Add Revenue by Segment chart
    visualizationData.charts.push({
      chartType: 'multiBar',
      config: {
        title: 'Revenue by Segment',
        description: 'Q2 2024 vs Q2 2023 Revenue Comparison',
        xAxisKey: 'segment'
      },
      data: [
        { segment: 'Piping Systems', 'Q2 2024': 688.5, 'Q2 2023': 638.0 },
        { segment: 'Industrial Metals', 'Q2 2024': 195.3, 'Q2 2023': 146.3 },
        { segment: 'Climate', 'Q2 2024': 130.5, 'Q2 2023': 124.0 }
      ],
      chartConfig: {
        'Q2 2024': { label: 'Q2 2024' },
        'Q2 2023': { label: 'Q2 2023' }
      }
    });

    // Add Operating Income chart
    visualizationData.charts.push({
      chartType: 'multiBar',
      config: {
        title: 'Operating Income by Segment',
        description: 'Q2 2024 vs Q2 2023 Operating Income',
        xAxisKey: 'segment'
      },
      data: [
        { segment: 'Piping Systems', 'Q2 2024': 162.3, 'Q2 2023': 151.1 },
        { segment: 'Industrial Metals', 'Q2 2024': 29.7, 'Q2 2023': 18.0 },
        { segment: 'Climate', 'Q2 2024': 39.0, 'Q2 2023': 57.1 }
      ],
      chartConfig: {
        'Q2 2024': { label: 'Q2 2024' },
        'Q2 2023': { label: 'Q2 2023' }
      }
    });

    // Add Key Performance Metrics table
    visualizationData.tables.push({
      tableType: 'comparison',
      config: {
        title: 'Key Financial Metrics',
        description: 'Q2 2024 vs Q2 2023 Performance',
        columns: [
          { key: 'metric', label: 'Metric', format: 'text' },
          { key: 'q2_2024', label: 'Q2 2024', format: 'currency' },
          { key: 'q2_2023', label: 'Q2 2023', format: 'currency' },
          { key: 'change', label: 'Change', format: 'percentage' }
        ]
      },
      data: [
        {
          metric: 'Net Sales',
          q2_2024: 997.7,
          q2_2023: 897.0,
          change: 11.2
        },
        {
          metric: 'Operating Income',
          q2_2024: 210.0,
          q2_2023: 210.7,
          change: -0.3
        },
        {
          metric: 'Net Income',
          q2_2024: 160.2,
          q2_2023: 177.7,
          change: -9.8
        }
      ]
    });

    return visualizationData;
  }, [extractFinancialDataFromMessages]);

  const visualizationData = processAnalysisResults(analysisResults, messages);

  if (loading) {
    return (
      <div role="status" aria-label="Loading visualizations" className="flex items-center justify-center p-8 bg-gray-50 rounded-lg min-h-[600px]">
        <div className="animate-pulse flex flex-col items-center">
          <div className="h-8 w-40 bg-gray-200 rounded mb-4" />
          <div className="h-80 w-full bg-gray-200 rounded" />
        </div>
      </div>
    );
  }

  if (error) {
    return (
      <div role="alert" className="flex items-center justify-center p-8 bg-red-50 rounded-lg min-h-[600px]">
        <div className="text-red-500 text-center">
          <h3 className="font-semibold mb-2">Error loading visualizations</h3>
          <p className="text-sm">{error.toString()}</p>
        </div>
      </div>
    );
  }

  if (!visualizationData) {
    return (
      <div role="status" aria-label="No data" className="flex items-center justify-center p-8 bg-gray-50 rounded-lg min-h-[600px]">
        <p className="text-gray-500">No visualization data available</p>
      </div>
    );
  }

  return (
    <div role="main" className="w-full rounded-lg bg-white shadow-sm">
      <div className="border-b border-gray-200">
        <div role="tablist" className="flex space-x-4 px-4">
          <button
            role="tab"
            aria-selected={currentTab === 'overview'}
            aria-controls="overview-panel"
            className={`py-4 px-1 text-sm font-medium ${
              currentTab === 'overview'
                ? 'text-blue-600 border-b-2 border-blue-600'
                : 'text-gray-500 hover:text-gray-700 hover:border-gray-300'
            }`}
            onClick={() => setCurrentTab('overview')}
          >
            Overview
          </button>
          <button
            role="tab"
            aria-selected={currentTab === 'charts'}
            aria-controls="charts-panel"
            className={`py-4 px-1 text-sm font-medium ${
              currentTab === 'charts'
                ? 'text-blue-600 border-b-2 border-blue-600'
                : 'text-gray-500 hover:text-gray-700 hover:border-gray-300'
            }`}
            onClick={() => setCurrentTab('charts')}
          >
            Charts ({visualizationData.charts?.length || 0})
          </button>
          <button
            role="tab"
            aria-selected={currentTab === 'tables'}
            aria-controls="tables-panel"
            className={`py-4 px-1 text-sm font-medium ${
              currentTab === 'tables'
                ? 'text-blue-600 border-b-2 border-blue-600'
                : 'text-gray-500 hover:text-gray-700 hover:border-gray-300'
            }`}
            onClick={() => setCurrentTab('tables')}
          >
            Tables ({visualizationData.tables?.length || 0})
          </button>
        </div>
      </div>

      <div className="p-4">
        {currentTab === 'overview' ? (
          <div className="space-y-6">
            <MetricGrid 
              metrics={visualizationData.metrics || []}
              title="Key Performance Indicators"
            />
            
            <div className="grid grid-cols-1 lg:grid-cols-2 gap-4">
              {visualizationData.charts && visualizationData.charts.length > 0 && (
                <ChartRenderer data={visualizationData.charts[0]} />
              )}
              {visualizationData.charts && visualizationData.charts.length > 1 && (
                <ChartRenderer data={visualizationData.charts[1]} />
              )}
            </div>
            
            {visualizationData.tables && visualizationData.tables.length > 0 && (
              <TableRenderer data={visualizationData.tables[0]} />
            )}
          </div>
        ) : (
        <div
          role="tabpanel"
          id={`${currentTab}-panel`}
          aria-labelledby={`${currentTab}-tab`}
          className="grid grid-cols-1 lg:grid-cols-2 gap-4"
        >
            {currentTab === 'charts' ? 
              (visualizationData.charts || []).map((chart, index) => (
            <div key={index} className="col-span-1">
                  <ChartRenderer data={chart} />
            </div>
              )) :
              (visualizationData.tables || []).map((table, index) => (
                <div key={index} className="col-span-1">
                  <TableRenderer data={table} />
        </div>
              ))
            }
          </div>
        )}
      </div>
    </div>
  );
};

export default Canvas; 
</file>
```

#### src/components/visualization/EnhancedChart\.tsx
*Size: 15.7 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/components/visualization/EnhancedChart.tsx">
'use client';

import React from 'react';
import {
  ResponsiveContainer,
  BarChart,
  Bar,
  LineChart,
  Line,
  XAxis,
  YAxis,
  CartesianGrid,
  Tooltip,
  Legend,
  PieChart as RechartsPieChart,
  Pie,
  Cell,
  ScatterChart,
  Scatter,
  ZAxis,
  ReferenceLine,
  AreaChart,
  Area
} from 'recharts';
import { ExternalLink } from 'lucide-react';
import { FinancialInsight, TrendAnalysis } from '@/types/enhanced';
import { ChartType, ChartSeries } from '@/types/visualization';
import { useRouter } from 'next/navigation';

interface EnhancedChartProps {
  data: any[] | ChartSeries[];
  chartType: ChartType;
  onDataPointClick?: (dataPoint: any) => void;
  insightData?: FinancialInsight[];
  trendData?: TrendAnalysis[];
  height?: number | string;
  xAxisTitle?: string;
  yAxisTitle?: string;
}

// Custom tooltip component that shows citations
export const CitationTooltip = ({ active, payload, label, onCitationClick }: any) => {
  const router = useRouter();

  if (active && payload && payload.length) {
    const data = payload[0].payload;
    
    const handleCitationClick = (citation: any) => {
      // Call the original callback if provided
      if (onCitationClick) {
        onCitationClick(citation);
      }
      
      // Navigate to the PDF viewer with citation details
      if (citation.highlightId && citation.documentId) {
        const page = citation.page || 1; // Default to page 1 if not specified
        router.push(`/pdf-viewer/${citation.documentId}?highlightId=${citation.highlightId}&page=${page}`);
      }
    };
    
    return (
      <div className="bg-white p-3 border border-gray-200 rounded shadow-lg max-w-xs">
        <p className="font-semibold text-gray-800">{`${label}`}</p>
        {payload.map((item: any, index: number) => (
          <p key={index} className="text-sm" style={{ color: item.color }}>
            {`${item.name}: ${item.value.toLocaleString()}`}
          </p>
        ))}
        
        {data.citation && (
          <button 
            className="mt-2 flex items-center text-xs text-indigo-600 hover:text-indigo-800"
            onClick={() => handleCitationClick(data.citation)}
          >
            <ExternalLink className="h-3 w-3 mr-1" />
            View source in document
          </button>
        )}
      </div>
    );
  }
  
  return null;
};

// Colors for the charts
export const CHART_COLORS = [
  'hsl(var(--chart-1))', // Primary
  'hsl(var(--chart-2))', // Red/Orange
  'hsl(var(--chart-3))', // Green
  'hsl(var(--chart-4))', // Purple
  'hsl(var(--chart-5))', // Yellow
  'hsl(var(--chart-6))', // Blue
  'hsl(var(--chart-7))', // Pink
  'hsl(var(--chart-8))'  // Teal
];

// Enhanced chart component for financial data with citation support
export const EnhancedChart: React.FC<EnhancedChartProps> = ({ 
  data, 
  chartType, 
  onDataPointClick, 
  insightData, 
  trendData,
  height = 300,
  xAxisTitle,
  yAxisTitle
}) => {
  const router = useRouter();
  
  // If there's no data, show a placeholder
  if (!data || Array.isArray(data) && data.length === 0) {
    return (
      <div className="h-full w-full flex items-center justify-center bg-gray-50 rounded">
        <p className="text-gray-400 text-sm">No chart data available</p>
      </div>
    );
  }
  
  // Check if we're dealing with series-based data format (from tool-based approach)
  const isSeriesData = React.useMemo(() => {
    if (!Array.isArray(data)) return false;
    // Check if the first item has a 'data' property that is an array
    return data.length > 0 && 'name' in data[0] && 'data' in data[0] && Array.isArray(data[0].data);
  }, [data]);
  
  // Determine what data keys are available for bar/line charts
  const getDataKeys = () => {
    if (!data || !Array.isArray(data) || data.length === 0) return [];
    
    // If we have series data, return the series names
    if (isSeriesData) {
      return (data as ChartSeries[]).map(series => series.name);
    }
    
    // First data item to check
    const firstItem = data[0];
    
    // Exclude these keys from being used in charts
    const excludedKeys = ['period', 'name', 'description', 'citation', 'timestamp', 'id'];
    
    // Get all keys that have numeric values
    return Object.keys(firstItem)
      .filter(key => 
        !excludedKeys.includes(key) && 
        typeof firstItem[key] === 'number'
      );
  };
  
  // Get the name key for data items (x-axis label)
  const getNameKey = () => {
    if (!data || !Array.isArray(data) || data.length === 0) return 'name';
    
    // If we have series data, use the x property of data items
    if (isSeriesData) {
      return 'x';
    }
    
    const firstItem = data[0];
    // Check for common name keys in priority order
    const possibleNameKeys = ['period', 'name', 'category', 'metric', 'term'];
    
    for (const key of possibleNameKeys) {
      if (key in firstItem) {
        return key;
      }
    }
    
    // Default to first string key if no common keys found
    const firstStringKey = Object.keys(firstItem).find(key => typeof firstItem[key] === 'string');
    return firstStringKey || 'name';
  };
  
  // Get the value key for pie charts
  const getValueKey = () => {
    if (!data || !Array.isArray(data) || data.length === 0) return 'value';
    
    // If we have series data, use the y property of data items
    if (isSeriesData) {
      return 'y';
    }
    
    const firstItem = data[0];
    // Check for common value keys
    const possibleValueKeys = ['value', 'count', 'amount'];
    
    for (const key of possibleValueKeys) {
      if (key in firstItem && typeof firstItem[key] === 'number') {
        return key;
      }
    }
    
    // Default to first numeric key
    const firstNumericKey = Object.keys(firstItem).find(key => typeof firstItem[key] === 'number');
    return firstNumericKey || 'value';
  };
  
  // Get the appropriate keys for the chart
  const dataKeys = getDataKeys();
  const nameKey = getNameKey();
  const valueKey = getValueKey();
  
  // Format data for chart based on the chart type and data format
  const formattedData = React.useMemo(() => {
    if (isSeriesData) {
      // For series data, we need to transform it to a format that works with recharts
      // For bar/line/area charts, we need a flat structure with all series data
      // combined into a single array of objects
      if (chartType === 'bar' || chartType === 'line' || chartType === 'area') {
        const series = data as ChartSeries[];
        // Create a map of all x values across all series
        const xValues = new Set<string | number>();
        series.forEach(s => s.data.forEach(d => xValues.add(d.x)));
        
        // Create a record for each x value with all series values
        return Array.from(xValues).map(x => {
          const record: any = { [nameKey]: x };
          series.forEach(s => {
            const point = s.data.find(d => d.x === x);
            record[s.name] = point ? point.y : null;
          });
          return record;
        });
      }
      
      // For scatter, we can use the series data directly
      if (chartType === 'scatter') {
        const series = data as ChartSeries[];
        return series.flatMap(s => s.data.map(d => ({
          ...d,
          seriesName: s.name,
          fill: s.color
        })));
      }
      
      // For pie charts, we need to transform the first series data
      if (chartType === 'pie') {
        const series = data as ChartSeries[];
        if (series.length === 0) return [];
        
        // Just use the first series for the pie chart
        return series[0].data.map(d => ({
          name: d.category || d.label || d.x,
          value: d.y
        }));
      }
    }
    
    // For scatter with trend data
    if (chartType === 'scatter' && trendData && trendData.length > 0) {
      // For scatter plots, we need to format data differently to show trends
      return trendData.flatMap(trend => 
        trend.periods.map((period, idx) => ({
          x: idx,
          y: trend.values[idx],
          metric: trend.metric,
          period,
          trendDirection: trend.trendDirection,
          growthRate: trend.growthRate,
          citation: trend.citations && trend.citations[0]
        }))
      );
    }
    
    // If none of the above, just return the original data
    return data;
  }, [data, chartType, isSeriesData, nameKey, trendData]);
  
  // Handle chart data point click with citation navigation
  const handleDataPointClick = (dataPoint: any) => {
    // Call the original callback
    if (onDataPointClick) {
      onDataPointClick(dataPoint);
    }
    
    // Navigate to PDF viewer if citation is available
    if (dataPoint && dataPoint.citation) {
      const citation = dataPoint.citation;
      const page = citation.page || 1; // Default to page 1 if not specified
      router.push(`/pdf-viewer/${citation.documentId}?highlightId=${citation.highlightId}&page=${page}`);
    }
  };
  
  // Common props for axes labels
  const xAxisProps = {
    dataKey: nameKey,
    ...(xAxisTitle ? { label: { value: xAxisTitle, position: 'insideBottom', offset: -5 } } : {})
  };
  
  const yAxisProps = {
    ...(yAxisTitle ? { label: { value: yAxisTitle, angle: -90, position: 'insideLeft' } } : {})
  };
  
  return (
    <ResponsiveContainer width="100%" height={height}>
      {chartType === 'bar' ? (
        <BarChart data={formattedData}>
          <CartesianGrid strokeDasharray="3 3" />
          <XAxis {...xAxisProps} />
          <YAxis {...yAxisProps} />
          <Tooltip content={<CitationTooltip onCitationClick={(citation) => handleDataPointClick({ citation })} />} />
          <Legend />
          {dataKeys.length > 0 ? (
            dataKeys.map((key, index) => {
              // For series data, we want to use the series color if available
              const seriesColor = isSeriesData ? 
                (data as ChartSeries[]).find(s => s.name === key)?.color : 
                undefined;
              
              return (
                <Bar 
                  key={key} 
                  dataKey={key} 
                  name={key} 
                  fill={seriesColor || CHART_COLORS[index % CHART_COLORS.length]} 
                  onClick={handleDataPointClick} 
                />
              );
            })
          ) : (
            <Bar dataKey="value" name="Value" fill={CHART_COLORS[0]} onClick={handleDataPointClick} />
          )}
        </BarChart>
      ) : chartType === 'line' ? (
        <LineChart data={formattedData}>
          <CartesianGrid strokeDasharray="3 3" />
          <XAxis {...xAxisProps} />
          <YAxis {...yAxisProps} />
          <Tooltip content={<CitationTooltip onCitationClick={(citation) => handleDataPointClick({ citation })} />} />
          <Legend />
          {dataKeys.length > 0 ? (
            dataKeys.map((key, index) => {
              // For series data, we want to use the series color if available
              const seriesColor = isSeriesData ? 
                (data as ChartSeries[]).find(s => s.name === key)?.color : 
                undefined;
                
              return (
                <Line 
                  key={key} 
                  type="monotone" 
                  dataKey={key} 
                  name={key} 
                  stroke={seriesColor || CHART_COLORS[index % CHART_COLORS.length]} 
                  activeDot={{ r: 8, onClick: handleDataPointClick }} 
                />
              );
            })
          ) : (
            <Line type="monotone" dataKey="value" name="Value" stroke={CHART_COLORS[0]} activeDot={{ r: 8, onClick: handleDataPointClick }} />
          )}
        </LineChart>
      ) : chartType === 'area' ? (
        <AreaChart data={formattedData}>
          <CartesianGrid strokeDasharray="3 3" />
          <XAxis {...xAxisProps} />
          <YAxis {...yAxisProps} />
          <Tooltip content={<CitationTooltip onCitationClick={(citation) => handleDataPointClick({ citation })} />} />
          <Legend />
          {dataKeys.length > 0 ? (
            dataKeys.map((key, index) => {
              // For series data, we want to use the series color if available
              const seriesColor = isSeriesData ? 
                (data as ChartSeries[]).find(s => s.name === key)?.color : 
                undefined;
                
              return (
                <Area 
                  key={key} 
                  type="monotone" 
                  dataKey={key} 
                  name={key} 
                  stackId={index.toString()} 
                  stroke={seriesColor || CHART_COLORS[index % CHART_COLORS.length]} 
                  fill={seriesColor ? `${seriesColor}70` : `${CHART_COLORS[index % CHART_COLORS.length]}70`} 
                />
              );
            })
          ) : (
            <Area type="monotone" dataKey="value" name="Value" stackId="1" stroke={CHART_COLORS[0]} fill={`${CHART_COLORS[0]}70`} />
          )}
        </AreaChart>
      ) : chartType === 'scatter' ? (
        <ScatterChart>
          <CartesianGrid strokeDasharray="3 3" />
          <XAxis type="number" dataKey="x" name={xAxisTitle || "Period"} {...xAxisProps} />
          <YAxis type="number" dataKey="y" name={yAxisTitle || "Value"} {...yAxisProps} />
          <ZAxis type="number" range={[60, 400]} />
          <Tooltip content={<CitationTooltip onCitationClick={(citation) => handleDataPointClick({ citation })} />} />
          <Legend />
          {isSeriesData ? (
            // For series-based scatter chart data
            (data as ChartSeries[]).map((series, seriesIndex) => (
              <Scatter
                key={`scatter-${seriesIndex}`}
                name={series.name}
                data={series.data}
                fill={series.color || CHART_COLORS[seriesIndex % CHART_COLORS.length]}
                onClick={handleDataPointClick}
              />
            ))
          ) : (
            // For traditional data format
            <Scatter 
              name="Financial Metrics" 
              data={formattedData} 
              fill={CHART_COLORS[0]}
              onClick={handleDataPointClick}
            />
          )}
          {trendData?.map((trend, index) => (
            <ReferenceLine
              key={index}
              stroke={trend.trendDirection === 'up' ? CHART_COLORS[2] : trend.trendDirection === 'down' ? CHART_COLORS[1] : CHART_COLORS[0]}
              strokeDasharray="3 3"
              segment={[
                { x: 0, y: trend.values[0] },
                { x: trend.periods.length - 1, y: trend.values[trend.values.length - 1] }
              ]}
            />
          ))}
        </ScatterChart>
      ) : chartType === 'pie' ? (
        <RechartsPieChart>
          <Pie
            data={formattedData}
            cx="50%"
            cy="50%"
            labelLine={false}
            outerRadius={80}
            fill="#8884d8"
            dataKey={valueKey}
            nameKey={nameKey}
            label={({ name, percent }) => `${name}: ${(percent * 100).toFixed(0)}%`}
            onClick={handleDataPointClick}
          >
            {Array.isArray(formattedData) && formattedData.map((entry: any, index: number) => {
              // For series data, we want to use the data point color if available
              const itemColor = isSeriesData && entry.color ? entry.color : CHART_COLORS[index % CHART_COLORS.length];
              return <Cell key={`cell-${index}`} fill={itemColor} />;
            })}
          </Pie>
          <Tooltip content={<CitationTooltip onCitationClick={(citation) => handleDataPointClick({ citation })} />} />
          <Legend />
        </RechartsPieChart>
      ) : (
        // No chart type or 'none' specified
        <div className="h-full w-full flex items-center justify-center bg-gray-50 rounded">
          <p className="text-gray-400 text-sm">No visualization available</p>
        </div>
      )}
    </ResponsiveContainer>
  );
};
</file>
```

#### src/lib/api/analysis\.ts
*Size: 26.2 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/lib/api/analysis.ts">
import { AnalysisResult } from '@/types';
import { apiService } from './apiService';
import { AnalysisResultSchema, ConversationAnalysisResponseSchema } from '@/validation/schemas';
import { EnhancedAnalysisResult, ConversationAnalysisResponse } from '@/types/enhanced';

// Function to handle API errors
const handleApiError = (error: any): never => {
  console.error('API Error:', error);
  if (error.response && error.response.data && error.response.data.detail) {
    throw new Error(error.response.data.detail);
  }
  throw new Error('An error occurred while communicating with the server');
};

interface EnhancedAnalysis {
  trends: any[];
  insights: any[];
  analysisBlocks?: any[]; // Optional field for direct analysis blocks
}

interface ChartDataResponse {
  chartData: any;
  chartType: string;
  title: string;
  description?: string;
}

/**
 * Extracts financial figures from raw text
 * @param rawText Raw text from document
 * @returns Object with extracted financial data
 */
function extractFinancialFiguresFromText(rawText: string): { 
  dollarAmounts: {value: number, context: string}[], 
  percentages: {value: number, context: string}[], 
  keywords: {term: string, count: number}[] 
} {
  if (!rawText) return { dollarAmounts: [], percentages: [], keywords: [] };
  
  console.log(`Extracting financial figures from text (${rawText.length} chars)`);
  
  // Extract dollar amounts with context
  // Improved to capture various currency formats
  const dollarRegex = /(\$\s*[\d,]+(\.\d+)?(\s*(million|billion|thousand|M|B|K))?)|(\d+(\.\d+)?\s*(million|billion|thousand|M|B|K)?\s*dollars)/gi;
  const dollarAmounts: {value: number, context: string}[] = [];
  
  // Find all dollar amounts
  const dollarMatches = Array.from(rawText.matchAll(dollarRegex) || []);
  console.log(`Found ${dollarMatches.length} potential dollar amount matches`);
  
  dollarMatches.forEach(matchArray => {
    const match = matchArray[0];
    try {
      // Find the sentence containing this match
      const sentenceRegex = new RegExp(`[^.!?]*${match.replace(/\$/g, '\\$').replace(/\(/g, '\\(').replace(/\)/g, '\\)')}[^.!?]*[.!?]`, 'i');
      const sentenceMatch = rawText.match(sentenceRegex);
      const context = sentenceMatch ? sentenceMatch[0].trim() : 'Unknown context';
      
      // Extract numeric portion from the match
      let numericPart = match.replace(/\$/g, '')
                             .replace(/,/g, '')
                             .replace(/dollars/i, '')
                             .trim();
      
      // Handle multiplier suffixes
      let multiplier = 1;
      if (/(million|M)$/i.test(numericPart)) {
        multiplier = 1000000;
        numericPart = numericPart.replace(/(million|M)$/i, '').trim();
      } else if (/(billion|B)$/i.test(numericPart)) {
        multiplier = 1000000000;
        numericPart = numericPart.replace(/(billion|B)$/i, '').trim();
      } else if (/(thousand|K)$/i.test(numericPart)) {
        multiplier = 1000;
        numericPart = numericPart.replace(/(thousand|K)$/i, '').trim();
      }
      
      // Convert to a number
      const value = parseFloat(numericPart) * multiplier;
      
      if (!isNaN(value) && value > 0) {
        dollarAmounts.push({ value, context });
      }
    } catch (e) {
      console.warn(`Error processing dollar amount match: ${match}`, e);
    }
  });
  
  console.log(`Successfully extracted ${dollarAmounts.length} valid dollar amounts`);
  
  // Extract percentages with context - improved to handle more formats
  const percentRegex = /([\d,]+(\.\d+)?\s*(%|percent))|(\d+(\.\d+)?\s*percentage points)/gi;
  const percentages: {value: number, context: string}[] = [];
  
  // Find all percentages
  const percentMatches = Array.from(rawText.matchAll(percentRegex) || []);
  console.log(`Found ${percentMatches.length} potential percentage matches`);
  
  percentMatches.forEach(matchArray => {
    const match = matchArray[0];
    try {
      // Find the sentence containing this match
      const sentenceRegex = new RegExp(`[^.!?]*${match.replace(/%/g, '\\%').replace(/\(/g, '\\(').replace(/\)/g, '\\)')}[^.!?]*[.!?]`, 'i');
      const sentenceMatch = rawText.match(sentenceRegex);
      const context = sentenceMatch ? sentenceMatch[0].trim() : 'Unknown context';
      
      // Extract numeric portion from the match
      let numericPart = match.replace(/%/g, '')
                             .replace(/percent/gi, '')
                             .replace(/percentage points/gi, '')
                             .replace(/,/g, '')
                             .trim();
      
      // Convert to a number
      const value = parseFloat(numericPart);
      
      if (!isNaN(value)) {
        percentages.push({ value, context });
      }
    } catch (e) {
      console.warn(`Error processing percentage match: ${match}`, e);
    }
  });
  
  console.log(`Successfully extracted ${percentages.length} valid percentages`);
  
  // Count financial keywords - expanded list of terms
  const keywordCounts: Record<string, number> = {};
  const financialTerms = [
    // Common financial statement items
    'revenue', 'income', 'profit', 'loss', 'margin', 'ebitda', 
    'asset', 'liability', 'equity', 'debt', 'cash flow', 'balance sheet',
    'earnings', 'net income', 'gross profit', 'dividend', 'investment',
    
    // Time periods
    'fiscal year', 'quarter', 'annual', 'quarterly', 'year-over-year', 'YoY',
    
    // Financial metrics
    'EPS', 'earnings per share', 'P/E', 'price to earnings',
    'ROI', 'return on investment', 'ROE', 'return on equity',
    'ROA', 'return on assets', 'NPV', 'net present value',
    
    // Balance sheet items
    'current assets', 'fixed assets', 'total assets',
    'current liabilities', 'long-term debt', 'total liabilities',
    'shareholders equity', 'retained earnings',
    
    // Income statement items
    'net sales', 'cost of goods sold', 'COGS', 'gross margin',
    'operating expenses', 'operating income', 'interest expense',
    'tax expense', 'net profit', 'depreciation', 'amortization',
    
    // Cash flow items
    'operating activities', 'investing activities', 'financing activities',
    'capital expenditure', 'CAPEX', 'free cash flow', 'FCF',
    
    // Financial analysis terms
    'growth rate', 'compound annual growth rate', 'CAGR',
    'liquidity ratio', 'solvency ratio', 'profitability ratio',
    'efficiency ratio', 'market value', 'book value'
  ];
  
  // Process each term with improved regex matching
  financialTerms.forEach(term => {
    // Create word boundary regex to match whole words/phrases
    const regex = new RegExp(`\\b${term.replace(/\s+/g, '\\s+')}\\b`, 'gi');
    const matches = rawText.match(regex) || [];
    if (matches.length > 0) {
      keywordCounts[term] = matches.length;
    }
  });
  
  const keywords = Object.entries(keywordCounts)
    .map(([term, count]) => ({ term, count }))
    .sort((a, b) => b.count - a.count);
  
  console.log(`Found ${keywords.length} unique financial terms in the document`);
  
  return { dollarAmounts, percentages, keywords };
}

/**
 * Generate visualization data from extracted financial figures
 */
function generateVisualizationFromExtractedData(extractedData: ReturnType<typeof extractFinancialFiguresFromText>): Record<string, any> {
  // Generate monetary value chart data
  const monetaryChartData = {
    type: 'bar',
    title: 'Key Monetary Values Mentioned',
    data: extractedData.dollarAmounts.slice(0, 5).map((item, index) => ({
      name: `Amount ${index + 1}`,
      value: item.value,
      description: item.context
    }))
  };
  
  // Generate percentage chart data
  const percentageChartData = {
    type: 'bar',
    title: 'Key Percentages Mentioned',
    data: extractedData.percentages.slice(0, 5).map((item, index) => ({
      name: `Percentage ${index + 1}`,
      value: item.value,
      description: item.context
    }))
  };
  
  // Generate keyword frequency chart
  const keywordChartData = {
    type: 'bar',
    title: 'Financial Terms Frequency',
    data: extractedData.keywords.slice(0, 10).map(item => ({
      name: item.term,
      value: item.count
    }))
  };
  
  return {
    monetaryValues: monetaryChartData,
    percentages: percentageChartData,
    keywordFrequency: keywordChartData
  };
}

/**
 * Generate basic metrics and ratios from extracted financial figures
 */
function generateMetricsFromExtractedData(extractedData: ReturnType<typeof extractFinancialFiguresFromText>, documentTitle: string): {
  metrics: any[],
  ratios: any[],
  insights: string[]
} {
  const metrics = [];
  const ratios = [];
  const insights = [];
  
  // Add insights based on what we found
  if (extractedData.dollarAmounts.length === 0 && 
      extractedData.percentages.length === 0 &&
      extractedData.keywords.length === 0) {
    insights.push("No financial indicators were found in the document.");
    insights.push("The document may not contain financial data or it may be in a format that's difficult to extract.");
  } else {
    insights.push("Limited financial analysis based on text extraction.");
    insights.push(`Found ${extractedData.dollarAmounts.length} monetary values and ${extractedData.percentages.length} percentages in the document.`);
    
    if (extractedData.keywords.length > 0) {
      const topKeywords = extractedData.keywords.slice(0, 3).map(k => k.term).join(', ');
      insights.push(`Most frequently mentioned financial terms: ${topKeywords}.`);
    }
    
    // Add context for the top monetary values
    if (extractedData.dollarAmounts.length > 0) {
      extractedData.dollarAmounts.slice(0, 3).forEach(item => {
        insights.push(`Monetary reference: ${item.context}`);
      });
    }
    
    // Add context for the top percentages
    if (extractedData.percentages.length > 0) {
      extractedData.percentages.slice(0, 3).forEach(item => {
        insights.push(`Percentage reference: ${item.context}`);
      });
    }
  }
  
  // Create some basic metrics based on the extracted data
  if (extractedData.dollarAmounts.length > 0) {
    // Sort by value (descending)
    const sortedAmounts = [...extractedData.dollarAmounts].sort((a, b) => b.value - a.value);
    
    // Add the top 3 values as metrics
    sortedAmounts.slice(0, 3).forEach((item, index) => {
      metrics.push({
        category: 'Extracted Values',
        name: `Monetary Value ${index + 1}`,
        period: 'Current',
        value: item.value,
        unit: 'USD',
        isEstimated: true
      });
    });
    
    // Calculate average and add as a metric
    const average = sortedAmounts.reduce((sum, item) => sum + item.value, 0) / sortedAmounts.length;
    metrics.push({
      category: 'Calculated Metrics',
      name: 'Average Monetary Value',
      period: 'Current',
      value: average,
      unit: 'USD',
      isEstimated: true
    });
  }
  
  // Add some basic metrics for percentages
  if (extractedData.percentages.length > 0) {
    // Sort by value (descending)
    const sortedPercentages = [...extractedData.percentages].sort((a, b) => b.value - a.value);
    
    // Add the top 3 percentages as metrics
    sortedPercentages.slice(0, 3).forEach((item, index) => {
      metrics.push({
        category: 'Extracted Percentages',
        name: `Percentage Value ${index + 1}`,
        period: 'Current',
        value: item.value,
        unit: '%',
        isEstimated: true
      });
    });
    
    // Calculate average percentage and add as a metric
    const averagePercentage = sortedPercentages.reduce((sum, item) => sum + item.value, 0) / sortedPercentages.length;
    metrics.push({
      category: 'Calculated Metrics',
      name: 'Average Percentage',
      period: 'Current',
      value: averagePercentage,
      unit: '%',
      isEstimated: true
    });
  }
  
  // Add a note about data quality to the insights
  insights.push("Note: This is a limited analysis based on text extraction, not structured financial data.");
  insights.push("For a more detailed analysis, try using documents with standardized financial statements.");
  
  return { metrics, ratios, insights };
}

// Extract citations from Claude's raw analysis if available
function extractCitationsFromRawAnalysis(rawAnalysis: string): any[] {
  if (!rawAnalysis) return [];
  
  const citations = [];
  
  // Pattern for finding citations in Claude's output
  // Looking for patterns like "[1]", "p. 45", "page 3", etc.
  const citationPatterns = [
    /\[(\d+)\]/g,                  // [1], [2], etc.
    /\(p\.\s*(\d+)\)/gi,           // (p. 45), (p.3), etc.
    /page\s+(\d+)/gi,              // page 3, Page 45, etc.
    /\(page\s+(\d+)\)/gi,          // (page 3), (Page 45), etc.
    /\[page\s+(\d+)\]/gi,          // [page 3], [Page 45], etc.
    /on\s+page\s+(\d+)/gi          // on page 3, On Page 45, etc.
  ];
  
  // Extract different citation formats
  for (const pattern of citationPatterns) {
    const matches = [...rawAnalysis.matchAll(pattern)];
    for (const match of matches) {
      // Find the surrounding context (sentence)
      const sentenceStart = rawAnalysis.lastIndexOf('.', match.index) + 1;
      const sentenceEnd = rawAnalysis.indexOf('.', match.index + match[0].length);
      
      const context = rawAnalysis.substring(
        Math.max(0, sentenceStart), 
        sentenceEnd > -1 ? sentenceEnd + 1 : rawAnalysis.length
      ).trim();
      
      citations.push({
        type: 'page_reference',
        page: match[1] || '1',
        context: context,
        text: match[0]
      });
    }
  }
  
  return citations;
}

export const analysisApi = {
  /**
   * Run financial analysis on document(s)
   */
  async runAnalysis(
    documentIds: string[], 
    analysisType: string, 
    parameters: Record<string, any> = {},
    customKnowledgeBase?: string,
    customUserQuery?: string
  ): Promise<AnalysisResult> {
    try {
      console.log(`Running ${analysisType} analysis for documents:`, documentIds, 'with parameters:', parameters);
      
      // Add optional parameters if provided
      const finalParameters = { ...parameters };
      if (customKnowledgeBase) finalParameters.knowledge_base = customKnowledgeBase;
      if (customUserQuery) finalParameters.query = customUserQuery;
      
      // Run analysis with the appropriate analysis type
      const requestBody = {
        documentIds: documentIds,
        analysisType: analysisType === 'comprehensive_tools' ? 'comprehensive' : analysisType,
        parameters: finalParameters,
        query: parameters.query || customUserQuery || ""
      };
      
      console.log('Making analysis API request with data:', requestBody);
      
      // Use the new API endpoint which supports tool-based visualization
      const response = await apiService.post('/api/analysis/run', requestBody);
      console.log('Analysis API response:', response.data);
      
      // Check if we have results in the expected format
      if (!response.data || !response.data.id) {
        console.error('Invalid analysis response:', response.data);
        throw new Error('The analysis service returned an invalid response');
      }
            
      // Process the API response into our application's format
      const responseData = response.data;
      
      // Create base result structure
      const result: AnalysisResult = {
        id: responseData.id,
        documentIds: Array.isArray(responseData.documentIds) ? responseData.documentIds : documentIds,
        analysisType: responseData.analysisType || analysisType,
        timestamp: responseData.timestamp || new Date().toISOString(),
        data: {
          metrics: [],
          charts: [],
          tables: []
        },
        citationReferences: responseData.citationReferences || {}
      };
      
      // Add analysis text if available
      if (responseData.analysisText) {
        result.analysisText = responseData.analysisText;
      }
      
      // Add query if available
      if (responseData.query || parameters.query || customUserQuery) {
        result.query = responseData.query || parameters.query || customUserQuery;
      }
      
      // Check if we have the new tool-based visualization format
      if (responseData.visualizationData) {
        console.log('Found visualization data in the tool-based format:', Object.keys(responseData.visualizationData));
        
        // Set the visualization data from the API response
        result.visualizationData = {
          charts: Array.isArray(responseData.visualizationData.charts) ? responseData.visualizationData.charts : [],
          tables: Array.isArray(responseData.visualizationData.tables) ? responseData.visualizationData.tables : [],
          // Preserve backwards compatibility with older visualization data formats
          monetaryValues: responseData.visualizationData.monetaryValues || null,
          percentages: responseData.visualizationData.percentages || null,
          keywordFrequency: responseData.visualizationData.keywordFrequency || null
        };
        
        console.log(`Processed visualization data: ${result.visualizationData.charts.length} charts, ${result.visualizationData.tables.length} tables`);
      } else {
        console.log('No visualization data found in tool-based format, falling back to legacy approach');
      }
      
      // Process metrics, ratios, and comparativePeriods from the response
      if (Array.isArray(responseData.metrics)) {
        result.data.metrics = responseData.metrics.map((metric: any) => ({
          name: metric.name,
          value: metric.value,
          unit: metric.unit || '',
          category: metric.category || 'General',
          description: metric.description || '',
          previousValue: metric.previousValue,
          percentChange: metric.percentChange,
          trend: metric.trend || 'neutral'
        }));
      }
      
      // If no visualizationData in tool format, but we have the old visualization_data format
      if (!result.visualizationData && responseData.visualization_data) {
        console.log('Using legacy visualization_data format');
        result.visualizationData = {
          charts: [],
          tables: [],
          ...responseData.visualization_data
        };
      }
      
      // For any case, provide a fallback by generating visualization from extracted data
      if (!result.visualizationData || 
          (!result.visualizationData.charts.length && 
           !result.visualizationData.tables.length &&
           !result.visualizationData.monetaryValues)) {
        
        console.log('Generating fallback visualization data');
        
        // Extract document text from the response if available
        let documentText = '';
        if (responseData.analysisText) {
          documentText = responseData.analysisText;
        } else if (responseData.raw_analysis) {
          documentText = responseData.raw_analysis;
        }
        
        // Generate visualization data from extracted text
        if (documentText) {
          const extractedData = extractFinancialFiguresFromText(documentText);
          const visualizationData = generateVisualizationFromExtractedData(extractedData);
          
          result.visualizationData = {
            charts: [],
            tables: [],
            ...visualizationData
          };
          
          console.log('Generated fallback visualization data');
        }
      }
      
      return result;
      
    } catch (error) {
      return handleApiError(error);
    }
  },
  
  /**
   * Get a specific analysis result by ID
   */
  async getAnalysis(analysisId: string): Promise<AnalysisResult> {
    try {
      console.log(`Fetching analysis result: ${analysisId}`);
      
      // Get the analysis result from the API
      const response = await apiService.get(`/api/analysis/${analysisId}`);
      console.log('Analysis get response:', response.data);
      
      // Check if we have results in the expected format
      if (!response.data || !response.data.id) {
        console.error('Invalid analysis response:', response.data);
        throw new Error('The analysis service returned an invalid response');
      }
      
      // Process the API response into our application's format
      const responseData = response.data;
      
      // Create base result structure
      const result: AnalysisResult = {
        id: responseData.id,
        documentIds: Array.isArray(responseData.documentIds) ? responseData.documentIds : [responseData.documentIds],
        analysisType: responseData.analysisType || 'unknown',
        timestamp: responseData.timestamp || new Date().toISOString(),
        data: {
          metrics: [],
          charts: [],
          tables: []
        },
        citationReferences: responseData.citationReferences || {}
      };
      
      // Add analysis text if available
      if (responseData.analysisText) {
        result.analysisText = responseData.analysisText;
      }
      
      // Add query if available
      if (responseData.query) {
        result.query = responseData.query;
      }
      
      // Check if we have the new tool-based visualization format
      if (responseData.visualizationData) {
        console.log('Found visualization data in the tool-based format:', Object.keys(responseData.visualizationData));
        
        // Set the visualization data from the API response
        result.visualizationData = {
          charts: Array.isArray(responseData.visualizationData.charts) ? responseData.visualizationData.charts : [],
          tables: Array.isArray(responseData.visualizationData.tables) ? responseData.visualizationData.tables : [],
          // Preserve backwards compatibility with older visualization data formats
          monetaryValues: responseData.visualizationData.monetaryValues || null,
          percentages: responseData.visualizationData.percentages || null,
          keywordFrequency: responseData.visualizationData.keywordFrequency || null
        };
        
        console.log(`Processed visualization data: ${result.visualizationData.charts.length} charts, ${result.visualizationData.tables.length} tables`);
      } else {
        console.log('No visualization data found in tool-based format, falling back to legacy approach');
      }
      
      // Process metrics, ratios, and comparativePeriods from the response
      if (Array.isArray(responseData.metrics)) {
        result.data.metrics = responseData.metrics.map((metric: any) => ({
          name: metric.name,
          value: metric.value,
          unit: metric.unit || '',
          category: metric.category || 'General',
          description: metric.description || '',
          previousValue: metric.previousValue,
          percentChange: metric.percentChange,
          trend: metric.trend || 'neutral'
        }));
      }
      
      return result;
    } catch (error) {
      return handleApiError(error);
    }
  },
  
  /**
   * Get chart data for a specific analysis result
   */
  async getChartData(analysisId: string, chartType: string): Promise<ChartDataResponse> {
    try {
      return await apiService.get<ChartDataResponse>(
        `/api/analysis/${analysisId}/chart/${chartType}`
      );
    } catch (error) {
      throw handleApiError(error);
    }
  },
  
  /**
   * Get enhanced analysis with trends and extra insights
   */
  async getEnhancedAnalysis(analysisId: string): Promise<EnhancedAnalysis> {
    try {
      console.log(`Getting enhanced analysis for ${analysisId}`);
      
      // First get the standard analysis result
      const analysisResult = await this.getAnalysis(analysisId);
      
      // Then get enhanced data from API, or fall back to generating it client-side
      try {
        return await apiService.get<EnhancedAnalysis>(`/api/analysis/${analysisId}/enhanced`);
      } catch (error) {
        console.warn('Enhanced analysis endpoint not available, generating client-side', error);
        
        // Generate enhanced data client-side based on the standard analysis
        return {
          trends: this.generateTrendsFromAnalysis(analysisResult),
          insights: this.generateEnhancedInsightsFromAnalysis(analysisResult)
        };
      }
    } catch (error) {
      throw handleApiError(error);
    }
  },
  
  /**
   * Helper to generate trends from basic analysis
   */
  generateTrendsFromAnalysis(analysis: AnalysisResult): any[] {
    // Generate trends based on the metrics from the standard analysis
    return analysis.metrics.map(metric => ({
      id: `trend-${Math.random().toString(16).slice(2)}`,
      name: `${metric.name} Trend`,
      description: `Trend analysis for ${metric.name}`,
      value: metric.value,
      change: Math.random() * 0.2 - 0.1, // Random change between -10% and +10%
      direction: Math.random() > 0.5 ? 'increasing' : 'decreasing',
      significance: Math.random() > 0.7 ? 'high' : 'medium',
      category: metric.category
    }));
  },
  
  /**
   * Helper to generate enhanced insights from basic analysis
   */
  generateEnhancedInsightsFromAnalysis(analysis: AnalysisResult): any[] {
    // Generate enhanced insights based on the standard analysis
    return analysis.insights.map((insight, index) => ({
      id: `insight-${Math.random().toString(16).slice(2)}`,
      text: insight,
      category: index % 3 === 0 ? 'critical' : index % 3 === 1 ? 'important' : 'informational',
      relatedMetrics: analysis.metrics.slice(0, 2).map(m => m.name),
      confidence: 0.8 + Math.random() * 0.15
    }));
  },
  
  /**
   * Run a specific type of analysis with appropriate parameters
   */
  async runSpecificAnalysis(
    analysisType: 'financial_ratios' | 'trend_analysis' | 'benchmark_comparison' | 'sentiment_analysis',
    documentIds: string[],
    specificParams: Record<string, any> = {}
  ): Promise<AnalysisResult> {
    // Default params by analysis type
    const defaultParams: Record<string, Record<string, any>> = {
      financial_ratios: {
        include_categories: ['profitability', 'liquidity', 'solvency', 'efficiency'],
        detailed: true
      },
      trend_analysis: {
        baseline_period: 'previous_year',
        metrics: ['revenue', 'net_income', 'total_assets']
      },
      benchmark_comparison: {
        benchmark: 'industry_average',
        metrics: ['profit_margin', 'debt_to_equity', 'return_on_assets']
      },
      sentiment_analysis: {
        sections: ['management_discussion', 'outlook', 'risk_factors'],
        detailed: true
      }
    };
    
    // Merge default params with specific params
    const params = {
      ...defaultParams[analysisType],
      ...specificParams
    };
    
    return this.runAnalysis(documentIds, analysisType, params);
  }
};
</file>
```

#### src/lib/api/apiService\.ts
*Size: 15.4 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/lib/api/apiService.ts">
import { z } from 'zod';
import { ApiError, ErrorDetail } from '../errors/ApiError';

// API base URL - would be configured based on environment
const API_BASE_URL = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8000';

// Configuration for retries
const MAX_RETRY_ATTEMPTS = 3;
const RETRY_DELAY_MS = 1000;

/**
 * Validates data against a schema and returns the validated data
 */
export function validate<T>(schema: z.ZodType<T>, data: unknown): T {
  const result = schema.safeParse(data);
  if (!result.success) {
    const errorMessage = result.error.errors.map(
      (err) => `${err.path.join('.')}: ${err.message}`
    ).join(', ');
    throw new Error(`Validation error: ${errorMessage}`);
  }
  return result.data;
}

/**
 * API Service class providing standardized methods for API interactions
 * with error handling, validation, and retry functionality
 */
class ApiService {
  /**
   * Send a request to the API with validation
   */
  private async request<T>(
    endpoint: string,
    method: string = 'GET',
    data?: any,
    formData?: FormData,
    schema?: z.ZodType<T>,
    retryOptions?: {
      maxAttempts?: number;
      retryDelay?: number;
    }
  ): Promise<T> {
    // Configuration
    const maxAttempts = retryOptions?.maxAttempts || MAX_RETRY_ATTEMPTS;
    const retryDelay = retryOptions?.retryDelay || RETRY_DELAY_MS;
    
    // Ensure endpoint starts with /
    if (!endpoint.startsWith('/')) {
      endpoint = '/' + endpoint;
    }
    
    // Ensure URL doesn't have duplicated /api
    const finalUrl = API_BASE_URL.endsWith('/api') 
      ? `${API_BASE_URL}${endpoint}`
      : `${API_BASE_URL}${endpoint}`;
      
    console.log(`Sending ${method} request to ${finalUrl}`);
    
    // Create request options
    const options: RequestInit = {
      method,
      headers: {
        'Accept': 'application/json'
      }
    };
    
    // Add request body if provided
    if (data) {
      options.headers = {
        ...options.headers,
        'Content-Type': 'application/json'
      };
      options.body = JSON.stringify(data);
    }
    
    // Add form data if provided
    if (formData) {
      // Remove Content-Type header to let the browser set it with the boundary
      if (options.headers && typeof options.headers === 'object') {
        const headers = options.headers as Record<string, string>;
        delete headers['Content-Type'];
      }
      options.body = formData;
    }
    
    // Implementation of retry logic
    let lastError: any;
    
    for (let attempt = 1; attempt <= maxAttempts; attempt++) {
      try {
        const response = await fetch(finalUrl, options);
        
        // Handle non-OK responses
        if (!response.ok) {
          // Try to parse error response as our standard format
          try {
            const errorData = await response.json();
            
            // Check if the response matches our standard error format
            if (errorData.status_code !== undefined && errorData.detail !== undefined) {
              throw new ApiError({
                statusCode: errorData.status_code,
                detail: errorData.detail,
                errorType: errorData.error_type,
                originalError: new Error(`API error: ${response.status} ${response.statusText}`)
              });
            } 
            // Fallback for older API endpoints not yet updated
            else if (errorData.detail) {
              let detail: ErrorDetail = errorData.detail;
              throw new ApiError({
                statusCode: response.status,
                detail,
                originalError: new Error(`API error: ${response.status} ${response.statusText}`)
              });
            } else {
              // Generic JSON error without our expected structure
              throw new ApiError({
                statusCode: response.status,
                detail: JSON.stringify(errorData),
                originalError: new Error(`API error: ${response.status} ${response.statusText}`)
              });
            }
          } catch (e) {
            // If error is already an ApiError, just rethrow it
            if (e instanceof ApiError) {
              throw e;
            }
            
            // If JSON parsing failed, try to get plain text
            try {
              const errorText = await response.text();
              throw new ApiError({
                statusCode: response.status,
                detail: errorText || `API error: ${response.status} ${response.statusText}`,
                originalError: e
              });
            } catch (textError) {
              // If all else fails, create a generic API error
              throw new ApiError({
                statusCode: response.status,
                detail: `API error: ${response.status} ${response.statusText}`,
                originalError: textError
              });
            }
          }
        }
        
        // Parse the response
        const responseData = await response.json();
        
        // Validate the response if a schema is provided
        if (schema) {
          return validate(schema, responseData);
        }
        
        return responseData as T;
        
      } catch (error) {
        console.error(`API request error (attempt ${attempt}/${maxAttempts}):`, error);
        lastError = error;
        
        // If we have more attempts and this isn't a client error (4xx), retry
        // Don't retry client errors like 400, 404, etc.
        const isClientError = error instanceof ApiError && error.statusCode >= 400 && error.statusCode < 500;
        
        if (attempt < maxAttempts && !isClientError) {
          const delay = retryDelay * Math.pow(2, attempt - 1);
          console.log(`Retrying in ${delay}ms...`);
          await new Promise(resolve => setTimeout(resolve, delay));
        } else {
          // No more retries or client error, throw the last error
          throw lastError;
        }
      }
    }
    
    // If we've exhausted all retry attempts, throw the last error
    console.error('All retry attempts failed');
    throw lastError;
  }
  
  /**
   * Performs a GET request to the API
   */
  async get<T>(endpoint: string, schema?: z.ZodType<T>, retryOptions?: {
    maxAttempts?: number;
    retryDelay?: number;
  }): Promise<T> {
    return this.request<T>(endpoint, 'GET', undefined, undefined, schema, retryOptions);
  }
  
  /**
   * Performs a POST request to the API
   */
  async post<T>(endpoint: string, data?: any, schema?: z.ZodType<T>, retryOptions?: {
    maxAttempts?: number;
    retryDelay?: number;
  }): Promise<T> {
    return this.request<T>(endpoint, 'POST', data, undefined, schema, retryOptions);
  }
  
  /**
   * Performs a POST request with multipart/form-data to the API
   */
  async postFormData<T>(endpoint: string, formData: FormData, schema?: z.ZodType<T>, retryOptions?: {
    maxAttempts?: number;
    retryDelay?: number;
  }): Promise<T> {
    return this.request<T>(endpoint, 'POST', undefined, formData, schema, retryOptions);
  }
  
  /**
   * Performs a PUT request to the API
   */
  async put<T>(endpoint: string, data?: any, schema?: z.ZodType<T>, retryOptions?: {
    maxAttempts?: number;
    retryDelay?: number;
  }): Promise<T> {
    return this.request<T>(endpoint, 'PUT', data, undefined, schema, retryOptions);
  }
  
  /**
   * Performs a DELETE request to the API
   */
  async delete<T>(endpoint: string, schema?: z.ZodType<T>, retryOptions?: {
    maxAttempts?: number;
    retryDelay?: number;
  }): Promise<T> {
    return this.request<T>(endpoint, 'DELETE', undefined, undefined, schema, retryOptions);
  }
  
  /**
   * Uploads a file to the API with progress tracking
   */
  async uploadWithProgress<T>(
    endpoint: string, 
    formData: FormData,
    onProgress?: (progress: number) => void,
    schema?: z.ZodType<T>
  ): Promise<T> {
    // Ensure endpoint starts with /
    if (!endpoint.startsWith('/')) {
      endpoint = '/' + endpoint;
    }
    
    // Ensure URL doesn't have duplicated /api
    const finalUrl = API_BASE_URL.endsWith('/api') 
      ? `${API_BASE_URL}${endpoint}`
      : `${API_BASE_URL}${endpoint}`;
      
    console.log(`Uploading file to ${finalUrl}`);
    
    return new Promise((resolve, reject) => {
      const xhr = new XMLHttpRequest();
      
      // Set up progress tracking
      if (onProgress) {
        xhr.upload.onprogress = (event) => {
          if (event.lengthComputable) {
            const progress = Math.round((event.loaded / event.total) * 100);
            onProgress(progress);
          }
        };
      }
      
      xhr.open('POST', finalUrl);
      
      xhr.onload = async () => {
        if (xhr.status >= 200 && xhr.status < 300) {
          try {
            const response = JSON.parse(xhr.responseText);
            
            // Validate the response if a schema is provided
            if (schema) {
              try {
                const validatedData = validate(schema, response);
                resolve(validatedData);
              } catch (validationError) {
                reject(validationError);
              }
            } else {
              resolve(response as T);
            }
          } catch (parseError) {
            reject(new Error('Failed to parse response as JSON'));
          }
        } else {
          let errorMessage = `Upload failed with status ${xhr.status}`;
          
          try {
            const errorData = JSON.parse(xhr.responseText);
            if (errorData.detail) {
              errorMessage = errorData.detail;
            } else {
              errorMessage = JSON.stringify(errorData);
            }
          } catch (e) {
            // If the response isn't JSON, use the response text
            if (xhr.responseText) {
              errorMessage = xhr.responseText;
            }
          }
          
          reject(new Error(errorMessage));
        }
      };
      
      xhr.onerror = () => {
        reject(new Error('Network error during upload'));
      };
      
      xhr.onabort = () => {
        reject(new Error('Upload was aborted'));
      };
      
      xhr.send(formData);
    });
  }
  
  /**
   * Performs a streaming request to the API and processes the chunks
   * This is especially useful for LLM-generated content that comes as a stream
   */
  async stream<T>(
    endpoint: string, 
    data: any, 
    onChunk: (chunk: any) => void, 
    onComplete: (fullResponse: T) => void,
    onError: (error: Error) => void
  ): Promise<void> {
    // Ensure endpoint starts with /
    if (!endpoint.startsWith('/')) {
      endpoint = '/' + endpoint;
    }
    
    // Ensure URL doesn't have duplicated /api
    const finalUrl = API_BASE_URL.endsWith('/api') 
      ? `${API_BASE_URL}${endpoint}`
      : `${API_BASE_URL}${endpoint}`;
    
    try {
      const response = await fetch(finalUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Accept': 'text/event-stream'
        },
        body: JSON.stringify(data)
      });
      
      if (!response.ok) {
        let errorMessage = `API error: ${response.status} ${response.statusText}`;
        try {
          const errorData = await response.json();
          if (errorData.detail) {
            errorMessage = typeof errorData.detail === 'string' 
              ? errorData.detail 
              : JSON.stringify(errorData.detail);
          }
        } catch (e) {
          // If we can't parse JSON, try to get text
          try {
            const errorText = await response.text();
            if (errorText) errorMessage = errorText;
          } catch (textError) {
            // Keep original error message
          }
        }
        throw new Error(errorMessage);
      }
      
      // Check if the response is actually a stream
      if (response.headers.get('content-type')?.includes('event-stream')) {
        // Handle server-sent events
        const reader = response.body?.getReader();
        const decoder = new TextDecoder();
        let buffer = '';
        let fullResponseText = '';
        
        if (!reader) {
          throw new Error('Stream reader could not be created');
        }
        
        let done = false;
        
        while (!done) {
          const { value, done: readerDone } = await reader.read();
          done = readerDone;
          
          if (done) break;
          
          // Convert the chunk to text
          const chunk = decoder.decode(value, { stream: true });
          buffer += chunk;
          fullResponseText += chunk;
          
          // Process any complete events in the buffer
          let eventEnd = buffer.indexOf('\n\n');
          while (eventEnd >= 0) {
            const event = buffer.substring(0, eventEnd);
            buffer = buffer.substring(eventEnd + 2);
            
            // Process the event (typically 'data: {...}')
            if (event.startsWith('data:')) {
              const data = event.substring(5).trim();
              try {
                // Try to parse as JSON
                const parsedData = JSON.parse(data);
                onChunk(parsedData);
              } catch (e) {
                // If not valid JSON, just pass the raw data
                onChunk(data);
              }
            }
            
            eventEnd = buffer.indexOf('\n\n');
          }
        }
        
        // Attempt to parse the full response as JSON
        try {
          const fullResponse = JSON.parse(fullResponseText);
          onComplete(fullResponse as T);
        } catch (e) {
          console.warn('Could not parse full response as JSON:', e);
          onComplete(fullResponseText as unknown as T);
        }
      } else {
        // If not a stream, handle as regular JSON response
        const data = await response.json();
        onComplete(data as T);
      }
    } catch (error) {
      console.error('Stream request error:', error);
      onError(error instanceof Error ? error : new Error(String(error)));
    }
  }
  
  /**
   * Polls an endpoint until a condition is met or max attempts are reached
   * Useful for checking the status of long-running operations
   */
  async poll<T>(
    endpoint: string,
    checkCondition: (data: T) => boolean,
    options: {
      interval?: number,
      maxAttempts?: number,
      initialDelay?: number
    } = {}
  ): Promise<T> {
    const {
      interval = 2000,
      maxAttempts = 30,
      initialDelay = 0
    } = options;
    
    // Wait for initial delay if specified
    if (initialDelay > 0) {
      await new Promise(resolve => setTimeout(resolve, initialDelay));
    }
    
    // Start polling
    for (let attempt = 1; attempt <= maxAttempts; attempt++) {
      const data = await this.get<T>(endpoint);
      
      if (checkCondition(data)) {
        return data;
      }
      
      // Wait before the next attempt
      if (attempt < maxAttempts) {
        await new Promise(resolve => setTimeout(resolve, interval));
      }
    }
    
    throw new Error(`Polling timed out after ${maxAttempts} attempts`);
  }
}

// Create a singleton instance of the ApiService
export const apiService = new ApiService();

// In development, expose the API service to the window object for debugging
if (process.env.NODE_ENV === 'development' && typeof window !== 'undefined') {
  (window as any).__apiService = apiService;
  
  console.log(
    '%cğŸŒ API Service Available',
    'background: #edf8ff; color: #0066cc; font-size: 12px; font-weight: bold; padding: 4px 8px; border-radius: 4px;'
  );
  console.log('Use __apiService to access the API directly in the console');
}
</file>
```

#### src/lib/api/conversation\.ts
*Size: 6.9 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/lib/api/conversation.ts">
import { Message, Citation } from '@/types';
import { MessageRequestSchema, ConversationCreateRequestSchema } from '@/validation/schemas';
import { validateRequest } from '../../lib/validation/api-validation';

// API base URL - would be configured based on environment
const API_BASE_URL = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8000/api';

/**
 * Conversation API service
 * Handles communication with the backend for conversation operations
 */
class ConversationApiService {
  /**
   * Send a request to the API
   */
  private async request<T>(
    endpoint: string,
    method: string = 'GET',
    data?: any,
    formData?: FormData
  ): Promise<T> {
    // Ensure endpoint starts with / 
    if (!endpoint.startsWith('/')) {
      endpoint = '/' + endpoint;
    }
    
    // Fixed URL construction to prevent duplicated /api
    const finalUrl = API_BASE_URL.endsWith('/api') 
      ? `${API_BASE_URL}${endpoint}`
      : `${API_BASE_URL}/api${endpoint}`;
      
    console.log(`Sending ${method} request to ${finalUrl}`);
    
    // Create request options
    const options: RequestInit = {
      method,
      headers: {
        'Accept': 'application/json'
      }
    };
    
    // Add request body if provided
    if (data) {
      options.headers = {
        ...options.headers,
        'Content-Type': 'application/json'
      };
      options.body = JSON.stringify(data);
    }
    
    // Add form data if provided
    if (formData) {
      // Remove Content-Type header to let the browser set it with the boundary
      if (options.headers && typeof options.headers === 'object') {
        const headers = options.headers as Record<string, string>;
        delete headers['Content-Type'];
      }
      options.body = formData;
    }
    
    try {
      const response = await fetch(finalUrl, options);
      
      // Handle non-OK responses
      if (!response.ok) {
        let errorMessage = `API error: ${response.status} ${response.statusText}`;
        
        // Try to parse error response as JSON
        try {
          const errorData = await response.json();
          if (errorData.detail) {
            if (typeof errorData.detail === 'string') {
              errorMessage = errorData.detail;
            } else if (Array.isArray(errorData.detail)) {
              // Handle Pydantic validation errors
              errorMessage = errorData.detail.map((err: any) => 
                `${err.loc.join('.')}: ${err.msg}`
              ).join(', ');
            } else {
              errorMessage = JSON.stringify(errorData.detail);
            }
          } else {
            errorMessage = JSON.stringify(errorData);
          }
        } catch (e) {
          // If not JSON, try to get text
          try {
            const errorText = await response.text();
            if (errorText) {
              errorMessage = errorText;
            }
          } catch (textError) {
            // Keep the original error message if we can't parse the response
          }
        }
        
        throw new Error(errorMessage);
      }
      
      // Parse the response
      const responseData = await response.json();
      return responseData as T;
    } catch (error) {
      console.error('API request error:', error);
      throw error;
    }
  }
  
  /**
   * Create a new conversation
   */
  async createConversation(title: string = 'New Conversation', documentIds: string[] = []): Promise<{ session_id: string }> {
    try {
      // Validate request data against schema
      const validatedData = validateRequest(ConversationCreateRequestSchema, {
        title,
        documentIds: documentIds,
        userId: 'default-user' // This is handled by the backend, but we'll include it for completeness
      });
      
      const response = await this.request<{ session_id: string }>(
        `/conversation`,
        'POST',
        validatedData
      );
      
      console.log(`Created conversation session: ${response.session_id}`);
      return response;
    } catch (error) {
      console.error('Error creating conversation:', error);
      throw new Error(`Failed to create conversation: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
  
  /**
   * List conversations
   */
  async listConversations(): Promise<any[]> {
    try {
      const conversations = await this.request<any[]>(
        '/conversation',
        'GET'
      );
      return conversations;
    } catch (error) {
      console.error('Error listing conversations:', error);
      return [];
    }
  }
  
  /**
   * Send a message to the conversation
   */
  async sendMessage(sessionId: string, message: string, documentIds: string[] = []): Promise<Message> {
    if (!sessionId) {
      throw new Error('Session ID is required');
    }

    try {
      // Format the request body to match the backend's expected format
      const requestBody = {
        session_id: sessionId,  // Use snake_case for backend compatibility
        content: message,
        document_ids: documentIds,  // Use snake_case for backend compatibility
        user_id: 'default-user'  // Use snake_case for backend compatibility
      };
      
      const response = await this.request<Message>(
        `/conversation/${sessionId}/message`,
        'POST',
        requestBody
      );
      
      return response;
    } catch (error) {
      console.error('Error sending message:', error);
      throw new Error(`Failed to send message: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
  
  /**
   * Get messages for a conversation
   */
  async getMessages(sessionId: string, limit: number = 50, offset: number = 0): Promise<Message[]> {
    try {
      const response = await this.request<{ messages: Message[] }>(
        `/conversation/${sessionId}/history?limit=${limit}&offset=${offset}`,
        'GET'
      );
      
      return response.messages;
    } catch (error) {
      console.error('Error getting messages:', error);
      return [];
    }
  }
  
  /**
   * Get document citations
   */
  async getDocumentCitations(documentId: string): Promise<Citation[]> {
    try {
      const citations = await this.request<Citation[]>(
        `/document/${documentId}/citations`,
        'GET'
      );
      
      return citations;
    } catch (error) {
      console.error('Error getting document citations:', error);
      return [];
    }
  }

  /**
   * Add a document to a conversation
   */
  async addDocumentToConversation(conversationId: string, documentId: string): Promise<boolean> {
    try {
      await this.request(
        `/conversation/${conversationId}/document/${documentId}`,
        'POST'
      );
      console.log(`Document ${documentId} added to conversation ${conversationId}`);
      return true;
    } catch (error) {
      console.error('Error adding document to conversation:', error);
      return false;
    }
  }
}

// Create a singleton instance
export const conversationApi = new ConversationApiService();
</file>
```

#### src/lib/api/conversation\.ts\.bak
*Size: 8.4 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/lib/api/conversation.ts.bak">
import { Message, Citation } from '@/types';

// API base URL - would be configured based on environment
const API_BASE_URL = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8000/api';

/**
 * Conversation API service
 * Handles communication with the backend for conversation operations
 */
class ConversationApiService {
  /**
   * Send a request to the API
   */
  private async request<T>(
    endpoint: string,
    method: string = 'GET',
    data?: any,
    formData?: FormData
  ): Promise<T> {
    // Ensure endpoint starts with / 
    if (!endpoint.startsWith('/')) {
      endpoint = '/' + endpoint;
    }
    
    // Fixed URL construction to prevent duplicated /api
    const finalUrl = API_BASE_URL.endsWith('/api') 
      ? `${API_BASE_URL}${endpoint}`
      : `${API_BASE_URL}/api${endpoint}`;
      
    console.log(`Sending ${method} request to ${finalUrl}`);
    
    // Create request options
    const options: RequestInit = {
      method,
      headers: {
        'Accept': 'application/json'
      }
    };
    
    // Add request body if provided
    if (data) {
      options.headers = {
        ...options.headers,
        'Content-Type': 'application/json'
      };
      options.body = JSON.stringify(data);
    }
    
    // Add form data if provided
    if (formData) {
      // Remove Content-Type header to let the browser set it with the boundary
      if (options.headers && typeof options.headers === 'object') {
        const headers = options.headers as Record<string, string>;
        delete headers['Content-Type'];
      }
      options.body = formData;
    }
    
    try {
      const response = await fetch(finalUrl, options);
      
      // Handle non-OK responses
      if (!response.ok) {
        let errorMessage = `API error: ${response.status} ${response.statusText}`;
        
        // Try to parse error response as JSON
        try {
          const errorData = await response.json();
          if (errorData.detail) {
            if (typeof errorData.detail === 'string') {
              errorMessage = errorData.detail;
            } else if (Array.isArray(errorData.detail)) {
              // Handle Pydantic validation errors
              errorMessage = errorData.detail.map((err: any) => 
                `${err.loc.join('.')}: ${err.msg}`
              ).join(', ');
            } else {
              errorMessage = JSON.stringify(errorData.detail);
            }
          } else {
            errorMessage = JSON.stringify(errorData);
          }
        } catch (e) {
          // If not JSON, try to get text
          try {
            const errorText = await response.text();
            if (errorText) {
              errorMessage = errorText;
            }
          } catch (textError) {
            // Keep the original error message if we can't parse the response
          }
        }
        
        throw new Error(errorMessage);
      }
      
      // Parse the response
      const responseData = await response.json();
      return responseData as T;
    } catch (error) {
      console.error('API request error:', error);
      throw error;
    }
  }

  /**
   * Create a new conversation
   */
  async createConversation(data: { title: string, document_ids?: string[] }): Promise<{ session_id: string }> {
    try {
      // Send request
      const response = await this.request<any>(
        '/conversation',
        'POST',
        data
      );
      
      // Extract the session ID from the response
      if (response && response.session_id) {
        return { session_id: response.session_id };
      } else if (response && response.id) {
        // Handle alternative response format
        return { session_id: response.id };
      } else {
        throw new Error('Unexpected response format from conversation creation');
      }
    } catch (error) {
      console.error('Error creating conversation:', error);
      throw new Error(`Failed to create conversation: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
  
  /**
   * List user conversations
   */
  async listConversations(): Promise<Array<{ id: string, title: string }>> {
    try {
      // Get list of conversations for the current user
      const response = await this.request<any[]>(
        '/conversation',
        'GET'
      );
      
      // Convert backend format to our frontend format
      const conversations = response.map(conv => ({
        id: conv.id || conv.session_id || conv.conversation_id,
        title: conv.title || 'Untitled Conversation'
      }));
      
      return conversations;
    } catch (error) {
      console.error('Error listing conversations:', error);
      return [];
    }
  }
  
  /**
   * Send a message to the conversation
   */
  async sendMessage(sessionId: string, message: string, documentIds: string[] = []): Promise<Message> {
    try {
      const response = await this.request<Message>(
        `/conversation/${sessionId}/message`,
        'POST',
        {
          content: message,
          document_ids: documentIds
        }
      );
      
      return response;
    } catch (error) {
      console.error('Error sending message:', error);
      throw new Error(`Failed to send message: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
  
  /**
   * Get messages for a conversation
   */
  async getMessages(sessionId: string): Promise<Message[]> {
    try {
      const response = await this.request<Message[]>(
        `/conversation/${sessionId}/messages`,
        'GET'
      );
      
      return response;
    } catch (error) {
      console.error('Error getting messages:', error);
      return [];
    }
  }
  
  /**
   * Get a single conversation
   */
  async getConversation(sessionId: string): Promise<{ id: string, title: string, messages: Message[] }> {
    try {
      const conversation = await this.request<any>(
        `/conversation/${sessionId}`,
        'GET'
      );
      
      const messages = await this.getMessages(sessionId);
      
      return {
        id: conversation.id || conversation.session_id,
        title: conversation.title || 'Untitled Conversation',
        messages
      };
    } catch (error) {
      console.error('Error getting conversation:', error);
      throw new Error(`Failed to get conversation: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
  
  /**
   * Get citations for a message
   */
  async getMessageCitations(messageId: string): Promise<Citation[]> {
    try {
      const response = await this.request<Citation[]>(
        `/message/${messageId}/citations`,
        'GET'
      );
      
      return response;
    } catch (error) {
      console.error('Error getting message citations:', error);
      return [];
    }
  }

  /**
   * Add a document to a conversation
   */
  async addDocumentToConversation(sessionId: string, documentId: string): Promise<void> {
    try {
      await this.request(
        `/conversation/${sessionId}/document/${documentId}`,
        'POST'
      );
    } catch (error) {
      console.error('Error adding document to conversation:', error);
      throw new Error(`Failed to add document to conversation: ${error instanceof Error ? error.message : String(error)}`);
    }
  }

  /**
   * Remove a document from a conversation
   */
  async removeDocumentFromConversation(sessionId: string, documentId: string): Promise<void> {
    try {
      await this.request(
        `/conversation/${sessionId}/document/${documentId}`,
        'DELETE'
      );
    } catch (error) {
      console.error('Error removing document from conversation:', error);
      throw new Error(`Failed to remove document from conversation: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
  
  /**
   * Create a new analysis from conversation
   */
  async createAnalysisFromConversation(
    sessionId: string, 
    documentIds: string[], 
    analysisType: string
  ): Promise<{ analysis_id: string }> {
    try {
      const response = await this.request<{ analysis_id: string }>(
        `/conversation/${sessionId}/analysis`,
        'POST',
        {
          document_ids: documentIds,
          analysis_type: analysisType
        }
      );
      
      return response;
    } catch (error) {
      console.error('Error creating analysis from conversation:', error);
      throw new Error(`Failed to create analysis: ${error instanceof Error ? error.message : String(error)}`);
    }
  }
}

export const conversationApi = new ConversationApiService(); 
</file>
```

#### src/lib/api/conversations\.ts
*Size: 14.6 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/lib/api/conversations.ts">
import { Message, ConversationMetadata } from '@/types';
import { apiService } from './apiService';
import {
  MessageSchema,
  ConversationAnalysisResponseSchema
} from '@/validation/schemas';
import { Citation, ConversationAnalysisResponse } from '@/types/enhanced';

// Function to handle API errors - keeping for backwards compatibility
const handleApiError = (error: any): never => {
  console.error('API Error:', error);
  if (error.response && error.response.data && error.response.data.detail) {
    throw new Error(error.response.data.detail);
  }
  throw new Error('An error occurred while communicating with the server');
};

// Define response types for better type safety
interface ConversationListResponse {
  items: ConversationMetadata[];
  total: number;
  page: number;
  pageSize: number;
}

interface ConversationCreateResponse {
  session_id: string;
  id?: string;
}

export const conversationsApi = {
  /**
   * Create a new conversation
   */
  async createConversation(data: { 
    title: string, 
    document_ids?: string[] 
  }): Promise<string> {
    try {
      const response = await apiService.post<ConversationCreateResponse>(
        '/conversation',
        data
      );
      
      // Extract the session ID from the response
      if (response.session_id) {
        return response.session_id;
      } else if (response.id) {
        // Handle alternative response format
        return response.id;
      } else {
        console.error('Unexpected response format:', response);
        throw new Error('Unexpected response format from conversation creation');
      }
    } catch (error) {
      throw handleApiError(error);
    }
  },
  
  /**
   * List all conversations for the current user
   */
  async listConversations(page: number = 1, pageSize: number = 10): Promise<ConversationListResponse> {
    try {
      const conversations = await apiService.get<ConversationMetadata[]>(
        '/conversation'
      );
      
      // Get the total count (if available in the API)
      let total = conversations.length;
      try {
        const countResponse = await apiService.get<{ count: number }>(
          '/conversation/count'
        );
        total = countResponse.count;
      } catch (error) {
        console.warn('Error getting conversation count, using list length:', error);
      }
      
      // Apply pagination (if not already done by the backend)
      const paginatedItems = Array.isArray(conversations) 
        ? conversations.slice((page - 1) * pageSize, page * pageSize)
        : [];
      
      return {
        items: paginatedItems.map(conv => ({
          id: conv.id || conv.session_id || '',
          title: conv.title || 'Untitled Conversation',
          createdAt: conv.createdAt || new Date().toISOString(),
          updatedAt: conv.updatedAt || new Date().toISOString(),
          documentIds: conv.documentIds || [],
          messageCount: conv.messageCount || 0
        })),
        total,
        page,
        pageSize
      };
    } catch (error) {
      console.error('Error listing conversations:', error);
      return {
        items: [],
        total: 0,
        page,
        pageSize
      };
    }
  },
  
  /**
   * Get conversation history
   */
  async getConversationHistory(sessionId: string, limit: number = 50): Promise<Message[]> {
    try {
      const response = await apiService.get<any[]>(
        `/conversation/${sessionId}/history?limit=${limit}`
      );
      
      // Convert backend format to frontend format if necessary
      return response.map(msg => ({
        id: msg.id,
        sessionId: msg.sessionId || msg.session_id || msg.conversation_id || sessionId,
        timestamp: msg.timestamp || msg.created_at || new Date().toISOString(),
        role: msg.role,
        content: msg.content,
        referencedDocuments: msg.referencedDocuments || msg.referenced_documents || [],
        referencedAnalyses: msg.referencedAnalyses || msg.referenced_analyses || [],
        citations: msg.citations || []
      }));
    } catch (error) {
      console.error('Error getting conversation history:', error);
      return [];
    }
  },
  
  /**
   * Send a message to the AI assistant
   */
  async sendMessage(
    message: string, 
    sessionId: string, 
    documentIds: string[] = [], 
    citations: Citation[] = []
  ): Promise<Message> {
    try {
      console.log(`Sending message with document references: ${JSON.stringify(documentIds)}`);
      
      // Verify documents have processed financial data
      let documentDataMissing = false;
      
      if (documentIds.length > 0) {
        try {
          for (const docId of documentIds) {
            const docInfo = await apiService.get<any>(`/documents/${docId}`);
            console.log('Referenced document data:', docId, docInfo.extractedData);
            
            // Check if the document has actual financial data
            if (!docInfo.extractedData || 
                !docInfo.extractedData.financial_data || 
                Object.keys(docInfo.extractedData.financial_data || {}).length === 0) {
              documentDataMissing = true;
            }
          }
        } catch (err) {
          console.warn('Error checking document data:', err);
        }
      }
      
      // Create data payload for message
      const data = {
        session_id: sessionId,
        content: message,
        referenced_documents: documentIds,
        citation_links: citations.map(c => c.id)
      };
      
      // Send request 
      const response = await apiService.post<any>(
        `/conversation/${sessionId}/message`,
        data
      );
      
      console.log('AI response:', response);
      
      // Convert backend message to frontend format
      const frontendMessage: Message = {
        id: response.id,
        role: response.role,
        content: response.content,
        timestamp: response.timestamp || response.created_at || new Date().toISOString(),
        sessionId: response.sessionId || response.conversation_id || sessionId,
        referencedDocuments: response.referencedDocuments || response.referenced_documents || documentIds,
        referencedAnalyses: response.referencedAnalyses || response.referenced_analyses || [],
        citations: response.citations || []
      };
      
      // If we detected missing document data but the AI didn't mention it, append a note
      if (documentDataMissing && 
          !frontendMessage.content.includes("don't see any") && 
          !frontendMessage.content.toLowerCase().includes("missing") &&
          !frontendMessage.content.toLowerCase().includes("no financial data")) {
        frontendMessage.content += "\n\nâš ï¸ Note: The document appears to be processed but may not contain proper financial data. This could be due to incomplete extraction or an unsupported document format.";
      }
      
      return frontendMessage;
    } catch (error) {
      console.error('Error sending message:', error);
      
      const errorMessage = error instanceof Error ? error.message : String(error);
      
      // Provide more helpful error messages
      if (errorMessage.includes('404')) {
        throw new Error('Conversation endpoint not found. The backend API may not be properly configured.');
      }
      
      if (errorMessage.includes('500')) {
        throw new Error('The conversation service encountered an error. This might be due to issues with document data or server configuration.');
      }
      
      throw error;
    }
  },
  
  /**
   * Send a message to the AI assistant with streaming response
   */
  async sendMessageStreaming(
    message: string,
    sessionId: string,
    documentIds: string[] = [],
    citations: Citation[] = [],
    callbacks: {
      onChunk: (chunk: any) => void,
      onComplete: (message: Message) => void,
      onError: (error: Error) => void
    }
  ): Promise<void> {
    try {
      console.log(`Sending streaming message with document references: ${JSON.stringify(documentIds)}`);
      
      // Verify documents have processed financial data (same as in non-streaming version)
      let documentDataMissing = false;
      if (documentIds.length > 0) {
        try {
          for (const docId of documentIds) {
            const docInfo = await apiService.get<any>(`/documents/${docId}`);
            
            // Check if the document has actual financial data
            if (!docInfo.extractedData || 
                !docInfo.extractedData.financial_data || 
                Object.keys(docInfo.extractedData.financial_data || {}).length === 0) {
              documentDataMissing = true;
            }
          }
        } catch (err) {
          console.warn('Error checking document data:', err);
        }
      }
      
      // Create data payload for message
      const data = {
        session_id: sessionId,
        content: message,
        referenced_documents: documentIds,
        citation_links: citations.map(c => c.id),
        stream: true // Explicitly request streaming response
      };
      
      // Store partial content during streaming
      let accumulatedContent = '';
      let messageId: string = '';
      let messageCitations: any[] = [];
      
      // Use the streaming API
      await apiService.stream<any>(
        `/conversation/${sessionId}/message/stream`,
        data,
        // Handle each chunk
        (chunk) => {
          // Different backends might format chunks differently
          const content = chunk.content || chunk.delta || chunk.text || '';
          
          if (content) {
            accumulatedContent += content;
            callbacks.onChunk({
              content,
              full: accumulatedContent
            });
          }
          
          // Some LLM services might include citations in chunks
          if (chunk.citations && Array.isArray(chunk.citations)) {
            messageCitations = [...messageCitations, ...chunk.citations];
          }
          
          // Save message ID if provided
          if (chunk.id && !messageId) {
            messageId = chunk.id;
          }
        },
        // Handle complete message
        (fullResponse) => {
          // Create the final message object
          const frontendMessage: Message = {
            id: messageId || fullResponse.id || `msg-${Date.now()}`,
            role: 'assistant',
            content: accumulatedContent || fullResponse.content || '',
            timestamp: fullResponse.timestamp || fullResponse.created_at || new Date().toISOString(),
            sessionId: fullResponse.sessionId || fullResponse.conversation_id || sessionId,
            referencedDocuments: fullResponse.referencedDocuments || fullResponse.referenced_documents || documentIds,
            referencedAnalyses: fullResponse.referencedAnalyses || fullResponse.referenced_analyses || [],
            citations: messageCitations.length > 0 ? messageCitations : (fullResponse.citations || [])
          };
          
          // Add missing document data warning if needed
          if (documentDataMissing && 
              !frontendMessage.content.includes("don't see any") && 
              !frontendMessage.content.toLowerCase().includes("missing") &&
              !frontendMessage.content.toLowerCase().includes("no financial data")) {
            frontendMessage.content += "\n\nâš ï¸ Note: The document appears to be processed but may not contain proper financial data. This could be due to incomplete extraction or an unsupported document format.";
          }
          
          callbacks.onComplete(frontendMessage);
        },
        // Handle errors
        (error) => {
          console.error('Streaming error:', error);
          
          const errorMessage = error.message || String(error);
          
          // Provide more helpful error messages
          if (errorMessage.includes('404')) {
            callbacks.onError(new Error('Streaming endpoint not found. The backend API may not support streaming or may not be properly configured.'));
          } else if (errorMessage.includes('500')) {
            callbacks.onError(new Error('The conversation service encountered an error during streaming. This might be due to issues with document data or server configuration.'));
          } else {
            callbacks.onError(error);
          }
        }
      );
    } catch (error) {
      console.error('Error initializing message stream:', error);
      callbacks.onError(error instanceof Error ? error : new Error(String(error)));
    }
  },
  
  /**
   * Add a document to a conversation
   */
  async addDocumentToConversation(conversationId: string, documentId: string): Promise<void> {
    try {
      await apiService.post(
        `/conversation/${conversationId}/documents`,
        { document_id: documentId }
      );
    } catch (error) {
      console.error('Error adding document to conversation:', error);
      throw error;
    }
  },
  
  /**
   * Get comprehensive conversation analysis with multiple visualization blocks
   */
  async getConversationAnalysis(sessionId: string): Promise<ConversationAnalysisResponse> {
    try {
      const response = await apiService.get<ConversationAnalysisResponse>(
        `/conversation/${sessionId}/analysis`,
        ConversationAnalysisResponseSchema
      );
      return response;
    } catch (error) {
      console.error('Error getting conversation analysis:', error);
      
      // Return a default/empty response structure
      return {
        sessionId,
        insights: ['Unable to retrieve analysis for this conversation.'],
        visualizationBlocks: []
      };
    }
  },
  
  /**
   * Remove a document from a conversation
   */
  async removeDocumentFromConversation(conversationId: string, documentId: string): Promise<void> {
    try {
      await apiService.delete(
        `/conversation/${conversationId}/documents/${documentId}`
      );
    } catch (error) {
      console.error('Error removing document from conversation:', error);
      throw error;
    }
  },
  
  /**
   * Delete a conversation
   */
  async deleteConversation(conversationId: string): Promise<void> {
    try {
      await apiService.delete(`/conversation/${conversationId}`);
    } catch (error) {
      console.error('Error deleting conversation:', error);
      throw error;
    }
  },
  
  /**
   * Get document content recommendations based on a message
   */
  async getContentRecommendations(message: string, documentIds: string[] = []): Promise<any> {
    try {
      const response = await apiService.post<any>(
        '/conversation/recommendations',
        {
          content: message,
          document_ids: documentIds
        }
      );
      
      return response;
    } catch (error) {
      console.error('Error getting content recommendations:', error);
      return { recommendations: [] };
    }
  }
};
</file>
```

#### src/lib/api/documents\.ts
*Size: 20.7 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/lib/api/documents.ts">
import { ProcessedDocument, DocumentUploadResponse, Citation } from '@/types';
import { apiService } from './apiService';
import { 
  DocumentUploadResponseSchema, 
  ProcessedDocumentSchema,
  CitationSchema
} from '@/validation/schemas';

// API base URL - would be configured based on environment
const API_BASE_URL = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8000';

// Function to handle API errors - keeping for backwards compatibility
const handleApiError = (error: any): never => {
  console.error('API Error:', error);
  if (error.response && error.response.data && error.response.data.detail) {
    throw new Error(error.response.data.detail);
  }
  throw new Error('An error occurred while communicating with the server');
};

// Define response types for better type safety
interface DocumentCountResponse {
  count: number;
}

interface DocumentResponse extends ProcessedDocument {
  // Support snake_case backend format
  processing_status?: string;
  content_type?: string;
  extracted_data?: any;
  confidence_score?: number;
  error_message?: string;
}

interface DocumentUrlResponse {
  url: string;
}

interface FinancialDataCheckResponse {
  hasFinancialData: boolean;
  diagnosis: string;
}

interface FinancialDataVerifyResponse {
  success: boolean;
  message: string;
}

// API citation format (for request/response to/from backend)
interface ApiCitation {
  id?: string;
  text: string;
  document_id: string;
  highlight_id?: string;
  page: number;
  rects: any[];
  message_id?: string;
  analysis_id?: string;
}

// Store created blob URLs for later cleanup
const createdBlobUrls: string[] = [];

// Add a function to clean up blob URLs
export const cleanupBlobUrls = () => {
  createdBlobUrls.forEach(url => {
    try {
      URL.revokeObjectURL(url);
    } catch (e) {
      console.error('Error revoking URL:', e);
    }
  });
  createdBlobUrls.length = 0; // Clear the array
};

export const documentsApi = {
  /**
   * Upload a document to the server
   */
  async uploadDocument(file: File): Promise<ProcessedDocument> {
    try {
      console.log(`API Client - uploadDocument: Starting upload for file ${file.name}`);
      
      const formData = new FormData();
      formData.append("file", file);
      
      // Type assertion to resolve schema compatibility issue
      const data = await apiService.postFormData<DocumentUploadResponse>(
        `/api/documents/upload`,
        formData,
        DocumentUploadResponseSchema as any
      );
      
      console.log(`API Client - uploadDocument: Upload successful, document ID: ${data.document_id}`);
      
      // For now, return a placeholder ProcessedDocument until re-processing is complete
      return {
        metadata: {
          id: data.document_id,
          filename: data.filename,
          upload_timestamp: data.upload_timestamp,
          file_size: data.file_size,
          mime_type: data.mime_type,
          user_id: data.user_id,
          processing_status: data.status || 'processing'
        },
        content_type: data.content_type || 'unknown',
        extractedData: data.extracted_data || {},
        processingStatus: data.status || 'processing',
        filename: data.filename
      };
      
    } catch (error) {
      console.error('API Client - uploadDocument: Upload failed', error);
      throw error;
    }
  },
  
  /**
   * Lists all documents
   */
  async listDocuments(page: number = 1, pageSize: number = 10): Promise<any[]> {
    try {
      return await apiService.get(`/api/documents?page=${page}&page_size=${pageSize}`);
    } catch (error) {
      throw handleApiError(error);
    }
  },
  
  /**
   * Gets document count
   */
  async getDocumentCount(): Promise<number> {
    try {
      const response = await apiService.get<DocumentCountResponse>('/api/documents/count');
      return response.count;
    } catch (error) {
      throw handleApiError(error);
    }
  },
  
  /**
   * Checks if a document has valid financial data
   */
  async checkDocumentFinancialData(documentId: string): Promise<FinancialDataCheckResponse> {
    try {
      return await apiService.get<FinancialDataCheckResponse>(`/api/documents/${documentId}/check-financial-data`);
    } catch (error) {
      throw handleApiError(error);
    }
  },
  
  /**
   * Verify a document's financial data and optionally trigger re-extraction
   */
  async verifyDocumentFinancialData(documentId: string, retryExtraction: boolean = false): Promise<FinancialDataVerifyResponse> {
    try {
      // First check if document has financial data
      const checkResponse = await apiService.get<FinancialDataCheckResponse>(`/api/documents/${documentId}/check-financial-data`);
      
      // If check passes, return success
      if (checkResponse.hasFinancialData) {
        return {
          success: true,
          message: checkResponse.diagnosis || "Document content available for analysis"
        };
      }
      
      // If check fails and retry is enabled, try verification endpoint which will accept any content
      if (retryExtraction) {
        const verifyResponse = await apiService.post<FinancialDataVerifyResponse>(
          `/api/documents/${documentId}/verify-financial-data`,
          { retry_extraction: true }
        );
        return verifyResponse;
      }
      
      // Even if verification fails, we'll still allow using the document
      // This ensures users can still try to use documents that might not have
      // ideal structure but could still be useful
      return {
        success: true, // Force success to allow document use regardless of content
        message: "Document available for analysis (verification bypassed)"
      };
    } catch (error) {
      console.error("Error verifying document:", error);
      
      // Even if verification fails, we'll allow continuing with the document
      return {
        success: true, // Force success to allow document use
        message: "Document available for analysis (verification bypassed)"
      };
    }
  },
  
  /**
   * Uploads and verifies a document, ensuring it has valid financial data
   */
  async uploadAndVerifyDocument(
    file: File, 
    autoVerify: boolean = true
  ): Promise<ProcessedDocument> {
    try {
      // Step 1: Upload the document
      console.log('Uploading document...');
      const initialDocument = await this.uploadDocument(file);
      
      // Step 2: Poll for document processing completion
      console.log('Polling for document processing completion...');
      let document = initialDocument;
      let retries = 0;
      const maxRetries = 30; // 30 * 2 seconds = 1 minute max
      
      while (retries < maxRetries && document.processingStatus !== 'completed' && document.processingStatus !== 'failed') {
        await new Promise(resolve => setTimeout(resolve, 2000)); // Wait 2 seconds
        
        // Fetch the document's current state
        try {
          const response = await apiService.get<DocumentResponse>(`/api/documents/${document.metadata.id}`);
          
          // Update document with the latest data
          document = {
            ...document,
            processingStatus: response.processingStatus || response.processing_status || document.processingStatus,
            contentType: response.contentType || response.content_type || document.contentType,
            extractedData: response.extractedData || response.extracted_data || document.extractedData,
            periods: response.periods || document.periods,
            confidenceScore: response.confidenceScore || response.confidence_score || document.confidenceScore,
            errorMessage: response.errorMessage || response.error_message || document.errorMessage
          };
          
          console.log(`Document status after attempt ${retries + 1}: ${document.processingStatus}`);
          
          if (document.processingStatus === 'failed') {
            throw new Error(`Document processing failed: ${document.errorMessage || 'Unknown error'}`);
          }
        } catch (error) {
          console.error('Error polling document status:', error);
          // Continue trying even if an individual poll fails
        }
        
        retries++;
      }
      
      if (document.processingStatus !== 'completed') {
        throw new Error('Document processing timed out or failed');
      }
      
      // Step 3: If auto-verify is enabled, check and potentially enhance financial data
      if (autoVerify) {
        console.log('Verifying financial data...');
        try {
          const checkResult = await this.checkDocumentFinancialData(document.metadata.id);
          
          if (!checkResult.hasFinancialData) {
            console.log('Document needs financial data verification:', checkResult.diagnosis);
            
            // If financial data is missing or insufficient, try to verify and enhance it
            const verifyResult = await this.verifyDocumentFinancialData(document.metadata.id, true);
            console.log('Financial data verification result:', verifyResult);
            
            if (verifyResult.success) {
              // Re-fetch the document to get the enhanced data
              const response = await apiService.get<DocumentResponse>(`/api/documents/${document.metadata.id}`);
              
              document = {
                ...document,
                contentType: response.contentType || response.content_type || document.contentType,
                extractedData: response.extractedData || response.extracted_data || document.extractedData,
                periods: response.periods || document.periods,
                confidenceScore: response.confidenceScore || response.confidence_score || document.confidenceScore
              };
            }
          } else {
            console.log('Document has valid financial data');
          }
        } catch (error) {
          console.error('Error during financial data verification:', error);
          // Continue even if verification fails
        }
      }
      
      return document;
    } catch (error) {
      throw handleApiError(error);
    }
  },
  
  /**
   * Get a secure URL to access the document
   */
  async getDocumentUrl(documentId: string): Promise<string> {
    try {
      // Instead of using a sample PDF URL which causes CORS issues,
      // fetch the actual document content as binary data and create a blob URL
      
      // Fetch the document content as a blob
      const response = await fetch(`${API_BASE_URL}/api/documents/${documentId}/file`, {
        method: 'GET',
        headers: {
          'Accept': 'application/pdf',
        },
      });
      
      // Check if the endpoint exists and returns proper data
      if (!response.ok) {
        // If the /file endpoint doesn't exist, we'll try an alternative approach
        console.warn(`Document file endpoint returned ${response.status}, trying alternative approach`);
        
        // Alternative approach: Use the backend API to fetch the document directly
        // This assumes the backend serves the document content at this endpoint
        const documentResponse = await apiService.get(`/api/documents/${documentId}`, undefined, {
          maxAttempts: 1 // Only try once, don't retry
        });
        
        // If the document has raw_text, we can create a simple PDF from it
        if (documentResponse.raw_text || (documentResponse.extractedData && documentResponse.extractedData.raw_text)) {
          const text = documentResponse.raw_text || documentResponse.extractedData.raw_text;
          
          // Create a simple PDF from the text using a data URL
          // Note: This is a very basic approach for testing
          const pdfBlob = new Blob([text], { type: 'application/pdf' });
          const url = URL.createObjectURL(pdfBlob);
          createdBlobUrls.push(url);
          return url;
        }
        
        // If we get here, we couldn't fetch a proper document - show error
        throw new Error(`Could not retrieve document file. Backend returned ${response.status}`);
      }
      
      // Get the PDF data as a blob
      const blob = await response.blob();
      
      // Create a URL for the blob
      const url = URL.createObjectURL(blob);
      createdBlobUrls.push(url);
      return url;
    } catch (error) {
      console.error("Error creating document URL:", error);
      
      // Fallback to a simple text-based PDF for now
      // Create a small placeholder PDF with an error message
      const errorText = `Error loading document: ${error instanceof Error ? error.message : 'Unknown error'}`;
      const pdfBlob = new Blob([errorText], { type: 'application/pdf' });
      const url = URL.createObjectURL(pdfBlob);
      createdBlobUrls.push(url);
      return url;
    }
  },
  
  /**
   * Get all citations for a document
   */
  async getDocumentCitations(documentId: string): Promise<Citation[]> {
    try {
      const response = await apiService.get<ApiCitation[]>(`/api/documents/${documentId}/citations`);
      
      // Ensure the response is an array
      if (Array.isArray(response)) {
        // Validate each citation
        return response.map(citation => ({
          id: citation.id || '',
          text: citation.text,
          documentId: citation.document_id,
          highlightId: citation.highlight_id,
          page: citation.page,
          rects: citation.rects,
          messageId: citation.message_id,
          analysisId: citation.analysis_id
        }));
      }
      
      return [];
    } catch (error) {
      console.error('Error getting document citations:', error);
      throw handleApiError(error);
    }
  },
  
  /**
   * Create a new citation in a document
   */
  async createCitation(documentId: string, citation: Omit<Citation, 'id'>): Promise<Citation> {
    try {
      // Convert to snake_case for the API
      const apiCitation: ApiCitation = {
        text: citation.text,
        document_id: documentId,
        highlight_id: citation.highlightId,
        page: citation.page,
        rects: citation.rects,
        message_id: citation.messageId,
        analysis_id: citation.analysisId
      };
      
      const response = await apiService.post<ApiCitation>(`/api/documents/${documentId}/citations`, apiCitation);
      
      // Convert response back to camelCase
      return {
        id: response.id || '',
        text: response.text,
        documentId: response.document_id,
        highlightId: response.highlight_id,
        page: response.page,
        rects: response.rects,
        messageId: response.message_id,
        analysisId: response.analysis_id
      };
    } catch (error) {
      throw handleApiError(error);
    }
  },
  
  /**
   * Upload a document with progress tracking
   */
  async uploadDocumentWithProgress(
    file: File, 
    onProgress?: (progress: number) => void
  ): Promise<ProcessedDocument> {
    try {
      const formData = new FormData();
      formData.append('file', file);
      
      // Use the progress-enabled upload method - using type assertion for schema compatibility
      const data = await apiService.uploadWithProgress<DocumentUploadResponse>(
        '/api/documents/upload',
        formData,
        onProgress,
        DocumentUploadResponseSchema as any
      );
      
      // Return placeholder document with the ID
      return {
        metadata: {
          id: data.document_id,
          filename: data.filename,
          uploadTimestamp: new Date().toISOString(),
          fileSize: file.size,
          mimeType: file.type,
          userId: 'current-user',
        },
        contentType: 'other',
        extractionTimestamp: new Date().toISOString(),
        periods: [],
        extractedData: {},
        confidenceScore: 0,
        processingStatus: data.status,
        errorMessage: data.status === 'failed' ? data.message : undefined,
      };
    } catch (error) {
      throw handleApiError(error);
    }
  },
  
  /**
   * Uploads and verifies a document with progress tracking,
   * ensuring it has valid financial data
   */
  async uploadAndVerifyDocumentWithProgress(
    file: File, 
    onProgress?: (progress: number, stage: string) => void,
    autoVerify: boolean = true
  ): Promise<ProcessedDocument> {
    try {
      // Create wrapper for progress that includes the stage
      const uploadProgressWrapper = onProgress 
        ? (progress: number) => onProgress(progress * 0.4, 'Uploading file')
        : undefined;
      
      // Step 1: Upload the document (40% of total progress)
      console.log('Uploading document...');
      onProgress?.(0, 'Starting upload');
      const initialDocument = await this.uploadDocumentWithProgress(file, uploadProgressWrapper);
      
      // Step 2: Poll for document processing completion (40% of total progress)
      console.log('Polling for document processing completion...');
      onProgress?.(40, 'Processing document');
      
      let document = initialDocument;
      let retries = 0;
      const maxRetries = 30; // 30 * 2 seconds = 1 minute max
      
      while (retries < maxRetries && document.processingStatus !== 'completed' && document.processingStatus !== 'failed') {
        await new Promise(resolve => setTimeout(resolve, 2000)); // Wait 2 seconds
        
        // Update progress during polling
        if (onProgress) {
          const pollingProgress = 40 + Math.min(40, (retries / maxRetries) * 40);
          onProgress(pollingProgress, 'Processing document');
        }
        
        // Fetch the document's current state
        try {
          const response = await apiService.get<DocumentResponse>(`/api/documents/${document.metadata.id}`);
          
          // Update document with the latest data
          document = {
            ...document,
            processingStatus: response.processingStatus || response.processing_status || document.processingStatus,
            contentType: response.contentType || response.content_type || document.contentType,
            extractedData: response.extractedData || response.extracted_data || document.extractedData,
            periods: response.periods || document.periods,
            confidenceScore: response.confidenceScore || response.confidence_score || document.confidenceScore,
            errorMessage: response.errorMessage || response.error_message || document.errorMessage
          };
          
          console.log(`Document status after attempt ${retries + 1}: ${document.processingStatus}`);
          
          if (document.processingStatus === 'failed') {
            throw new Error(`Document processing failed: ${document.errorMessage || 'Unknown error'}`);
          }
        } catch (error) {
          console.error('Error polling document status:', error);
          // Continue trying even if an individual poll fails
        }
        
        retries++;
      }
      
      if (document.processingStatus !== 'completed') {
        throw new Error('Document processing timed out or failed');
      }
      
      // Step 3: If auto-verify is enabled, check and potentially enhance financial data (20% of total progress)
      if (autoVerify) {
        console.log('Verifying financial data...');
        onProgress?.(80, 'Verifying financial data');
        
        try {
          const checkResult = await this.checkDocumentFinancialData(document.metadata.id);
          
          if (!checkResult.hasFinancialData) {
            console.log('Document needs financial data verification:', checkResult.diagnosis);
            onProgress?.(85, 'Enhancing financial data');
            
            // If financial data is missing or insufficient, try to verify and enhance it
            const verifyResult = await this.verifyDocumentFinancialData(document.metadata.id, true);
            console.log('Financial data verification result:', verifyResult);
            
            if (verifyResult.success) {
              onProgress?.(90, 'Retrieving enhanced data');
              
              // Re-fetch the document to get the enhanced data
              const response = await apiService.get<DocumentResponse>(`/api/documents/${document.metadata.id}`);
              
              document = {
                ...document,
                contentType: response.contentType || response.content_type || document.contentType,
                extractedData: response.extractedData || response.extracted_data || document.extractedData,
                periods: response.periods || document.periods,
                confidenceScore: response.confidenceScore || response.confidence_score || document.confidenceScore
              };
            }
          } else {
            console.log('Document has valid financial data');
          }
        } catch (error) {
          console.error('Error during financial data verification:', error);
          // Continue even if verification fails
        }
      }
      
      // Complete the process
      onProgress?.(100, 'Document ready');
      return document;
    } catch (error) {
      throw handleApiError(error);
    }
  }
};
</file>
```

#### src/lib/api/index\.ts
*Size: 240 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/lib/api/index.ts">
/**
 * API Services Index
 * 
 * This file exports all API services for easy importing throughout the application.
 */

export * from './apiService';
export * from './documents';
export * from './conversations';
export * from './analysis';
</file>
```

#### src/lib/errors/ApiError\.ts
*Size: 3.0 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/lib/errors/ApiError.ts">
/**
 * Standard API error class that maps to backend error response structure
 */
export interface ValidationErrorDetail {
  loc: (string | number)[];
  msg: string;
  type: string;
}

export type ErrorDetail = string | ValidationErrorDetail[] | Record<string, any>;

export interface ApiErrorOptions {
  statusCode: number;
  detail: ErrorDetail;
  errorType?: string;
  originalError?: unknown;
}

export class ApiError extends Error {
  statusCode: number;
  detail: ErrorDetail;
  errorType: string;
  originalError?: unknown;

  constructor(options: ApiErrorOptions) {
    // Create a human-readable message from the error detail
    const message = ApiError.formatErrorMessage(options.detail);
    super(message);
    
    this.name = 'ApiError';
    this.statusCode = options.statusCode;
    this.detail = options.detail;
    this.errorType = options.errorType || ApiError.getDefaultErrorType(options.statusCode);
    this.originalError = options.originalError;
    
    // Preserve the stack trace in modern JS engines
    if (Error.captureStackTrace) {
      Error.captureStackTrace(this, ApiError);
    }
  }

  /**
   * Format error details into a human-readable string
   */
  private static formatErrorMessage(detail: ErrorDetail): string {
    if (typeof detail === 'string') {
      return detail;
    } else if (Array.isArray(detail)) {
      // Handle validation error details
      return detail.map(err => `${err.loc.join('.')}: ${err.msg}`).join(', ');
    } else {
      return JSON.stringify(detail);
    }
  }

  /**
   * Get a default error type based on HTTP status code
   */
  private static getDefaultErrorType(statusCode: number): string {
    const errorTypes: Record<number, string> = {
      400: 'bad_request',
      401: 'unauthorized',
      403: 'forbidden',
      404: 'not_found',
      409: 'conflict',
      422: 'validation_error',
      429: 'too_many_requests',
      500: 'server_error',
      503: 'service_unavailable'
    };
    
    return errorTypes[statusCode] || 'unknown_error';
  }

  /**
   * Check if this error is of a specific type
   */
  isType(errorType: string): boolean {
    return this.errorType === errorType;
  }

  /**
   * Check if this error is a validation error
   */
  isValidationError(): boolean {
    return this.isType('validation_error') || this.statusCode === 422;
  }

  /**
   * Check if this error is a "not found" error
   */
  isNotFoundError(): boolean {
    return this.isType('not_found') || this.statusCode === 404;
  }
  
  /**
   * Get validation errors as a simple object map for form handling
   * Returns an object with field paths as keys and error messages as values
   */
  getValidationErrorsMap(): Record<string, string> {
    if (!this.isValidationError() || !Array.isArray(this.detail)) {
      return {};
    }
    
    return (this.detail as ValidationErrorDetail[]).reduce((acc, error) => {
      // Create a field name from the location path
      const fieldName = error.loc.join('.');
      acc[fieldName] = error.msg;
      return acc;
    }, {} as Record<string, string>);
  }
}
</file>
```

#### src/lib/pdf/citationService\.ts
*Size: 2.8 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/lib/pdf/citationService.ts">
import { Citation } from '@/types';
import { IHighlight } from 'react-pdf-highlighter';

/**
 * Convert a Citation object to the IHighlight format used by react-pdf-highlighter
 */
export const convertCitationToHighlight = (citation: Citation): IHighlight => {
  return {
    id: citation.highlightId,
    content: {
      text: citation.text,
    },
    position: {
      boundingRect: citation.rects[0] || {
        x1: 0, y1: 0, x2: 0, y2: 0, width: 0, height: 0
      },
      rects: citation.rects,
      pageNumber: citation.page
    },
    comment: {
      text: citation.text,
      emoji: "ğŸ“"
    },
    isAICitation: true // Custom property to identify AI-generated citations
  };
};

/**
 * Convert an IHighlight object to a Citation format for API storage
 */
export const convertHighlightToCitation = (
  highlight: IHighlight, 
  documentId: string,
  messageId?: string,
  analysisId?: string
): Omit<Citation, 'id'> => {
  return {
    text: highlight.content.text || '',
    documentId,
    highlightId: highlight.id,
    page: highlight.position.pageNumber,
    rects: highlight.position.rects,
    messageId,
    analysisId
  };
};

/**
 * Group citations by page number for efficient rendering
 */
export const groupCitationsByPage = (citations: Citation[]): Record<number, Citation[]> => {
  return citations.reduce((grouped, citation) => {
    const page = citation.page;
    if (!grouped[page]) {
      grouped[page] = [];
    }
    
    grouped[page].push(citation);
    return grouped;
  }, {} as Record<number, Citation[]>);
};

/**
 * Find a citation in a given page by coordinates (for click handling)
 */
export const findCitationByCoordinates = (
  citations: Citation[], 
  page: number, 
  x: number, 
  y: number
): Citation | null => {
  const pageCitations = citations.filter(citation => citation.page === page);
  
  for (const citation of pageCitations) {
    for (const rect of citation.rects) {
      if (
        x >= rect.x1 && 
        x <= rect.x2 && 
        y >= rect.y1 && 
        y <= rect.y2
      ) {
        return citation;
      }
    }
  }
  
  return null;
};

/**
 * Filter citations by source (message or analysis)
 */
export const filterCitationsBySource = (
  citations: Citation[],
  sourceType: 'message' | 'analysis',
  sourceId?: string
): Citation[] => {
  if (sourceType === 'message') {
    return citations.filter(citation => 
      sourceId ? citation.messageId === sourceId : !!citation.messageId
    );
  } else {
    return citations.filter(citation => 
      sourceId ? citation.analysisId === sourceId : !!citation.analysisId
    );
  }
};

/**
 * Custom type declaration to augment the IHighlight interface
 * with our isAICitation property
 */
declare module 'react-pdf-highlighter' {
  interface IHighlight {
    isAICitation?: boolean;
  }
}
</file>
```

#### src/lib/utils\.ts
*Size: 1.1 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/lib/utils.ts">
import { type ClassValue, clsx } from "clsx"
import { twMerge } from "tailwind-merge"
 
/**
 * Merge multiple class names with Tailwind CSS support
 * This is a utility function used by shadcn components
 */
export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs))
}

export function formatDate(date: string | Date): string {
  const d = typeof date === 'string' ? new Date(date) : date
  return d.toLocaleDateString('en-US', {
    year: 'numeric',
    month: 'short',
    day: 'numeric',
  })
}

export function truncateText(text: string, maxLength: number = 60): string {
  if (text.length <= maxLength) return text
  return text.substring(0, maxLength) + '...'
}

export function generateUUID(): string {
  return crypto.randomUUID()
}

export function formatBytes(bytes: number, decimals: number = 2): string {
  if (bytes === 0) return '0 Bytes'
  
  const k = 1024
  const dm = decimals < 0 ? 0 : decimals
  const sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB']
  
  const i = Math.floor(Math.log(bytes) / Math.log(k))
  
  return parseFloat((bytes / Math.pow(k, i)).toFixed(dm)) + ' ' + sizes[i]
}
</file>
```

#### src/lib/validation/api\-validation\.ts
*Size: 1.5 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/lib/validation/api-validation.ts">
import { z } from 'zod';

/**
 * Validate a request object against a Zod schema
 * This is useful for validating data before sending to API endpoints
 */
export function validateRequest<T>(schema: z.ZodType<T>, data: unknown): T {
  try {
    return schema.parse(data);
  } catch (error) {
    if (error instanceof z.ZodError) {
      // Format error message for better debugging
      const formattedError = error.errors.map(err => 
        `${err.path.join('.')}: ${err.message}`
      ).join(', ');
      console.error(`Validation error: ${formattedError}`);
      throw new Error(`Request validation failed: ${formattedError}`);
    }
    throw error;
  }
}

/**
 * Safe parse: validates data against a Zod schema and returns the result without throwing
 */
export function safeValidateRequest<T>(schema: z.ZodType<T>, data: unknown): { 
  success: boolean; 
  data?: T; 
  error?: string 
} {
  try {
    const result = schema.safeParse(data);
    if (result.success) {
      return { success: true, data: result.data };
    } else {
      // Format error message for better debugging
      const formattedError = result.error.errors.map(err => 
        `${err.path.join('.')}: ${err.message}`
      ).join(', ');
      console.error(`Validation error: ${formattedError}`);
      return { success: false, error: formattedError };
    }
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    return { success: false, error: errorMessage };
  }
}
</file>
```

#### src/services/visualizationService\.ts
*Size: 3.1 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/services/visualizationService.ts">
/**
 * Service for fetching visualization data from the backend API
 */

import { VisualizationData, ChartData, TableData } from '@/types/visualization';

const API_BASE_URL = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8000';

/**
 * Fetch all visualizations for an analysis
 * @param analysisId The ID of the analysis to fetch visualizations for
 * @returns VisualizationData object containing charts and tables
 */
export async function fetchVisualizations(analysisId: string): Promise<VisualizationData> {
  try {
    const response = await fetch(`${API_BASE_URL}/api/analysis/${analysisId}/visualizations`);
    
    if (!response.ok) {
      throw new Error(`Error fetching visualizations: ${response.statusText}`);
    }
    
    const data = await response.json();
    return data as VisualizationData;
  } catch (error) {
    console.error('Error fetching visualizations:', error);
    throw error;
  }
}

/**
 * Fetch a specific chart by ID
 * @param chartId The ID of the chart to fetch
 * @returns ChartData object
 */
export async function fetchChart(chartId: string): Promise<ChartData> {
  try {
    const response = await fetch(`${API_BASE_URL}/api/charts/${chartId}`);
    
    if (!response.ok) {
      throw new Error(`Error fetching chart: ${response.statusText}`);
    }
    
    const data = await response.json();
    return data as ChartData;
  } catch (error) {
    console.error('Error fetching chart:', error);
    throw error;
  }
}

/**
 * Fetch a specific table by ID
 * @param tableId The ID of the table to fetch
 * @returns TableData object
 */
export async function fetchTable(tableId: string): Promise<TableData> {
  try {
    const response = await fetch(`${API_BASE_URL}/api/tables/${tableId}`);
    
    if (!response.ok) {
      throw new Error(`Error fetching table: ${response.statusText}`);
    }
    
    const data = await response.json();
    return data as TableData;
  } catch (error) {
    console.error('Error fetching table:', error);
    throw error;
  }
}

/**
 * Fetch financial metrics for an analysis
 * @param analysisId The ID of the analysis to fetch metrics for
 * @returns Array of financial metrics
 */
export async function fetchFinancialMetrics(analysisId: string) {
  try {
    const response = await fetch(`${API_BASE_URL}/api/analysis/${analysisId}/metrics`);
    
    if (!response.ok) {
      throw new Error(`Error fetching metrics: ${response.statusText}`);
    }
    
    const data = await response.json();
    return data.metrics;
  } catch (error) {
    console.error('Error fetching metrics:', error);
    throw error;
  }
}

/**
 * Fetch period data for comparative analysis
 * @param analysisId The ID of the analysis to fetch period data for
 * @returns Array of period data objects
 */
export async function fetchPeriodData(analysisId: string) {
  try {
    const response = await fetch(`${API_BASE_URL}/api/analysis/${analysisId}/periods`);
    
    if (!response.ok) {
      throw new Error(`Error fetching period data: ${response.statusText}`);
    }
    
    const data = await response.json();
    return data.periods;
  } catch (error) {
    console.error('Error fetching period data:', error);
    throw error;
  }
} 
</file>
```

#### src/types/enhanced\.ts
*Size: 2.3 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/types/enhanced.ts">
export interface FinancialInsight {
  id: string;
  metric: string;
  value: number;
  description: string;
  importance: 'high' | 'medium' | 'low';
  sentiment: 'positive' | 'negative' | 'neutral';
  citations?: Array<{
    highlightId: string;
    documentId: string;
    text: string;
  }>;
}

export interface TrendAnalysis {
  metric: string;
  periods: string[];
  values: number[];
  trendDirection: 'up' | 'down' | 'stable';
  growthRate?: number;
  citations?: Array<{
    highlightId: string;
    documentId: string;
    text: string;
  }>;
}

export interface EnhancedAnalysisResult {
  id: string;
  documentIds: string[];
  analysisType: string;
  timestamp: string;
  metrics: Array<{
    id: string;
    name: string;
    description: string;
    value: number;
    change: number;
    direction: 'increasing' | 'decreasing' | 'stable';
    significance: 'high' | 'medium' | 'low';
    category: string;
  }>;
  insights: Array<{
    id: string;
    text: string;
    category: 'critical' | 'important' | 'informational';
    relatedMetrics: string[];
    confidence: number;
  }>;
  trends: TrendAnalysis[];
  forecasts?: Array<{
    metric: string;
    periods: string[];
    values: number[];
    confidence: number;
  }>;
}

export interface VisualizationBlock {
  id?: string;
  type?: 'chart' | 'table' | 'metric' | 'insight' | 'comparison';
  title?: string;
  description?: string;
  data?: any;
  chartType?: 'bar' | 'line' | 'pie' | 'radar' | 'scatter' | 'area';
  sourceAnalysisId?: string;
  sourceDocumentIds?: string[];
}

export interface Citation {
  id?: string;
  text?: string;
  documentId?: string;
  highlightId?: string;
  page?: number;
  rects?: Array<{
    x1?: number;
    y1?: number;
    x2?: number;
    y2?: number;
    width?: number;
    height?: number;
  }>;
  position?: {
    pageNumber?: number;
    boundingRect?: {
      x1?: number;
      y1?: number;
      x2?: number;
      y2?: number;
      width?: number;
      height?: number;
    };
  };
  messageId?: string;
  analysisId?: string;
}

export interface ConversationAnalysisResponse {
  id?: string;
  conversationId?: string;
  sessionId?: string;
  timestamp?: string;
  summary?: string;
  keyInsights?: string[];
  insights?: string[];
  visualizationBlocks?: VisualizationBlock[];
  relatedDocuments?: string[];
  citations?: Citation[];
}
</file>
```

#### src/types/index\.ts
*Size: 2.7 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/types/index.ts">
export interface DocumentMetadata {
  id: string;
  filename: string;
  uploadTimestamp: string;
  fileSize: number;
  mimeType: string;
  userId: string;
  citationLinks?: string[];
}

export interface ProcessedDocument {
  metadata: DocumentMetadata;
  contentType: 'balance_sheet' | 'income_statement' | 'cash_flow' | 'notes' | 'other';
  extractionTimestamp: string;
  periods: string[];
  extractedData: Record<string, any>;
  confidenceScore: number;
  processingStatus: 'pending' | 'processing' | 'completed' | 'failed';
  errorMessage?: string;
  citations?: Array<Citation>;
}

export interface DocumentUploadResponse {
  document_id: string;
  filename: string;
  status: 'pending' | 'processing' | 'completed' | 'failed';
  message: string;
}

export interface Citation {
  id: string;
  text: string;
  documentId: string;
  highlightId: string;
  page: number;
  rects: Array<{
    x1: number;
    y1: number;
    x2: number;
    y2: number;
    width: number;
    height: number;
  }>;
  messageId?: string;
  analysisId?: string;
}

export interface FinancialRatio {
  name: string;
  value: number;
  description: string;
  benchmark?: number;
  trend?: number;
}

export interface FinancialMetric {
  category: string;
  name: string;
  period: string;
  value: number;
  unit: string;
  isEstimated: boolean;
}

export interface Message {
  id: string;
  sessionId: string;
  timestamp: string;
  role: 'user' | 'assistant' | 'system';
  content: string;
  referencedDocuments: string[];
  referencedAnalyses: string[];
  citationLinks?: string[];
  citations?: Array<Citation>;
}

export interface ConversationState {
  sessionId: string;
  activeDocuments: string[];
  activeAnalyses: string[];
  currentFocus?: string;
  userPreferences: Record<string, any>;
  lastUpdated: string;
}

export interface AnalysisResult {
  id: string;
  documentIds: string[];
  analysisType: string;
  timestamp: string;
  analysisText?: string;
  visualizationData?: {
    charts: any[];
    tables: any[];
    monetaryValues?: any;
    percentages?: any;
    keywordFrequency?: any;
  };
  data: {
    metrics: FinancialMetric[];
    charts?: ChartData[];
    tables?: TableData[];
  };
  citationReferences?: Record<string, string>;
  query?: string;
}

export interface ClaudeCitation {
  type: string;
  cited_text: string;
  document_title: string;
  start_page_number?: number;
  end_page_number?: number;
  start_char_index?: number;
  end_char_index?: number;
  start_block_index?: number;
  end_block_index?: number;
}

export interface ConversationMetadata {
  id: string;
  title: string;
  createdAt: string;
  updatedAt: string;
  documentIds: string[];
  messageCount: number;
  session_id?: string; // For backward compatibility with backend response
}
</file>
```

#### src/types/visualization\.ts
*Size: 3.0 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/types/visualization.ts">
/**
 * TypeScript interfaces for visualization data
 * These interfaces match the backend Pydantic models
 */

// Supported chart types
export type ChartType = 'line' | 'bar' | 'area' | 'pie' | 'multiBar' | 'scatter';

// Supported table types
export type TableType = 'comparison' | 'summary' | 'detailed';

// Format types for table columns
export type FormatType = 'number' | 'currency' | 'percentage' | 'text';

// Direction for financial metrics trend
export type TrendDirection = 'up' | 'down' | 'neutral';

// Configuration for individual metrics in charts
export interface MetricConfig {
  label: string;
  unit?: string;
  color?: string;
  formatter?: string;
  precision?: number;
}

// Configuration for charts
export interface ChartConfig {
  title: string;
  description?: string;
  xAxisKey: string;
  yAxisKey?: string;
  [key: string]: any;
}

// Chart data item - used in tool-based visualization
export interface ChartDataItem {
  x: string | number;
  y: number;
  label?: string;
  category?: string;
  [key: string]: any;
}

// Chart data series - used in tool-based visualization
export interface ChartSeries {
  name: string;
  data: ChartDataItem[];
  color?: string;
}

// Chart data structure
export interface ChartData {
  chartType: ChartType;
  config: ChartConfig;
  data: any[] | ChartSeries[];  // Support both direct data array and series format
  chartConfig?: {
    [key: string]: {
      label: string;
      color?: string;
    };
  };
  // Added for tool-based visualization approach
  series?: ChartSeries[];
  xAxisTitle?: string;
  yAxisTitle?: string;
  legendPosition?: 'top' | 'right' | 'bottom' | 'left';
}

// Table column configuration
export interface TableColumn {
  key: string;
  header: string;
  label?: string;
  width?: number;
  align?: 'left' | 'center' | 'right';
  formatter?: string;
  format?: FormatType;
}

// Table configuration
export interface TableConfig {
  title: string;
  description?: string;
  columns: {
    key: string;
    label: string;
    format?: 'text' | 'number' | 'currency' | 'percentage' | 'date';
  }[];
}

// Table data structure
export interface TableData {
  tableType: TableType;
  config: TableConfig;
  data: any[];
}

// Combined visualization data that can contain both charts and tables
export interface VisualizationData {
  charts: ChartData[];
  tables: TableData[];
  metrics?: FinancialMetric[];
  // Legacy format fields - keep for backward compatibility
  monetaryValues?: any;
  percentages?: any;
  keywordFrequency?: any;
}

// Interface for financial metrics to be displayed in cards
export interface FinancialMetric {
  name: string;
  value: number;
  previousValue?: number;
  percentChange?: number;
  trend?: TrendDirection;
  unit?: string;
  category?: string;
  description?: string;
  highlight?: boolean;
}

export interface AnalysisResult {
  id: string;
  type: 'financial' | 'market' | 'operational';
  data: {
    metrics: FinancialMetric[];
    charts?: ChartData[];
    tables?: TableData[];
  };
  timestamp: string;
} 
</file>
```

#### src/utils/formatters\.ts
*Size: 4.0 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/utils/formatters.ts">
/**
 * Utility functions for formatting values in charts and tables
 */

/**
 * Format a value according to the specified formatter and precision
 * @param value The numeric value to format
 * @param formatter The formatter to use (currency, percent, number, compact)
 * @param precision The number of decimal places to include
 * @returns Formatted string value
 */
export function formatValue(
  value: number,
  formatter?: string,
  precision: number = 2
): string {
  if (value === undefined || value === null) {
    return 'N/A';
  }

  // Use specified precision or default to 2
  const decimals = precision !== undefined ? precision : 2;

  switch (formatter) {
    case 'currency':
      return formatCurrency(value, decimals);
    case 'percent':
      return formatPercent(value, decimals);
    case 'compact':
      return formatCompact(value, decimals);
    case 'integer':
      return Math.round(value).toLocaleString();
    default:
      return Number(value.toFixed(decimals)).toLocaleString();
  }
}

/**
 * Format a value as currency (USD by default)
 * @param value The numeric value to format
 * @param decimals The number of decimal places to include
 * @param currency The currency code (default: USD)
 * @returns Formatted currency string
 */
export function formatCurrency(
  value: number,
  decimals: number = 2,
  currency: string = 'USD'
): string {
  return new Intl.NumberFormat('en-US', {
    style: 'currency',
    currency,
    minimumFractionDigits: decimals,
    maximumFractionDigits: decimals,
  }).format(value);
}

/**
 * Format a value as a percentage
 * @param value The numeric value to format (0.1 = 10%)
 * @param decimals The number of decimal places to include
 * @returns Formatted percentage string
 */
export function formatPercent(value: number, decimals: number = 2): string {
  return new Intl.NumberFormat('en-US', {
    style: 'percent',
    minimumFractionDigits: decimals,
    maximumFractionDigits: decimals,
  }).format(value);
}

/**
 * Format a value as a compact number (e.g., 1.2M, 5.3B)
 * @param value The numeric value to format
 * @param decimals The number of decimal places to include
 * @returns Formatted compact number string
 */
export function formatCompact(value: number, decimals: number = 1): string {
  return new Intl.NumberFormat('en-US', {
    notation: 'compact',
    compactDisplay: 'short',
    minimumFractionDigits: decimals,
    maximumFractionDigits: decimals,
  }).format(value);
}

/**
 * Format a value with the appropriate suffix (K, M, B, T)
 * @param value The numeric value to format
 * @param decimals The number of decimal places to include
 * @returns Formatted string with suffix
 */
export function formatWithSuffix(value: number, decimals: number = 2): string {
  if (value < 1000) {
    return value.toFixed(decimals);
  }
  
  const suffixes = ['', 'K', 'M', 'B', 'T'];
  const suffixIndex = Math.floor(Math.log10(Math.abs(value)) / 3);
  const scaledValue = value / Math.pow(10, suffixIndex * 3);
  
  return scaledValue.toFixed(decimals) + suffixes[suffixIndex];
}

/**
 * Format a change value with a plus or minus sign
 * @param value The numeric value to format
 * @param formatter The formatter to use
 * @param precision The number of decimal places to include
 * @returns Formatted string with sign
 */
export function formatChange(
  value: number,
  formatter?: string,
  precision: number = 2
): string {
  const prefix = value >= 0 ? '+' : '';
  return prefix + formatValue(value, formatter, precision);
}

/**
 * Determine the trend direction based on a value
 * @param value The numeric value to evaluate
 * @param isPositiveGood Whether a positive value is considered good (default: true)
 * @returns 'up' | 'down' | 'neutral'
 */
export function getTrend(
  value: number,
  isPositiveGood: boolean = true
): 'up' | 'down' | 'neutral' {
  if (value === 0) return 'neutral';
  
  const isPositive = value > 0;
  
  if (isPositiveGood) {
    return isPositive ? 'up' : 'down';
  } else {
    return isPositive ? 'down' : 'up';
  }
} 
</file>
```

#### src/validation/schemas\.ts
*Size: 8.8 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/validation/schemas.ts">
import { z } from 'zod';

// Document schema validations
export const DocumentMetadataSchema = z.object({
  id: z.string().uuid(),
  filename: z.string(),
  uploadTimestamp: z.string().datetime(),
  fileSize: z.number().int().positive(),
  mimeType: z.string(),
  userId: z.string(),
  citationLinks: z.array(z.string()).optional()
});

// Add the DocumentUploadResponseSchema to match the backend's response
export const DocumentUploadResponseSchema = z.object({
  document_id: z.string().uuid(),
  filename: z.string(),
  status: z.enum(['pending', 'processing', 'completed', 'failed']),
  message: z.string().optional()
});

export const ProcessedDocumentSchema = z.object({
  metadata: DocumentMetadataSchema,
  contentType: z.enum(['balance_sheet', 'income_statement', 'cash_flow', 'financial_report', 'notes', 'other']),
  extractionTimestamp: z.string().datetime(),
  periods: z.array(z.string()),
  extractedData: z.record(z.any()),
  confidenceScore: z.number().min(0).max(1),
  processingStatus: z.enum(['pending', 'processing', 'completed', 'failed']),
  errorMessage: z.string().optional()
});

// Financial data validations
export const FinancialRatioSchema = z.object({
  name: z.string(),
  value: z.number(),
  description: z.string(),
  benchmark: z.number().optional(),
  trend: z.number().optional()
});

export const FinancialMetricSchema = z.object({
  category: z.string(),
  name: z.string(),
  period: z.string(),
  value: z.number(),
  unit: z.string(),
  isEstimated: z.boolean().default(false)
});

// Citation schemas
export const CitationRectSchema = z.object({
  x1: z.number(),
  y1: z.number(),
  x2: z.number(),
  y2: z.number(),
  width: z.number(),
  height: z.number()
});

export const CitationSchema = z.object({
  id: z.string(),
  text: z.string(),
  documentId: z.string(),
  highlightId: z.string(),
  page: z.number().int().positive(),
  rects: z.array(CitationRectSchema),
  messageId: z.string().optional(),
  analysisId: z.string().optional()
});

// Message schema
export const MessageSchema = z.object({
  id: z.string(),
  sessionId: z.string().optional(),
  conversationId: z.string().optional(),
  timestamp: z.string().datetime().optional(),
  createdAt: z.string().datetime().optional(),
  role: z.enum(['user', 'assistant', 'system']),
  content: z.string(),
  referencedDocuments: z.array(z.string()).optional().default([]),
  referencedAnalyses: z.array(z.string()).optional().default([]),
  citations: z.array(CitationSchema).optional().default([]),
  contentBlocks: z.any().optional()
});

// Message Request Schema - Used when sending messages to the API
export const MessageRequestSchema = z.object({
  sessionId: z.string(),
  content: z.string(),
  userId: z.string().default('default-user').optional(),
  documentIds: z.array(z.string()).optional().default([]),
  referencedDocuments: z.array(z.string()).optional().default([]),
  referencedAnalyses: z.array(z.string()).optional().default([]),
  citationLinks: z.array(z.string()).optional().default([]),
  citationIds: z.array(z.string()).optional().default([])
});

// Conversation Create Request Schema - Used when creating new conversations
export const ConversationCreateRequestSchema = z.object({
  title: z.string(),
  userId: z.string().default('default-user').optional(),
  documentIds: z.array(z.string()).optional().default([]),
  metadata: z.record(z.any()).optional()
});

// Backend Message Schema (snake_case)
export const BackendMessageSchema = z.object({
  id: z.string(),
  session_id: z.string().optional(),
  conversation_id: z.string().optional(),
  timestamp: z.string().optional(),
  created_at: z.string().optional(),
  role: z.enum(['user', 'assistant', 'system']),
  content: z.string(),
  referenced_documents: z.array(z.string()).optional().default([]),
  referenced_analyses: z.array(z.string()).optional().default([]),
  citation_links: z.array(z.string()).optional().default([]),
  citations: z.array(CitationSchema).optional().default([]),
  content_blocks: z.any().optional()
});

// Financial insight schemas
export const FinancialInsightSchema = z.object({
  id: z.string(),
  category: z.string(),
  title: z.string(),
  description: z.string(),
  severity: z.enum(['low', 'medium', 'high']),
  relatedMetrics: z.array(z.string()),
  recommendations: z.array(z.string()).optional(),
  citationReferences: z.array(z.string()).optional()
});

export const TrendAnalysisSchema = z.object({
  metricName: z.string(),
  direction: z.enum(['increasing', 'decreasing', 'stable']),
  percentChange: z.number(),
  periods: z.array(z.string()),
  values: z.array(z.number()),
  significance: z.enum(['low', 'medium', 'high'])
});

export const AnalysisBlockSchema = z.object({
  id: z.string(),
  type: z.enum(['text', 'chart', 'table', 'insight']),
  content: z.string(),
  chartData: z.record(z.any()).optional(),
  insightId: z.string().optional(),
  tableData: z.array(z.record(z.any())).optional()
});

export const AnalysisResultSchema = z.object({
  id: z.string().refine(
    (val) => {
      // Accept both direct UUIDs and prefixed IDs (analysis-uuid, local-uuid)
      const uuidPattern = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;
      const prefixedPattern = /^(analysis-|local-)[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;
      return uuidPattern.test(val) || prefixedPattern.test(val);
    },
    { message: "ID must be a valid UUID or a prefixed UUID (analysis-uuid, local-uuid)" }
  ),
  documentIds: z.array(z.string().refine(
    (val) => {
      // Accept both direct UUIDs and prefixed IDs (document-, local-)
      const uuidPattern = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;
      const prefixedPattern = /^(document-|local-)[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;
      return uuidPattern.test(val) || prefixedPattern.test(val);
    },
    { message: "Document ID must be a valid UUID or a prefixed UUID" }
  )),
  analysisType: z.string(),
  timestamp: z.string().refine(
    (val) => {
      // Accept ISO datetime strings with flexible formats
      try {
        return !isNaN(new Date(val).getTime());
      } catch (e) {
        return false;
      }
    },
    { message: "Timestamp must be a valid date string" }
  ),
  metrics: z.array(FinancialMetricSchema),
  ratios: z.array(FinancialRatioSchema),
  insights: z.array(z.string()),
  visualizationData: z.record(z.any()),
  citationReferences: z.record(z.any()).optional()
});

export const EnhancedAnalysisResultSchema = AnalysisResultSchema.extend({
  insights: z.array(FinancialInsightSchema),
  trends: z.array(TrendAnalysisSchema),
  anomalies: z.array(
    z.object({
      metric: z.string(),
      expectedValue: z.number(),
      actualValue: z.number(),
      deviation: z.number(),
      explanation: z.string()
    })
  )
});

export const ConversationAnalysisResponseSchema = z.object({
  id: z.string(),
  conversationId: z.string(),
  timestamp: z.string().refine(
    (val) => {
      // Accept ISO datetime strings with flexible formats
      try {
        return !isNaN(new Date(val).getTime());
      } catch (e) {
        return false;
      }
    },
    { message: "Timestamp must be a valid date string" }
  ),
  summary: z.string(),
  keyInsights: z.array(z.string()),
  visualizationBlocks: z.array(
    z.object({
      id: z.string(),
      type: z.enum(['chart', 'table', 'metric', 'insight', 'comparison']),
      title: z.string(),
      description: z.string().optional(),
      data: z.any(),
      chartType: z.enum(['bar', 'line', 'pie', 'radar', 'scatter', 'area']).optional(),
      sourceAnalysisId: z.string().optional(),
      sourceDocumentIds: z.array(z.string()).optional()
    })
  ),
  relatedDocuments: z.array(z.string()),
  citations: z.array(CitationSchema)
});

// Type inference from Zod schemas
export type DocumentMetadata = z.infer<typeof DocumentMetadataSchema>;
export type ProcessedDocument = z.infer<typeof ProcessedDocumentSchema>;
export type FinancialRatio = z.infer<typeof FinancialRatioSchema>;
export type FinancialMetric = z.infer<typeof FinancialMetricSchema>;
export type AnalysisResult = z.infer<typeof AnalysisResultSchema>;
export type Citation = z.infer<typeof CitationSchema>;
export type Message = z.infer<typeof MessageSchema>;
export type FinancialInsight = z.infer<typeof FinancialInsightSchema>;
export type TrendAnalysis = z.infer<typeof TrendAnalysisSchema>;
export type AnalysisBlock = z.infer<typeof AnalysisBlockSchema>;
export type ConversationAnalysisResponse = z.infer<typeof ConversationAnalysisResponseSchema>;
export type EnhancedAnalysisResult = z.infer<typeof EnhancedAnalysisResultSchema>;

// Add the DocumentUploadResponse type
export type DocumentUploadResponse = z.infer<typeof DocumentUploadResponseSchema>;

// Add the MessageRequest type
export type MessageRequest = z.infer<typeof MessageRequestSchema>;

// Add the ConversationCreateRequest type
export type ConversationCreateRequest = z.infer<typeof ConversationCreateRequestSchema>;
</file>
```

#### src/validation/validate\.ts
*Size: 1.2 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/src/validation/validate.ts">
import { z } from 'zod';

/**
 * Validates data against a schema and returns the validated data or throws an error
 */
export function validate<T>(schema: z.ZodType<T>, data: unknown): T {
  const result = schema.safeParse(data);
  if (!result.success) {
    const errorMessage = result.error.errors.map(
      (err) => `${err.path.join('.')}: ${err.message}`
    ).join(', ');
    throw new Error(`Validation error: ${errorMessage}`);
  }
  return result.data;
}

/**
 * Safe parsing of data against a schema with detailed error info
 */
export function safeParse<T>(schema: z.ZodType<T>, data: unknown): { 
  success: boolean;
  data?: T;
  error?: string;
} {
  const result = schema.safeParse(data);
  if (!result.success) {
    const errorMessage = result.error.errors.map(
      (err) => `${err.path.join('.')}: ${err.message}`
    ).join(', ');
    return {
      success: false,
      error: errorMessage
    };
  }
  return {
    success: true,
    data: result.data
  };
}

/**
 * Validates array data against a schema and returns the validated data or throws an error
 */
export function validateArray<T>(schema: z.ZodType<T>, data: unknown[]): T[] {
  return data.map(item => validate(schema, item));
}
</file>
```

#### tailwind\.config\.js
*Size: 2.1 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/tailwind.config.js">
/** @type {import('tailwindcss').Config} */
module.exports = {
  darkMode: ["class"],
  content: [
    './src/pages/**/*.{js,ts,jsx,tsx,mdx}',
    './src/components/**/*.{js,ts,jsx,tsx,mdx}',
    './src/app/**/*.{js,ts,jsx,tsx,mdx}',
  ],
  theme: {
    container: {
      center: true,
      padding: "2rem",
      screens: {
        "2xl": "1400px",
      },
    },
    extend: {
      colors: {
        border: "hsl(var(--border))",
        input: "hsl(var(--input))",
        ring: "hsl(var(--ring))",
        background: "hsl(var(--background))",
        foreground: "hsl(var(--foreground))",
        primary: {
          DEFAULT: "hsl(var(--primary))",
          foreground: "hsl(var(--primary-foreground))",
        },
        secondary: {
          DEFAULT: "hsl(var(--secondary))",
          foreground: "hsl(var(--secondary-foreground))",
        },
        destructive: {
          DEFAULT: "hsl(var(--destructive))",
          foreground: "hsl(var(--destructive-foreground))",
        },
        muted: {
          DEFAULT: "hsl(var(--muted))",
          foreground: "hsl(var(--muted-foreground))",
        },
        accent: {
          DEFAULT: "hsl(var(--accent))",
          foreground: "hsl(var(--accent-foreground))",
        },
        popover: {
          DEFAULT: "hsl(var(--popover))",
          foreground: "hsl(var(--popover-foreground))",
        },
        card: {
          DEFAULT: "hsl(var(--card))",
          foreground: "hsl(var(--card-foreground))",
        },
      },
      borderRadius: {
        lg: "var(--radius)",
        md: "calc(var(--radius) - 2px)",
        sm: "calc(var(--radius) - 4px)",
      },
      keyframes: {
        "accordion-down": {
          from: { height: 0 },
          to: { height: "var(--radix-accordion-content-height)" },
        },
        "accordion-up": {
          from: { height: "var(--radix-accordion-content-height)" },
          to: { height: 0 },
        },
      },
      animation: {
        "accordion-down": "accordion-down 0.2s ease-out",
        "accordion-up": "accordion-up 0.2s ease-out",
      },
    },
  },
  plugins: [require("tailwindcss-animate")],
}
</file>
```

#### tsconfig\.json
*Size: 648 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/nextjs-fdas/tsconfig.json">
{
  "compilerOptions": {
    "lib": [
      "dom",
      "dom.iterable",
      "esnext"
    ],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": false,
    "noEmit": true,
    "incremental": true,
    "module": "esnext",
    "esModuleInterop": true,
    "moduleResolution": "node",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "plugins": [
      {
        "name": "next"
      }
    ]
  },
  "include": [
    "next-env.d.ts",
    ".next/types/**/*.ts",
    "**/*.ts",
    "**/*.tsx"
  ],
  "exclude": [
    "node_modules"
  ]
}
</file>
```

## Directory: backend
**Path**: /Users/alexc/Documents/AlexCoding/cfin/backend
### File Tree
```
âš ï¸ .coverage [excluded]
âš ï¸ .env [excluded]
ğŸ“„ README.md
âš ï¸ __init__.py [excluded]
ğŸ“ api/
  ğŸ“„ conversation.py
  ğŸ“„ router.py
ğŸ“ app/
  ğŸ“„ __init__.py
  ğŸ“„ main.py
  ğŸ“ routes/
    ğŸ“„ __init__.py
    ğŸ“„ analysis.py
    ğŸ“„ conversation.py
    ğŸ“„ document.py
ğŸ“„ check_document_context.py
ğŸ“„ claude_test.sh
ğŸ“„ create_db.py
ğŸ“„ curl_test.sh
ğŸ“ data/
  ğŸ“ templates/
    ğŸ“„ balance_sheet_template.md
    ğŸ“„ cash_flow_template.md
    ğŸ“„ income_statement_template.md
    ğŸ“„ template_loader.py
ğŸ“„ debug_server.py
âš ï¸ fdas.db [excluded]
ğŸ“„ main.py
ğŸ“ models/
  ğŸ“„ __init__.py
  ğŸ“„ analysis.py
  ğŸ“„ api_models.py
  ğŸ“„ citation.py
  ğŸ“„ database_models.py
  ğŸ“„ document.py
  ğŸ“„ error.py
  ğŸ“„ message.py
  ğŸ“„ tools.py
  ğŸ“„ visualization.py
ğŸ“ pdf_processing/
  ğŸ“„ __init__.py
  ğŸ“„ claude_service.py
  ğŸ“„ document_service.py
  ğŸ“„ enhanced_pdf_service.py
  ğŸ“„ financial_agent.py
  ğŸ“„ langchain_service.py
  ğŸ“„ langgraph_service.py
ğŸ“„ pytest.ini
ğŸ“ repositories/
  ğŸ“„ __init__.py
  ğŸ“„ analysis_repository.py
  ğŸ“„ conversation_repository.py
  ğŸ“„ document_repository.py
ğŸ“„ requirements.txt
ğŸ“„ restart_server.sh
ğŸ“„ run.py
ğŸ“„ run_server.py
âš ï¸ run_tests.sh [excluded]
âš ï¸ run_visibility_tests.py [excluded]
âš ï¸ sample_financial_report.pdf [excluded]
âš ï¸ server.log [excluded]
ğŸ“ services/
  ğŸ“„ __init__.py
  ğŸ“„ analysis_service.py
  ğŸ“„ conversation_service.py
ğŸ“„ test_api.sh
ğŸ“„ test_citations_with_pdf.py
ğŸ“„ test_claude_api.py
ğŸ“„ test_document_api.py
ğŸ“„ test_document_api_only.sh
ğŸ“„ test_document_endpoints.sh
ğŸ“„ test_document_persistence.sh
ğŸ“„ test_document_upload.py
ğŸ“„ test_document_visibility.py
ğŸ“„ test_imports.py
ğŸ“„ test_langgraph_with_pdf.py
ğŸ“„ test_pdf_visibility_fix.py
ğŸ“ utils/
  ğŸ“„ __init__.py
  ğŸ“„ database.py
  ğŸ“„ db_verification.py
  ğŸ“„ dependencies.py
  ğŸ“„ error_handling.py
  ğŸ“„ init_db.py
  ğŸ“„ message_converters.py
  ğŸ“„ response.py
  ğŸ“„ storage.py
```
### File Contents
#### README\.md
*Size: 3.4 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/README.md">
# FDAS (Financial Document Analysis System) Backend

This is the backend server for the Financial Document Analysis System, providing API endpoints for document upload, processing, and analysis using Claude API's native PDF capabilities, LangChain, and LangGraph.

## Features

- Direct PDF document processing via Claude API (no preprocessing required)
- Native citation extraction and linking
- Automatic financial data recognition and extraction
- Support for complex financial document structures
- Fallback OCR processing (only if needed)
- Conversation management with document context
- Financial analysis and visualization

## Requirements

- Python 3.9+
- FastAPI
- SQLAlchemy
- Anthropic Claude API access (claude-3-sonnet-latest or higher)
- LangChain and LangGraph

## Setup

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

### 2. Configure environment variables

Create a `.env` file in the backend directory with the following variables:

```
# API Keys
ANTHROPIC_API_KEY=your_anthropic_api_key_here
CLAUDE_MODEL=claude-3-sonnet-latest

# Database Configuration
DATABASE_URL=sqlite:///./fdas.db  # For development; use PostgreSQL in production

# Storage Configuration
UPLOAD_DIR=./uploads
STORAGE_TYPE=local  # Options: local, s3

# Server Configuration
PORT=8000
HOST=0.0.0.0
DEBUG=True
```

### 3. Run the server

```bash
python run.py
```

The server will start on `http://localhost:8000` by default.

## API Endpoints

### Documents

- `POST /api/documents/upload` - Upload a financial document
- `GET /api/documents/{document_id}` - Get document details
- `GET /api/documents` - List user documents
- `GET /api/documents/{document_id}/citations` - Get document citations
- `GET /api/documents/{document_id}/citations/{citation_id}` - Get citation details
- `DELETE /api/documents/{document_id}` - Delete a document

### Conversation

- `POST /api/conversation/message` - Send a message
- `GET /api/conversation/{conversation_id}` - Get conversation history
- `POST /api/conversation/create` - Create a new conversation
- `GET /api/conversation` - List user conversations

### Analysis

- `POST /api/analysis/run` - Run analysis on a document
- `GET /api/analysis/{analysis_id}` - Get analysis results

## Architecture

The backend is built with the following components:

1. **FastAPI Application** - Provides RESTful API endpoints and handles requests
2. **Document Service** - Manages document upload, storage, and processing
3. **Claude Service** - Interacts with Claude API for document analysis
4. **LangChain/LangGraph Service** - Orchestrates AI workflows and enhances document processing
5. **Database Models** - SQLAlchemy ORM models for persistent data storage
6. **Storage Service** - Manages file storage (local filesystem or S3)

## Development

### Database Migrations

The application uses SQLAlchemy for database management. If you need to make changes to the database schema:

1. Update the models in `models/database_models.py`
2. Run database initialization:

```bash
python -c "from utils.init_db import run_init_db; run_init_db()"
```

### Testing

Run tests with pytest:

```bash
pytest
```

## Production Deployment

For production deployment:

1. Use a production-grade database (PostgreSQL recommended)
2. Set up proper authentication (OAuth, API keys)
3. Configure CORS for your specific frontend domain
4. Use HTTPS for secure communication
5. Consider Docker containerization for easier deployment
</file>
```

#### api/conversation\.py
*Size: 22.3 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/api/conversation.py">
from typing import Dict, List, Any
import logging
import uuid
from datetime import datetime
from models.citation import PageLocationCitation, CitationType
from fastapi import APIRouter, Depends, HTTPException, Path, Query, Body
from schemas.chat import (
    MessageRole,
    MessageRequest,
    MessageResponse,
    ConversationHistoryResponse,
)
from services.document_service import DocumentService, get_document_service
from pdf_processing.langgraph_service import LangGraphService, get_langgraph_service
from services.auth import get_current_user_id

router = APIRouter(tags=["conversation"])
logger = logging.getLogger(__name__)

# Mock services that don't exist yet
class DocumentService:
    def __init__(self, db=None):
        pass
    
    async def get_document(self, doc_id):
        # Mock implementation
        return {
            "metadata":{
                "id": doc_id,
                "filename": f"document_{doc_id}.pdf",
                "upload_timestamp": "2023-01-01T00:00:00",
                "file_size": 1000,
                "mime_type": "application/pdf",
                "user_id": "test-user"
            },
            "content_type":"balance_sheet",
            "extraction_timestamp":"2023-01-01T00:00:01",
            "extracted_data":{"raw_text": f"Test content for document {doc_id}"}
        }

# Mock database session
class AsyncSession:
    pass

async def get_db():
    return AsyncSession()

# Mock authentication
async def get_current_user_id():
    return "test-user-id"

# Mock session service
async def get_session_service():
    class SessionService:
        async def get_sessions_for_user(self, user_id, limit, offset):
            return [
                type('obj', (object,), {
                    'id': 'test-conversation-id',
                    'title': 'Test Conversation',
                    'created_at': '2023-01-01T00:00:00',
                    'updated_at': '2023-01-01T00:00:01',
                    'documents': []
                })
            ]
        
        async def delete_session(self, session_id):
            return True
    
    return SessionService()

# Dependency for LangGraph service
async def get_langgraph_service():
    return LangGraphService()

# Dependency for Document service
async def get_document_service(db: AsyncSession = Depends(get_db)):
    return DocumentService(db)

@router.post("/conversation", response_model=Dict[str, Any])
async def create_conversation(
    request: MessageRequest,
    langgraph_service: LangGraphService = Depends(get_langgraph_service),
    current_user_id: str = Depends(get_current_user_id)
):
    """
    Create a new conversation session with LangGraph.
    
    Args:
        request: Conversation creation request with title and document IDs
        langgraph_service: LangGraph service dependency
        current_user_id: Current authenticated user ID
        
    Returns:
        Newly created conversation session details
    """
    try:
        # Generate a new conversation ID
        conversation_id = str(uuid.uuid4())
        
        # Initialize conversation in LangGraph
        conversation = await langgraph_service.initialize_conversation(
            conversation_id=conversation_id,
            user_id=current_user_id,
            document_ids=request.document_ids,
            conversation_title=request.title
        )
        
        return {
            "conversation_id": conversation_id,
            "title": request.title or f"Conversation {conversation_id[:8]}",
            "created_at": conversation.get("state", {}).get("context", {}).get("created_at", ""),
            "status": "created"
        }
    except Exception as e:
        logger.exception(f"Error creating conversation: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to create conversation: {str(e)}")

@router.post("/conversation/{conversation_id}/documents", response_model=Dict[str, Any])
async def add_documents_to_conversation(
    conversation_id: str,
    document_ids: List[str],
    langgraph_service: LangGraphService = Depends(get_langgraph_service),
    document_service: DocumentService = Depends(get_document_service),
    current_user_id: str = Depends(get_current_user_id)
):
    """
    Add documents to a conversation.
    
    Args:
        conversation_id: ID of the conversation
        document_ids: List of document IDs to add
        langgraph_service: LangGraph service dependency
        document_service: Document service dependency
        current_user_id: Current authenticated user ID
        
    Returns:
        Status of document addition
    """
    try:
        valid_documents = []
        invalid_documents = []
        
        # Verify each document exists and belongs to the user
        for doc_id in document_ids:
            doc = await document_service.get_document(doc_id)
            if doc:
                valid_documents.append(doc)
            else:
                invalid_documents.append(doc_id)
        
        # If no valid documents were found, return an error
        if not valid_documents and document_ids:
            raise HTTPException(
                status_code=404, 
                detail=f"No valid documents found from the provided IDs: {document_ids}"
            )
        
        # Build ProcessedDocument objects from the document metadata
        documents = []
        for doc in valid_documents:
            # The mock document return value is already a dict.
            # In a real implementation, we might need to convert from 
            # a database model to a ProcessedDocument
            documents.append(doc)
        
        # Add documents to the conversation
        await langgraph_service.add_documents_to_conversation(
            conversation_id=conversation_id,
            documents=documents
        )
        
        # Format the response to match test expectations
        return {
            "conversation_id": conversation_id,
            "documents_added": len(valid_documents),
            "document_ids": [doc_id for doc_id in document_ids if doc_id not in invalid_documents],
            "invalid_documents": invalid_documents,
            "status": "documents_added"
        }
    except HTTPException as e:
        # Re-raise HTTP exceptions so they maintain their status code
        raise e
    except ValueError as e:
        error_msg = str(e).lower()
        if "not found" in error_msg or "does not exist" in error_msg:
            logger.error(f"Conversation not found: {e}")
            raise HTTPException(status_code=404, detail=f"Conversation not found: {conversation_id}")
        logger.error(f"ValueError adding documents: {e}")
        raise HTTPException(status_code=400, detail=f"Error adding documents: {str(e)}")
    except Exception as e:
        logger.exception(f"Error adding documents: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to add documents: {str(e)}")

@router.post("/conversation/{conversation_id}/document/{document_id}", response_model=Dict[str, Any])
async def add_document_to_conversation(
    conversation_id: str,
    document_id: str,
    langgraph_service: LangGraphService = Depends(get_langgraph_service),
    document_service: DocumentService = Depends(get_document_service),
    current_user_id: str = Depends(get_current_user_id)
):
    """
    Add a single document to a conversation.
    
    Args:
        conversation_id: ID of the conversation
        document_id: ID of the document to add
        langgraph_service: LangGraph service dependency
        document_service: Document service dependency
        current_user_id: Current authenticated user ID
        
    Returns:
        Status of document addition
    """
    try:
        # Verify document exists and belongs to the user
        doc = await document_service.get_document(document_id)
        if not doc:
            raise HTTPException(
                status_code=404, 
                detail=f"Document not found: {document_id}"
            )
        
        # Add document to the conversation
        result = await langgraph_service.add_document_to_conversation(
            conversation_id=conversation_id,
            document_id=document_id
        )
        
        if not result:
            # The conversation might not exist
            raise HTTPException(
                status_code=404,
                detail=f"Conversation not found: {conversation_id}"
            )
        
        # Format the response to match the multi-document endpoint
        return {
            "conversation_id": conversation_id,
            "documents_added": 1,
            "document_ids": [document_id],
            "invalid_documents": [],
            "status": "document_added"
        }
    except HTTPException as e:
        # Re-raise HTTP exceptions so they maintain their status code
        raise e
    except ValueError as e:
        error_msg = str(e).lower()
        if "not found" in error_msg or "does not exist" in error_msg:
            logger.error(f"Conversation not found: {e}")
            raise HTTPException(status_code=404, detail=f"Conversation not found: {conversation_id}")
        logger.error(f"ValueError adding document: {e}")
        raise HTTPException(status_code=400, detail=f"Error adding document: {str(e)}")
    except Exception as e:
        logger.exception(f"Error adding document: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to add document: {str(e)}")

@router.post("/conversation/{conversation_id}/message", response_model=MessageResponse)
async def send_message(
    conversation_id: str,
    request: MessageRequest,
    langgraph_service: LangGraphService = Depends(get_langgraph_service),
    current_user_id: str = Depends(get_current_user_id)
):
    """
    Send a message to the conversation and get a response.
    
    Args:
        conversation_id: ID of the conversation
        request: Message request with content and optional document references
        langgraph_service: LangGraph service dependency
        current_user_id: Current authenticated user ID
        
    Returns:
        AI assistant response with any citations
    """
    try:
        # Ensure the conversation_id in the path matches the session_id in the request
        # This helps prevent inconsistencies in the API
        if request.session_id != conversation_id:
            request.session_id = conversation_id
        
        # Process the message through LangGraph
        response = await langgraph_service.process_message(
            conversation_id=conversation_id,
            message_content=request.content,
            cited_document_ids=request.referenced_documents
        )
        
        # Create proper Citation objects if needed
        citations = []
        if "citations" in response and response["citations"]:
            for citation in response["citations"]:
                # Create a document citation
                citations.append(PageLocationCitation(
                    type=CitationType.PAGE_LOCATION,
                    cited_text=citation.get("text", ""),
                    document_index=citation.get("document_index", 0),
                    document_title=citation.get("document_title", "Unknown"),
                    start_page_number=citation.get("page", 1),
                    # If end_page is provided, use it, otherwise use start_page + 1 for exclusive range
                    end_page_number=citation.get("end_page", citation.get("page", 1) + 1)
                ))
        
        # Format the message response
        message_response = MessageResponse(
            id=response.get("message_id", str(uuid.uuid4())),
            session_id=conversation_id,
            timestamp=datetime.now(),
            role=MessageRole.ASSISTANT,
            content=response.get("content", ""),
            citations=citations,
            referenced_documents=request.referenced_documents,
            referenced_analyses=request.referenced_analyses or []
        )
        
        return message_response
    except ValueError as e:
        # Check if this is actually a "not found" error
        error_msg = str(e).lower()
        if "not found" in error_msg or "does not exist" in error_msg:
            logger.error(f"Conversation not found: {e}")
            raise HTTPException(status_code=404, detail=f"Conversation not found: {conversation_id}")
        logger.error(f"ValueError in send_message: {e}")
        raise HTTPException(status_code=400, detail=f"Invalid request: {str(e)}")
    except Exception as e:
        logger.exception(f"Error sending message: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to process message: {str(e)}")

@router.get("/conversation/{conversation_id}/history", response_model=ConversationHistoryResponse)
async def get_conversation_history(
    conversation_id: str,
    limit: int = Query(50, ge=1, le=100),
    langgraph_service: LangGraphService = Depends(get_langgraph_service),
    current_user_id: str = Depends(get_current_user_id)
):
    """
    Get conversation history for a specific conversation.
    
    Args:
        conversation_id: ID of the conversation
        limit: Maximum number of messages to return
        langgraph_service: LangGraph service dependency
        current_user_id: Current authenticated user ID
        
    Returns:
        Conversation history with messages
    """
    try:
        # Get conversation history from LangGraph
        messages = await langgraph_service.get_conversation_history(
            conversation_id=conversation_id,
            limit=limit
        )
        
        # Convert messages to MessageResponse format
        formatted_messages = []
        for msg in messages:
            # Create proper Citation objects if needed
            citations = []
            if "citations" in msg and msg["citations"]:
                for citation in msg["citations"]:
                    # Create a document citation
                    citations.append(PageLocationCitation(
                        type=CitationType.PAGE_LOCATION,
                        cited_text=citation.get("text", ""),
                        document_index=citation.get("document_index", 0),
                        document_title=citation.get("document_title", "Unknown"),
                        start_page_number=citation.get("page", 1),
                        # If end_page is provided, use it, otherwise use start_page + 1 for exclusive range
                        end_page_number=citation.get("end_page", citation.get("page", 1) + 1)
                    ))
            
            # Parse the timestamp or use current time
            try:
                if isinstance(msg.get("timestamp"), str):
                    timestamp = datetime.fromisoformat(msg.get("timestamp"))
                else:
                    timestamp = datetime.now()
            except (ValueError, TypeError):
                timestamp = datetime.now()
            
            # Determine the role
            try:
                role = MessageRole(msg.get("role", "user"))
            except ValueError:
                role = MessageRole.USER
            
            # Create MessageResponse
            formatted_messages.append(MessageResponse(
                id=msg.get("id", str(uuid.uuid4())),
                session_id=conversation_id,
                timestamp=timestamp,
                role=role,
                content=msg.get("content", ""),
                citations=citations,
                referenced_documents=msg.get("referenced_documents", []),
                referenced_analyses=msg.get("referenced_analyses", [])
            ))
        
        # Format the response
        return ConversationHistoryResponse(
            session_id=conversation_id,
            messages=formatted_messages,
            has_more=len(messages) >= limit
        )
    except ValueError as e:
        error_msg = str(e).lower()
        if "not found" in error_msg or "does not exist" in error_msg:
            logger.error(f"Conversation not found: {e}")
            raise HTTPException(status_code=404, detail=f"Conversation not found: {conversation_id}")
        logger.error(f"ValueError in get_conversation_history: {e}")
        raise HTTPException(status_code=400, detail=f"Invalid request: {str(e)}")
    except Exception as e:
        logger.exception(f"Error getting conversation history: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to retrieve conversation history: {str(e)}")

@router.get("/conversations", response_model=List[Dict[str, Any]])
async def list_conversations(
    limit: int = Query(10, ge=1, le=50),
    offset: int = Query(0, ge=0),
    session_service = Depends(get_session_service),
    current_user_id: str = Depends(get_current_user_id)
):
    """
    List all conversations for the current user.
    
    Args:
        limit: Maximum number of conversations to return
        offset: Number of conversations to skip for pagination
        session_service: Session service dependency
        current_user_id: Current authenticated user ID
        
    Returns:
        List of conversation metadata
    """
    try:
        # Get conversations from database
        conversations = await session_service.get_sessions_for_user(
            user_id=current_user_id,
            limit=limit,
            offset=offset
        )
        
        # Format the response
        result = []
        for conv in conversations:
            result.append({
                "conversation_id": str(conv.id),
                "title": conv.title or f"Conversation {str(conv.id)[:8]}",
                "created_at": str(conv.created_at),
                "updated_at": str(conv.updated_at),
                "document_count": len(conv.documents) if hasattr(conv, "documents") else 0
            })
        
        return result
    except Exception as e:
        logger.exception(f"Error listing conversations: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to list conversations: {str(e)}")

@router.get("/conversation/{conversation_id}/debug", response_model=Dict[str, Any])
async def debug_conversation_state(
    conversation_id: str,
    langgraph_service: LangGraphService = Depends(get_langgraph_service),
    current_user_id: str = Depends(get_current_user_id)
):
    """
    Debug endpoint to inspect conversation state and document context.
    
    Args:
        conversation_id: ID of the conversation to debug
        langgraph_service: LangGraph service dependency
        current_user_id: Current authenticated user ID
        
    Returns:
        Detailed information about the conversation state and document context
    """
    try:
        # Get current state
        thread_id = f"conversation_{conversation_id}"
        config = langgraph_service.conversation_graph.get_config()
        state = langgraph_service.memory.load(thread_id, config.name)
        
        if not state:
            raise HTTPException(status_code=404, detail=f"Conversation {conversation_id} not found")
        
        # Prepare document context as it would be sent to Claude
        doc_context = langgraph_service._prepare_document_context(state)
        
        # Check what's in the messages
        formatted_messages = langgraph_service._format_messages(state)
        
        # Extract document content details
        documents_info = []
        for i, doc in enumerate(state.get("documents", [])):
            doc_info = {
                "position": i,
                "id": doc.get("id", "unknown"),
                "title": doc.get("title", f"Document {i+1}"),
                "document_type": doc.get("document_type", "unknown"),
                "has_raw_text": "raw_text" in doc,
                "raw_text_length": len(doc.get("raw_text", "")) if "raw_text" in doc else 0,
                "has_extracted_data": "extracted_data" in doc,
                "extracted_data_fields": list(doc.get("extracted_data", {}).keys()) if "extracted_data" in doc else [],
                "content_sample": (doc.get("raw_text", "")[:100] + "...") if doc.get("raw_text", "") else "No content"
            }
            documents_info.append(doc_info)
        
        # Check active document IDs
        active_documents = state.get("active_documents", [])
        
        # Check if document IDs in active_documents match those in documents
        document_ids = [doc.get("id") for doc in state.get("documents", [])]
        mismatched_ids = [doc_id for doc_id in active_documents if doc_id not in document_ids]
        
        return {
            "conversation_id": conversation_id,
            "state_summary": {
                "documents_count": len(state.get("documents", [])),
                "active_documents_count": len(active_documents),
                "messages_count": len(state.get("messages", [])),
                "has_document_context": bool(doc_context),
                "document_context_length": len(doc_context),
                "mismatched_document_ids": mismatched_ids
            },
            "documents": documents_info,
            "active_documents": active_documents,
            "document_context_sample": doc_context[:500] + "..." if len(doc_context) > 500 else doc_context,
            "message_count": len(formatted_messages),
            "message_types": [msg.__class__.__name__ for msg in formatted_messages]
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"Error debugging conversation state: {e}")
        raise HTTPException(status_code=500, detail=f"Error debugging conversation state: {str(e)}")

@router.delete("/conversation/{conversation_id}", response_model=Dict[str, Any])
async def delete_conversation(
    conversation_id: str,
    session_service = Depends(get_session_service),
    current_user_id: str = Depends(get_current_user_id)
):
    """
    Delete a conversation.
    
    Args:
        conversation_id: ID of the conversation to delete
        session_service: Session service dependency
        current_user_id: Current authenticated user ID
        
    Returns:
        Deletion status
    """
    try:
        # Delete conversation from database
        deleted = await session_service.delete_session(
            session_id=conversation_id
        )
        
        if not deleted:
            raise HTTPException(status_code=404, detail=f"Conversation not found: {conversation_id}")
        
        return {
            "conversation_id": conversation_id,
            "status": "deleted"
        }
    except Exception as e:
        logger.exception(f"Error deleting conversation: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to delete conversation: {str(e)}") 
</file>
```

#### api/router\.py
*Size: 798 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/api/router.py">
from fastapi import APIRouter

# Import only the modules that exist
# from api.document import router as document_router
# from api.chat import router as chat_router
# from api.auth import router as auth_router
# from api.analysis import router as analysis_router
from api.conversation import router as conversation_router

api_router = APIRouter()

# Include only the routers that exist
# api_router.include_router(auth_router, prefix="/auth", tags=["auth"])
# api_router.include_router(document_router, prefix="/documents", tags=["documents"])
# api_router.include_router(chat_router, prefix="/chat", tags=["chat"])
# api_router.include_router(analysis_router, prefix="/analysis", tags=["analysis"])
api_router.include_router(conversation_router, prefix="/conversations", tags=["conversations"]) 
</file>
```

#### app/\_\_init\_\_\.py
*Size: 78 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/app/__init__.py">
# This file is intentionally left empty to make the directory a Python package
</file>
```

#### app/main\.py
*Size: 7.6 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/app/main.py">
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.exceptions import RequestValidationError
from fastapi import HTTPException
import logging
import os
import sys
from dotenv import load_dotenv
from pathlib import Path
import uvicorn
from fastapi.responses import JSONResponse

from .routes import document, conversation, analysis
from utils.init_db import init_db
from utils.error_handling import http_exception_handler, validation_exception_handler, add_cors_headers
from utils.response import add_cors_headers as add_response_cors_headers

# Load environment variables from .env file in the project root
project_root = Path(__file__).resolve().parent.parent.parent
env_path = project_root / '.env'
if env_path.exists():
    load_dotenv(dotenv_path=env_path)
    logging.info(f"Loaded environment variables from {env_path}")
else:
    logging.warning(f".env file not found at {env_path}")

# Verify critical environment variables
claude_api_key = os.getenv("ANTHROPIC_API_KEY")
if not claude_api_key:
    logging.warning("ANTHROPIC_API_KEY not found in environment variables")
else:
    # Mask API key for logging (show first 8 chars and last 4)
    if len(claude_api_key) > 12:
        masked_key = f"{claude_api_key[:8]}...{claude_api_key[-4:]}"
    else:
        masked_key = "***masked***"
    logging.info(f"ANTHROPIC_API_KEY loaded: {masked_key}")

# Configure logging
logging.basicConfig(
    level=logging.INFO if os.getenv("DEBUG") != "True" else logging.DEBUG,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)

logger = logging.getLogger(__name__)

# Create the FastAPI app
app = FastAPI(
    title="Financial Document Analysis System API",
    description="API for analyzing financial documents with Claude API",
    version="0.1.0",
)

# Configure CORS
allowed_origins = os.getenv(
    "ALLOWED_ORIGINS", 
    "http://localhost:3000,http://localhost:3001,http://localhost:3002,http://localhost:3003,http://127.0.0.1:3000,http://127.0.0.1:3001,http://127.0.0.1:3002,http://127.0.0.1:3003"
).split(",")
logger.info(f"CORS: Allowing origins: {allowed_origins}")

# Add CORS middleware directly to the app
app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["Content-Type", "X-Total-Count"]
)

# Register exception handlers for standardized error responses
@app.exception_handler(RequestValidationError)
async def custom_validation_exception_handler(request: Request, exc: RequestValidationError):
    """Custom validation exception handler that adds CORS headers."""
    response = await validation_exception_handler(request, exc)
    return add_response_cors_headers(response)

@app.exception_handler(HTTPException)
async def custom_http_exception_handler(request: Request, exc: HTTPException):
    """Custom HTTP exception handler that adds CORS headers."""
    response = await http_exception_handler(request, exc)
    return add_response_cors_headers(response)

# Handle unexpected errors with CORS headers - this needs to be BEFORE the handle_options middleware
@app.middleware("http")
async def add_cors_headers_to_errors(request: Request, call_next):
    """Add CORS headers to all responses including errors."""
    try:
        # Get the origin from the request
        origin = request.headers.get("origin", "*")
        # Check if the origin is allowed
        if origin in allowed_origins or origin == "*":
            allowed_origin = origin
        else:
            allowed_origin = allowed_origins[0] if allowed_origins else "*"
            
        try:
            response = await call_next(request)
            
            # Add CORS headers if needed
            if "access-control-allow-origin" not in response.headers:
                response.headers["Access-Control-Allow-Origin"] = allowed_origin
                response.headers["Access-Control-Allow-Credentials"] = "true"
                response.headers["Access-Control-Allow-Methods"] = "*"
                response.headers["Access-Control-Allow-Headers"] = "*"
            
            return response
            
        except Exception as e:
            # For any uncaught exception, make sure we return a response with CORS headers
            logging.exception(f"Unhandled exception: {str(e)}")
            
            # Create error response with CORS headers
            response = JSONResponse(
                status_code=500,
                content={"detail": f"Internal server error: {str(e)}"}
            )
            response.headers["Access-Control-Allow-Origin"] = allowed_origin
            response.headers["Access-Control-Allow-Credentials"] = "true"
            response.headers["Access-Control-Allow-Methods"] = "*"
            response.headers["Access-Control-Allow-Headers"] = "*"
            
            return response
    except Exception as outer_e:
        # Last resort fallback
        logging.exception(f"Critical error in CORS middleware: {str(outer_e)}")
        response = JSONResponse(
            status_code=500,
            content={"detail": "Critical internal server error"}
        )
        response.headers["Access-Control-Allow-Origin"] = "*"
        response.headers["Access-Control-Allow-Credentials"] = "true"
        response.headers["Access-Control-Allow-Methods"] = "*"
        response.headers["Access-Control-Allow-Headers"] = "*"
        return response

# Add a middleware to handle OPTIONS requests for CORS preflight
@app.middleware("http")
async def handle_options(request: Request, call_next):
    if request.method == "OPTIONS":
        # Get the origin from the request
        origin = request.headers.get("origin", "*")
        # Check if the origin is allowed
        if origin in allowed_origins or origin == "*":
            allowed_origin = origin
        else:
            allowed_origin = allowed_origins[0] if allowed_origins else "*"
            
        # Return empty response with CORS headers for preflight requests
        response = JSONResponse(
            status_code=200,
            content={}
        )
        response.headers["Access-Control-Allow-Origin"] = allowed_origin
        response.headers["Access-Control-Allow-Methods"] = "*"
        response.headers["Access-Control-Allow-Headers"] = "*"
        response.headers["Access-Control-Allow-Credentials"] = "true"
        response.headers["Access-Control-Max-Age"] = "3600"
        return response
    
    # For non-OPTIONS requests, proceed normally
    return await call_next(request)

# Include routers
app.include_router(document.router)
app.include_router(conversation.router)
app.include_router(analysis.router)

@app.get("/")
async def root():
    return {
        "message": "Welcome to the Financial Document Analysis System API",
        "version": "0.1.0",
        "endpoints": {
            "documents": "/api/documents",
            "conversation": "/api/conversation",
            "analysis": "/api/analysis"
        }
    }

@app.get("/health")
async def health_check():
    return {"status": "ok"}

@app.on_event("startup")
async def startup_event():
    """Initialize the application on startup."""
    logger.info("Initializing database...")
    try:
        await init_db()
        logger.info("Database initialization completed successfully")
    except Exception as e:
        logger.error(f"Error initializing database: {str(e)}")
        # Continue even if database initialization fails
        # In production, you might want to exit the application
        pass

if __name__ == "__main__":
    # Run the app with uvicorn when script is executed directly
    uvicorn.run("app.main:app", host="0.0.0.0", port=8000, reload=True)
</file>
```

#### app/routes/\_\_init\_\_\.py
*Size: 78 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/app/routes/__init__.py">
# This file is intentionally left empty to make the directory a Python package
</file>
```

#### app/routes/analysis\.py
*Size: 26.7 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/app/routes/analysis.py">
from fastapi import APIRouter, HTTPException, Depends, Query, Path, Body
from typing import Dict, List, Optional, Any
import uuid
import logging
from datetime import datetime
from sqlalchemy.ext.asyncio import AsyncSession
import re
from fastapi.responses import JSONResponse
import json
from fastapi.encoders import jsonable_encoder
from pydantic import BaseModel, Field

from models.analysis import AnalysisRequest, AnalysisResult as AnalysisResultResponse
from models.analysis import FinancialMetric, FinancialRatio, ComparativePeriod
from models.visualization import VisualizationData, ChartData, TableData
from models.document import ProcessedDocument
from models.database_models import ProcessingStatusEnum
from repositories.document_repository import DocumentRepository
from repositories.analysis_repository import AnalysisRepository
from services.analysis_service import AnalysisService
from pdf_processing.document_service import DocumentService
from pdf_processing.claude_service import ClaudeService
from pdf_processing.langchain_service import LangChainService
from utils.database import get_db
from utils.response import handle_exception, create_error_response, get_error_type_from_status, add_cors_headers

# Configure more verbose logging
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)

router = APIRouter(prefix="/api/analysis", tags=["analysis"])

# Dependencies
async def get_document_repository(db: AsyncSession = Depends(get_db)):
    return DocumentRepository(db)

async def get_document_service(db: AsyncSession = Depends(get_db)):
    document_repository = DocumentRepository(db)
    return DocumentService(document_repository)

async def get_analysis_repository(db: AsyncSession = Depends(get_db)):
    return AnalysisRepository(db)

async def get_analysis_service(
    db: AsyncSession = Depends(get_db),
    analysis_repository: AnalysisRepository = Depends(get_analysis_repository),
    document_repository: DocumentRepository = Depends(get_document_repository)
):
    return AnalysisService(analysis_repository, document_repository)

async def get_claude_service():
    return ClaudeService()

async def get_langchain_service():
    return LangChainService()

# --- Pydantic models for API response ---
class VisualizationDataResponse(BaseModel):
    charts: List[Any] = Field(default_factory=list)
    tables: List[Any] = Field(default_factory=list)
    # Include other potential keys from processing if needed
    monetaryValues: Optional[Any] = None
    percentages: Optional[Any] = None
    keywordFrequency: Optional[Any] = None

class AnalysisApiResponse(BaseModel):
    id: str
    documentIds: List[str]
    analysisType: str
    timestamp: str # Use string for ISO format
    analysisText: Optional[str] = None
    visualizationData: VisualizationDataResponse
    metrics: List[FinancialMetric] = Field(default_factory=list)
    ratios: List[FinancialRatio] = Field(default_factory=list)
    comparativePeriods: List[ComparativePeriod] = Field(default_factory=list)
    insights: List[str] = Field(default_factory=list)
    citationReferences: Dict[str, str] = Field(default_factory=dict)
    document_type: Optional[str] = None
    periods: List[str] = Field(default_factory=list)
    query: Optional[str] = None

@router.post("/run", response_model=AnalysisApiResponse)
async def run_analysis_endpoint(
    analysis_request: AnalysisRequest,
    analysis_service: AnalysisService = Depends(get_analysis_service)
):
    """
    Run an analysis on document(s). This endpoint now routes to the
    appropriate analysis logic, primarily the tool-based comprehensive analysis.
    """
    try:
        logger.info(f"API Request - Run Analysis: Type='{analysis_request.analysisType}', Docs='{analysis_request.documentIds}', Query='{analysis_request.query}'")

        # Prepare parameters dictionary
        parameters = analysis_request.parameters or {}
        
        # Always include the query if provided
        if analysis_request.query:
            parameters["query"] = analysis_request.query

        # Call the analysis service
        analysis_id, result_data = await analysis_service.run_analysis(
            document_ids=[str(doc_id) for doc_id in analysis_request.documentIds],
            analysis_type=analysis_request.analysisType,
            parameters=parameters
        )

        # Log the structure of the result_data before validation
        logger.debug(f"Raw result_data from service: {result_data}")

        # Validate and return the response using the Pydantic model
        # The service now returns the correctly structured payload
        # Make sure the keys match exactly (camelCase vs snake_case)
        api_response = AnalysisApiResponse(
            id=result_data.get("id", analysis_id),
            documentIds=result_data.get("documentIds", analysis_request.documentIds),
            analysisType=result_data.get("analysisType", analysis_request.analysisType),
            timestamp=result_data.get("timestamp", datetime.now().isoformat()),
            analysisText=result_data.get("analysisText"),
            visualizationData=VisualizationDataResponse(
                 charts=result_data.get("visualizationData", {}).get("charts", []),
                 tables=result_data.get("visualizationData", {}).get("tables", []),
                 # Pass through other keys if they exist
                 **{k: v for k, v in result_data.get("visualizationData", {}).items() if k not in ['charts', 'tables']}
            ),
            metrics=result_data.get("metrics", []),
            ratios=result_data.get("ratios", []),
            comparativePeriods=result_data.get("comparativePeriods", []),
            insights=result_data.get("insights", []),
            citationReferences=result_data.get("citationReferences", {}),
            document_type=result_data.get("document_type"),
            periods=result_data.get("periods", []),
            query=result_data.get("query")
        )

        logger.info(f"API Response - Analysis successful: ID='{api_response.id}'")
        # Log counts for verification
        logger.info(f"Charts: {len(api_response.visualizationData.charts)}, Tables: {len(api_response.visualizationData.tables)}")
        logger.info(f"Metrics: {len(api_response.metrics)}, Ratios: {len(api_response.ratios)}, Comparisons: {len(api_response.comparativePeriods)}")

        return api_response

    except ValueError as ve:
        logger.warning(f"Value error during analysis run: {ve}")
        raise HTTPException(status_code=400, detail=str(ve))
    except Exception as e:
        logger.exception(f"Unhandled error during analysis run: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to run analysis: {str(e)}")

@router.post("/run-with-tools", response_model=AnalysisApiResponse, deprecated=True)
async def run_analysis_with_tools(
    analysis_request: AnalysisRequest,
    analysis_service: AnalysisService = Depends(get_analysis_service)
):
    """
    DEPRECATED: Use the primary /run endpoint instead, which now supports tool-based analysis.
    This endpoint is maintained for backwards compatibility but routes to the same implementation.
    """
    return await run_analysis_endpoint(analysis_request, analysis_service)

# Get endpoint for retrieving results
@router.get("/{analysis_id}", response_model=AnalysisApiResponse)
async def get_analysis_result(
    analysis_id: str,
    analysis_service: AnalysisService = Depends(get_analysis_service)
):
    """
    Retrieve analysis results along with linked citation references.
    """
    try:
        result_data = await analysis_service.get_analysis(analysis_id)

        # Validate and return the response using the Pydantic model
        api_response = AnalysisApiResponse(
            id=result_data.get("id", analysis_id),
            documentIds=result_data.get("documentIds", []),
            analysisType=result_data.get("analysisType", "unknown"),
            timestamp=result_data.get("timestamp", datetime.now().isoformat()),
            analysisText=result_data.get("analysisText"),
            visualizationData=VisualizationDataResponse(
                 charts=result_data.get("visualizationData", {}).get("charts", []),
                 tables=result_data.get("visualizationData", {}).get("tables", []),
                  # Pass through other keys if they exist
                 **{k: v for k, v in result_data.get("visualizationData", {}).items() if k not in ['charts', 'tables']}
            ),
            metrics=result_data.get("metrics", []),
            ratios=result_data.get("ratios", []),
            comparativePeriods=result_data.get("comparativePeriods", []),
            insights=result_data.get("insights", []),
            citationReferences=result_data.get("citationReferences", {}),
            document_type=result_data.get("document_type"),
            periods=result_data.get("periods", []),
            query=result_data.get("query")
        )
        return api_response

    except ValueError as ve:
        logger.warning(f"Analysis not found: {ve}")
        raise HTTPException(status_code=404, detail=str(ve))
    except Exception as e:
        logger.exception(f"Error retrieving analysis {analysis_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Error retrieving analysis: {str(e)}")

@router.get("/document/{document_id}", response_model=List[Dict[str, Any]])
async def list_document_analyses(
    document_id: str,
    analysis_type: Optional[str] = None,
    limit: int = 10,
    offset: int = 0,
    analysis_service: AnalysisService = Depends(get_analysis_service)
):
    """
    List analyses for a document.
    """
    try:
        # Get the analyses from the database
        analyses = await analysis_service.list_document_analyses(
            document_id=document_id,
            analysis_type=analysis_type,
            limit=limit,
            offset=offset
        )
        
        return analyses
    except Exception as e:
        # Ensure JSONResponse is imported in case we need it
        from fastapi.responses import JSONResponse
        
        logger.error(f"Error listing analyses: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Error listing analyses: {str(e)}")

@router.delete("/{analysis_id}")
async def delete_analysis(
    analysis_id: str,
    analysis_repository: AnalysisRepository = Depends(get_analysis_repository)
):
    """
    Delete an analysis.
    """
    try:
        # Check if analysis exists
        analysis = await analysis_repository.get_analysis(analysis_id)
        if not analysis:
            raise HTTPException(status_code=404, detail=f"Analysis {analysis_id} not found")
        
        # Delete the analysis
        success = await analysis_repository.delete_analysis(analysis_id)
        if not success:
            raise HTTPException(status_code=500, detail="Failed to delete analysis")
        
        return {"message": f"Analysis {analysis_id} deleted successfully"}
    except HTTPException:
        raise
    except Exception as e:
        # Ensure JSONResponse is imported in case we need it
        from fastapi.responses import JSONResponse
        
        logger.error(f"Error deleting analysis: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Error deleting analysis: {str(e)}")

# Helper functions to generate mock data for demonstration/testing
def generate_mock_metrics(period: str) -> List[FinancialMetric]:
    """Generate mock financial metrics for demo purposes."""
    return [
        FinancialMetric(
            category="Revenue",
            name="Total Revenue",
            period=period,
            value=24.5,
            unit="million USD"
        ),
        FinancialMetric(
            category="Revenue",
            name="YoY Growth",
            period=period,
            value=12.0,
            unit="percent"
        ),
        FinancialMetric(
            category="Expenses",
            name="Operating Expenses",
            period=period,
            value=18.3,
            unit="million USD"
        ),
        FinancialMetric(
            category="Profitability",
            name="Net Income",
            period=period,
            value=4.2,
            unit="million USD"
        ),
        FinancialMetric(
            category="Liquidity",
            name="Cash Position",
            period=period,
            value=15.6,
            unit="million USD"
        )
    ]

def generate_mock_ratios() -> List[FinancialRatio]:
    """Generate mock financial ratios for demo purposes."""
    return [
        FinancialRatio(
            name="Current Ratio",
            value=1.8,
            description="Measures the company's ability to pay short-term obligations",
            benchmark=2.1,
            trend=-0.1
        ),
        FinancialRatio(
            name="Quick Ratio",
            value=1.2,
            description="Measures the company's ability to pay short-term obligations using liquid assets",
            benchmark=1.5,
            trend=-0.05
        ),
        FinancialRatio(
            name="Debt-to-Equity",
            value=0.85,
            description="Measures the company's financial leverage",
            benchmark=0.7,
            trend=0.03
        ),
        FinancialRatio(
            name="Profit Margin",
            value=12.4,
            description="Measures the company's profitability as a percentage of revenue",
            benchmark=10.2,
            trend=0.5
        ),
        FinancialRatio(
            name="Return on Assets",
            value=8.2,
            description="Measures how efficiently the company is using its assets to generate profit",
            benchmark=7.5,
            trend=0.3
        )
    ]

@router.get("/{analysis_id}/enhanced", response_model=Dict[str, Any])
async def get_enhanced_analysis(
    analysis_id: str,
    analysis_service: AnalysisService = Depends(get_analysis_service)
):
    """
    Retrieve enhanced analysis with trends and extra insights
    """
    try:
        # Get the base analysis
        analysis = await analysis_service.get_analysis(analysis_id)
        if not analysis:
            raise HTTPException(status_code=404, detail=f"Analysis {analysis_id} not found")
        
        # Generate enhanced data based on the basic analysis
        trends = []
        insights = []
        
        # Extract metrics for trend generation
        metrics = analysis.get("result_data", {}).get("metrics", [])
        chart_data = analysis.get("result_data", {}).get("chart_data", {})
        base_insights = analysis.get("result_data", {}).get("insights", [])
        
        # Generate trends if we have metrics
        if metrics:
            for metric in metrics:
                # Create trend data for each metric
                trend = {
                    "id": f"trend-{uuid.uuid4()}",
                    "name": f"{metric.get('name', 'Unknown')} Trend",
                    "description": f"Trend analysis for {metric.get('name', 'Unknown')}",
                    "value": metric.get("value", 0.0),
                    "change": 0.05,  # Mock value: 5% change
                    "direction": "increasing" if 0.05 > 0 else "decreasing",
                    "significance": "high" if metric.get("name", "").lower() in ["revenue", "net income"] else "medium",
                    "category": metric.get("category", "Unknown")
                }
                trends.append(trend)
        
        # Generate enhanced insights
        if base_insights:
            for i, insight_text in enumerate(base_insights):
                # Categorize insights
                category = "critical" if i == 0 else "important" if i == 1 else "informational"
                
                # Link to metrics where possible
                related_metrics = []
                for metric in metrics[:2]:  # Just link to first two metrics for demo
                    related_metrics.append(metric.get("name", "Unknown"))
                
                insight = {
                    "id": f"insight-{uuid.uuid4()}",
                    "text": insight_text,
                    "category": category,
                    "relatedMetrics": related_metrics,
                    "confidence": 0.9 - (i * 0.05)  # Decreasing confidence for later insights
                }
                insights.append(insight)
        
        # Return the enhanced analysis
        return {
            "trends": trends,
            "insights": insights
        }
        
    except HTTPException:
        raise
    except Exception as e:
        # Ensure JSONResponse is imported in case we need it
        from fastapi.responses import JSONResponse
        
        logger.error(f"Error getting enhanced analysis: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Error retrieving enhanced analysis: {str(e)}")

@router.get("/{analysis_id}/chart/{chart_type}", response_model=Dict[str, Any])
async def get_chart_data(
    analysis_id: str,
    chart_type: str,
    analysis_service: AnalysisService = Depends(get_analysis_service)
):
    """
    Retrieve chart data for a specific analysis and chart type
    """
    try:
        # Get the base analysis
        analysis = await analysis_service.get_analysis(analysis_id)
        if not analysis:
            raise HTTPException(status_code=404, detail=f"Analysis {analysis_id} not found")
        
        # Extract chart data from the analysis
        chart_data = analysis.get("result_data", {}).get("chart_data", {})
        
        # If time series data is available, return it with the requested chart type
        if "timeSeriesData" in chart_data:
            return {
                "chartData": chart_data["timeSeriesData"],
                "chartType": chart_type,
                "title": f"Financial {chart_type.capitalize()} Chart",
                "description": f"Generated from analysis {analysis_id}"
            }
        
        # If no chart data available, return empty result
        return {
            "chartData": [],
            "chartType": chart_type,
            "title": f"No data available",
            "description": "No chart data found for this analysis"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        # Ensure JSONResponse is imported in case we need it
        from fastapi.responses import JSONResponse
        
        logger.error(f"Error getting chart data: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Error retrieving chart data: {str(e)}")

# Helper functions for generating chart data
def generate_monetary_values_data(metrics, insights):
    """Generate monetary values data for visualization."""
    # First, try to use actual metrics with appropriate units
    monetary_metrics = [
        {"name": metric.name, "value": metric.value, "description": f"{metric.category}: {metric.name} ({metric.period})"}
        for metric in metrics
        if any(keyword in metric.unit.lower() for keyword in ["usd", "$", "dollar", "million", "billion", "revenue", "cost", "price", "value"])
        or any(keyword in metric.name.lower() for keyword in ["revenue", "sales", "cost", "price", "income", "profit", "expense", "asset"])
    ]
    
    # Log the available metrics
    logger.info(f"CHART_LOG: Found {len(metrics)} total metrics for monetary values chart")
    logger.info(f"CHART_LOG: Filtered down to {len(monetary_metrics)} monetary metrics")
    if monetary_metrics:
        logger.info(f"CHART_LOG: Using actual monetary metrics for chart: {json.dumps([m['name'] for m in monetary_metrics])}")
    
    # If we don't have metrics, extract monetary values from insights
    if not monetary_metrics and insights:
        import re
        # Look for patterns like "$X million" or "X million dollars" in insights
        monetary_pattern = r'\$\s*[\d,\.]+\s*(million|billion|thousand|M|B|K)?|\d+(\.\d+)?\s*(million|billion|thousand|M|B|K)?\s*(dollars|USD)'
        monetary_insights = []
        
        logger.info(f"CHART_LOG: No monetary metrics found, attempting to extract from {len(insights)} insights")
        
        for idx, insight in enumerate(insights[:5]):
            matches = re.findall(monetary_pattern, insight, re.IGNORECASE)
            if matches:
                logger.info(f"CHART_LOG: Found monetary pattern in insight {idx+1}: {matches}")
                value = 1000000 * (idx + 1)  # Placeholder value if we can't parse the actual number
                monetary_insights.append({
                    "name": f"Value {idx+1}",
                    "value": value, 
                    "description": insight[:100] + "..."
                })
        
        if monetary_insights:
            logger.info(f"CHART_LOG: Using {len(monetary_insights)} monetary values extracted from insights")
            return monetary_insights
        else:
            logger.info("CHART_LOG: Failed to extract monetary values from insights")
    
    # If we still don't have data, provide sample data
    if not monetary_metrics:
        logger.warning("CHART_LOG: âš ï¸ USING FALLBACK STATIC DATA for monetary values chart - no real metrics or insights found")
        return [
            {"name": "Revenue", "value": 1250000, "description": "Estimated revenue based on document context"},
            {"name": "Cost", "value": 875000, "description": "Estimated costs based on document context"},
            {"name": "Profit", "value": 375000, "description": "Calculated profit (Revenue - Cost)"}
        ]
    
    return monetary_metrics[:5]  # Limit to 5 data points

def generate_percentage_data(metrics, insights):
    """Generate percentage data for visualization."""
    # First, try to use actual metrics with percentage units
    percentage_metrics = [
        {"name": metric.name, "value": metric.value, "description": f"{metric.category}: {metric.name} ({metric.period})"}
        for metric in metrics
        if any(keyword in metric.unit.lower() for keyword in ["percent", "%", "ratio", "rate", "growth"]) 
        or any(keyword in metric.name.lower() for keyword in ["percent", "rate", "ratio", "growth", "margin", "yield", "return"])
    ]
    
    # Log the available metrics 
    logger.info(f"CHART_LOG: Found {len(metrics)} total metrics for percentage chart")
    logger.info(f"CHART_LOG: Filtered down to {len(percentage_metrics)} percentage metrics")
    if percentage_metrics:
        logger.info(f"CHART_LOG: Using actual percentage metrics for chart: {json.dumps([m['name'] for m in percentage_metrics])}")
    
    # If we don't have metrics, extract percentage values from insights
    if not percentage_metrics and insights:
        import re
        # Look for patterns like "X%" or "X percent" in insights
        percentage_pattern = r'(\d+(\.\d+)?)\s*(%|percent|percentage)'
        percentage_insights = []
        
        logger.info(f"CHART_LOG: No percentage metrics found, attempting to extract from {len(insights)} insights")
        
        for idx, insight in enumerate(insights[:5]):
            matches = re.findall(percentage_pattern, insight, re.IGNORECASE)
            if matches:
                logger.info(f"CHART_LOG: Found percentage pattern in insight {idx+1}: {matches}")
                try:
                    value = float(matches[0][0])
                    percentage_insights.append({
                        "name": f"Rate {idx+1}",
                        "value": value,
                        "description": insight[:100] + "..."
                    })
                except:
                    percentage_insights.append({
                        "name": f"Rate {idx+1}",
                        "value": (idx + 1) * 5,  # Placeholder percentage
                        "description": insight[:100] + "..."
                    })
        
        if percentage_insights:
            logger.info(f"CHART_LOG: Using {len(percentage_insights)} percentage values extracted from insights")
            return percentage_insights
        else:
            logger.info("CHART_LOG: Failed to extract percentage values from insights")
    
    # If we still don't have data, provide sample data
    if not percentage_metrics:
        logger.warning("CHART_LOG: âš ï¸ USING FALLBACK STATIC DATA for percentage chart - no real metrics or insights found")
        return [
            {"name": "Growth Rate", "value": 8.5, "description": "Estimated annual growth rate"},
            {"name": "Profit Margin", "value": 15.3, "description": "Estimated profit margin percentage"},
            {"name": "Market Share", "value": 12.7, "description": "Estimated market share percentage"}
        ]
    
    return percentage_metrics[:5]  # Limit to 5 data points

def generate_keyword_frequency_data(insights):
    """Generate keyword frequency data for visualization."""
    # Generate frequency data from insights
    if not insights:
        # Provide sample data if no insights
        logger.warning("CHART_LOG: âš ï¸ USING FALLBACK STATIC DATA for keyword frequency chart - no insights found")
        return [
            {"name": "Revenue", "value": 3, "description": "Mentions of revenue in document"},
            {"name": "Profit", "value": 2, "description": "Mentions of profit in document"},
            {"name": "Growth", "value": 2, "description": "Mentions of growth in document"},
            {"name": "Market", "value": 1, "description": "Mentions of market in document"}
        ]
    
    logger.info(f"CHART_LOG: Generating keyword frequency data from {len(insights)} insights")
    
    # Extract financial keywords from insights
    import re
    financial_terms = [
        "revenue", "profit", "loss", "growth", "income", "cost", "expense", "asset", 
        "liability", "equity", "debt", "cash", "margin", "dividend", "earnings", 
        "investment", "capital", "fiscal", "quarter", "annual"
    ]
    
    # Count term frequency
    term_count = {}
    for insight in insights:
        for term in financial_terms:
            pattern = r'\b' + re.escape(term) + r'\b'
            matches = re.findall(pattern, insight.lower())
            if matches:
                term_count[term] = term_count.get(term, 0) + len(matches)
    
    logger.info(f"CHART_LOG: Found {len(term_count)} financial terms in insights")
    if term_count:
        logger.info(f"CHART_LOG: Most frequent terms: {json.dumps(dict(sorted(term_count.items(), key=lambda x: x[1], reverse=True)[:5]))}")
    
    # Sort by frequency and convert to chart data format
    frequency_data = [
        {"name": term.capitalize(), "value": count, "description": f"Mentions of {term} in document"}
        for term, count in sorted(term_count.items(), key=lambda x: x[1], reverse=True)
    ]
    
    # If we still don't have data from terms, use the insights themselves
    if not frequency_data:
        logger.warning("CHART_LOG: No financial terms found in insights, using fallback method")
        return [{"name": insight[:20] + "...", "value": 1, "description": insight[:100]} for insight in insights[:5]]
    
    return frequency_data[:5]  # Limit to 5 most frequent terms
</file>
```

#### app/routes/conversation\.py
*Size: 19.8 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/app/routes/conversation.py">
from fastapi import APIRouter, HTTPException, Depends, Query, status
from typing import List, Optional, Dict, Any
import uuid
from datetime import datetime
import logging
from sqlalchemy.ext.asyncio import AsyncSession

from models.message import Message, MessageRole, MessageRequest, ConversationState, ConversationCreateRequest
from models.document import ProcessedDocument, Citation
from pdf_processing.document_service import DocumentService
from repositories.document_repository import DocumentRepository
from repositories.conversation_repository import ConversationRepository
from services.conversation_service import ConversationService
from pdf_processing.claude_service import ClaudeService
from utils.database import get_db

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/conversation", tags=["conversation"])

# Dependencies
async def get_document_repository(db: AsyncSession = Depends(get_db)):
    return DocumentRepository(db)

async def get_document_service(
    document_repository: DocumentRepository = Depends(get_document_repository)
):
    return DocumentService(document_repository)

async def get_conversation_repository(db: AsyncSession = Depends(get_db)):
    return ConversationRepository(db)

async def get_conversation_service(
    conversation_repository: ConversationRepository = Depends(get_conversation_repository),
    document_repository: DocumentRepository = Depends(get_document_repository)
):
    return ConversationService(
        conversation_repository=conversation_repository,
        document_repository=document_repository
    )

async def get_claude_service():
    return ClaudeService()

async def get_current_user_id():
    # This is a placeholder for authentication
    # In a real application, this would validate the JWT token and return the user ID
    return "default-user"

@router.post("", response_model=ConversationState, status_code=status.HTTP_201_CREATED)
async def create_conversation(
    conversation_data: ConversationCreateRequest,
    conversation_service: ConversationService = Depends(get_conversation_service),
    user_id: str = Depends(get_current_user_id)
):
    """
    Create a new conversation with optional document associations.
    """
    try:
        # Override the user_id with the authenticated user
        conversation_data.user_id = user_id
        
        # Create the conversation
        conversation = await conversation_service.create_conversation(
            title=conversation_data.title,
            user_id=conversation_data.user_id,
            document_ids=conversation_data.document_ids or []
        )
        
        # Create and return the conversation state
        state = ConversationState(
            session_id=conversation.id,
            active_documents=conversation_data.document_ids or [],
            last_updated=conversation.updated_at
        )
        
        logger.info(f"Created conversation: {conversation.id} for user: {user_id}")
        return state
    except Exception as e:
        logger.error(f"Error creating conversation: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error creating conversation: {str(e)}"
        )

@router.post("/{session_id}/message")
async def send_message(
    session_id: str,
    message: MessageRequest,
    conversation_service: ConversationService = Depends(get_conversation_service),
):
    """
    Send a message to a conversation and get an AI response using Claude API.
    
    The message will be processed and a response generated based on the conversation context.
    If documents are attached to the conversation, they will be used for context.
    
    Args:
        session_id: The ID of the conversation session
        message: The message content and optional citation IDs
        
    Returns:
        The AI response message
    """
    if message.session_id != session_id:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Session ID in path must match session ID in request body"
        )
    
    try:
        result = await conversation_service.process_user_message(
            conversation_id=session_id,
            content=message.content,
            citation_ids=message.citation_links
        )
        
        if not result.get("success", True):
            # Return the error message but with a 200 status code
            # This allows the client to handle the error gracefully
            logger.warning(f"Error processing message: {result.get('error', 'Unknown error')}")
            return result.get("message")
        
        return result.get("message")
    except ValueError as e:
        logger.error(f"Bad request while processing message: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        logger.exception(f"Error processing message: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"An error occurred while processing the message: {str(e)}"
        )

def is_financial_analysis_request(message: str) -> bool:
    """
    Determine if a message is asking for financial analysis.
    
    Args:
        message: User message text
        
    Returns:
        True if the message appears to be a financial question, False otherwise
    """
    # Simple heuristic to determine if this is a financial question
    financial_keywords = [
        "financial", "revenue", "profit", "margin", "expense", "income",
        "balance sheet", "cash flow", "ratio", "trend", "growth", "forecast",
        "comparison", "analyze", "calculate", "metric", "performance", "quarterly",
        "annual", "fiscal", "q1", "q2", "q3", "q4", "year-over-year", "yoy"
    ]
    
    message_lower = message.lower()
    
    # Check for financial keywords
    if any(keyword in message_lower for keyword in financial_keywords):
        return True
    
    # Check for questions about calculations, comparisons, or visualizations
    calculation_phrases = [
        "calculate", "compare", "show me", "what is the", "how much",
        "visualize", "chart", "graph", "plot", "trend", "over time"
    ]
    
    if any(phrase in message_lower for phrase in calculation_phrases):
        return True
    
    return False

@router.get("/{conversation_id}/history", response_model=List[Message])
async def get_conversation_history(
    conversation_id: str,
    limit: int = Query(50, ge=1, le=100),
    offset: int = Query(0, ge=0),
    conversation_service: ConversationService = Depends(get_conversation_service),
    user_id: str = Depends(get_current_user_id)
):
    """
    Retrieve conversation history including citation links.
    """
    try:
        # Check if the conversation exists and belongs to the user
        conversation = await conversation_service.get_conversation(conversation_id)
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Conversation {conversation_id} not found"
            )
        
        if conversation.user_id != user_id:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="You don't have permission to access this conversation"
            )
        
        # Get messages from the database
        messages = await conversation_service.get_conversation_messages(
            conversation_id=conversation_id,
            limit=limit,
            offset=offset
        )
        
        # Convert to API message models
        api_messages = []
        for msg in messages:
            # Get citations for this message
            citations = await conversation_service.conversation_repository.get_message_citations(msg.id)
            
            # Convert citations to Citation objects
            citation_objects = []
            for citation in citations:
                # Get the document for this citation
                document = await conversation_service.document_repository.get_document(citation.document_id)
                doc_title = document.filename if document else "Unknown Document"
                
                citation_objects.append(
                    Citation(
                        id=citation.id,
                        document_id=citation.document_id,
                        document_title=doc_title,
                        content=citation.content,
                        metadata=citation.metadata or {},
                        type=citation.metadata.get("type", "unknown") if citation.metadata else "unknown"
                    )
                )
            
            # Create content blocks if available
            content_blocks = None
            if hasattr(msg, 'content_blocks') and msg.content_blocks:
                content_blocks = msg.content_blocks
            
            api_messages.append(
                Message(
                    id=msg.id,
                    session_id=msg.conversation_id,
                    timestamp=msg.created_at,
                    role=MessageRole(msg.role),
                    content=msg.content,
                    referenced_documents=[],  # We don't store this directly in the database
                    referenced_analyses=[],   # We don't store this directly in the database
                    citation_links=[citation.id for citation in citations],
                    citations=citation_objects,
                    content_blocks=content_blocks
                )
            )
        
        return api_messages
    except HTTPException:
        # Re-raise HTTP exceptions
        raise
    except Exception as e:
        logger.error(f"Error getting conversation history: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error getting conversation history: {str(e)}"
        )

@router.get("", response_model=List[Dict[str, Any]])
async def list_conversations(
    limit: int = Query(10, ge=1, le=50),
    offset: int = Query(0, ge=0),
    conversation_service: ConversationService = Depends(get_conversation_service),
    user_id: str = Depends(get_current_user_id)
):
    """
    List all conversations for the current user.
    """
    try:
        conversations = await conversation_service.list_conversations(
            user_id=user_id,
            limit=limit,
            offset=offset
        )
        
        # Get the total count
        total_count = await conversation_service.conversation_repository.count_conversations(user_id)
        
        # Format the response
        result = []
        for conversation in conversations:
            # Get the last message for preview
            messages = await conversation_service.get_conversation_messages(
                conversation_id=conversation.id,
                limit=1
            )
            
            last_message = None
            if messages:
                last_message = {
                    "content": messages[0].content[:100] + "..." if len(messages[0].content) > 100 else messages[0].content,
                    "role": messages[0].role,
                    "timestamp": messages[0].created_at.isoformat()
                }
            
            # Get associated documents
            documents = await conversation_service.conversation_repository.get_conversation_documents(conversation.id)
            document_count = len(documents)
            
            result.append({
                "id": conversation.id,
                "title": conversation.title,
                "created_at": conversation.created_at.isoformat(),
                "updated_at": conversation.updated_at.isoformat(),
                "last_message": last_message,
                "document_count": document_count
            })
        
        return result
    except Exception as e:
        logger.error(f"Error listing conversations: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error listing conversations: {str(e)}"
        )

@router.delete("/{conversation_id}", status_code=status.HTTP_204_NO_CONTENT)
async def delete_conversation(
    conversation_id: str,
    conversation_service: ConversationService = Depends(get_conversation_service),
    user_id: str = Depends(get_current_user_id)
):
    """
    Delete a conversation and all associated messages.
    """
    try:
        # Check if the conversation exists and belongs to the user
        conversation = await conversation_service.get_conversation(conversation_id)
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Conversation {conversation_id} not found"
            )
        
        if conversation.user_id != user_id:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="You don't have permission to delete this conversation"
            )
        
        # Delete the conversation
        deleted = await conversation_service.conversation_repository.delete_conversation(conversation_id)
        if not deleted:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="Failed to delete conversation"
            )
        
        return None
    except HTTPException:
        # Re-raise HTTP exceptions
        raise
    except Exception as e:
        logger.error(f"Error deleting conversation: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error deleting conversation: {str(e)}"
        )

@router.post("/{conversation_id}/document/{document_id}", status_code=status.HTTP_200_OK)
async def add_document_to_conversation(
    conversation_id: str,
    document_id: str,
    conversation_service: ConversationService = Depends(get_conversation_service),
    document_service: DocumentService = Depends(get_document_service),
    user_id: str = Depends(get_current_user_id)
):
    """
    Add a document to a conversation.
    """
    try:
        # Check if the conversation exists and belongs to the user
        conversation = await conversation_service.get_conversation(conversation_id)
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Conversation {conversation_id} not found"
            )
        
        if conversation.user_id != user_id:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="You don't have permission to modify this conversation"
            )
        
        # Check if the document exists and belongs to the user
        document = await document_service.document_repository.get_document(document_id)
        if not document:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Document {document_id} not found"
            )
        
        if document.user_id != user_id:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="You don't have permission to access this document"
            )
        
        # Add the document to the conversation
        success = await conversation_service.conversation_repository.add_document_to_conversation(
            conversation_id=conversation_id,
            document_id=document_id
        )
        
        if not success:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="Failed to add document to conversation"
            )
        
        return {"message": "Document added to conversation successfully"}
    except HTTPException:
        # Re-raise HTTP exceptions
        raise
    except Exception as e:
        logger.error(f"Error adding document to conversation: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error adding document to conversation: {str(e)}"
        )

@router.get("/{conversation_id}/document", response_model=List[Dict[str, Any]])
async def get_conversation_documents(
    conversation_id: str,
    conversation_service: ConversationService = Depends(get_conversation_service),
    user_id: str = Depends(get_current_user_id)
):
    """
    Get all documents associated with a conversation.
    """
    try:
        # Check if the conversation exists and belongs to the user
        conversation = await conversation_service.get_conversation(conversation_id)
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Conversation {conversation_id} not found"
            )
        
        if conversation.user_id != user_id:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="You don't have permission to access this conversation"
            )
        
        # Get the documents
        documents = await conversation_service.conversation_repository.get_conversation_documents(conversation_id)
        
        # Format the response
        result = []
        for doc in documents:
            result.append({
                "id": doc.id,
                "filename": doc.filename,
                "file_size": doc.file_size,
                "mime_type": doc.mime_type,
                "upload_timestamp": doc.upload_timestamp.isoformat(),
                "document_type": doc.document_type.value if doc.document_type else "other"
            })
        
        return result
    except HTTPException:
        # Re-raise HTTP exceptions
        raise
    except Exception as e:
        logger.error(f"Error getting conversation documents: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error getting conversation documents: {str(e)}"
        )

@router.delete("/{conversation_id}/document/{document_id}", status_code=status.HTTP_204_NO_CONTENT)
async def remove_document_from_conversation(
    conversation_id: str,
    document_id: str,
    conversation_service: ConversationService = Depends(get_conversation_service),
    user_id: str = Depends(get_current_user_id)
):
    """
    Remove a document from a conversation.
    """
    try:
        # Check if the conversation exists and belongs to the user
        conversation = await conversation_service.get_conversation(conversation_id)
        if not conversation:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"Conversation {conversation_id} not found"
            )
        
        if conversation.user_id != user_id:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="You don't have permission to modify this conversation"
            )
        
        # Remove the document from the conversation
        success = await conversation_service.conversation_repository.remove_document_from_conversation(
            conversation_id=conversation_id,
            document_id=document_id
        )
        
        if not success:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Document not found in conversation"
            )
        
        return None
    except HTTPException:
        # Re-raise HTTP exceptions
        raise
    except Exception as e:
        logger.error(f"Error removing document from conversation: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error removing document from conversation: {str(e)}"
        )
</file>
```

#### app/routes/document\.py
*Size: 16.7 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/app/routes/document.py">
from fastapi import APIRouter, UploadFile, File, Form, HTTPException, Depends, Query, Path, Body
from fastapi.responses import JSONResponse, FileResponse, Response
from typing import List, Optional, Dict, Any
import uuid
import logging
import os
import io

from models.document import DocumentUploadResponse, ProcessedDocument, DocumentMetadata, Citation
from models.api_models import RetryExtractionRequest
from models.database_models import ProcessingStatusEnum
from repositories.document_repository import DocumentRepository
from pdf_processing.document_service import DocumentService
from utils.database import get_db
from sqlalchemy.ext.asyncio import AsyncSession
from utils.dependencies import get_document_service, get_document_repository

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/documents", tags=["documents"])

# Dependency to get the document repository
async def get_document_repository(db: AsyncSession = Depends(get_db)):
    return DocumentRepository(db)

# Dependency to get the document service
async def get_document_service(db: AsyncSession = Depends(get_db)):
    document_repository = DocumentRepository(db)
    return DocumentService(document_repository)

@router.post("/upload", response_model=DocumentUploadResponse)
async def upload_document(
    file: UploadFile = File(...),
    user_id: str = Form("default-user"),  # In a real app, this would come from auth
    document_service: DocumentService = Depends(get_document_service)
):
    """
    Upload a financial document for processing, including citation metadata extraction.
    """
    # Validate file is a PDF
    if file.content_type != "application/pdf":
        raise HTTPException(status_code=400, detail="File must be a PDF")
    
    # Validate file size (10MB max)
    if file.size and file.size > 10 * 1024 * 1024:
        raise HTTPException(status_code=413, detail="File size must be less than 10MB")
    
    try:
        # Read the file
        file_data = await file.read()
        
        # Upload and process the document
        response = await document_service.upload_document(file_data, file.filename, user_id)
        
        return response
    except Exception as e:
        logger.error(f"Error uploading document: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error uploading document: {str(e)}")

@router.get("/count")
async def count_documents(
    user_id: str = "default-user",  # In a real app, this would come from auth
    document_repository: DocumentRepository = Depends(get_document_repository)
):
    """
    Count the number of documents for the current user.
    """
    count = await document_repository.count_documents(user_id)
    return {"count": count}

@router.get("", response_model=List[DocumentMetadata])
async def list_documents(
    user_id: str = "default-user",  # In a real app, this would come from auth
    page: int = Query(1, ge=1),
    page_size: int = Query(10, ge=1, le=100),
    document_repository: DocumentRepository = Depends(get_document_repository)
):
    """
    List all documents for the current user.
    """
    offset = (page - 1) * page_size
    documents = await document_repository.list_documents(user_id, page_size, offset)
    
    # Convert to API schema
    return [document_repository.document_to_metadata_schema(doc) for doc in documents]

@router.get("/{document_id}", response_model=ProcessedDocument)
async def get_document(
    document_id: str,
    document_repository: DocumentRepository = Depends(get_document_repository)
):
    """
    Retrieve document metadata, processed content, and citation highlights.
    """
    document = await document_repository.get_document(document_id)
    if not document:
        raise HTTPException(status_code=404, detail="Document not found")
    
    return document_repository.document_to_api_schema(document)

@router.get("/{document_id}/citations", response_model=List[Citation])
async def get_document_citations(
    document_id: str,
    document_repository: DocumentRepository = Depends(get_document_repository)
):
    """
    Get all citations for a document.
    """
    document = await document_repository.get_document(document_id)
    if not document:
        raise HTTPException(status_code=404, detail="Document not found")
    
    citations = await document_repository.get_document_citations(document_id)
    
    # Convert to API schema
    return [document_repository.citation_to_api_schema(citation) for citation in citations]

@router.get("/{document_id}/citations/{citation_id}", response_model=Citation)
async def get_citation(
    document_id: str,
    citation_id: str,
    document_repository: DocumentRepository = Depends(get_document_repository)
):
    """
    Get a specific citation.
    """
    # Check if document exists
    document = await document_repository.get_document(document_id)
    if not document:
        raise HTTPException(status_code=404, detail="Document not found")
    
    # Get the citation
    citation = await document_repository.get_citation(citation_id)
    if not citation or citation.document_id != document_id:
        raise HTTPException(status_code=404, detail="Citation not found")
    
    return document_repository.citation_to_api_schema(citation)

@router.delete("/{document_id}")
async def delete_document(
    document_id: str,
    document_repository: DocumentRepository = Depends(get_document_repository)
):
    """
    Delete a document.
    """
    document = await document_repository.get_document(document_id)
    if not document:
        raise HTTPException(status_code=404, detail="Document not found")
    
    success = await document_repository.delete_document(document_id)
    if not success:
        raise HTTPException(status_code=500, detail="Failed to delete document")
    
    return {"message": f"Document {document_id} deleted successfully"}

@router.post("/{document_id}/retry-extraction", response_model=Dict[str, Any])
async def retry_extraction(
    document_id: str = Path(..., description="Document ID to retry extraction for"),
    request: RetryExtractionRequest = Body(..., description="Extraction parameters"),
    document_service: DocumentService = Depends(get_document_service)
):
    """
    Retry extraction of structured data from a document.
    
    Args:
        document_id: ID of the document to process
        request: Parameters for extraction
        document_service: Document service dependency
        
    Returns:
        Status of the extraction
    """
    try:
        logger.info(f"Retrying extraction for document {document_id}, type: {request.extraction_type}")
        
        # Verify the document exists
        document = await document_service.get_document(document_id)
        if not document:
            raise HTTPException(status_code=404, detail=f"Document {document_id} not found")
        
        # Get raw text from document
        raw_text = None
        if document.extracted_data and "raw_text" in document.extracted_data:
            raw_text = document.extracted_data["raw_text"]
        
        if not raw_text:
            return {"success": False, "error": "Document has no extracted text to process"}
        
        # Call the specific extraction method based on extraction_type
        if request.extraction_type == "structured_financial_data":
            # Call the structured financial data extraction
            result = await document_service.extract_structured_financial_data(document_id, raw_text)
            return {"success": True, "extraction_type": request.extraction_type, "result": result}
        else:
            return {"success": False, "error": f"Unsupported extraction type: {request.extraction_type}"}
    
    except Exception as e:
        logger.exception(f"Error in retry extraction: {e}")
        return {"success": False, "error": str(e)}

@router.get("/{document_id}/check-financial-data", response_model=Dict[str, Any])
async def check_document_financial_data(
    document_id: str,
    document_service: DocumentService = Depends(get_document_service)
):
    """
    Check if a document has valid financial data.
    Now always returns success to ensure all documents are analyzed.
    
    Args:
        document_id: ID of the document to check
        document_service: Document service dependency
        
    Returns:
        Status of the financial data check (always successful)
    """
    try:
        # Get the document
        document = await document_service.document_repository.get_document(document_id)
        if not document:
            raise HTTPException(status_code=404, detail="Document not found")
        
        # Always return success, regardless of actual financial data
        # This ensures all documents are sent for analysis with Claude
        logger.info(f"Document {document_id} accepted for financial analysis")
        
        return {
            "has_financial_data": True,
            "diagnosis": "Document accepted for financial analysis",
            "metrics_count": 0,
            "ratios_count": 0,
            "insights_count": 0
        }
    
    except Exception as e:
        logger.error(f"Error checking document financial data: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Error checking document financial data: {str(e)}")

@router.post("/{document_id}/verify-financial-data", response_model=Dict[str, Any])
async def verify_document_financial_data(
    document_id: str,
    retry_extraction: bool = Query(False, description="Whether to retry extraction of structured data"),
    document_service: DocumentService = Depends(get_document_service)
):
    """
    Verify a document's financial data and optionally trigger re-extraction.
    Now more flexible - accepts any document with content.
    
    Args:
        document_id: ID of the document to verify
        retry_extraction: Whether to retry extraction of structured data
        document_service: Document service dependency
        
    Returns:
        Status of the verification
    """
    try:
        # Get the document
        document = await document_service.document_repository.get_document(document_id)
        if not document:
            raise HTTPException(status_code=404, detail="Document not found")
        
        # If retry_extraction is True, trigger re-extraction
        if retry_extraction:
            logger.info(f"Triggering re-extraction of financial data for document {document_id}")
            result = await document_service.extract_structured_financial_data(document_id)
            
            if result.get("error"):
                return {
                    "success": False,
                    "message": f"Error extracting financial data: {result['error']}"
                }
            
            return {
                "success": True,
                "message": f"Successfully extracted financial data with {result.get('metrics_count', 0)} metrics, {result.get('ratios_count', 0)} ratios, and {result.get('insights_count', 0)} insights"
            }
        
        # Check for any content
        has_content = False
        
        # Check raw_text
        if document.raw_text and len(document.raw_text.strip()) > 0:
            has_content = True
            logger.info(f"Document {document_id} has {len(document.raw_text)} characters of raw text")
        
        # Check extracted_data for raw_text or any other content
        if document.extracted_data:
            if isinstance(document.extracted_data, dict):
                if document.extracted_data.get("raw_text"):
                    has_content = True
                    logger.info(f"Document {document_id} has raw_text in extracted_data")
                elif len(document.extracted_data) > 0:
                    # Any other extracted data is acceptable
                    has_content = True
                    logger.info(f"Document {document_id} has extracted_data with keys: {list(document.extracted_data.keys())}")
        
        if has_content:
            # Mark the document as verified if it has any content
            await document_service.document_repository.update_document_status(
                document_id=document_id,
                status=ProcessingStatusEnum.COMPLETED
            )
            
            return {
                "success": True,
                "message": "Document content verified for analysis"
            }
        else:
            return {
                "success": False,
                "message": "No document content detected"
            }
        
    except Exception as e:
        logger.error(f"Error verifying document financial data: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Error verifying document financial data: {str(e)}")

@router.get("/{document_id}/file", response_class=Response)
async def get_document_file(
    document_id: str,
    document_service: DocumentService = Depends(get_document_service)
):
    """
    Retrieve the actual PDF file for a document.
    
    Args:
        document_id: ID of the document to retrieve
        document_service: Document service dependency
        
    Returns:
        PDF file content with appropriate content-type
    """
    try:
        # Get the document
        document = await document_service.document_repository.get_document(document_id)
        if not document:
            logger.warning(f"Document not found: {document_id}")
            raise HTTPException(status_code=404, detail="Document not found")
        
        logger.info(f"Retrieving file for document: {document_id}")
        
        # Get the raw PDF data directly
        try:
            pdf_data = await document_service.document_repository.get_document_binary(document_id)
            
            if pdf_data:
                logger.info(f"Returning binary PDF data for document {document_id}, size: {len(pdf_data)} bytes")
                return Response(
                    content=pdf_data,
                    media_type="application/pdf",
                    headers={
                        "Content-Disposition": f"attachment; filename={document.filename}",
                        "Access-Control-Allow-Origin": "*",
                        "Access-Control-Allow-Methods": "*",
                        "Access-Control-Allow-Headers": "*"
                    }
                )
        except Exception as e:
            logger.error(f"Error getting binary data: {str(e)}")
        
        # If binary retrieval failed, try physical file
        # Get the actual file path
        file_path = document_service.document_repository.get_document_file_path(document_id)
        
        # Check if the file exists
        if os.path.exists(file_path):
            logger.info(f"Returning file from disk: {file_path}")
            return FileResponse(
                file_path, 
                media_type="application/pdf",
                filename=document.filename
            )
        
        # If we don't have a physical file, try to create one from raw_text
        if document.raw_text:
            # Create a simple text file with the raw text
            logger.info(f"Creating text file from raw text for document {document_id}")
            content = document.raw_text.encode('utf-8')
            
            # Return the content as text/plain instead of PDF
            return Response(
                content=content,
                media_type="text/plain",
                headers={
                    "Content-Disposition": f"attachment; filename={document.filename}.txt",
                    "Access-Control-Allow-Origin": "*",
                    "Access-Control-Allow-Methods": "*", 
                    "Access-Control-Allow-Headers": "*"
                }
            )
        
        # As a last resort, create a simple text response with document metadata
        logger.warning(f"No file content found for document {document_id}, returning metadata only")
        metadata_text = f"Document ID: {document_id}\nFilename: {document.filename}\n"
        metadata_text += f"Content Type: {document.document_type}\nProcessed: {document.processed_at}\n"
        
        if document.extracted_data:
            metadata_text += "\nExtracted Data Keys:\n"
            for key in document.extracted_data.keys():
                metadata_text += f"- {key}\n"
        
        return Response(
            content=metadata_text.encode('utf-8'),
            media_type="text/plain",
            headers={
                "Content-Disposition": f"attachment; filename={document.filename}.txt",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Methods": "*",
                "Access-Control-Allow-Headers": "*"
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error retrieving document file: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"Error retrieving document file: {str(e)}"
        )
</file>
```

#### check\_document\_context\.py
*Size: 3.6 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/check_document_context.py">
#!/usr/bin/env python
"""
A utility script to verify PDF document context preparation.

This script accesses an existing document and conversation, and checks if Claude can "see" the document content.
"""

import os
import logging
import sys
import asyncio
from pdf_processing.langgraph_service import LangGraphService
from pdf_processing.claude_service import ClaudeService

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

async def check_document_context(document_id=None, conversation_id=None):
    """
    Check if a document can be properly seen by Claude in a conversation context.
    
    Args:
        document_id: ID of an existing document to check (if none provided, use the first one found)
        conversation_id: ID of an existing conversation to check (if none provided, use the first one found)
    """
    try:
        # Initialize Claude Service (which initializes LangGraph)
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            logger.error("ANTHROPIC_API_KEY environment variable is not set")
            return False
            
        logger.info(f"Using API key: {api_key[:8]}...{api_key[-4:]}")
        claude_service = ClaudeService(api_key=api_key)
        langgraph_service = claude_service.langgraph_service
        
        # Mock document content
        mock_document = {
            "id": document_id or "test-doc-1",
            "title": "Test Financial Report",
            "raw_text": "This is a test financial document with important data. Revenue: $1M, Profit: $200K",
            "processed": True
        }
        
        # Test document content preparation
        logger.info(f"Testing document context preparation with document: {mock_document['id']}")
        
        # Create a mock state with the document
        mock_state = {
            "messages": [],
            "documents": [mock_document],
            "citations": [],
            "active_documents": [mock_document["id"]],
            "context": {
                "documents_loaded": True
            }
        }
        
        # Try to prepare document context
        document_context = langgraph_service._prepare_document_context(mock_state)
        
        # Check if document content is included in the context
        if document_context:
            logger.info(f"Document context created successfully! Length: {len(document_context)}")
            logger.info(f"Document context preview: {document_context[:200]}...")
            
            # Verify document content is in context
            if "Revenue: $1M" in document_context:
                logger.info("âœ… Document content is properly included in context")
            else:
                logger.warning("âŒ Document content not found in context")
                
            return True
        else:
            logger.error("Failed to create document context")
            return False
            
    except Exception as e:
        logger.error(f"Error checking document context: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    # Get document ID from command line if provided
    document_id = sys.argv[1] if len(sys.argv) > 1 else None
    conversation_id = sys.argv[2] if len(sys.argv) > 2 else None
    
    result = asyncio.run(check_document_context(document_id, conversation_id))
    
    if result:
        logger.info("Document context check completed successfully")
        sys.exit(0)
    else:
        logger.error("Document context check failed")
        sys.exit(1)
</file>
```

#### claude\_test\.sh
*Size: 3.6 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/claude_test.sh">
#!/bin/bash
set -e

# Define colors for better output readability
GREEN='\033[0;32m'
RED='\033[0;31m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

echo -e "${BLUE}Testing Claude API with PDF citations...${NC}"
echo "This script will create a conversation, upload a PDF, and test the Claude API response"
echo "---------------------------------------------------------------------------------"

# Base URL
API_URL="http://127.0.0.1:8000"

# Step 1: Create a new conversation
echo -e "\n${BLUE}Step 1: Creating a new conversation...${NC}"
CONVERSATION_RESPONSE=$(curl -s -X POST "$API_URL/api/conversation" \
    -H "Content-Type: application/json" \
    -d '{"title":"Mueller Industries Earnings Analysis","user_id":"default-user"}')

echo "Response: $CONVERSATION_RESPONSE"

# Extract conversation ID
CONVERSATION_ID=$(echo $CONVERSATION_RESPONSE | grep -o '"session_id":"[^"]*"' | cut -d'"' -f4)

if [ -z "$CONVERSATION_ID" ]; then
    echo -e "${RED}Failed to create conversation or extract ID${NC}"
    exit 1
fi

echo -e "${GREEN}Created conversation with ID: $CONVERSATION_ID${NC}"

# Step 2: Upload a sample PDF document
echo -e "\n${BLUE}Step 2: Uploading sample PDF document...${NC}"

# Use the provided sample PDF
SAMPLE_PDF="/Users/alexc/Documents/AlexCoding/cfin/ExampleDocs/Mueller Industries Earnings Release.pdf"
if [ ! -f "$SAMPLE_PDF" ]; then
    echo -e "${RED}Sample PDF not found at $SAMPLE_PDF${NC}"
    exit 1
fi

echo -e "${GREEN}Using sample PDF: $SAMPLE_PDF${NC}"

# Upload the PDF using the correct endpoint
DOCUMENT_RESPONSE=$(curl -s -X POST "$API_URL/api/documents/upload" \
    -F "file=@$SAMPLE_PDF" \
    -F "user_id=default-user")

echo "Document response: $DOCUMENT_RESPONSE"

# Extract document ID
DOCUMENT_ID=$(echo $DOCUMENT_RESPONSE | grep -o '"document_id":"[^"]*"' | cut -d'"' -f4)

if [ -z "$DOCUMENT_ID" ]; then
    echo -e "${RED}Failed to upload document or extract ID${NC}"
    exit 1
fi

echo -e "${GREEN}Uploaded document with ID: $DOCUMENT_ID${NC}"

# Step 3: Associate document with conversation
echo -e "\n${BLUE}Step 3: Associating document with conversation...${NC}"
ASSOCIATION_RESPONSE=$(curl -s -X POST "$API_URL/api/conversation/$CONVERSATION_ID/documents/$DOCUMENT_ID" \
    -H "Content-Type: application/json")

echo "Association response: $ASSOCIATION_RESPONSE"

echo -e "${GREEN}Document associated with conversation${NC}"

# Step 4: Send a message to analyze the document
echo -e "\n${BLUE}Step 4: Sending message to analyze the document...${NC}"
MESSAGE_RESPONSE=$(curl -s -X POST "$API_URL/api/conversation/$CONVERSATION_ID/message" \
    -H "Content-Type: application/json" \
    -d "{\"content\":\"What were the key financial results in the Mueller Industries earnings release? Please provide specific figures and give me actual citations to the document that I can verify. I need explicit page numbers where each financial figure appears. Use the citations feature to link each fact directly to the source document. This is very important - please include structured citations for all data.\",\"user_id\":\"default-user\",\"session_id\":\"$CONVERSATION_ID\"}")

echo "Message response: $MESSAGE_RESPONSE"

echo -e "${GREEN}Message sent to analyze document${NC}"

# Step 5: Get conversation history to see the response
echo -e "\n${BLUE}Step 5: Getting conversation history...${NC}"
sleep 5  # Wait a bit longer for processing since we're using a real PDF
HISTORY_RESPONSE=$(curl -s -X GET "$API_URL/api/conversation/$CONVERSATION_ID/history")

echo -e "${GREEN}Conversation history:${NC}"
echo "$HISTORY_RESPONSE" | python -m json.tool

echo -e "\n${BLUE}Test completed!${NC}" 
</file>
```

#### create\_db\.py
*Size: 4.9 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/create_db.py">
#!/usr/bin/env python3
"""
Script to create the database schema for FDAS.
Run this script to initialize the database.
"""

import asyncio
import logging
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy import text
import os

from models.database_models import Base
from utils.database import get_db, SyncSessionLocal, sync_engine

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Get the database URL from environment variables
DATABASE_URL = os.getenv("DATABASE_URL", "sqlite:///./fdas.db")

async def create_database():
    """Create the database tables."""
    try:
        # Create tables
        from models.database_models import (
            User, Document, Citation, MessageCitation, 
            Conversation, ConversationDocument, Message,
            AnalysisResult, AnalysisBlock
        )
        
        # Explicitly import Message for content_blocks column
        logger.info("Ensuring Message model includes content_blocks column")
        
        # Create tables
        async with create_async_engine(
            DATABASE_URL.replace("sqlite:///", "sqlite+aiosqlite:///", 1) if DATABASE_URL.startswith("sqlite") else DATABASE_URL, 
            echo=True
        ) as engine:
            async with engine.begin() as conn:
                logger.info("Creating database tables...")
                await conn.run_sync(Base.metadata.drop_all)
                await conn.run_sync(Base.metadata.create_all)
            
            logger.info("Database tables created successfully.")
            
            # Create default user
            async with AsyncSession(engine) as session:
                # Check if default user exists
                result = await session.execute(text("SELECT id FROM users WHERE username = 'default'"))
                user = result.scalar_one_or_none()
                
                if not user:
                    # Create default user
                    logger.info("Creating default user...")
                    await session.execute(
                        text("""
                            INSERT INTO users (id, username, email, hashed_password, is_active, created_at)
                            VALUES ('default-user', 'default', 'default@example.com', 'not-a-real-password', 1, CURRENT_TIMESTAMP)
                        """)
                    )
                    await session.commit()
                    logger.info("Default user created successfully.")
                else:
                    logger.info("Default user already exists.")
            
            logger.info("Database initialization completed successfully.")
        
    except Exception as e:
        logger.error(f"Error creating database: {str(e)}", exc_info=True)
        raise

def create_database_sync():
    """Create the database tables synchronously."""
    try:
        # Create tables
        from models.database_models import (
            User, Document, Citation, MessageCitation, 
            Conversation, ConversationDocument, Message,
            AnalysisResult, AnalysisBlock
        )
        
        # Explicitly import Message for content_blocks column
        logger.info("Ensuring Message model includes content_blocks column")
        
        # Create tables using sync engine
        logger.info("Creating database tables synchronously...")
        Base.metadata.drop_all(sync_engine)
        Base.metadata.create_all(sync_engine)
        
        logger.info("Database tables created successfully.")
        
        # Create default user
        with SyncSessionLocal() as session:
            # Check if default user exists
            user = session.execute(text("SELECT id FROM users WHERE username = 'default'")).scalar_one_or_none()
            
            if not user:
                # Create default user
                logger.info("Creating default user...")
                session.execute(
                    text("""
                        INSERT INTO users (id, username, email, hashed_password, is_active, created_at)
                        VALUES ('default-user', 'default', 'default@example.com', 'not-a-real-password', 1, CURRENT_TIMESTAMP)
                    """)
                )
                session.commit()
                logger.info("Default user created successfully.")
            else:
                logger.info("Default user already exists.")
        
        logger.info("Database initialization completed successfully.")
        
    except Exception as e:
        logger.error(f"Error creating database: {str(e)}", exc_info=True)
        raise

if __name__ == "__main__":
    logger.info("Initializing database...")
    
    # Run the database creation
    if DATABASE_URL.startswith("sqlite"):
        # SQLite - use synchronous version for simplicity
        create_database_sync()
    else:
        # PostgreSQL or other async-compatible DB - use async version
        asyncio.run(create_database())
</file>
```

#### curl\_test\.sh
*Size: 1.2 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/curl_test.sh">
#!/bin/bash

echo "Testing POST /api/conversation endpoint"
curl -v -X POST "http://127.0.0.1:8000/api/conversation" \
    -H "Content-Type: application/json" \
    -d '{"title":"Test Conversation","user_id":"default-user"}'

# Store the conversation ID from the response
CONVERSATION_ID=$(curl -s -X POST "http://127.0.0.1:8000/api/conversation" \
    -H "Content-Type: application/json" \
    -d '{"title":"Another Test Conversation","user_id":"default-user"}' | \
    grep -o '"session_id":"[^"]*' | sed 's/"session_id":"//')

echo -e "\nConversation ID: $CONVERSATION_ID"

echo -e "\nTesting GET /api/conversation endpoint"
curl -v "http://127.0.0.1:8000/api/conversation"

echo -e "\nTesting GET specific conversation"
curl -v "http://127.0.0.1:8000/api/conversation/$CONVERSATION_ID"

echo -e "\nTesting POST /api/conversation/message endpoint"
curl -v -X POST "http://127.0.0.1:8000/api/conversation/$CONVERSATION_ID/message" \
    -H "Content-Type: application/json" \
    -d "{\"content\":\"What can you tell me about financial analysis?\",\"user_id\":\"default-user\",\"session_id\":\"$CONVERSATION_ID\"}"

echo -e "\nTesting GET conversation history"
curl -v "http://127.0.0.1:8000/api/conversation/$CONVERSATION_ID/history" 
</file>
```

#### data/templates/balance\_sheet\_template\.md
*Size: 3.1 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/data/templates/balance_sheet_template.md">
# Balance Sheet Analysis Template

You are a specialized financial analyst focusing on balance sheet analysis for regional banks. Your analysis MUST use visualization tools to present findings.

## Analysis Structure

### 1. Asset Composition Analysis
Use `generate_graph_data` to create:
- Pie chart showing asset composition
- Bar chart comparing asset categories over time
- Line chart tracking key asset ratios

Required metrics:
- Total assets breakdown
- Loan portfolio composition
- Securities portfolio
- Cash and equivalents
- Other assets

### 2. Liability Structure Analysis
Use `generate_graph_data` to create:
- Stacked bar chart of funding sources
- Line chart of deposit trends
- Area chart of liability composition

Required metrics:
- Deposit composition
- Borrowings breakdown
- Other liabilities
- Cost of funds analysis

### 3. Capital Analysis
Use `generate_graph_data` to create:
- Line chart of capital ratios
- Bar chart of capital components
- Comparison chart with regulatory minimums

Required metrics:
- Tier 1 capital ratio
- Total capital ratio
- Leverage ratio
- Risk-weighted assets

### 4. Key Ratios Table
Use `generate_table_data` to create:
```json
{
  "tableType": "comparison",
  "config": {
    "title": "Key Balance Sheet Ratios",
    "description": "Period over period comparison of key ratios",
    "columns": [
      {"key": "metric", "label": "Metric", "format": "text"},
      {"key": "current", "label": "Current Period", "format": "percentage"},
      {"key": "previous", "label": "Previous Period", "format": "percentage"},
      {"key": "change", "label": "Change", "format": "percentage"}
    ]
  }
}
```

### 5. Period Comparison
Use `generate_table_data` to create detailed comparisons:
```json
{
  "tableType": "matrix",
  "config": {
    "title": "Balance Sheet Comparison",
    "description": "Year over year and quarter over quarter changes",
    "columns": [
      {"key": "category", "label": "Category", "format": "text"},
      {"key": "current_quarter", "label": "Current Quarter", "format": "currency"},
      {"key": "previous_quarter", "label": "Previous Quarter", "format": "currency"},
      {"key": "qoq_change", "label": "QoQ Change", "format": "percentage"},
      {"key": "previous_year", "label": "Previous Year", "format": "currency"},
      {"key": "yoy_change", "label": "YoY Change", "format": "percentage"}
    ]
  }
}
```

## Analysis Guidelines

1. Always start with the largest components of the balance sheet
2. Focus on:
   - Asset quality trends
   - Funding stability
   - Capital adequacy
   - Growth patterns

3. Required Visualizations:
   - Asset composition pie chart
   - Liability structure stacked bar
   - Capital ratios line chart
   - Key metrics comparison table

4. Highlight:
   - Significant changes from prior periods
   - Regulatory compliance status
   - Risk concentrations
   - Funding mix evolution

5. Recommendations should address:
   - Asset-liability matching
   - Capital planning
   - Growth opportunities
   - Risk mitigation

Remember: NEVER describe data in text - ALWAYS use the visualization tools to present findings. 
</file>
```

#### data/templates/cash\_flow\_template\.md
*Size: 3.3 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/data/templates/cash_flow_template.md">
# Cash Flow Analysis Template

You are a specialized financial analyst focusing on cash flow analysis for regional banks. Your analysis MUST use visualization tools to present findings.

## Analysis Structure

### 1. Operating Cash Flow Analysis
Use `generate_graph_data` to create:
- Line chart of operating cash flow trends
- Bar chart of major operating cash components
- Area chart showing cumulative cash generation

Required metrics:
- Net income adjustments
- Working capital changes
- Non-cash item impact
- Core operating cash flow
- Operating cash flow ratio

### 2. Investing Activities Analysis
Use `generate_graph_data` to create:
- Stacked bar chart of investment activities
- Line chart of investment trends
- Pie chart of investment allocation

Required metrics:
- Capital expenditures
- Investment securities activity
- Acquisition investments
- Divestiture proceeds
- Net investment cash flow

### 3. Financing Activities Analysis
Use `generate_graph_data` to create:
- Bar chart of financing sources and uses
- Line chart of debt levels
- Area chart of capital structure changes

Required metrics:
- Debt issuance/repayment
- Dividend payments
- Share repurchases
- Capital raising activities
- Net financing cash flow

### 4. Liquidity Metrics Table
Use `generate_table_data` to create:
```json
{
  "tableType": "comparison",
  "config": {
    "title": "Key Liquidity Metrics",
    "description": "Period over period comparison of liquidity metrics",
    "columns": [
      {"key": "metric", "label": "Metric", "format": "text"},
      {"key": "current", "label": "Current Period", "format": "percentage"},
      {"key": "previous", "label": "Previous Period", "format": "percentage"},
      {"key": "change", "label": "Change", "format": "percentage"}
    ]
  }
}
```

### 5. Cash Flow Summary
Use `generate_table_data` to create:
```json
{
  "tableType": "matrix",
  "config": {
    "title": "Cash Flow Components Analysis",
    "description": "Detailed analysis of cash flow components",
    "columns": [
      {"key": "component", "label": "Component", "format": "text"},
      {"key": "current_quarter", "label": "Current Quarter", "format": "currency"},
      {"key": "qoq_change", "label": "QoQ Change", "format": "percentage"},
      {"key": "ytd_amount", "label": "Year to Date", "format": "currency"},
      {"key": "yoy_change", "label": "YoY Change", "format": "percentage"},
      {"key": "impact", "label": "Impact Rating", "format": "text"}
    ]
  }
}
```

## Analysis Guidelines

1. Focus on cash flow quality:
   - Operating cash sustainability
   - Investment strategy effectiveness
   - Financing efficiency
   - Liquidity management

2. Required Visualizations:
   - Operating cash flow trend chart
   - Investment activity breakdown
   - Financing activities analysis
   - Liquidity metrics dashboard

3. Highlight:
   - Cash flow sustainability
   - Investment patterns
   - Financing decisions
   - Liquidity position
   - Working capital efficiency

4. Analyze:
   - Free cash flow generation
   - Investment requirements
   - Funding needs
   - Dividend sustainability
   - Capital allocation

5. Recommendations should address:
   - Working capital optimization
   - Investment prioritization
   - Financing strategy
   - Liquidity management
   - Capital allocation strategy

Remember: NEVER describe data in text - ALWAYS use the visualization tools to present findings. 
</file>
```

#### data/templates/income\_statement\_template\.md
*Size: 3.2 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/data/templates/income_statement_template.md">
# Income Statement Analysis Template

You are a specialized financial analyst focusing on income statement analysis for regional banks. Your analysis MUST use visualization tools to present findings.

## Analysis Structure

### 1. Revenue Analysis
Use `generate_graph_data` to create:
- Line chart of net interest income trends
- Stacked bar chart of non-interest income sources
- Area chart of total revenue composition

Required metrics:
- Net interest income
- Non-interest income breakdown
- Net interest margin
- Yield on earning assets
- Cost of funds

### 2. Expense Analysis
Use `generate_graph_data` to create:
- Pie chart of expense composition
- Bar chart comparing expense categories
- Line chart of efficiency ratio

Required metrics:
- Personnel expenses
- Occupancy costs
- Technology expenses
- Other operating expenses
- Efficiency ratio

### 3. Profitability Analysis
Use `generate_graph_data` to create:
- Line chart of key profitability metrics
- Bar chart of income components
- Comparison chart with peer averages

Required metrics:
- Return on assets (ROA)
- Return on equity (ROE)
- Net interest margin (NIM)
- Pre-provision net revenue
- Net income

### 4. Performance Metrics Table
Use `generate_table_data` to create:
```json
{
  "tableType": "comparison",
  "config": {
    "title": "Key Performance Metrics",
    "description": "Quarter over quarter comparison of key metrics",
    "columns": [
      {"key": "metric", "label": "Metric", "format": "text"},
      {"key": "current", "label": "Current Quarter", "format": "percentage"},
      {"key": "previous", "label": "Previous Quarter", "format": "percentage"},
      {"key": "change", "label": "Change", "format": "percentage"}
    ]
  }
}
```

### 5. Trend Analysis
Use `generate_table_data` to create:
```json
{
  "tableType": "matrix",
  "config": {
    "title": "Income Statement Trends",
    "description": "Multi-period trend analysis",
    "columns": [
      {"key": "category", "label": "Category", "format": "text"},
      {"key": "current_quarter", "label": "Current Quarter", "format": "currency"},
      {"key": "qoq_change", "label": "QoQ Change", "format": "percentage"},
      {"key": "ytd", "label": "Year to Date", "format": "currency"},
      {"key": "yoy_change", "label": "YoY Change", "format": "percentage"},
      {"key": "trailing_twelve", "label": "Trailing 12M", "format": "currency"}
    ]
  }
}
```

## Analysis Guidelines

1. Focus on core earnings components:
   - Net interest income trends
   - Non-interest income diversity
   - Expense management
   - Credit quality impact

2. Required Visualizations:
   - Revenue composition chart
   - Expense breakdown pie chart
   - Profitability metrics line chart
   - Performance comparison table

3. Highlight:
   - Margin pressure/expansion
   - Fee income trends
   - Expense control effectiveness
   - Credit cost impact
   - Core vs non-core earnings

4. Analyze:
   - Operating leverage
   - Revenue sustainability
   - Cost management effectiveness
   - Earnings quality
   - Growth drivers

5. Recommendations should address:
   - Revenue enhancement opportunities
   - Cost optimization strategies
   - Profitability improvement
   - Risk-adjusted returns

Remember: NEVER describe data in text - ALWAYS use the visualization tools to present findings. 
</file>
```

#### data/templates/template\_loader\.py
*Size: 3.2 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/data/templates/template_loader.py">
"""
Template loader utility for financial analysis templates.
Provides easy access to specialized analysis templates.
"""

import os
from typing import Dict, Optional
from pathlib import Path

class TemplateLoader:
    """Loads and manages financial analysis templates."""
    
    def __init__(self):
        """Initialize the template loader."""
        self.template_dir = Path(__file__).parent
        self.templates: Dict[str, str] = {}
        self._load_templates()
    
    def _load_templates(self) -> None:
        """Load all available templates."""
        template_files = {
            'balance_sheet': 'balance_sheet_template.md',
            'income_statement': 'income_statement_template.md',
            'cash_flow': 'cash_flow_template.md'
        }
        
        for key, filename in template_files.items():
            path = self.template_dir / filename
            try:
                with open(path, 'r') as f:
                    self.templates[key] = f.read()
            except FileNotFoundError:
                print(f"Warning: Template file {filename} not found")
    
    def get_template(self, template_type: str) -> Optional[str]:
        """
        Get a specific template by type.
        
        Args:
            template_type: Type of template ('balance_sheet', 'income_statement', or 'cash_flow')
            
        Returns:
            Template content if found, None otherwise
        """
        return self.templates.get(template_type)
    
    def get_combined_template(self, template_types: list[str]) -> str:
        """
        Combine multiple templates for comprehensive analysis.
        
        Args:
            template_types: List of template types to combine
            
        Returns:
            Combined template content
        """
        templates = []
        for template_type in template_types:
            if template := self.get_template(template_type):
                templates.append(template)
        
        return "\n\n".join(templates)
    
    def list_available_templates(self) -> list[str]:
        """List all available template types."""
        return list(self.templates.keys())
    
    def get_template_preview(self, template_type: str, max_length: int = 200) -> Optional[str]:
        """
        Get a preview of a template.
        
        Args:
            template_type: Type of template to preview
            max_length: Maximum length of preview
            
        Returns:
            Template preview if found, None otherwise
        """
        if template := self.get_template(template_type):
            preview = template.split('\n')[0:5]
            return '\n'.join(preview) + '...'
        return None

# Example usage:
if __name__ == "__main__":
    loader = TemplateLoader()
    
    # List available templates
    print("Available templates:", loader.list_available_templates())
    
    # Get a specific template
    if balance_sheet_template := loader.get_template('balance_sheet'):
        print("\nBalance Sheet Template Preview:")
        print(loader.get_template_preview('balance_sheet'))
    
    # Combine templates for comprehensive analysis
    comprehensive = loader.get_combined_template(['balance_sheet', 'income_statement', 'cash_flow'])
    print("\nComprehensive Analysis Template Created") 
</file>
```

#### debug\_server\.py
*Size: 990 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/debug_server.py">
#!/usr/bin/env python
import sys
import os
from pathlib import Path
import logging
import uvicorn

# Set up logging
logging.basicConfig(level=logging.DEBUG)

# Configure Python's path to include the project root
current_dir = Path(__file__).parent.absolute()
parent_dir = current_dir.parent
sys.path.append(str(current_dir))
sys.path.append(str(parent_dir))

# Import the FastAPI app manually to see any import errors
print("Trying to import the FastAPI app...")
try:
    from app.main import app
    print("Successfully imported the FastAPI app!")
except Exception as e:
    print(f"ERROR importing app.main: {e}")
    raise

if __name__ == "__main__":
    print(f"Current directory: {current_dir}")
    print(f"Parent directory: {parent_dir}")
    print(f"sys.path: {sys.path}")
    
    # Start the FastAPI server
    uvicorn.run(
        "app.main:app",
        host="127.0.0.1",
        port=8000,
        reload=False,  # Disable reload to see errors
        log_level="debug",
    ) 
</file>
```

#### main\.py
*Size: 2.1 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/main.py">
import os
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import logging
from dotenv import load_dotenv

from cfin.backend.app.routes import document, conversation, analysis
from pdf_processing.langgraph_service import LangGraphService

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

# Initialize application
app = FastAPI(title="Financial Document Analysis Service API")

# Configure CORS
origins = [
    "http://localhost:3000",
    "http://localhost:8000",
    "https://fdas.vercel.app",
    os.getenv("FRONTEND_URL", ""),
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize services
@app.on_event("startup")
async def startup_event():
    logger.info("Initializing services...")
    # Initialize LangGraph service (will be created on demand through dependency injection)
    try:
        # Validate environment variables are set for LangGraph
        if not os.getenv("ANTHROPIC_API_KEY"):
            logger.warning("ANTHROPIC_API_KEY environment variable not set")
        
        logger.info("Services initialized successfully")
    except Exception as e:
        logger.error(f"Error initializing services: {e}")

# Include API routers
app.include_router(document.router, prefix="/api")
app.include_router(conversation.router, prefix="/api")
app.include_router(analysis.router, prefix="/api")

# Health check endpoint
@app.get("/health")
async def health_check():
    return {"status": "healthy", "version": "0.2.0"}

# Add version endpoint
@app.get("/version")
async def version():
    return {
        "version": "0.2.0",
        "name": "Financial Document Analysis Service",
        "features": [
            "Document processing",
            "Claude integration with citations",
            "LangGraph conversation state management",
            "Financial data extraction"
        ]
    } 
</file>
```

#### models/\_\_init\_\_\.py
*Size: 78 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/models/__init__.py">
# This file is intentionally left empty to make the directory a Python package
</file>
```

#### models/analysis\.py
*Size: 2.6 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/models/analysis.py">
from typing import Dict, List, Optional, Any, Literal
from datetime import datetime
import uuid
from pydantic import BaseModel, Field, UUID4, ConfigDict


class FinancialRatio(BaseModel):
    name: str
    value: float
    description: str
    benchmark: Optional[float] = None
    trend: Optional[float] = None


class FinancialMetric(BaseModel):
    category: str
    name: str
    period: str
    value: float
    unit: str
    isEstimated: bool = Field(default=False, alias="is_estimated")
    
    model_config = ConfigDict(
        populate_by_name=True,
        alias_generator=None,
        validate_assignment=True,
        protected_namespaces=()
    )


class ComparativePeriod(BaseModel):
    metric: str
    currentPeriod: str = Field(alias="current_period")
    previousPeriod: str = Field(alias="previous_period")
    currentValue: float = Field(alias="current_value")
    previousValue: float = Field(alias="previous_value")
    change: float
    percentChange: float = Field(alias="percent_change")
    trend: Literal["positive", "negative", "neutral"] = "neutral"
    
    model_config = ConfigDict(
        populate_by_name=True,
        alias_generator=None,
        validate_assignment=True,
        protected_namespaces=()
    )


class AnalysisResult(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    documentIds: List[str] = Field(alias="document_ids")
    analysisType: str = Field(alias="analysis_type")
    timestamp: datetime = Field(default_factory=datetime.now)
    metrics: List[FinancialMetric] = Field(default_factory=list)
    ratios: List[FinancialRatio] = Field(default_factory=list)
    insights: List[str] = Field(default_factory=list)
    visualizationData: Dict[str, Any] = Field(default_factory=dict, alias="visualization_data")
    citationReferences: Dict[str, str] = Field(default_factory=dict, alias="citation_references")
    comparativePeriods: List[ComparativePeriod] = Field(default_factory=list, alias="comparative_periods")
    analysisText: Optional[str] = Field(default=None, alias="analysis_text")
    
    model_config = ConfigDict(
        populate_by_name=True,
        alias_generator=None,
        validate_assignment=True,
        protected_namespaces=()
    )


class AnalysisRequest(BaseModel):
    analysisType: str = Field(alias="analysis_type")
    documentIds: List[str] = Field(alias="document_ids")
    parameters: Dict[str, Any] = Field(default_factory=dict)
    query: Optional[str] = None
    
    model_config = ConfigDict(
        populate_by_name=True,
        alias_generator=None,
        validate_assignment=True,
        protected_namespaces=()
    )
</file>
```

#### models/api\_models\.py
*Size: 515 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/models/api_models.py">
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any, Literal

class RetryExtractionRequest(BaseModel):
    """
    Request model for retrying document extraction
    """
    extraction_type: Literal["structured_financial_data", "text_only", "tables_only"] = Field(
        "structured_financial_data", 
        description="Type of extraction to perform"
    )
    options: Optional[Dict[str, Any]] = Field(
        None,
        description="Additional options for extraction"
    ) 
</file>
```

#### models/citation\.py
*Size: 1.5 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/models/citation.py">
from enum import Enum
from typing import Dict, List, Optional, Any, Union, Literal
from pydantic import BaseModel, Field

class CitationType(str, Enum):
    CHAR_LOCATION = "char_location"
    PAGE_LOCATION = "page_location"
    CONTENT_BLOCK_LOCATION = "content_block_location"

class CitationBase(BaseModel):
    """Base class for all citation types."""
    type: CitationType
    cited_text: str
    document_index: int
    document_title: str

class CharLocationCitation(CitationBase):
    """Citation for plain text documents."""
    type: Literal[CitationType.CHAR_LOCATION] = CitationType.CHAR_LOCATION
    start_char_index: int
    end_char_index: int

class PageLocationCitation(CitationBase):
    """Citation for PDF documents."""
    type: Literal[CitationType.PAGE_LOCATION] = CitationType.PAGE_LOCATION
    start_page_number: int
    end_page_number: int

class ContentBlockLocationCitation(CitationBase):
    """Citation for custom content documents."""
    type: Literal[CitationType.CONTENT_BLOCK_LOCATION] = CitationType.CONTENT_BLOCK_LOCATION
    start_block_index: int
    end_block_index: int

# Generic Citation type that could be any of the specific citation types
Citation = Union[CharLocationCitation, PageLocationCitation, ContentBlockLocationCitation]

class ContentBlock(BaseModel):
    """Model for a content block in Claude's response."""
    type: Literal["text"] = "text"
    text: str
    citations: Optional[List[Citation]] = None

class AnthropicMessage(BaseModel):
    """Model for a message in Claude's response."""
    content: List[ContentBlock] 
</file>
```

#### models/database\_models\.py
*Size: 7.0 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/models/database_models.py">
from sqlalchemy import Column, Integer, String, Float, DateTime, ForeignKey, Text, JSON, Boolean, Enum as SQLAlchemyEnum
from sqlalchemy.orm import relationship
import uuid
from datetime import datetime
import enum
from typing import List, Dict, Any, Optional

from utils.database import Base


class DocumentType(enum.Enum):
    BALANCE_SHEET = "balance_sheet"
    INCOME_STATEMENT = "income_statement"
    CASH_FLOW = "cash_flow"
    NOTES = "notes"
    OTHER = "other"


class ProcessingStatusEnum(enum.Enum):
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"


def generate_uuid():
    return str(uuid.uuid4())


class User(Base):
    """User model for authentication."""
    __tablename__ = "users"
    
    id = Column(String, primary_key=True, default=generate_uuid)
    username = Column(String, unique=True, index=True)
    email = Column(String, unique=True, index=True)
    hashed_password = Column(String)
    is_active = Column(Boolean, default=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    documents = relationship("Document", back_populates="user")
    conversations = relationship("Conversation", back_populates="user")


class Document(Base):
    """Document model for storing uploaded financial documents."""
    __tablename__ = "documents"
    
    id = Column(String, primary_key=True, default=generate_uuid)
    filename = Column(String, nullable=False)
    file_path = Column(String, nullable=False)  # Path or URL to the stored file
    file_size = Column(Integer, nullable=False)
    mime_type = Column(String, nullable=False)
    upload_timestamp = Column(DateTime, default=datetime.utcnow)
    user_id = Column(String, ForeignKey("users.id"))
    
    # Document processing fields
    document_type = Column(SQLAlchemyEnum(DocumentType), default=DocumentType.OTHER)
    processing_status = Column(SQLAlchemyEnum(ProcessingStatusEnum), default=ProcessingStatusEnum.PENDING)
    processing_timestamp = Column(DateTime)
    extraction_timestamp = Column(DateTime)
    confidence_score = Column(Float, default=0.0)
    error_message = Column(Text)
    
    # Document content
    raw_text = Column(Text)
    periods = Column(JSON, default=lambda: [])
    extracted_data = Column(JSON, default=lambda: {})
    
    # Relationships
    user = relationship("User", back_populates="documents")
    citations = relationship("Citation", back_populates="document", cascade="all, delete-orphan")
    analysis_results = relationship("AnalysisResult", back_populates="document")
    conversations = relationship(
        "Conversation", 
        secondary="conversation_documents",
        back_populates="documents",
        primaryjoin="Document.id == ConversationDocument.document_id",
        secondaryjoin="ConversationDocument.conversation_id == Conversation.id"
    )


class Citation(Base):
    """Citation model for storing document citations."""
    __tablename__ = "citations"
    
    id = Column(String, primary_key=True, default=generate_uuid)
    document_id = Column(String, ForeignKey("documents.id"), nullable=False)
    page = Column(Integer, nullable=False)
    text = Column(Text, nullable=False)
    section = Column(String)
    bounding_box = Column(JSON)  # JSON object with coordinates
    
    # Relationships
    document = relationship("Document", back_populates="citations")
    messages = relationship("MessageCitation", back_populates="citation")


class MessageCitation(Base):
    """Many-to-many relationship between messages and citations."""
    __tablename__ = "message_citations"
    
    message_id = Column(String, ForeignKey("messages.id"), primary_key=True)
    citation_id = Column(String, ForeignKey("citations.id"), primary_key=True)
    
    # Relationships
    message = relationship("Message", back_populates="citations")
    citation = relationship("Citation", back_populates="messages")


class Conversation(Base):
    """Conversation model for storing chat interactions."""
    __tablename__ = "conversations"
    
    id = Column(String, primary_key=True, default=generate_uuid)
    title = Column(String, nullable=False)
    user_id = Column(String, ForeignKey("users.id"))
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    # Relationships
    user = relationship("User", back_populates="conversations")
    messages = relationship("Message", back_populates="conversation", cascade="all, delete-orphan")
    documents = relationship(
        "Document", 
        secondary="conversation_documents",
        back_populates="conversations",
        primaryjoin="Conversation.id == ConversationDocument.conversation_id",
        secondaryjoin="ConversationDocument.document_id == Document.id"
    )


class ConversationDocument(Base):
    """Many-to-many relationship between conversations and documents."""
    __tablename__ = "conversation_documents"
    
    conversation_id = Column(String, ForeignKey("conversations.id"), primary_key=True)
    document_id = Column(String, ForeignKey("documents.id"), primary_key=True)


class Message(Base):
    """Message model for storing conversation messages."""
    __tablename__ = "messages"
    
    id = Column(String, primary_key=True, default=generate_uuid)
    conversation_id = Column(String, ForeignKey("conversations.id"), nullable=False)
    content = Column(Text, nullable=False)
    role = Column(String, nullable=False)  # "user" or "assistant"
    created_at = Column(DateTime, default=datetime.utcnow)
    content_blocks = Column(JSON)  # Store structured content blocks from Claude API
    
    # Relationships
    conversation = relationship("Conversation", back_populates="messages")
    citations = relationship("MessageCitation", back_populates="message")
    analysis_blocks = relationship("AnalysisBlock", back_populates="message", cascade="all, delete-orphan")


class AnalysisResult(Base):
    """Analysis result model for storing document analysis results."""
    __tablename__ = "analysis_results"
    
    id = Column(String, primary_key=True, default=generate_uuid)
    document_id = Column(String, ForeignKey("documents.id"), nullable=False)
    analysis_type = Column(String, nullable=False)  # e.g., "financial_ratios", "sentiment", etc.
    result_data = Column(JSON, nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relationships
    document = relationship("Document", back_populates="analysis_results")


class AnalysisBlock(Base):
    """Analysis block model for storing message-related analysis blocks."""
    __tablename__ = "analysis_blocks"
    
    id = Column(String, primary_key=True, default=generate_uuid)
    message_id = Column(String, ForeignKey("messages.id"), nullable=False)
    block_type = Column(String, nullable=False)  # e.g., "chart", "insight", etc.
    title = Column(String)
    content = Column(JSON, nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relationships
    message = relationship("Message", back_populates="analysis_blocks")
</file>
```

#### models/document\.py
*Size: 1.6 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/models/document.py">
from enum import Enum
from typing import Dict, List, Optional, Any, Union
from datetime import datetime
import uuid
from pydantic import BaseModel, Field, UUID4


class DocumentContentType(str, Enum):
    BALANCE_SHEET = "balance_sheet"
    INCOME_STATEMENT = "income_statement"
    CASH_FLOW = "cash_flow"
    NOTES = "notes"
    OTHER = "other"


class ProcessingStatus(str, Enum):
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"


class Citation(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    page: int
    text: str
    bounding_box: Optional[Dict[str, float]] = None
    section: Optional[str] = None


class DocumentMetadata(BaseModel):
    id: UUID4 = Field(default_factory=uuid.uuid4)
    filename: str
    upload_timestamp: datetime = Field(default_factory=datetime.now)
    file_size: int
    mime_type: str
    user_id: str
    citation_links: List[str] = Field(default_factory=list)


class ProcessedDocument(BaseModel):
    metadata: DocumentMetadata
    content_type: DocumentContentType = DocumentContentType.OTHER
    extraction_timestamp: datetime = Field(default_factory=datetime.now)
    periods: List[str] = Field(default_factory=list)
    extracted_data: Dict[str, Any] = Field(default_factory=dict)
    citations: List[Citation] = Field(default_factory=list)
    confidence_score: float = 0.0
    processing_status: ProcessingStatus = ProcessingStatus.PENDING
    error_message: Optional[str] = None


class DocumentUploadResponse(BaseModel):
    document_id: UUID4
    filename: str
    status: ProcessingStatus
    message: str
</file>
```

#### models/error\.py
*Size: 1.8 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/models/error.py">
"""
Standard error response models for API endpoints.
"""
from typing import List, Dict, Any, Optional, Union
from pydantic import BaseModel, Field


class ValidationErrorDetail(BaseModel):
    """Detailed validation error for a specific field."""
    loc: List[Union[str, int]] = Field(
        ..., 
        description="Location of the error (field path)"
    )
    msg: str = Field(..., description="Error message")
    type: str = Field(..., description="Error type")


class ErrorResponse(BaseModel):
    """Standard error response model for all API endpoints."""
    status_code: int = Field(..., description="HTTP status code")
    detail: Union[str, List[ValidationErrorDetail], Dict[str, Any]] = Field(
        ...,
        description="Error details - can be a string message, validation errors array, or structured data"
    )
    error_type: Optional[str] = Field(
        None, 
        description="Optional error type for categorization (not_found, validation_error, etc.)"
    )
    
    class Config:
        schema_extra = {
            "example": {
                "status_code": 404,
                "detail": "Resource not found",
                "error_type": "not_found"
            }
        }


def create_error_response(
    status_code: int, 
    detail: Union[str, List[ValidationErrorDetail], Dict[str, Any]],
    error_type: Optional[str] = None
) -> Dict[str, Any]:
    """
    Create a standardized error response dictionary.
    
    Args:
        status_code: HTTP status code
        detail: Error details (string, validation errors, or structured data)
        error_type: Optional error type for categorization
        
    Returns:
        Dictionary with standardized error format
    """
    return ErrorResponse(
        status_code=status_code,
        detail=detail,
        error_type=error_type
    ).dict()
</file>
```

#### models/message\.py
*Size: 2.3 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/models/message.py">
from enum import Enum
from typing import List, Optional, Dict, Any, Union
from datetime import datetime
import uuid
from pydantic import BaseModel, Field, UUID4

from models.citation import Citation, ContentBlock


class MessageRole(str, Enum):
    USER = "user"
    ASSISTANT = "assistant"
    SYSTEM = "system"


class Message(BaseModel):
    id: UUID4 = Field(default_factory=uuid.uuid4)
    session_id: str
    timestamp: datetime = Field(default_factory=datetime.now)
    role: MessageRole
    content: str
    referenced_documents: List[str] = Field(default_factory=list)
    referenced_analyses: List[str] = Field(default_factory=list)
    citation_links: List[str] = Field(default_factory=list)
    citations: Optional[List[Citation]] = Field(default_factory=list)
    content_blocks: Optional[List[ContentBlock]] = None


class ConversationState(BaseModel):
    session_id: str
    active_documents: List[str] = Field(default_factory=list)
    active_analyses: List[str] = Field(default_factory=list)
    current_focus: Optional[str] = None
    user_preferences: Dict[str, Any] = Field(default_factory=dict)
    last_updated: datetime = Field(default_factory=datetime.now)
    message_history: List[Dict[str, Any]] = Field(default_factory=list)


class MessageRequest(BaseModel):
    session_id: str
    content: str
    user_id: str = "default-user"
    referenced_documents: List[str] = Field(default_factory=list)
    referenced_analyses: List[str] = Field(default_factory=list)
    citation_links: List[str] = Field(default_factory=list)
    citation_ids: Optional[List[str]] = Field(default_factory=list)


class ConversationCreateRequest(BaseModel):
    title: str
    user_id: str = "default-user"
    document_ids: Optional[List[str]] = None
    metadata: Optional[Dict[str, Any]] = None


class MessageResponse(BaseModel):
    id: str
    session_id: str
    timestamp: datetime
    role: MessageRole
    content: str
    referenced_documents: List[str] = Field(default_factory=list)
    referenced_analyses: List[str] = Field(default_factory=list)
    citation_links: List[str] = Field(default_factory=list)
    citations: Optional[List[Citation]] = None
    content_blocks: Optional[List[ContentBlock]] = None


class ConversationHistoryResponse(BaseModel):
    session_id: str
    messages: List[MessageResponse]
    has_more: bool = False
    next_cursor: Optional[str] = None
</file>
```

#### models/tools\.py
*Size: 11.8 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/models/tools.py">
from typing import Dict, List, Optional, Any, Literal, Union
from pydantic import BaseModel, Field, ConfigDict, RootModel
import logging

logger = logging.getLogger(__name__)

# Base Tool Schema
class ToolSchema(BaseModel):
    """Base model for tool definitions to be used with Claude API."""
    name: str
    description: str
    input_schema: Dict[str, Any]
    cache_control: Optional[Dict[str, str]] = Field(default=None, description="Optional cache control settings")

    model_config = ConfigDict(
        populate_by_name=True,
        alias_generator=None,
        validate_assignment=True,
        protected_namespaces=()
    )

# --- Chart Generation Tool ---

class ChartMetricConfig(BaseModel):
    """Configuration for a single metric/series in a chart."""
    label: str = Field(description="Display label for the metric/series")
    color: Optional[str] = Field(default=None, description="Hex color code for the series (e.g., '#8884d8')")
    unit: Optional[str] = Field(default=None, description="Unit for the metric (e.g., '$', '%')")
    formatter: Optional[str] = Field(default=None, description="Formatting type (e.g., 'currency', 'percent', 'compact')")
    precision: Optional[int] = Field(default=None, description="Number of decimal places for formatting")

class ChartConfig(BaseModel):
    """Configuration for the overall chart appearance and axes."""
    title: str = Field(description="Main title of the chart")
    description: Optional[str] = Field(default=None, description="Subtitle or description below the title")
    xAxisKey: Optional[str] = Field(default="name", description="The key in the 'data' array objects representing the x-axis category/label (e.g., 'period', 'category', 'name')")
    yAxisKey: Optional[str] = Field(default=None, description="The key for y-axis values if only one series (used less often with chartConfig)")
    xAxisLabel: Optional[str] = Field(default=None, description="Label for the x-axis")
    yAxisLabel: Optional[str] = Field(default=None, description="Label for the y-axis")
    showLegend: bool = Field(default=True, description="Whether to display the chart legend")
    legendPosition: Optional[Literal["top", "bottom", "left", "right"]] = Field(default="bottom", description="Position of the legend")
    showGrid: Optional[bool] = Field(default=True, description="Whether to show the chart grid lines")
    stack: Optional[bool] = Field(default=False, description="Whether bars/areas should be stacked")
    colors: Optional[List[str]] = Field(default=None, description="Optional list of hex colors for chart series")
    footer: Optional[str] = Field(default=None, description="Optional text to display below the chart")
    totalLabel: Optional[str] = Field(default=None, description="Optional label for displaying a total (e.g., for pie charts)")

class ChartDataItem(RootModel):
    """Represents a single data point or category in the chart data array."""
    # Example structure: { "name": "Q1 2023", "revenue": 120000, "profit": 35000 }
    # The specific keys (like 'revenue', 'profit') are defined dynamically
    # and should match the keys in chartConfig.
    # The key used for the x-axis label must match ChartConfig.xAxisKey.
    root: Dict[str, Union[str, float, int, None]] = Field(description="A flexible dictionary for chart data points")

class ChartGenerationInputSchema(BaseModel):
    """Input schema for the generate_graph_data tool."""
    chartType: Literal["bar", "multiBar", "line", "pie", "area", "stackedArea", "scatter"] = Field(description="The type of chart to generate")
    config: ChartConfig = Field(description="Overall configuration for the chart")
    data: List[Dict[str, Any]] = Field(description="The array of data points for the chart. Each object represents a category/period. Keys should match xAxisKey and keys in chartConfig.")
    chartConfig: Dict[str, ChartMetricConfig] = Field(description="Configuration for each metric/series being plotted. Keys must match the metric keys in the 'data' objects.")

class ChartGenerationTool(ToolSchema):
    """Tool for generating chart data in a format consumable by the frontend ChartRenderer."""
    name: str = "generate_graph_data"
    description: str = """Use this tool to generate structured JSON data for financial charts and graphs (bar, line, pie, area, scatter).
    Specify the chartType, provide general config (title, axis labels), the data array, and chartConfig for each series/metric.
    The 'data' array objects must contain a key matching 'config.xAxisKey' and keys matching the keys used in 'chartConfig'.
    For pie charts, 'data' objects typically have 'name' and 'value' keys.
    """
    input_schema: Dict[str, Any] = ChartGenerationInputSchema.model_json_schema()

# --- Table Generation Tool ---

class TableColumnConfig(BaseModel):
    """Configuration for a single table column."""
    key: str = Field(description="The key in the 'data' array objects for this column")
    label: str = Field(description="The display label for the column header")
    header: Optional[str] = Field(default=None, description="Alternative header text (if label is different)")
    format: Optional[Literal["number", "currency", "percentage", "text", "date"]] = Field(default="text", description="How to format the data in this column")
    width: Optional[int] = Field(default=None, description="Optional fixed width for the column in pixels")
    align: Optional[Literal["left", "center", "right"]] = Field(default="left", description="Text alignment for the column")

class TableConfig(BaseModel):
    """Configuration for the overall table appearance and behavior."""
    title: str = Field(description="Main title of the table")
    description: Optional[str] = Field(default=None, description="Subtitle or description below the title")
    footer: Optional[str] = Field(default=None, description="Optional text to display below the table")
    columns: List[TableColumnConfig] = Field(description="Array defining the columns of the table")
    showRowNumbers: Optional[bool] = Field(default=False, description="Whether to display row numbers")
    sortable: Optional[bool] = Field(default=True, description="Whether columns should be sortable")
    pagination: Optional[bool] = Field(default=True, description="Whether to enable pagination")
    pageSize: Optional[int] = Field(default=10, description="Number of rows per page if pagination is enabled")

class TableGenerationInputSchema(BaseModel):
    """Input schema for the generate_table_data tool."""
    tableType: Literal["simple", "matrix", "comparison", "detailed"] = Field(default="simple", description="The general type or purpose of the table")
    config: TableConfig = Field(description="Configuration for the table structure and appearance")
    data: List[Dict[str, Any]] = Field(description="The array of data objects representing table rows. Keys in objects must match 'config.columns.key'.")

class TableGenerationTool(ToolSchema):
    """Tool for generating structured tabular data for financial information."""
    name: str = "generate_table_data"
    description: str = """Use this tool to generate structured JSON data for creating financial data tables.
    Specify the tableType (e.g., 'comparison', 'detailed'), provide config (title, column definitions), and the data array.
    The 'data' objects' keys must match the 'key' values defined in 'config.columns'.
    Use appropriate 'format' values in column definitions (number, currency, percentage, text, date)."""
    input_schema: Dict[str, Any] = TableGenerationInputSchema.model_json_schema()

# Keep the existing FinancialMetricGenerationTool and ComparativePeriodGenerationTool
class FinancialMetricGenerationTool(ToolSchema):
    """Tool for generating financial metrics."""
    name: str = "generate_financial_metric"
    description: str = """Generate structured financial metrics with period information.
    
Metrics should include:
- Category: The metric category (Revenue, Expenses, Assets, etc.)
- Name: The specific metric name
- Period: The time period the metric applies to
- Value: The numeric value
- Unit: The unit of measurement (%, $, etc.)
- IsEstimated: Whether the value is estimated or directly from the document
"""
    
    input_schema: Dict[str, Any] = {
        "type": "object",
        "properties": {
            "category": {
                "type": "string",
                "description": "The category of the financial metric"
            },
            "name": {
                "type": "string",
                "description": "The name of the financial metric"
            },
            "period": {
                "type": "string",
                "description": "The time period the metric applies to"
            },
            "value": {
                "type": "number",
                "description": "The value of the metric"
            },
            "unit": {
                "type": "string",
                "description": "The unit of measurement (%, $, etc.)"
            },
            "isEstimated": {
                "type": "boolean",
                "description": "Whether the value is estimated"
            }
        },
        "required": ["category", "name", "period", "value"]
    }

class ComparativePeriodGenerationTool(ToolSchema):
    """Tool for generating comparative period data."""
    name: str = "generate_comparative_period"
    description: str = """Generate structured data for period-over-period comparisons.
    
Comparative periods should include:
- Metric: The metric being compared
- CurrentPeriod: The current time period
- PreviousPeriod: The previous time period
- CurrentValue: The value in the current period
- PreviousValue: The value in the previous period
- Change: The absolute change
- PercentChange: The percentage change
- Trend: Whether the change is positive, negative, or neutral
"""
    
    input_schema: Dict[str, Any] = {
        "type": "object",
        "properties": {
            "metric": {
                "type": "string",
                "description": "The metric being compared"
            },
            "currentPeriod": {
                "type": "string",
                "description": "The current time period"
            },
            "previousPeriod": {
                "type": "string",
                "description": "The previous time period"
            },
            "currentValue": {
                "type": "number",
                "description": "The value in the current period"
            },
            "previousValue": {
                "type": "number",
                "description": "The value in the previous period"
            },
            "change": {
                "type": "number",
                "description": "The absolute change"
            },
            "percentChange": {
                "type": "number",
                "description": "The percentage change"
            },
            "trend": {
                "type": "string",
                "enum": ["positive", "negative", "neutral"],
                "description": "The trend direction"
            }
        },
        "required": ["metric", "currentPeriod", "previousPeriod", "currentValue", "previousValue"]
    }

# List of all available tools for Claude
ALL_TOOLS: List[ToolSchema] = [
    ChartGenerationTool(),
    TableGenerationTool(),
    FinancialMetricGenerationTool(),
    ComparativePeriodGenerationTool()
]

# Create dictionary versions for the API call if needed
ALL_TOOLS_DICT = [tool.model_dump(exclude_none=True) for tool in ALL_TOOLS]

# Legacy name for backward compatibility
DEFAULT_TOOLS = ALL_TOOLS

logger.info(f"Loaded {len(ALL_TOOLS)} tools for Claude API.")
logger.info(f"Tool names: {[tool.name for tool in ALL_TOOLS]}")

# Example Usage (for testing schema generation)
if __name__ == "__main__":
    chart_schema = ChartGenerationTool().model_dump_json(indent=2)
    print("Chart Generation Tool Schema:")
    print(chart_schema)

    table_schema = TableGenerationTool().model_dump_json(indent=2)
    print("\nTable Generation Tool Schema:")
    print(table_schema) 
</file>
```

#### models/visualization\.py
*Size: 3.9 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/models/visualization.py">
from typing import Dict, List, Optional, Any, Literal, Union
from pydantic import BaseModel, Field, ConfigDict
import uuid
from datetime import datetime

class MetricConfig(BaseModel):
    """Configuration for a metric in a chart."""
    label: str
    unit: Optional[str] = None  # Added for frontend consistency
    color: Optional[str] = None
    formatter: Optional[str] = None  # Added for frontend formatting
    precision: Optional[int] = None  # Added for frontend number formatting

class ChartConfig(BaseModel):
    """Configuration for a chart."""
    title: str
    description: str
    subtitle: Optional[str] = None  # Added for frontend consistency
    xAxisLabel: Optional[str] = None  # Added for frontend chart labels
    yAxisLabel: Optional[str] = None  # Added for frontend chart labels
    xAxisKey: Optional[str] = None
    trend: Optional[Dict[str, Any]] = None
    footer: Optional[str] = None
    totalLabel: Optional[str] = None
    showLegend: bool = True  # Added for frontend chart legend control
    legendPosition: Optional[Literal["top", "bottom", "left", "right"]] = "bottom"  # Added for frontend
    showGrid: Optional[bool] = True  # Added for frontend grid display
    height: Optional[int] = None  # Added for frontend sizing
    width: Optional[int] = None  # Added for frontend sizing
    stack: Optional[bool] = False  # Added for frontend stacked charts

class ChartData(BaseModel):
    """Base model for chart data."""
    chartType: Literal["bar", "multiBar", "line", "pie", "area", "stackedArea"]
    config: ChartConfig
    data: List[Dict[str, Any]]
    chartConfig: Dict[str, MetricConfig]
    
    model_config = ConfigDict(
        populate_by_name=True,
        alias_generator=None,
        validate_assignment=True,
        protected_namespaces=()
    )

class TableColumn(BaseModel):
    """Definition of a table column."""
    key: str
    label: str  # Backend uses 'label'
    header: Optional[str] = None  # Added for frontend (uses 'header' instead of 'label')
    format: Optional[Literal["number", "currency", "percentage", "text"]] = None
    width: Optional[int] = None  # Added for frontend column sizing
    align: Optional[Literal["left", "center", "right"]] = "left"  # Added for frontend text alignment
    formatter: Optional[str] = None  # Added for frontend custom formatting

class TableConfig(BaseModel):
    """Configuration for a table."""
    title: str
    description: str
    subtitle: Optional[str] = None  # Added for frontend consistency
    footer: Optional[str] = None
    columns: List[TableColumn]
    showRowNumbers: Optional[bool] = False  # Added for frontend row numbering
    sortable: Optional[bool] = True  # Added for frontend sorting functionality
    pagination: Optional[bool] = True  # Added for frontend pagination
    pageSize: Optional[int] = 10  # Added for frontend pagination size
    height: Optional[int] = None  # Added for frontend sizing
    width: Optional[int] = None  # Added for frontend sizing

class TableData(BaseModel):
    """Model for table data."""
    tableType: Literal["simple", "matrix", "comparison"]
    config: TableConfig
    data: List[Dict[str, Any]]
    
    model_config = ConfigDict(
        populate_by_name=True,
        alias_generator=None,
        validate_assignment=True,
        protected_namespaces=()
    )

class VisualizationData(BaseModel):
    """Container for different visualization types."""
    charts: Optional[List[ChartData]] = Field(default_factory=list)
    tables: Optional[List[TableData]] = Field(default_factory=list)
    
    # Common chart types expected by frontend
    monetaryValues: Optional[Dict[str, Any]] = Field(default_factory=dict)
    percentages: Optional[Dict[str, Any]] = Field(default_factory=dict)
    keywordFrequency: Optional[Dict[str, Any]] = Field(default_factory=dict)
    
    model_config = ConfigDict(
        populate_by_name=True,
        alias_generator=None,
        validate_assignment=True,
        protected_namespaces=()
    ) 
</file>
```

#### pdf\_processing/\_\_init\_\_\.py
*Size: 78 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/pdf_processing/__init__.py">
# This file is intentionally left empty to make the directory a Python package
</file>
```

#### pdf\_processing/claude\_service\.py
*Size: 102.2 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/pdf_processing/claude_service.py">
import os
import base64
import asyncio
import json
import re
import uuid
from typing import Dict, List, Optional, Any, Tuple, Union, TYPE_CHECKING, ForwardRef
import logging
from anthropic import AsyncAnthropic
from anthropic.types import Message as AnthropicMessage, ToolUseBlock
import string
from datetime import datetime
import contextlib
import httpx

from models.document import ProcessedDocument, Citation as DocumentCitation, DocumentContentType, DocumentMetadata, ProcessingStatus
from models.citation import Citation, CitationType, CharLocationCitation, PageLocationCitation, ContentBlockLocationCitation
from pdf_processing.langchain_service import LangChainService

# Set up logger
logger = logging.getLogger(__name__)

# Create a ToolSchema type reference for type checking
if TYPE_CHECKING:
    from models.tools import ToolSchema
else:
    ToolSchema = ForwardRef('ToolSchema')

# Import tool models
try:
    from models.tools import ToolSchema, ALL_TOOLS, ALL_TOOLS_DICT
    TOOLS_SUPPORT = True
except ImportError as e:
    TOOLS_SUPPORT = False
    logger.warning(f"Tools import failed: {e}. Tools features will be disabled.")
except Exception as e:
    TOOLS_SUPPORT = False
    logger.warning(f"Tools unexpected error: {e}. Tools features will be disabled.")

# Refined System Prompt for Tool Usage
FINANCIAL_ANALYSIS_SYSTEM_PROMPT = """You are an expert financial analyst. Your primary task is to analyze the provided financial document(s) and respond to the user's query.

CRITICAL INSTRUCTION: Whenever you need to present data in a chart, graph, or table format, you MUST use the provided tools ('generate_graph_data' for charts, 'generate_table_data' for tables). Do NOT describe chart data or table data in plain text. Use the tools to generate the structured JSON required for visualization based on their input schemas.

Analysis Steps:
1. Understand the user's query in the context of the provided document(s).
2. Extract relevant financial figures, metrics, trends, and tables from the document(s).
3. If the query requires a chart or graph visualization, use the 'generate_graph_data' tool. Ensure the chartType, config, data, and chartConfig match the tool's input schema precisely.
4. If the query requires presenting detailed data in a table, use the 'generate_table_data' tool. Ensure the tableType, config, columns, and data match the tool's input schema precisely.
5. Provide a concise textual analysis summarizing key findings and directly answering the user's query, referencing the generated visualizations/tables where appropriate (e.g., "As shown in the Revenue Trend chart...").
"""

@contextlib.asynccontextmanager
async def get_anthropic_client():
    """
    Context manager to get an Anthropic client.
    This function helps avoid circular imports between modules.
    
    Yields:
        AsyncAnthropic: An Anthropic API client
    """
    api_key = os.environ.get("ANTHROPIC_API_KEY")
    if not api_key:
        raise ValueError("ANTHROPIC_API_KEY environment variable is not set")
    
    client = AsyncAnthropic(api_key=api_key)
    try:
        yield client
    finally:
        # No need to close the client explicitly as AsyncAnthropic handles this
        pass

# Conditionally import LangGraphService
try:
    from pdf_processing.langgraph_service import LangGraphService
    LANGGRAPH_AVAILABLE = True
except ImportError as e:
    LANGGRAPH_AVAILABLE = False
    logger.warning(f"LangGraph import failed: {e}. LangGraph features will be disabled.")
except Exception as e:
    LANGGRAPH_AVAILABLE = False
    logger.warning(f"LangGraph unexpected error: {e}. LangGraph features will be disabled.")


class ClaudeService:
    def __init__(self, api_key: Optional[str] = None):
        """
        Initialize Claude API service with API key from parameter or environment variable.
        Configures AsyncAnthropic client with the API key.
        
        Args:
            api_key: Optional API key to use instead of environment variable
        """
        # Try to get API key from parameter first, then environment
        self.api_key = api_key
        if not self.api_key:
            self.api_key = os.environ.get("ANTHROPIC_API_KEY")
            logger.info("Using ANTHROPIC_API_KEY from environment variables")
        
        if not self.api_key:
            logger.warning("Missing ANTHROPIC_API_KEY environment variable or API key parameter")
            self.client = None
            return
        
        # Mask API key for logging (show first 8 chars and last 4)
        if len(self.api_key) > 12:
            masked_key = f"{self.api_key[:8]}...{self.api_key[-4:]}"
        else:
            masked_key = "***masked***"
        
        logger.info(f"Initializing Claude API with key prefix: {masked_key}")
        
        # Using Claude 3.5 Sonnet for enhanced PDF support and citations
        self.model = "claude-3-5-sonnet-latest"  # Use the latest model version that supports citations
        try:
            self.client = AsyncAnthropic(
                api_key=self.api_key,
                # No longer need to specify the PDF beta feature - it's built into the API now
            )
            logger.info(f"ClaudeService initialized with model: {self.model} and PDF support")
        except Exception as e:
            logger.error(f"Failed to initialize AsyncAnthropic client: {str(e)}")
            self.client = None
        
        # Initialize LangChain service
        self.langchain_service = LangChainService()
        
        # Initialize LangGraph service if available
        if LANGGRAPH_AVAILABLE:
            try:
                self.langgraph_service = LangGraphService()
                logger.info("LangGraph service successfully initialized")
            except ValueError as e:
                logger.error(f"LangGraph service configuration error: {str(e)}")
                self.langgraph_service = None
            except Exception as e:
                logger.error(f"Failed to initialize LangGraph service: {str(e)}")
                self.langgraph_service = None
        else:
            logger.warning("LangGraph service not available, skipping initialization")
            self.langgraph_service = None

    async def generate_response(
        self,
        system_prompt: str,
        messages: List[Dict[str, Any]],
        temperature: float = 0.7,
        max_tokens: int = 4000
    ) -> str:
        """
        Generate a response from Claude based on a conversation with a system prompt.
        
        Args:
            system_prompt: System prompt that guides Claude's behavior
            messages: List of message dictionaries with 'role' and 'content' keys
            temperature: Temperature for generation (0.0 to 1.0)
            max_tokens: Maximum number of tokens to generate
            
        Returns:
            Generated response text
        """
        if not self.client:
            # Mock response for testing or when API key is not available
            logger.warning("Using mock response because Claude API client is not available")
            return "I'm sorry, I cannot process your request because the Claude API is not configured properly. Please check the API key and try again."
        
        try:
            # Convert message format to Anthropic's format
            formatted_messages = []
            for msg in messages:
                role = "user" if msg["role"] == "user" else "assistant"
                formatted_messages.append({"role": role, "content": msg["content"]})
            
            logger.info(f"Sending request to Claude API with {len(formatted_messages)} messages")
            
            # Call Claude API
            response = await self.client.messages.create(
                model=self.model,
                system=system_prompt,
                messages=formatted_messages,
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            return response.content[0].text
        except Exception as e:
            logger.error(f"Error calling Claude API: {str(e)}")
            error_message = f"I apologize, but there was an error processing your request: {str(e)}"
            return error_message

    async def process_pdf(self, pdf_data: bytes, filename: str) -> Tuple[ProcessedDocument, List[DocumentCitation]]:
        """
        Process a PDF using Claude's PDF support and citation extraction.
        
        Args:
            pdf_data: Raw bytes of the PDF file
            filename: Name of the PDF file
            
        Returns:
            A tuple containing the processed document and a list of citations
        """
        if not self.client:
            logger.error("Cannot process PDF because Claude API client is not available")
            raise ValueError("Claude API client is not available. Check your API key.")
        
        try:
            logger.info(f"Processing PDF: {filename} with Claude API and citations support")
            
            # Encode PDF data as base64
            pdf_base64 = base64.b64encode(pdf_data).decode('utf-8')
            
            # Step 1: Extract raw text from PDF using PyPDF2
            raw_text = ""
            try:
                import io
                from PyPDF2 import PdfReader
                
                pdf_file = io.BytesIO(pdf_data)
                pdf_reader = PdfReader(pdf_file)
                
                # Extract text from each page
                page_texts = []
                for page_num in range(len(pdf_reader.pages)):
                    page = pdf_reader.pages[page_num]
                    page_text = page.extract_text()
                    if page_text:
                        page_texts.append(f"--- Page {page_num+1} ---\n{page_text}")
                
                raw_text = "\n\n".join(page_texts)
                logger.info(f"Successfully extracted {len(raw_text)} characters from PDF using PyPDF2")
            except Exception as extract_error:
                logger.warning(f"Failed to extract text from PDF using PyPDF2: {extract_error}")
                logger.info("Will continue with alternative extraction methods")
            
            # Step 2: Analyze document to determine type and periods
            logger.info("Analyzing document type")
            document_type, periods = await self._analyze_document_type(pdf_base64, filename)
            logger.info(f"Document classified as: {document_type.value} with periods: {periods}")
            
            # Step 3: Extract financial data with citations
            logger.info("Extracting financial data and citations")
            extracted_data, citations = await self._extract_financial_data_with_citations(
                pdf_content=pdf_data, 
                filename=filename, 
                document_type=document_type
            )
            logger.info(f"Extracted {len(citations)} citations")
            
            # Add or update raw_text in extracted_data if we have it
            if raw_text and len(raw_text.strip()) > 0:
                if not extracted_data:
                    extracted_data = {}
                extracted_data["raw_text"] = raw_text
                logger.info(f"Added {len(raw_text)} characters of raw text to extracted_data")
            
            # If we weren't able to extract raw text with PyPDF2, try to get it from Claude's response
            if not raw_text or len(raw_text.strip()) == 0:
                # Try to extract raw text from Claude's response if available
                if extracted_data.get("raw_text"):
                    raw_text = extracted_data.get("raw_text")
                    logger.info(f"Using raw text from Claude's response: {len(raw_text)} characters")
                else:
                    # If still no raw text, make one final attempt using OCR integration if available
                    try:
                        # Import OCR utility here to avoid circular imports
                        from pdf_processing.ocr_utilities import extract_text_with_ocr
                        
                        ocr_text = await extract_text_with_ocr(pdf_data)
                        if ocr_text and len(ocr_text.strip()) > 0:
                            raw_text = ocr_text
                            if not extracted_data:
                                extracted_data = {}
                            extracted_data["raw_text"] = raw_text
                            logger.info(f"Added {len(raw_text)} characters of OCR-extracted text")
                    except Exception as ocr_error:
                        logger.warning(f"OCR text extraction failed: {ocr_error}")
            
            # Log and return a warning if we still couldn't extract any text
            if not raw_text or len(raw_text.strip()) == 0:
                logger.warning(f"Failed to extract any text from PDF {filename} using multiple methods")
                # Create minimal raw text to avoid downstream issues
                raw_text = f"Failed to extract text content from {filename}. This document may contain scanned images or be password-protected."
                if not extracted_data:
                    extracted_data = {}
                extracted_data["raw_text"] = raw_text
            
            logger.info(f"Extracted data keys: {list(extracted_data.keys())}")
            
            # If we have financial data, update document type to FINANCIAL_REPORT if it wasn't already
            if extracted_data.get('financial_data') and extracted_data['financial_data']:
                if document_type != DocumentContentType.FINANCIAL_REPORT:
                    logger.info(f"Updating document type from {document_type.value} to FINANCIAL_REPORT based on extracted financial data")
                    document_type = DocumentContentType.FINANCIAL_REPORT
            
            # Create document metadata and processed document object
            document_id = str(uuid.uuid4())
            confidence_score = 0.8  # Default confidence score
            
            # Create document metadata
            metadata = DocumentMetadata(
                id=uuid.UUID(document_id),
                filename=filename,
                upload_timestamp=datetime.now(),
                file_size=len(pdf_data),
                mime_type="application/pdf",
                user_id="system"  # Default user for API processing
            )
            
            # Create processed document
            processed_document = ProcessedDocument(
                metadata=metadata,  # Include the required metadata
                content_type=document_type,
                extraction_timestamp=datetime.now(),
                periods=periods,
                extracted_data=extracted_data,
                confidence_score=confidence_score,
                processing_status=ProcessingStatus.COMPLETED
            )
            
            return processed_document, citations
            
        except Exception as e:
            logger.exception(f"Error processing PDF: {e}")
            
            # Create minimal document with error information
            document_id = str(uuid.uuid4())
            metadata = DocumentMetadata(
                id=uuid.UUID(document_id),
                filename=filename,
                upload_timestamp=datetime.now(),
                file_size=len(pdf_data) if pdf_data else 0,
                mime_type="application/pdf",
                user_id="system"
            )
            
            error_message = f"Error processing PDF: {str(e)}"
            processed_document = ProcessedDocument(
                metadata=metadata,
                content_type=DocumentContentType.OTHER,
                extraction_timestamp=datetime.now(),
                extracted_data={"error": error_message, "raw_text": f"Failed to process document due to error: {str(e)}"},
                confidence_score=0.0,
                processing_status=ProcessingStatus.FAILED
            )
            
            return processed_document, []

    async def _analyze_document_type(self, pdf_base64: str, filename: str) -> Tuple[DocumentContentType, List[str]]:
        """
        Analyze the PDF to determine its document type and extract time periods.
        Uses the new document content format but doesn't need citations for this step.
        
        Args:
            pdf_base64: Base64 encoded PDF data
            filename: Name of the PDF file
            
        Returns:
            Tuple of document type and list of time periods
        """
        if not self.client:
            logger.error("Cannot analyze document type because Claude API client is not available")
            raise ValueError("Claude API client is not available. Check your API key.")
        
        try:
            logger.info(f"Analyzing document type for: {filename}")
            
            # Create messages using the new document format
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "document",
                            "source": {
                                "type": "base64",
                                "media_type": "application/pdf",
                                "data": pdf_base64
                            }
                        },
                        {
                            "type": "text",
                            "text": "Analyze this financial document. Determine if it's a balance sheet, income statement, cash flow statement, or other type of document. Also identify the time periods covered (e.g., Q1 2023, FY 2022, etc.). Return ONLY a JSON response in this format:\n\n{\n  \"document_type\": \"balance_sheet|income_statement|cash_flow|notes|other\",\n  \"periods\": [\"period1\", \"period2\", ...]\n}"
                        }
                    ]
                }
            ]
            
            # Call Claude API
            response = await self.client.messages.create(
                model=self.model,
                max_tokens=1000,
                messages=messages
            )
            
            # Extract JSON from the response
            result_text = response.content[0].text
            json_match = re.search(r'{.*}', result_text, re.DOTALL)
            if not json_match:
                logger.error(f"Could not extract JSON from response: {result_text[:100]}...")
                return DocumentContentType.OTHER, []
            
            # Parse the JSON response
            try:
                result = json.loads(json_match.group(0))
                
                # Handle pipe-separated document types (e.g., "balance_sheet|income_statement")
                doc_type_str = result.get("document_type", "other")
                logger.info(f"Raw document_type from Claude: {doc_type_str}")
                
                # Split by pipe if present and try each type
                if "|" in doc_type_str:
                    doc_types = doc_type_str.split("|")
                    # Try each type in order
                    for dt in doc_types:
                        dt = dt.strip()
                        try:
                            document_type = DocumentContentType(dt)
                            logger.info(f"Selected document type '{dt}' from combined types: {doc_type_str}")
                            break
                        except ValueError:
                            pass
                    else:
                        # If no valid type found, use OTHER
                        logger.warning(f"No valid document type found in '{doc_type_str}', using OTHER")
                        document_type = DocumentContentType.OTHER
                else:
                    # Single document type
                    try:
                        document_type = DocumentContentType(doc_type_str)
                    except ValueError:
                        logger.warning(f"Invalid document type '{doc_type_str}', using OTHER")
                        document_type = DocumentContentType.OTHER
                
                periods = result.get("periods", [])
                
                logger.info(f"Document classified as {document_type.value} with periods: {periods}")
                return document_type, periods
            except Exception as json_e:
                logger.error(f"Error parsing JSON response: {json_e}")
                return DocumentContentType.OTHER, []
            
        except Exception as e:
            logger.exception(f"Error in document type analysis: {e}")
            return DocumentContentType.OTHER, []

    async def _extract_financial_data_with_citations(self, pdf_content: bytes, filename: str = "document.pdf", document_type: DocumentContentType = None) -> Tuple[Dict[str, Any], List[Any]]:
        """
        Extract financial data from a PDF with citations.
        
        Args:
            pdf_content: PDF file content as bytes or base64 string
            filename: Name of the PDF file
            document_type: Type of document being processed
            
        Returns:
            Tuple of extracted data dictionary and list of citations
        """
        if not self.client:
            logger.error("Cannot extract financial data because Claude API client is not available")
            raise ValueError("Claude API client is not available. Check your API key.")
        
        try:
            logger.info(f"Extracting financial data with citations from: {filename}")
            
            # Convert to base64 if needed
            if isinstance(pdf_content, bytes):
                pdf_base64 = base64.b64encode(pdf_content).decode('utf-8')
            else:
                pdf_base64 = pdf_content
            
            # Prepare document type for the prompt
            doc_type_str = document_type.value if document_type else "financial document"
            
            # Financial analysis prompt with structured data extraction
            system_prompt = """You are a highly specialized financial document analysis assistant. Extract structured financial data from the document accurately.
Follow these guidelines:
1. Identify all financial tables and metrics
2. Extract values with their correct time periods, labels, and units
3. Present the data in a structured JSON format
4. Provide citations for all extracted data"""
            
            # Create messages with the PDF document
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "document",
                            "source": {
                                "type": "base64",
                                "media_type": "application/pdf",
                                "data": pdf_base64
                            }
                        },
                        {
                            "type": "text",
                            "text": f"Analyze this {doc_type_str} and extract all financial data in a structured format. Include key metrics, time periods, and values. Return a comprehensive JSON with all the financial information."
                        }
                    ]
                }
            ]
            
            # Call Claude API with citations enabled
            response = await self.client.messages.create(
                model=self.model,
                max_tokens=4000,
                system=system_prompt,
                messages=messages
            )
            
            # Extract text content and citations
            content = self._process_claude_response(response)
            text = content.get("text", "")
            citations = content.get("citations", [])
            
            # Parse the extracted data from the response text
            extracted_data = {}
            try:
                # Check for JSON format in the response
                json_match = re.search(r'```json\s*([\s\S]*?)\s*```|{[\s\S]*}', text, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1) if json_match.group(1) else json_match.group(0)
                    # Clean up the JSON string if needed
                    json_str = re.sub(r'^```json\s*|\s*```$', '', json_str)
                    json_data = json.loads(json_str)
                    extracted_data = json_data
                else:
                    logger.warning("Could not find JSON data in Claude's response")
                    extracted_data = {"raw_text": text}
            except Exception as e:
                logger.error(f"Error parsing extracted data JSON: {str(e)}")
                extracted_data = {"raw_text": text, "error": str(e)}
            
            return extracted_data, citations
            
        except Exception as e:
            logger.error(f"Error extracting financial data: {str(e)}")
            return {"error": str(e)}, []

    async def generate_response_with_citations(self, messages: List[Dict[str, Any]], documents: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Generate a response from Claude with support for citations.
        
        Args:
            messages: List of conversation messages with 'role' and 'content'
            documents: List of documents to include for citation
            
        Returns:
            Response with content, content blocks, and citations
        """
        # Debug logging for request tracking using print for immediate visibility
        print(f"DEBUG: generate_response_with_citations called with {len(messages)} messages and {len(documents)} documents")
        logger.info(f"generate_response_with_citations called with {len(messages)} messages and {len(documents)} documents")
        for doc in documents:
            doc_id = doc.get('id', 'unknown')
            doc_title = doc.get('title', 'Untitled')
            doc_type = doc.get('mime_type', 'unknown')
            print(f"DEBUG: Document in request: ID={doc_id}, Title={doc_title}, Type={doc_type}")
            logger.info(f"Document in request: ID={doc_id}, Title={doc_title}, Type={doc_type}")
        try:
            # Check if API client is available
            if not self.client:
                logger.error("Claude API client not initialized")
                return {
                    "content": "Error: Claude API not available. Please check your API key and try again.",
                    "content_blocks": [],
                    "citations": []
                }
            
            # Log message count and document count
            logger.info(f"Generating response with {len(messages)} messages and {len(documents)} documents")
            
            # Set system message as a separate parameter
            system_prompt = "You are Claude, an AI assistant by Anthropic. When you reference documents, provide specific citations."
            
            # Convert messages to Claude API format
            claude_messages = []
            
            # Process user and assistant messages
            for msg in messages:
                role = msg.get("role", "").lower()
                content = msg.get("content", "")
                
                # Map roles from our format to Claude's expected format
                if role == "user":
                    claude_role = "user"
                elif role == "assistant":
                    claude_role = "assistant"
                elif role == "system":
                    # Skip system messages as we're using a top-level system parameter
                    continue
                else:
                    logger.warning(f"Unknown message role: {role}, defaulting to user")
                    claude_role = "user"
                
                # Format the content correctly for Claude API
                if isinstance(content, str):
                    claude_content = [{"type": "text", "text": content}]
                elif isinstance(content, list):
                    claude_content = []
                    for item in content:
                        if isinstance(item, str):
                            claude_content.append({"type": "text", "text": item})
                        elif isinstance(item, dict) and "type" in item:
                            claude_content.append(item)
                        else:
                            logger.warning(f"Unsupported content format: {item}")
                else:
                    logger.warning(f"Unsupported content format: {content}")
                    claude_content = [{"type": "text", "text": str(content)}]
                
                claude_messages.append({
                    "role": claude_role,
                    "content": claude_content
                })
            
            # Prepare documents for citation
            if documents:
                # Find the user's last message to append documents
                last_user_msg_idx = -1
                for i, msg in enumerate(claude_messages):
                    if msg["role"] == "user":
                        last_user_msg_idx = i
                
                # If no user message exists, create one
                if last_user_msg_idx == -1:
                    logger.warning("No user message found to attach documents. Creating an empty one.")
                    claude_messages.append({
                        "role": "user",
                        "content": [{"type": "text", "text": "Please analyze these documents:"}]
                    })
                    last_user_msg_idx = len(claude_messages) - 1
                
                # Process and add each document
                for doc in documents:
                    doc_content = self._prepare_document_for_citation(doc)
                    if doc_content:
                        # Add document to the user's message content
                        claude_messages[last_user_msg_idx]["content"].append(doc_content)
                        logger.info(f"Added document {doc.get('id', 'unknown')} to user message")
                    else:
                        logger.warning(f"Failed to prepare document {doc.get('id', 'unknown')} for citation")
            
            # Log the final message structure (without large content)
            debug_messages = []
            for msg in claude_messages:
                debug_msg = {"role": msg["role"], "content": []}
                for content in msg["content"]:
                    if content["type"] == "document":
                        # Don't log the full base64 data
                        debug_content = {
                            "type": "document",
                            "source_type": content.get("source", {}).get("type", "unknown")
                        }
                    else:
                        # For text content, include a preview
                        text = content.get("text", "")
                        debug_content = {
                            "type": "text",
                            "text": text[:100] + "..." if len(text) > 100 else text
                        }
                    debug_msg["content"].append(debug_content)
                debug_messages.append(debug_msg)
            
            logger.debug(f"Claude API request messages: {json.dumps(debug_messages)}")
            
            # Call Claude API with system prompt as a top-level parameter
            try:
                # Add explicit citation enabling guidance to the system prompt
                enhanced_system_prompt = system_prompt + "\n\nIMPORTANT: Please provide detailed citations for all information from the documents. Be specific about page numbers and locations."
                
                # Dump messages for debugging
                logger.info(f"Sending request to Claude API with {len(claude_messages)} messages and system prompt")
                # Log the document structure for the first document (not the entire content)
                for msg in claude_messages:
                    if msg.get("role") == "user" and isinstance(msg.get("content"), list):
                        for item in msg.get("content", []):
                            if isinstance(item, dict) and item.get("type") == "document":
                                doc_type = item.get("source", {}).get("type")
                                citations_enabled = item.get("citations", {}).get("enabled", False)
                                logger.info(f"Document in request: type={doc_type}, citations_enabled={citations_enabled}")
                
                response = await self.client.messages.create(
                    model=self.model,
                    max_tokens=4000,
                    messages=claude_messages,
                    system=enhanced_system_prompt
                )
                
                # Add detailed response logging with print for immediate visibility
                print(f"DEBUG: Claude API response received with {len(response.content)} content blocks")
                logger.info(f"Claude API response received with {len(response.content)} content blocks")
                
                # Inspect the full response object to see what fields it has
                print(f"DEBUG: Response type: {type(response)}")
                print(f"DEBUG: Response dir: {dir(response)}")
                
                # Dump first content block for analysis
                if len(response.content) > 0:
                    first_block = response.content[0]
                    print(f"DEBUG: First content block type: {first_block.type}")
                    print(f"DEBUG: First content block attrs: {dir(first_block)}")
                    # Check for raw citations field
                    if hasattr(first_block, '_citations') or hasattr(first_block, 'citations'):
                        citations_field = getattr(first_block, '_citations', getattr(first_block, 'citations', None))
                        print(f"DEBUG: First block citations: {citations_field}")
                
                # Check if there are any citations in the response
                citation_found = False
                for i, block in enumerate(response.content):
                    print(f"DEBUG: Content block {i} type: {block.type}")
                    if hasattr(block, 'citations') and block.citations:
                        citation_found = True
                        citation_count = len(block.citations)
                        print(f"DEBUG: Found {citation_count} citations in content block {i}")
                        logger.info(f"Found {citation_count} citations in content block {i}")
                        # Log first citation details for debugging
                        if citation_count > 0:
                            citation = block.citations[0]
                            citation_type = getattr(citation, 'type', 'unknown')
                            print(f"DEBUG: Sample citation type: {citation_type}")
                            print(f"DEBUG: Citation attributes: {dir(citation)}")
                            logger.info(f"Sample citation type: {citation_type}")
                    else:
                        print(f"DEBUG: No citations in content block {i}")
                        if hasattr(block, 'text'):
                            print(f"DEBUG: Block text preview: {block.text[:50]}...")
                
                if not citation_found:
                    print("DEBUG: WARNING - No citations found in the Claude API response")
                    logger.warning("No citations found in the Claude API response")
                
                # Process the response
                processed_response = self._process_claude_response(response)
                
                # Check if citations are available in the response
                citations = []
                if hasattr(response, 'content'):
                    for block in response.content:
                        if hasattr(block, 'citations') and block.citations:
                            for citation in block.citations:
                                citations.append(citation)
                
                logger.info(f"Extracted {len(citations)} citations from response")
                
                # Add citations to the processed response if available
                if citations:
                    processed_response["citations"] = citations
                    logger.info(f"Added {len(citations)} citations to response")
                
                return processed_response
                
            except Exception as e:
                logger.exception(f"Error calling Claude API: {e}")
                error_message = str(e)
                
                # Check for authentication errors
                if "authentication" in error_message.lower() or "api key" in error_message.lower() or "401" in error_message:
                    return {
                        "content": f"Error code: 401 - {error_message}",
                        "content_blocks": [],
                        "citations": []
                    }
                
                # Other API errors
                return {
                    "content": f"Error calling Claude API: {error_message}",
                    "content_blocks": [],
                    "citations": []
                }
            
        except Exception as e:
            logger.exception(f"Error generating response with citations: {e}")
            return {
                "content": f"An error occurred while processing your request: {str(e)}",
                "content_blocks": [],
                "citations": []
            }

    def _prepare_document_for_citation(self, document: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Prepare a document object for citation by Claude.
        
        Args:
            document: Document information dictionary
            
        Returns:
            Formatted document object for Claude API or None if invalid
        """
        try:
            # Extract document information
            doc_type = document.get("mime_type", "").lower()
            doc_id = document.get("id", "")
            doc_title = document.get("title", document.get("filename", f"Document {doc_id}"))
            
            # Try multiple sources for document content
            doc_content = None
            content_source = None
            
            # Log all available fields for debugging
            logger.info(f"Document fields: {list(document.keys())}")
            
            # First priority: "content" field
            if document.get("content"):
                doc_content = document.get("content")
                content_source = "content field"
            
            # Second priority: "raw_text" field
            elif document.get("raw_text"):
                doc_content = document.get("raw_text")
                content_source = "raw_text field"
                # For raw_text content, use text document type
                doc_type = "text/plain"
            
            # Third priority: "extracted_data.raw_text" field
            elif document.get("extracted_data") and isinstance(document.get("extracted_data"), dict) and document.get("extracted_data").get("raw_text"):
                doc_content = document.get("extracted_data").get("raw_text")
                content_source = "extracted_data.raw_text field"
                # For extracted text, use text document type
                doc_type = "text/plain"
            
            # Fourth priority: "text" field
            elif document.get("text"):
                doc_content = document.get("text")
                content_source = "text field"
                # For text content, use text document type
                doc_type = "text/plain"
                
            # Fifth priority: Try to get the raw PDF content from storage
            elif document.get("id"):
                try:
                    # Attempt to get the PDF data directly - this is a fallback mechanism
                    from repositories.document_repository import DocumentRepository
                    from repositories.database import get_database_session
                    
                    # Get session and repository
                    db_session = get_database_session()
                    document_repository = DocumentRepository(db_session)
                    
                    # Get document content directly
                    doc_content = asyncio.run(document_repository.get_document_file_content(document.get('id')))
                    
                    if doc_content and len(doc_content) > 0:
                        content_source = "direct PDF from storage"
                        doc_type = "application/pdf"
                        logger.info(f"Retrieved PDF content directly from storage for document {doc_id}")
                except Exception as storage_e:
                    logger.warning(f"Failed to get PDF directly from storage for document {doc_id}: {storage_e}")
                    
            # If all attempts to get content failed, create a minimal document with placeholder text
            if not doc_content:
                logger.warning(f"No document content found for {doc_id} - using fallback placeholder")
                doc_content = f"Document content unavailable for {doc_title}. Please try re-uploading the document."
                content_source = "fallback placeholder"
                doc_type = "text/plain"
            
            if content_source:
                logger.info(f"Using {content_source} for document {doc_id}")
            
            # Handle PDF documents
            if "pdf" in doc_type or doc_type == "application/pdf":
                # Ensure PDF content is bytes
                if not isinstance(doc_content, bytes):
                    if isinstance(doc_content, str) and doc_content.startswith(('data:application/pdf;base64,', 'data:;base64,')):
                        # Handle base64 encoded PDF data URLs
                        base64_content = doc_content.split('base64,')[1]
                        doc_content = base64.b64decode(base64_content)
                    elif isinstance(doc_content, str) and len(doc_content) > 0:
                        try:
                            # Check if it might be base64 encoded
                            if all(c in string.ascii_letters + string.digits + '+/=' for c in doc_content):
                                try:
                                    doc_content = base64.b64decode(doc_content)
                                    logger.info(f"Successfully decoded base64 content for document {doc_id}")
                                except:
                                    # Not valid base64, treat as text
                                    logger.warning(f"Content for {doc_id} looks like base64 but couldn't be decoded")
                                    doc_content = doc_content.encode('utf-8')
                            else:
                                # Regular text, encode to bytes
                                doc_content = doc_content.encode('utf-8')
                        except Exception as e:
                            logger.warning(f"Failed to convert string content to bytes for {doc_id}: {e}")
                            return None
                    else:
                        logger.warning(f"Invalid PDF content for {doc_id} - not bytes or base64 string")
                        return None
                
                # Validate PDF content
                if len(doc_content) < 10:  # Arbitrary small size check
                    logger.warning(f"PDF content for {doc_id} is too small ({len(doc_content)} bytes)")
                    return None
                
                # Check if content starts with PDF signature
                if not doc_content.startswith(b'%PDF'):
                    logger.warning(f"Content for {doc_id} doesn't start with PDF signature")
                    # We'll still try to use it, as it might be a valid PDF despite missing the signature
                
                # Create PDF document object for Claude API
                try:
                    base64_data = base64.b64encode(doc_content).decode()
                    logger.info(f"Successfully encoded PDF content for document {doc_id} ({len(doc_content)} bytes)")
                    
                    # Format according to Anthropic's Citations documentation
                    return {
                        "type": "document",
                        "source": {
                            "type": "base64",
                            "media_type": "application/pdf",
                            "data": base64_data
                        },
                        "title": doc_title,
                        "citations": {"enabled": True}
                    }
                except Exception as e:
                    logger.exception(f"Error encoding PDF content for {doc_id}: {e}")
                    return None
            
            # At this point, treat as text document (either originally or after conversion)
            # Ensure we have valid string content
            text_content = ""
            if isinstance(doc_content, str):
                text_content = doc_content
            elif isinstance(doc_content, bytes):
                try:
                    text_content = doc_content.decode('utf-8', errors='replace')
                except UnicodeDecodeError:
                    text_content = f"Binary content for {doc_title} (could not convert to text)"
            else:
                text_content = f"Content for {doc_title} in unsupported format: {type(doc_content)}"
            
            # Ensure we have some minimal content
            if not text_content.strip():
                text_content = f"Empty document content for {doc_title}"
            
            # Truncate very long text to avoid token limits (30,000 chars ~ 7,500 tokens)
            if len(text_content) > 30000:
                text_content = text_content[:30000] + f"\n\n[Document truncated due to length. Original size: {len(text_content)} characters]"
            
            logger.info(f"Prepared text document for Claude API: {doc_id}, length: {len(text_content)} chars")
            
            # Create proper text document format for Claude API
            return {
                "type": "document",
                "source": {
                    "type": "text",
                    "media_type": "text/plain",
                    "data": text_content
                },
                "title": doc_title,
                "citations": {"enabled": True}
            }
                
        except Exception as e:
            logger.exception(f"Error preparing document for citation: {e}")
            # Return a minimal valid document to prevent API errors
            return {
                "type": "document",
                "source": {
                    "type": "text",
                    "media_type": "text/plain",
                    "data": f"Error preparing document {document.get('id', 'unknown')} for citation: {str(e)}"
                },
                "title": document.get("title", document.get("filename", "Document")),
                "citations": {"enabled": True}
            }

    def _process_claude_response(self, response: AnthropicMessage) -> Dict[str, Any]:
        """
        Process Claude's response to extract content and citations.
        
        Args:
            response: Claude API response
            
        Returns:
            Processed response with text content and structured citations
        """
        result = {
            "text": "",
            "citations": []
        }
        
        # Extract text content
        if hasattr(response, "content") and response.content:
            # Combine all text content
            text_parts = []
            citations = []
            
            for block in response.content:
                if block.type == "text":
                    text_parts.append(block.text)
                    
                    # Process citations if available
                    if hasattr(block, "citations") and block.citations:
                        for citation in block.citations:
                            citation_obj = self._convert_claude_citation(citation)
                            if citation_obj:
                                citations.append(citation_obj)
            
            result["text"] = "\n".join(text_parts)
            result["citations"] = citations
        
        return result

    def _convert_claude_citation(self, citation: Any) -> Optional[Union[Dict[str, Any], Citation]]:
        """
        Convert Claude citation to our Citation model.
        
        Args:
            citation: Citation from Claude API
            
        Returns:
            Citation object or dictionary or None if conversion fails
        """
        try:
            # Handle both class attribute and dictionary access
            if hasattr(citation, 'type'):
                citation_type = citation.type
            elif isinstance(citation, dict):
                citation_type = citation.get('type')
            else:
                logger.warning(f"Unknown citation format: {type(citation)}")
                return None
            
            # Handle different citation types
            if citation_type == "page_citation" or citation_type == "page_location":
                # For PDF citations
                document_id = None
                # Only try to get document.id if the attribute exists
                if hasattr(citation, 'document') and hasattr(citation.document, 'id'):
                    document_id = citation.document.id
                elif isinstance(citation, dict) and 'document' in citation:
                    document_id = citation.get('document', {}).get('id')
                
                # Extract page information
                page_info = {}
                if hasattr(citation, 'page'):
                    page_info = {
                        'start_page': getattr(citation.page, 'start', 1),
                        'end_page': getattr(citation.page, 'end', 1)
                    }
                elif isinstance(citation, dict) and 'page' in citation:
                    page_info = {
                        'start_page': citation['page'].get('start', 1),
                        'end_page': citation['page'].get('end', 1)
                    }
                
                cited_text = ""
                if hasattr(citation, 'text'):
                    cited_text = citation.text
                elif isinstance(citation, dict):
                    cited_text = citation.get('text', '')
                
                return {
                    "type": "page_location",
                    "cited_text": cited_text,
                    "document_id": document_id,
                    "start_page_number": page_info.get('start_page', 1),
                    "end_page_number": page_info.get('end_page', 1)
                }
            
            elif citation_type in ["quote_citation", "text_citation", "char_location"]:
                # For text citations
                document_id = None
                # Only try to get document.id if the attribute exists
                if hasattr(citation, 'document') and hasattr(citation.document, 'id'):
                    document_id = citation.document.id
                elif isinstance(citation, dict) and 'document' in citation:
                    document_id = citation.get('document', {}).get('id')
                
                # Get cited text
                cited_text = ""
                if hasattr(citation, 'text'):
                    cited_text = citation.text
                elif hasattr(citation, 'cited_text'):
                    cited_text = citation.cited_text
                elif isinstance(citation, dict):
                    cited_text = citation.get('text', citation.get('cited_text', ''))
                
                # Get start and end indices if available
                start_index = 0
                end_index = 0
                
                # Handle different attribute names for character indices
                if hasattr(citation, 'start_index'):
                    start_index = citation.start_index
                elif hasattr(citation, 'start_char_index'):
                    start_index = citation.start_char_index
                elif isinstance(citation, dict):
                    start_index = citation.get('start_index', citation.get('start_char_index', 0))
                
                if hasattr(citation, 'end_index'):
                    end_index = citation.end_index
                elif hasattr(citation, 'end_char_index'):
                    end_index = citation.end_char_index
                elif isinstance(citation, dict):
                    end_index = citation.get('end_index', citation.get('end_char_index', 0))
                
                return {
                    "type": "char_location",
                    "cited_text": cited_text,
                    "document_id": document_id,
                    "start_char_index": start_index,
                    "end_char_index": end_index
                }
            
            else:
                logger.warning(f"Unknown citation type: {citation_type}")
                # Return a generic citation with available information
                if isinstance(citation, dict):
                    # Try to extract document info
                    document_id = citation.get('document', {}).get('id', 'unknown')
                    return {
                        "type": "unknown",
                        "document_id": document_id,
                        "cited_text": citation.get('text', '')
                    }
                return None
                
        except Exception as e:
            logger.exception(f"Error converting Claude citation: {e}")
            return None

    async def generate_response_with_langgraph(
        self,
        question: str,
        document_texts: List[Dict[str, Any]],
        conversation_history: List[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Generate a response using LangGraph for document Q&A.
        This is a lighter-weight alternative to running the full conversation graph.
        Supports Claude's citation feature for accurate document references.
        
        Args:
            question: The user's question
            document_texts: List of documents with their text content
            conversation_history: Previous conversation messages
            
        Returns:
            Dictionary containing the response text and any extracted citations
        """
        # Critical logging for document processing diagnosis
        logger.info(f"===== Claude API document processing request =====")
        logger.info(f"Question: {question[:100]}" + ("..." if len(question) > 100 else ""))
        logger.info(f"Number of documents: {len(document_texts)}")
        logger.info(f"History length: {len(conversation_history) if conversation_history else 0}")
        
        # Log document IDs for tracing
        doc_ids = [doc.get('id', 'unknown') for doc in document_texts]
        logger.info(f"Document IDs in request: {doc_ids}")
        
        # Check document content existence 
        for i, doc in enumerate(document_texts):
            doc_id = doc.get('id', f'doc_{i}')
            has_content = False
            
            # Check various possible content fields
            if 'raw_text' in doc and doc['raw_text']:
                has_content = True
                logger.info(f"Document {doc_id} has raw_text content: {len(doc['raw_text'])} chars")
            elif 'content' in doc and isinstance(doc['content'], str) and doc['content']:
                has_content = True
                logger.info(f"Document {doc_id} has string content: {len(doc['content'])} chars")
            elif 'text' in doc and doc['text']:
                has_content = True
                logger.info(f"Document {doc_id} has text content: {len(doc['text'])} chars")
            elif 'extracted_data' in doc and doc['extracted_data']:
                extracted_type = type(doc['extracted_data']).__name__
                logger.info(f"Document {doc_id} has extracted_data of type: {extracted_type}")
                
                if isinstance(doc['extracted_data'], dict) and 'raw_text' in doc['extracted_data']:
                    has_content = True
                    logger.info(f"Document {doc_id} has extracted_data.raw_text: {len(doc['extracted_data']['raw_text'])} chars")
            
            if not has_content:
                logger.warning(f"âš ï¸ Document {doc_id} has no usable text content! This may cause visibility issues.")
                logger.warning(f"Available keys: {list(doc.keys())}")
        
        logger.info(f"===== End Claude API document request information =====")
        
        if not LANGGRAPH_AVAILABLE or not self.langgraph_service:
            logger.warning("LangGraph service is not available, falling back to LangChain")
            # Fall back to LangChain if LangGraph is not available
            if self.langchain_service:
                logger.info("Using LangChain for response generation")
                response_text = await self.langchain_service.analyze_document_content(
                    question=question,
                    document_extracts=[doc.get("text", "") for doc in document_texts if "text" in doc],
                    conversation_history=conversation_history
                )
                return {
                    "content": response_text,
                    "citations": []  # No citations with LangChain fallback
                }
            else:
                logger.warning("LangChain service is not available, falling back to direct Claude API")
                # Fall back to regular response generation
                system_prompt = "You are a financial document analysis assistant. Answer questions based on your knowledge."
                messages = []
                
                # Add conversation history to messages
                if conversation_history:
                    for msg in conversation_history:
                        messages.append(msg)
                
                # Add current question
                messages.append({"role": "user", "content": question})
                
                response_text = await self.generate_response(
                    system_prompt=system_prompt,
                    messages=messages
                )
                return {
                    "content": response_text,
                    "citations": []  # No citations with direct API fallback
                }
        
        try:
            logger.info(f"Using LangGraph for response generation with {len(document_texts)} documents")
            # Use LangGraph service for document QA with citation support
            response = await self.langgraph_service.simple_document_qa(
                question=question,
                documents=document_texts,
                conversation_history=conversation_history
            )
            
            # Handle the response, which should now be a dictionary with content and citations
            if isinstance(response, dict):
                content = response.get("content", "")
                citations = response.get("citations", [])
                
                logger.info(f"Generated response with {len(citations)} citations")
                
                # Return the structured response with citations
                return {
                    "content": content,
                    "citations": citations
                }
            elif isinstance(response, str):
                # Handle legacy response format (string only)
                logger.warning("Received legacy string response from simple_document_qa")
                return {
                    "content": response,
                    "citations": []
                }
            else:
                # Handle unexpected response type
                logger.error(f"Unexpected response type from simple_document_qa: {type(response)}")
                return {
                    "content": "I apologize, but there was an error processing your request.",
                    "citations": []
                }
                
        except Exception as e:
            logger.error(f"Error in generate_response_with_langgraph: {str(e)}", exc_info=True)
            return {
                "content": f"I apologize, but there was an error processing your request: {str(e)}",
                "citations": []
            }

    async def extract_structured_financial_data(self, text: str, pdf_data: bytes = None, filename: str = None) -> Dict[str, Any]:
        """
        Extract structured financial data from raw text using Claude.
        This is a fallback method when standard extraction fails to find financial tables.
        
        Args:
            text: Raw text from a document
            pdf_data: Optional raw bytes of the PDF file for improved extraction with native PDF support
            filename: Optional filename of the PDF
            
        Returns:
            Dictionary of structured financial data
        """
        if not self.client:
            logger.error("Cannot extract structured data because Claude API client is not available")
            return {"error": "Claude API client is not available"}
        
        try:
            logger.info("Attempting to extract structured financial data from text")
            
            # Create a specialized prompt for financial data extraction
            extraction_prompt = """Please analyze this financial document text and extract structured financial data.
            
            Output the data in the following JSON format:
            {
                "metrics": [
                    {"name": "Revenue", "value": 1000000, "period": "2023", "unit": "USD"},
                    {"name": "Net Income", "value": 200000, "period": "2023", "unit": "USD"}
                ],
                "ratios": [
                    {"name": "Profit Margin", "value": 0.2, "description": "Net income divided by revenue"}
                ],
                "periods": ["2023", "2022"],
                "key_insights": [
                    "Revenue increased by 15% from 2022 to 2023",
                    "Profit margin improved from 15% to 20%"
                ]
            }
            
            If you can identify any financial statements (income statement, balance sheet, cash flow), please structure them accordingly.
            Be sure to extract specific numbers, dates, and proper units.
            If you cannot find specific financial data, return an empty object for that category."""
            
            # Setup system prompt
            system_prompt = """You are a financial data extraction assistant. Your task is to extract structured financial data from text.
            Always output valid JSON. If specific financial metrics are not available, include empty arrays in those categories.
            Be precise with numbers and dates. Recognize financial statements and extract metrics, ratios, and insights."""
            
            # Prepare messages
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": extraction_prompt
                        }
                    ]
                }
            ]
            
            # If we have PDF data, use it with the document content type for better extraction
            if pdf_data:
                logger.info(f"Using native PDF document support for financial data extraction")
                
                # Prepare the document for citation using our enhanced method
                document = {
                    "id": "financial_document",
                    "title": filename if filename else "Financial Document",
                    "content": pdf_data,
                    "mime_type": "application/pdf"
                }
                
                prepared_document = self._prepare_document_for_citation(document)
                if not prepared_document:
                    logger.warning("Failed to prepare document for financial data extraction, falling back to text")
                else:
                    # Add the prepared document as content in the user message
                    messages.append({
                        "role": "user",
                        "content": [prepared_document]
                    })
            else:
                # Fall back to using just the text content
                logger.info("Using text-only mode for financial data extraction")
                messages.append({
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": text[:15000]  # Limit text length
                        }
                    ]
                })
            
            # Call Claude API
            response = await self.client.messages.create(
                model=self.model,
                max_tokens=2000,
                messages=messages,
                system=system_prompt,
                temperature=0.0  # Use low temperature for factual extraction
            )
            
            # Extract the JSON from the response
            response_text = response.content[0].text if response.content else ""
            
            # Find JSON in the response
            json_pattern = r'```json\s*([\s\S]*?)\s*```|{[\s\S]*}'
            json_match = re.search(json_pattern, response_text)
            
            if json_match:
                json_str = json_match.group(1) if json_match.group(1) else json_match.group(0)
                try:
                    structured_data = json.loads(json_str)
                    logger.info(f"Successfully extracted structured financial data: {len(structured_data)} categories")
                    return structured_data
                except json.JSONDecodeError as e:
                    logger.error(f"Failed to parse JSON from Claude response: {e}")
                    return {"error": "Failed to parse financial data", "raw_response": response_text}
            else:
                logger.error("No JSON data found in Claude response")
                return {"error": "No structured data found in response", "raw_response": response_text}
        
        except Exception as e:
            logger.exception(f"Error in structured financial data extraction: {e}")
            return {"error": f"Extraction failed: {str(e)}"}

    async def analyze_financial_document(
        self, 
        document_text: str,
        template: str
    ) -> Dict[str, Any]:
        """
        Analyze a financial document using Claude with a provided text template.
        This method is used when we have the document in text form.
        
        Args:
            document_text: Text content of the document
            template: Template to use for the analysis prompt
            
        Returns:
            Dictionary containing the analysis results
        """
        if not self.client:
            logger.error("Cannot analyze document because Claude API client is not available")
            raise ValueError("Claude API client is not available. Check your API key.")
        
        try:
            # Prepare the prompt using the template
            prompt_text = template.format(document_text="")
            
            logger.info(f"Analyzing financial document with Claude API, text length: {len(document_text)}")
            
            # Call Claude API
            response = await self.client.messages.create(
                model=self.model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "Please analyze this financial document according to the instructions that follow."
                            },
                            {
                                "type": "document",
                                "source": {
                                    "type": "text",
                                    "media_type": "text/plain",
                                    "data": document_text
                                },
                                "title": "Financial Document",
                                "citations": {"enabled": True}
                            },
                            {
                                "type": "text",
                                "text": prompt_text
                            }
                        ]
                    }
                ],
                temperature=0.2,  # Lower temperature for more focused analysis
                max_tokens=4000
            )
            
            # Extract the response text and citation data
            if response:
                logger.info(f"Received response from Claude API with {len(response.content)} content blocks")
                
                # Process content blocks to extract citations
                result = {
                    "content": "",
                    "timestamp": datetime.now().isoformat(),
                    "citations": []
                }
                
                for content_block in response.content:
                    if content_block.type == "text":
                        result["content"] += content_block.text
                        
                        # Extract citations if present in this block
                        if hasattr(content_block, 'citations') and content_block.citations:
                            for citation in content_block.citations:
                                citation_data = {
                                    "type": citation.type,
                                    "cited_text": citation.cited_text,
                                    "document_title": citation.document_title
                                }
                                
                                # Add location information based on citation type
                                if citation.type == "char_location":
                                    citation_data["start_char_index"] = citation.start_char_index
                                    citation_data["end_char_index"] = citation.end_char_index
                                
                                result["citations"].append(citation_data)
                
                logger.info(f"Extracted {len(result['citations'])} citations from response")
                return result
            else:
                logger.warning("Received empty response from Claude API")
                return {
                    "content": "No analysis could be generated for this document.",
                    "timestamp": datetime.now().isoformat(),
                    "citations": []
                }
                
        except Exception as e:
            logger.error(f"Error analyzing financial document with Claude API: {str(e)}", exc_info=True)
            raise

    async def analyze_financial_document_with_binary(
        self, 
        file_binary: bytes,
        template: str
    ) -> Dict[str, Any]:
        """
        Analyze a financial document using Claude with a provided file binary.
        This method is used when we have the document as a binary file (PDF).
        
        Args:
            file_binary: Binary content of the document file
            template: Template to use for the analysis prompt
            
        Returns:
            Dictionary containing the analysis results
        """
        if not self.client:
            logger.error("Cannot analyze document because Claude API client is not available")
            raise ValueError("Claude API client is not available. Check your API key.")
        
        try:
            # Encode the file as base64
            file_base64 = base64.b64encode(file_binary).decode('utf-8')
            
            logger.info(f"Analyzing financial document with Claude API using binary file, size: {len(file_binary)} bytes")
            
            # Call Claude API with the binary file
            response = await self.client.messages.create(
                model=self.model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": "Please analyze this financial document according to the instructions that follow."
                            },
                            {
                                "type": "document",
                                "source": {
                                    "type": "base64",
                                    "media_type": "application/pdf",
                                    "data": file_base64
                                },
                                "title": "Financial Document",
                                "citations": {"enabled": True}
                            },
                            {
                                "type": "text",
                                "text": template
                            }
                        ]
                    }
                ],
                temperature=0.2,  # Lower temperature for more focused analysis
                max_tokens=4000
            )
            
            # Extract the response text and citation data
            if response:
                logger.info(f"Received response from Claude API with {len(response.content)} content blocks")
                
                # Process content blocks to extract citations
                result = {
                    "content": "",
                    "timestamp": datetime.now().isoformat(),
                    "citations": []
                }
                
                for content_block in response.content:
                    if content_block.type == "text":
                        result["content"] += content_block.text
                        
                        # Extract citations if present in this block
                        if hasattr(content_block, 'citations') and content_block.citations:
                            for citation in content_block.citations:
                                citation_data = {
                                    "type": citation.type,
                                    "cited_text": citation.cited_text,
                                    "document_title": citation.document_title
                                }
                                
                                # Add page numbers for PDF citations
                                if citation.type == "page_location":
                                    citation_data["start_page_number"] = citation.start_page_number
                                    citation_data["end_page_number"] = citation.end_page_number
                                
                                result["citations"].append(citation_data)
                
                logger.info(f"Extracted {len(result['citations'])} citations from response")
                return result
            else:
                logger.warning("Received empty response from Claude API")
                return {
                    "content": "No analysis could be generated for this document.",
                    "timestamp": datetime.now().isoformat(),
                    "citations": []
                }
                
        except Exception as e:
            logger.error(f"Error analyzing financial document with Claude API: {str(e)}", exc_info=True)
            raise

    async def generate_response_with_tools(
        self,
        system_prompt: str,
        messages: List[Dict[str, Any]],
        tools: Optional[List[ToolSchema]] = None,
        temperature: float = 0.7,
        max_tokens: int = 4000
    ) -> Dict[str, Any]:
        """
        Generate a response from Claude with tool support.
        
        Args:
            system_prompt: System prompt that guides Claude's behavior
            messages: List of message dictionaries with 'role' and 'content' keys
            tools: Optional list of tools to make available to Claude
            temperature: Temperature for generation (0.0 to 1.0)
            max_tokens: Maximum number of tokens to generate
            
        Returns:
            Dictionary containing the response with tool usage
        """
        if not self.client:
            logger.warning("Using mock response because Claude API client is not available")
            return {
                "content": "I'm sorry, I cannot process your request because the Claude API is not configured properly. Please check the API key and try again.",
                "tool_use": None
            }
        
        try:
            # Check if tools support is available
            if not TOOLS_SUPPORT:
                logger.warning("Tools support is not available, falling back to regular response")
                return await self.generate_response(
                    system_prompt=system_prompt,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens
                )
            
            # Use ALL_TOOLS if none provided
            if tools is None:
                tools = ALL_TOOLS
            
            # Convert message format to Anthropic's format
            formatted_messages = []
            for msg in messages:
                role = "user" if msg["role"] == "user" else "assistant"
                
                # Handle both string and list content formats
                if isinstance(msg["content"], str):
                    content = [{"type": "text", "text": msg["content"]}]
                elif isinstance(msg["content"], list):
                    content = msg["content"]
                else:
                    content = [{"type": "text", "text": str(msg["content"])}]
                
                formatted_messages.append({"role": role, "content": content})
            
            logger.info(f"Sending request to Claude API with {len(formatted_messages)} messages and {len(tools)} tools")
            
            # Format tools for the API
            tool_schemas = []
            for tool in tools:
                tool_schemas.append({
                    "name": tool.name,
                    "description": tool.description,
                    "input_schema": tool.input_schema
                })
            
            # Call Claude API with tools
            response = await self.client.messages.create(
                model=self.model,
                system=system_prompt,
                messages=formatted_messages,
                temperature=temperature,
                max_tokens=max_tokens,
                tools=tool_schemas,
                tool_choice={"type": "any"}  # Allow the model to use any tool
            )
            
            # Process the response
            result = {
                "content": "",
                "content_blocks": [],
                "tool_uses": []
            }
            
            # Extract content and tool usages
            if hasattr(response, 'content'):
                for block in response.content:
                    if block.type == "text":
                        result["content"] += block.text
                        result["content_blocks"].append({"type": "text", "text": block.text})
                    elif block.type == "tool_use":
                        result["tool_uses"].append({
                            "type": "tool_use",
                            "id": getattr(block, "id", "unknown"),
                            "name": getattr(block, "name", "unknown"),
                            "input": getattr(block, "input", {})
                        })
                        # Also add a placeholder in content blocks
                        result["content_blocks"].append({
                            "type": "tool_use",
                            "id": getattr(block, "id", "unknown"),
                            "name": getattr(block, "name", "unknown")
                        })
            
            logger.info(f"Processed Claude API response with {len(result['tool_uses'])} tool uses")
            
            return result
            
        except Exception as e:
            logger.error(f"Error calling Claude API with tools: {str(e)}")
            error_message = f"I apologize, but there was an error processing your request: {str(e)}"
            return {
                "content": error_message,
                "content_blocks": [{"type": "text", "text": error_message}],
                "tool_uses": []
            }

    async def extract_financial_data_with_tools(
        self,
        pdf_content: bytes,
        filename: str = "document.pdf",
        document_type: DocumentContentType = None
    ) -> Dict[str, Any]:
        """
        Extract financial data from a PDF using tool-based approach.
        
        Args:
            pdf_content: PDF file content as bytes
            filename: Name of the PDF file
            document_type: Type of document being processed
            
        Returns:
            Dictionary containing the extracted data and visualizations
        """
        if not self.client:
            logger.error("Cannot extract financial data because Claude API client is not available")
            raise ValueError("Claude API client is not available. Check your API key.")
        
        # Check for tools support
        if not TOOLS_SUPPORT:
            logger.warning("Tools support is not available, falling back to regular extraction")
            return await self._extract_financial_data_with_citations(
                pdf_content=pdf_content,
                filename=filename,
                document_type=document_type
            )
        
        try:
            logger.info(f"Extracting financial data with tools from: {filename}")
            
            # Convert to base64
            pdf_base64 = base64.b64encode(pdf_content).decode('utf-8')
            
            # Prepare document type for the prompt
            doc_type_str = document_type.value if document_type else "financial document"
            
            # Financial analysis prompt with structured data extraction
            system_prompt = """You are a highly specialized financial document analysis assistant. Extract structured financial data from the document and create visualizations.
Follow these guidelines:
1. Identify all financial tables and metrics
2. Extract values with their correct time periods, labels, and units
3. Present the data in a structured JSON format
4. Use the generate_graph_data tool to create visualizations of key metrics
5. Use the generate_table_data tool for detailed financial tables"""
            
            # Create messages with the PDF document
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "document",
                            "source": {
                                "type": "base64",
                                "media_type": "application/pdf",
                                "data": pdf_base64
                            }
                        },
                        {
                            "type": "text",
                            "text": f"Analyze this {doc_type_str} and extract all financial data. Create charts for key metrics and tables for detailed data. Return comprehensive structured data with visualizations."
                        }
                    ]
                }
            ]
            
            # Import tools
            from models.tools import ChartGenerationTool, TableGenerationTool
            
            # Call Claude API with tools
            response = await self.generate_response_with_tools(
                system_prompt=system_prompt,
                messages=messages,
                tools=[ChartGenerationTool(), TableGenerationTool()],
                max_tokens=4000
            )
            
            # Extract text content and tool usages
            content_text = response.get("content", "")
            tool_uses = response.get("tool_uses", [])
            
            # Process visualization data from tool uses
            visualization_data = {
                "charts": [],
                "tables": []
            }
            
            for tool_use in tool_uses:
                tool_name = tool_use.get("name", "")
                tool_input = tool_use.get("input", {})
                
                if tool_name == "generate_graph_data":
                    visualization_data["charts"].append(tool_input)
                    
                    # Also add to visualization_data in the format expected by frontend
                    chart_type = tool_input.get("chartType", "")
                    if chart_type in ["bar", "multiBar", "line", "pie", "area", "stackedArea"]:
                        # Create a key based on chart type
                        key = f"{chart_type}Chart"
                        visualization_data[key] = tool_input
                    
                    # Add to specific chart type collections for compatibility with existing code
                    if chart_type == "bar" and "monetaryValues" not in visualization_data:
                        # This is likely a monetary values chart
                        visualization_data["monetaryValues"] = tool_input
                    elif chart_type == "bar" and "percentages" not in visualization_data:
                        # This could be a percentages chart
                        visualization_data["percentages"] = tool_input
                    elif chart_type == "bar" and "keywordFrequency" not in visualization_data:
                        # This could be a keyword frequency chart
                        visualization_data["keywordFrequency"] = tool_input
                
                elif tool_name == "generate_table_data":
                    visualization_data["tables"].append(tool_input)
                    
                    # Also add to visualization_data in the format expected by frontend
                    table_type = tool_input.get("tableType", "")
                    key = f"{table_type}Table"
                    visualization_data[key] = tool_input
            
            # Extract financial metrics and data from the text
            extracted_data = {}
            try:
                # Check for JSON format in the response
                json_match = re.search(r'```json\s*([\s\S]*?)\s*```|{[\s\S]*}', content_text, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1) if json_match.group(1) else json_match.group(0)
                    # Clean up the JSON string if needed
                    json_str = re.sub(r'^```json\s*|\s*```$', '', json_str)
                    json_data = json.loads(json_str)
                    extracted_data = json_data
                else:
                    logger.warning("Could not find JSON data in Claude's response")
                    extracted_data = {"raw_text": content_text}
            except Exception as e:
                logger.error(f"Error parsing extracted data JSON: {str(e)}")
                extracted_data = {"raw_text": content_text, "error": str(e)}
            
            # Add visualization data to the result
            extracted_data["visualization_data"] = visualization_data
            extracted_data["visualizationData"] = visualization_data  # camelCase version
            
            return extracted_data
            
        except Exception as e:
            logger.error(f"Error extracting financial data with tools: {str(e)}")
            return {"error": str(e), "visualization_data": {}, "visualizationData": {}}

    async def analyze_financial_document_with_tools(
        self,
        document_text: str,
        user_query: str,
        knowledge_base: str = ""
    ) -> Dict[str, Any]:
        """
        Analyze financial document using tool-based approach.
        
        Args:
            document_text: Text content of the financial document
            user_query: User's analysis query
            knowledge_base: Optional knowledge base content
            
        Returns:
            Dictionary containing analysis results and visualizations
        """
        if not self.client:
            logger.error("Cannot analyze financial document because Claude API client is not available")
            raise ValueError("Claude API client is not available. Check your API key.")
        
        # Check for tools support
        if not TOOLS_SUPPORT:
            logger.warning("Tools support is not available, falling back to regular analysis")
            # Return a simple text-based analysis without visualizations
            return {
                "analysis_text": "Tools support is not available. Please ensure the tools models are properly imported.",
                "visualizations": {"charts": [], "tables": []}
            }
        
        try:
            logger.info(f"Analyzing financial document with tools (document length: {len(document_text)} chars)")
            
            # Create system prompt for financial analysis
            system_prompt = """You are an expert financial analyst specializing in regional banks. Your task is to analyze 
            financial documents and answer user queries by generating structured data for visualizations and metrics.
            
            Follow these guidelines:
            1. Extract key financial data, metrics, and ratios relevant to the query
            2. Generate individual financial metrics using the generate_financial_metric tool
            3. Create period-over-period comparisons using the generate_comparative_period tool 
            4. Generate appropriate visualizations using the chart and table tools
            5. Each visualization should illustrate an important insight or finding
            6. Focus on metrics relevant to regional banks (NIM, efficiency ratio, loan growth, etc.)
            7. Include period-over-period comparisons where applicable
            8. Support recommendations with data from the financial documents
            
            Use tools for ALL data outputs - metrics, comparisons, and visualizations. Do not describe charts or metrics in text only."""
            
            # Format user message with document, knowledge base, and query
            user_message = f"""
            <financial_documents>
            {document_text}
            </financial_documents>
            
            <knowledge_base>
            {knowledge_base}
            </knowledge_base>
            
            <user_query>
            {user_query}
            </user_query>
            
            Analyze this financial document to answer the user's query. Generate individual financial metrics, period-over-period 
            comparisons, and appropriate charts and tables using the tools provided. For each visualization and metric, include 
            key insights about what the data shows.
            """
            
            # Prepare messages
            messages = [
                {
                    "role": "user",
                    "content": user_message
                }
            ]
            
            # Import tool schemas
            from models.tools import ChartGenerationTool, TableGenerationTool, FinancialMetricGenerationTool, ComparativePeriodGenerationTool
            
            # Call Claude API with tools
            result = await self.generate_response_with_tools(
                system_prompt=system_prompt,
                messages=messages,
                tools=[ChartGenerationTool(), TableGenerationTool(), FinancialMetricGenerationTool(), ComparativePeriodGenerationTool()],
                temperature=0.3,  # Lower temperature for more consistent outputs
                max_tokens=4000
            )
            
            # Format visualization data from tool outputs
            visualizations = {
                "charts": [],
                "tables": []
            }
            
            # Initialize lists for metrics and comparative periods
            metrics = []
            comparative_periods = []
            
            # Process tool outputs
            for tool_use in result.get("tool_uses", []):
                if tool_use["name"] == "generate_graph_data":
                    from models.visualization import ChartData
                    try:
                        chart_data = ChartData(**tool_use["input"])
                        visualizations["charts"].append(chart_data)
                        logger.info(f"Added chart: {chart_data.chartType} - {chart_data.config.title}")
                    except Exception as e:
                        logger.error(f"Error creating chart data: {str(e)}")
                elif tool_use["name"] == "generate_table_data":
                    from models.visualization import TableData
                    try:
                        table_data = TableData(**tool_use["input"])
                        visualizations["tables"].append(table_data)
                        logger.info(f"Added table: {table_data.tableType} - {table_data.config.title}")
                    except Exception as e:
                        logger.error(f"Error creating table data: {str(e)}")
                elif tool_use["name"] == "generate_financial_metric":
                    try:
                        metric_data = tool_use["input"]
                        metrics.append(metric_data)
                        logger.info(f"Added financial metric: {metric_data.get('name')} - {metric_data.get('value')}")
                    except Exception as e:
                        logger.error(f"Error creating financial metric data: {str(e)}")
                elif tool_use["name"] == "generate_comparative_period":
                    try:
                        period_data = tool_use["input"]
                        comparative_periods.append(period_data)
                        logger.info(f"Added comparative period: {period_data.get('metric')}")
                    except Exception as e:
                        logger.error(f"Error creating comparative period data: {str(e)}")
            
            logger.info(f"Generated {len(visualizations['charts'])} charts, {len(visualizations['tables'])} tables, "
                        f"{len(metrics)} metrics, and {len(comparative_periods)} comparative periods")
            
            # Return analysis text, visualizations, metrics, and comparative periods
            return {
                "analysis_text": result.get("content", ""),
                "visualizations": visualizations,
                "metrics": metrics,
                "comparative_periods": comparative_periods
            }
            
        except Exception as e:
            logger.error(f"Error analyzing financial document with tools: {str(e)}", exc_info=True)
            # Return error information
            return {
                "analysis_text": f"Error analyzing document: {str(e)}",
                "visualizations": {"charts": [], "tables": []},
                "metrics": [],
                "comparative_periods": []
            }

    # --- NEW METHOD for Tool-Based Analysis ---

    async def analyze_with_visualization_tools(
        self,
        document_text: str,
        user_query: str,
        knowledge_base: str = ""
    ) -> Dict[str, Any]:
        """
        Analyze a financial document using Claude with tool support for visualizations.

        Args:
            document_text: Text content of the financial document.
            user_query: The user's specific question or analysis request.
            knowledge_base: Optional additional context or domain knowledge.

        Returns:
            A dictionary containing:
            - "analysis_text": The textual analysis from Claude.
            - "visualizations": A dict with "charts": [...] and "tables": [...]
                                containing the structured JSON data generated by tools.
        """
        if not self.client:
            logger.error("Cannot analyze document because Claude API client is not available.")
            return {
                "analysis_text": "Error: Claude API client not configured.",
                "visualizations": {"charts": [], "tables": []}
            }

        try:
            logger.info(f"Starting analysis with visualization tools for query: '{user_query[:50]}...'")

            # Prepare the user message content, including the document text and knowledge base
            user_content_parts = [
                {"type": "text", "text": "Analyze the following financial document(s):"}
            ]

            # Add document text - using text type for simplicity here
            # In a more robust implementation, we might pass the PDF directly if available
            user_content_parts.append({
                "type": "text",
                "text": f"<financial_document>\n{document_text}\n</financial_document>"
            })

            if knowledge_base:
                user_content_parts.append({
                    "type": "text",
                    "text": f"<knowledge_base>\n{knowledge_base}\n</knowledge_base>"
                })

            user_content_parts.append({
                "type": "text",
                "text": f"\nUser Query: {user_query}"
            })

            # Prepare messages list for Claude API
            messages = [{"role": "user", "content": user_content_parts}]

            # Log request details
            logger.debug(f"Sending request to Claude with {len(messages)} message(s) and {len(ALL_TOOLS_DICT)} tools.")

            # Call Claude API with tools
            response = await self.client.messages.create(
                model=self.model,
                system=FINANCIAL_ANALYSIS_SYSTEM_PROMPT,  # Use the refined system prompt
                messages=messages,
                tools=ALL_TOOLS_DICT,
                tool_choice={"type": "any"},
                temperature=0.3, # Lower temp for more factual/structured output
                max_tokens=4096  # Maximize token limit for complex responses
            )

            logger.info("Received response from Claude API.")
            #logger.debug(f"Claude Raw Response: {response}") # Careful logging raw response

            # Process the response to extract text and tool uses
            processed_result = self._process_tool_calls(response)

            logger.info(f"Analysis complete. Text length: {len(processed_result['analysis_text'])}. "
                        f"Charts: {len(processed_result['visualizations']['charts'])}. "
                        f"Tables: {len(processed_result['visualizations']['tables'])}.")

            return processed_result

        except Exception as e:
            logger.exception(f"Error during analysis with visualization tools: {e}")
            return {
                "analysis_text": f"An error occurred during analysis: {e}",
                "visualizations": {"charts": [], "tables": []}
            }

    def _process_tool_calls(self, response: AnthropicMessage) -> Dict[str, Any]:
        """
        Processes Claude's response, extracting text and structured data from tool calls.

        Args:
            response: The AnthropicMessage object received from the API.

        Returns:
            A dictionary containing 'analysis_text' and 'visualizations' (with 'charts' and 'tables').
        """
        analysis_text = ""
        charts = []
        tables = []

        if not response.content:
            logger.warning("Claude response has no content.")
            return {
                "analysis_text": "No content received from analysis.",
                "visualizations": {"charts": [], "tables": []}
            }

        for block in response.content:
            if block.type == "text":
                analysis_text += block.text + "\n"
            elif block.type == "tool_use":
                tool_name = block.name
                tool_input = block.input

                logger.info(f"Processing tool use: {tool_name}")
                #logger.debug(f"Tool Input: {json.dumps(tool_input, indent=2)}") # Log tool input for debugging

                if tool_name == "generate_graph_data":
                    try:
                        # Basic validation (Pydantic models in tools.py handle deeper validation)
                        if isinstance(tool_input, dict) and "chartType" in tool_input and "config" in tool_input and "data" in tool_input:
                            charts.append(tool_input)
                            logger.info(f"Successfully processed chart data for tool ID {block.id}")
                        else:
                            logger.warning(f"Invalid input structure for generate_graph_data tool (ID: {block.id}): Missing required keys.")
                            # Optionally, include the invalid input in the analysis text for debugging
                            analysis_text += f"\n[Note: Failed to process chart data for tool {block.id}. Input: {json.dumps(tool_input)}]\n"
                    except Exception as e:
                        logger.error(f"Error processing generate_graph_data input (ID: {block.id}): {e}")
                        analysis_text += f"\n[Note: Error processing chart data for tool {block.id}: {e}]\n"

                elif tool_name == "generate_table_data":
                    try:
                        # Basic validation
                        if isinstance(tool_input, dict) and "tableType" in tool_input and "config" in tool_input and "data" in tool_input:
                            tables.append(tool_input)
                            logger.info(f"Successfully processed table data for tool ID {block.id}")
                        else:
                            logger.warning(f"Invalid input structure for generate_table_data tool (ID: {block.id}): Missing required keys.")
                            analysis_text += f"\n[Note: Failed to process table data for tool {block.id}. Input: {json.dumps(tool_input)}]\n"
                    except Exception as e:
                        logger.error(f"Error processing generate_table_data input (ID: {block.id}): {e}")
                        analysis_text += f"\n[Note: Error processing table data for tool {block.id}: {e}]\n"
                # Add handling for other tools if necessary
                # elif tool_name == "generate_financial_metric": ...
                # elif tool_name == "generate_comparative_period": ...

            else:
                logger.warning(f"Unsupported content block type: {block.type}")

        return {
            "analysis_text": analysis_text.strip(),
            "visualizations": {
                "charts": charts,
                "tables": tables
            }
        }

    # --- Keep other helper methods like _process_claude_response, _convert_claude_citation ---
</file>
```

#### pdf\_processing/document\_service\.py
*Size: 19.9 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/pdf_processing/document_service.py">
import os
import uuid
import json
import logging
from datetime import datetime
from typing import Dict, List, Optional, BinaryIO, Any
from pathlib import Path
import asyncio

from models.document import (
    ProcessedDocument, 
    DocumentMetadata, 
    ProcessingStatus,
    DocumentContentType,
    Citation as CitationSchema,
    DocumentUploadResponse
)
from models.database_models import DocumentType, ProcessingStatusEnum, Document, Citation
from pdf_processing.claude_service import ClaudeService
from pdf_processing.enhanced_pdf_service import EnhancedPDFService
from repositories.document_repository import DocumentRepository


logger = logging.getLogger(__name__)


class DocumentService:
    def __init__(self, document_repository: DocumentRepository):
        """
        Initialize the document service.
        
        Args:
            document_repository: Repository for document operations
        """
        self.document_repository = document_repository
        self.claude_service = ClaudeService()
        self.enhanced_pdf_service = EnhancedPDFService()
        
    async def upload_document(self, file_data: bytes, filename: str, user_id: str) -> DocumentUploadResponse:
        """
        Upload and process a document.
        
        Args:
            file_data: Raw bytes of the PDF file
            filename: Name of the file
            user_id: ID of the user uploading the document
            
        Returns:
            Document upload response with status and document ID
        """
        try:
            # Create the document record
            document = await self.document_repository.create_document(
                file_data=file_data,
                filename=filename,
                user_id=user_id,
                mime_type="application/pdf"
            )
            
            # Start background processing
            asyncio.create_task(self._process_document(document.id, file_data, filename))
            
            # Return upload response
            return self.document_repository.document_to_upload_response(document)
        
        except Exception as e:
            logger.error(f"Error uploading document: {str(e)}", exc_info=True)
            raise
    
    async def _process_document(self, document_id: str, pdf_data: bytes, filename: str):
        """
        Process a document with Claude API for PDF processing and citation extraction.
        
        Args:
            document_id: ID of the document
            pdf_data: Raw bytes of the PDF file
            filename: Name of the file
        """
        try:
            # Update status to processing
            await self.document_repository.update_document_status(document_id, ProcessingStatusEnum.PROCESSING)
            logger.info(f"Starting processing of document {document_id} ({filename}) with Claude API")
            
            # Process with Claude service directly for PDF processing and citation extraction
            try:
                logger.info(f"Processing document {document_id} with Claude service")
                processed_document, citations = await self.claude_service.process_pdf(pdf_data, filename)
                logger.info(f"Successfully processed document {document_id} with Claude service")
                logger.info(f"Extracted {len(citations)} citations from document")
            except Exception as e:
                logger.error(f"Error using Claude service: {str(e)}", exc_info=True)
                
                # Attempt to extract raw text even if Claude processing fails
                raw_text = ""
                try:
                    import io
                    from PyPDF2 import PdfReader
                    
                    pdf_file = io.BytesIO(pdf_data)
                    pdf_reader = PdfReader(pdf_file)
                    
                    # Extract text from each page
                    page_texts = []
                    for page_num in range(len(pdf_reader.pages)):
                        page = pdf_reader.pages[page_num]
                        page_text = page.extract_text()
                        if page_text:
                            page_texts.append(f"--- Page {page_num+1} ---\n{page_text}")
                    
                    raw_text = "\n\n".join(page_texts)
                    logger.info(f"Extracted {len(raw_text)} characters of raw text as fallback for document {document_id}")
                    
                    # Store the extracted text in database even if processing failed
                    await self.document_repository.update_document_content(
                        document_id=document_id,
                        document_type=DocumentType.OTHER,
                        extracted_data={"raw_text": raw_text},
                        raw_text=raw_text,
                        confidence_score=0.0
                    )
                    
                except Exception as extract_error:
                    logger.error(f"Failed to extract fallback text: {extract_error}", exc_info=True)
                
                # Update status to failed with error message
                await self.document_repository.update_document_status(
                    document_id=document_id,
                    status=ProcessingStatusEnum.FAILED,
                    error_message=f"Claude API processing error: {str(e)}"
                )
                return
            
            # Update document content
            document_type = DocumentType[processed_document.content_type.upper()] if processed_document.content_type else DocumentType.OTHER
            
            # Extract raw text from processed document
            raw_text = ""
            if processed_document.extracted_data and "raw_text" in processed_document.extracted_data:
                raw_text = processed_document.extracted_data["raw_text"]
                logger.info(f"Found {len(raw_text)} characters of raw text in processed document")
                logger.info(f"Sample text: {raw_text[:200]}...")
            
            # Ensure we have some raw text
            if not raw_text or len(raw_text.strip()) == 0:
                logger.warning(f"No raw text found in processed document for {document_id} - attempting extraction")
                try:
                    import io
                    from PyPDF2 import PdfReader
                    
                    pdf_file = io.BytesIO(pdf_data)
                    pdf_reader = PdfReader(pdf_file)
                    
                    # Extract text from each page
                    page_texts = []
                    for page_num in range(len(pdf_reader.pages)):
                        page = pdf_reader.pages[page_num]
                        page_text = page.extract_text()
                        if page_text:
                            page_texts.append(f"--- Page {page_num+1} ---\n{page_text}")
                    
                    raw_text = "\n\n".join(page_texts)
                    logger.info(f"Successfully extracted {len(raw_text)} characters as fallback raw text")
                    
                    # Update the extracted data with the raw text
                    if not processed_document.extracted_data:
                        processed_document.extracted_data = {}
                    processed_document.extracted_data["raw_text"] = raw_text
                    
                except Exception as extract_error:
                    logger.error(f"Failed to extract fallback text: {extract_error}", exc_info=True)
                    raw_text = f"Failed to extract text content from {filename}. PDF may contain images or be protected."
            
            # Update document with extracted content
            logger.info(f"Updating document {document_id} content in database")
            await self.document_repository.update_document_content(
                document_id=document_id,
                document_type=document_type,
                periods=processed_document.periods,
                extracted_data=processed_document.extracted_data,
                raw_text=raw_text,
                confidence_score=processed_document.confidence_score
            )
            
            # Log document processing details for debugging
            logger.info(f"Document {document_id} processed. Status: COMPLETED, Has raw_text: {bool(raw_text)}, Raw text length: {len(raw_text)}, Extracted data keys: {list(processed_document.extracted_data.keys()) if processed_document.extracted_data else 'None'}")
            
            # Add citations to the database
            added_citations = []
            logger.info(f"Storing {len(citations)} citations for document {document_id}")
            for citation in citations:
                # Create bounding box data if not present
                bounding_box = citation.bounding_box or {
                    "top": 0,
                    "left": 0,
                    "width": 0,
                    "height": 0
                }
                
                db_citation = await self.document_repository.add_citation(
                    document_id=document_id,
                    page=citation.page,
                    text=citation.text,
                    section=citation.section,
                    bounding_box=bounding_box
                )
                if db_citation:
                    added_citations.append(db_citation)
            
            # Link citations to financial insights if available
            if "financial_data" in processed_document.extracted_data and "insights" in processed_document.extracted_data["financial_data"]:
                insights = processed_document.extracted_data["financial_data"]["insights"]
                
                # Create a map of citation IDs to database citation IDs
                citation_id_map = {}
                for i, citation in enumerate(citations):
                    citation_id = f"citation_{i}"
                    if i < len(added_citations):
                        citation_id_map[citation_id] = str(added_citations[i].id)
                
                # Update the extracted data with database citation IDs
                for insight_id, insight_data in insights.items():
                    if "citations" in insight_data:
                        for i, citation_ref in enumerate(insight_data["citations"]):
                            if "citation_id" in citation_ref and citation_ref["citation_id"] in citation_id_map:
                                insight_data["citations"][i]["db_citation_id"] = citation_id_map[citation_ref["citation_id"]]
                
                # Update the document with the updated insights
                await self.document_repository.update_document_content(
                    document_id=document_id,
                    extracted_data=processed_document.extracted_data,
                    update_existing=True
                )
            
            # Update status to completed
            await self.document_repository.update_document_status(document_id, ProcessingStatusEnum.COMPLETED)
            
            logger.info(f"Document {document_id} processing completed with {len(added_citations)} citations extracted")
                
        except Exception as e:
            logger.error(f"Error processing document {document_id}: {str(e)}", exc_info=True)
            
            # Update status to failed
            await self.document_repository.update_document_status(
                document_id=document_id,
                status=ProcessingStatusEnum.FAILED,
                error_message=str(e)
            )
    
    async def get_document_financial_data(self, document_id: str) -> Dict[str, Any]:
        """
        Get content from a document that can be used for financial analysis.
        Now more flexible - returns any available content rather than requiring 
        specific financial_data structure.
        
        Args:
            document_id: ID of the document
                
        Returns:
            Dictionary containing document content suitable for analysis
        """
        document = await self.document_repository.get_document(document_id)
        
        if not document:
            logger.warning(f"Document {document_id} not found")
            return {"error": "Document not found"}
        
        result = {}
        
        # Add financial_data if it exists
        if document.extracted_data and isinstance(document.extracted_data, dict) and "financial_data" in document.extracted_data:
            result["financial_data"] = document.extracted_data["financial_data"]
        
        # Add raw_text if available
        if document.raw_text:
            result["raw_text"] = document.raw_text
            logger.info(f"Found {len(document.raw_text)} characters of raw text in document {document_id}")
        elif document.extracted_data and isinstance(document.extracted_data, dict) and "raw_text" in document.extracted_data:
            result["raw_text"] = document.extracted_data["raw_text"]
            logger.info(f"Found {len(document.extracted_data['raw_text'])} characters of raw text in extracted_data")
        
        # If we have any content, consider it valid
        if result:
            result["has_content"] = True
            return result
        
        # Return empty structure if no content found
        logger.warning(f"No analyzable content found in document {document_id}")
        return {
            "has_content": False,
            "raw_text": f"No content extracted from document {document_id}. The document may be empty or contain only images.",
            "revenue": {},
            "expenses": {},
            "profit": {},
            "assets": {},
            "liabilities": {},
            "equity": {}
        }
    
    async def get_document_content(self, document_id: str) -> Optional[Dict[str, Any]]:
        """
        Get the full content of a document including extracted data.
        
        Args:
            document_id: ID of the document
            
        Returns:
            Dictionary containing document content if found, None otherwise
        """
        document = await self.document_repository.get_document(document_id)
        
        if not document:
            return None
        
        # Get citations
        citations = await self.document_repository.get_document_citations(document_id)
        citation_schemas = [self.document_repository.citation_to_api_schema(citation) for citation in citations]
        
        return {
            "metadata": self.document_repository.document_to_metadata_schema(document).model_dump(),
            "content_type": document.document_type.value if document.document_type else "other",
            "periods": document.periods or [],
            "extracted_data": document.extracted_data or {},
            "citations": [citation.model_dump() for citation in citation_schemas],
            "confidence_score": document.confidence_score or 0.0
        }
        
    async def get_document(self, document_id: str) -> Optional[Dict[str, Any]]:
        """
        Get a document by ID. This is an alias for get_document_content for backwards compatibility.
        
        Args:
            document_id: ID of the document
            
        Returns:
            Dictionary containing document content if found, None otherwise
        """
        # This method should match what's being expected by the calling code
        return await self.get_document_content(document_id)

    async def extract_structured_financial_data(self, document_id: str, text: str = None) -> Dict[str, Any]:
        """
        Extract structured financial data from document text using Claude and update the document.
        
        Args:
            document_id: ID of the document to update
            text: Raw document text to analyze. If None, will be retrieved from the document.
            
        Returns:
            Dictionary with extraction results
        """
        try:
            logger.info(f"Extracting structured financial data for document {document_id}")
            
            # Get document from database to retrieve raw PDF data if available
            document = await self.document_repository.get_document(document_id)
            if not document:
                return {"error": f"Document {document_id} not found"}
            
            # If text not provided, use the one from the document
            if text is None and document.raw_text:
                text = document.raw_text
                logger.info(f"Using document's raw text ({len(text)} chars) for financial data extraction")
            elif text is None:
                return {"error": "No text available for document analysis"}
            
            # Get raw PDF data from storage if available
            pdf_data = None
            filename = document.filename if document else f"document_{document_id}.pdf"
            
            try:
                # Try to get the raw PDF data from storage
                pdf_data = await self.document_repository.get_document_binary(document_id)
                if pdf_data:
                    logger.info(f"Retrieved raw PDF data ({len(pdf_data)} bytes) for financial data extraction")
            except Exception as e:
                logger.warning(f"Could not retrieve PDF binary data: {str(e)}")
                # Continue with text-only extraction if PDF data is not available
            
            # Call Claude service to extract structured data - passing both text and PDF data
            structured_data = await self.claude_service.extract_structured_financial_data(
                text=text,
                pdf_data=pdf_data,
                filename=filename
            )
            
            # If error in extraction, return it
            if structured_data.get("error"):
                logger.error(f"Error extracting structured data: {structured_data['error']}")
                return structured_data
            
            # Prepare financial data structure
            financial_data = {}
            
            # Copy metrics if available
            if "metrics" in structured_data and structured_data["metrics"]:
                financial_data["metrics"] = structured_data["metrics"]
                
            # Copy ratios if available
            if "ratios" in structured_data and structured_data["ratios"]:
                financial_data["ratios"] = structured_data["ratios"]
                
            # Copy insights if available
            if "key_insights" in structured_data and structured_data["key_insights"]:
                financial_data["insights"] = structured_data["key_insights"]
            
            # Get periods from structured data
            periods = structured_data.get("periods", [])
            
            # Update the document with new financial data
            logger.info(f"Updating document {document_id} with structured financial data")
            
            # Create a merged extracted_data object that keeps existing data
            extracted_data = {
                "financial_data": financial_data
            }
            
            # Update document content
            await self.document_repository.update_document_content(
                document_id=document_id,
                document_type=DocumentType.FINANCIAL_REPORT,  # Force update to financial report type
                periods=periods if periods else None,
                extracted_data=extracted_data,
                update_existing=True  # Merge with existing data rather than replacing
            )
            
            # Return success with extracted data
            return {
                "document_id": document_id,
                "metrics_count": len(financial_data.get("metrics", [])),
                "ratios_count": len(financial_data.get("ratios", [])),
                "insights_count": len(financial_data.get("insights", [])),
                "periods": periods
            }
            
        except Exception as e:
            logger.exception(f"Error in structured financial data extraction: {e}")
            return {"error": str(e)}
</file>
```

#### pdf\_processing/enhanced\_pdf\_service\.py
*Size: 16.0 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/pdf_processing/enhanced_pdf_service.py">
import os
import base64
import io
import json
import logging
from typing import Dict, List, Optional, Any, Tuple, BinaryIO
import PyPDF2
from datetime import datetime

from langchain_core.prompts import ChatPromptTemplate
from langchain_anthropic import ChatAnthropic
from langchain_core.output_parsers import JsonOutputParser

from models.document import ProcessedDocument, DocumentContentType, Citation

logger = logging.getLogger(__name__)

class EnhancedPDFService:
    """Enhanced PDF processing service using LangChain."""
    
    def __init__(self):
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            raise ValueError("ANTHROPIC_API_KEY environment variable is not set")
        
        self.model = os.getenv("CLAUDE_MODEL", "claude-3-sonnet-latest")
        self.llm = ChatAnthropic(
            model=self.model,
            temperature=0.1,
            anthropic_api_key=api_key
        )
        
        # Initialize structured extraction prompts
        self._init_extraction_prompts()
    
    def _init_extraction_prompts(self):
        """Initialize the prompts for structured data extraction."""
        
        # Prompt for extracting table data
        self.table_extraction_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a financial document analysis assistant specialized in extracting tabular data from financial documents.
            Extract all tables from this financial document page. For each table:
            1. Identify the table title/caption
            2. Extract the table structure (headers and data)
            3. Determine the table position on the page
            
            Return the data in the following JSON format:
            {
              "tables": [
                {
                  "title": "string",
                  "headers": ["column1", "column2", ...],
                  "rows": [
                    ["cell1", "cell2", ...],
                    ...
                  ],
                  "page": number,
                  "position": {
                    "top": number,
                    "left": number,
                    "bottom": number,
                    "right": number
                  }
                }
              ]
            }
            
            Return ONLY valid JSON. Ensure the JSON is properly formatted and can be parsed."""),
            ("human", "Here is a page from a financial document:\n\n{page_content}")
        ])
        
        # Prompt for financial metrics extraction
        self.metrics_extraction_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a financial document analysis assistant specialized in extracting key financial metrics.
            Extract all important financial metrics from this document, such as:
            - Revenue figures
            - Profit/loss amounts
            - Growth percentages
            - Financial ratios
            - Cash flow figures
            
            For each metric, identify:
            1. The metric name
            2. The metric value
            3. The time period it applies to
            4. The page and paragraph/section where it appears
            
            Return the data in the following JSON format:
            {
              "metrics": [
                {
                  "name": "string",
                  "category": "Revenue|Expenses|Profitability|Liquidity|Growth|Other",
                  "value": number,
                  "unit": "string",
                  "period": "string",
                  "page": number,
                  "section": "string",
                  "text": "string" (the exact text where this metric appears)
                }
              ]
            }
            
            Return ONLY valid JSON. Ensure the JSON is properly formatted and can be parsed."""),
            ("human", "Here is a financial document:\n\n{document_content}")
        ])
        
        # Prompt for document type classification
        self.document_classification_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a financial document analysis assistant specialized in classifying financial documents.
            Classify this document as one of the following types:
            - balance_sheet
            - income_statement
            - cash_flow
            - notes
            - other
            
            Also identify the time periods covered in the document.
            
            Return the data in the following JSON format:
            {
              "document_type": "balance_sheet|income_statement|cash_flow|notes|other",
              "periods": ["period1", "period2", ...]
            }
            
            Return ONLY valid JSON. Ensure the JSON is properly formatted and can be parsed."""),
            ("human", "Here is a financial document:\n\n{document_content}")
        ])
        
        # Prompt for citation extraction
        self.citation_extraction_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a financial document analysis assistant specialized in identifying important information.
            Identify all important financial statements, facts, and figures in this document that would be useful for citation.
            For each important piece of information, extract:
            1. The exact text
            2. The page number
            3. The section or paragraph it appears in
            4. A unique ID for this citation
            
            Focus on extracting content that provides meaningful financial insights, such as:
            - Key financial metrics and their values
            - Important trends or changes
            - Significant financial events
            - Forward-looking statements
            - Risk factors
            
            Return the data in the following JSON format:
            {
              "citations": [
                {
                  "id": "string" (unique identifier),
                  "text": "string" (the exact text to cite),
                  "page": number,
                  "section": "string" (if available),
                  "importance": "high|medium|low" (indicating how crucial this information is)
                }
              ]
            }
            
            Return ONLY valid JSON. Ensure the JSON is properly formatted and can be parsed."""),
            ("human", "Here is a financial document:\n\n{document_content}")
        ])
    
    async def extract_tables(self, page_content: str, page_number: int) -> List[Dict[str, Any]]:
        """
        Extract tables from a single PDF page.
        
        Args:
            page_content: The text content of the page
            page_number: The page number
            
        Returns:
            List of extracted tables
        """
        try:
            # Create the extraction chain
            chain = (
                self.table_extraction_prompt 
                | self.llm 
                | JsonOutputParser()
            )
            
            # Run the chain
            result = await chain.ainvoke({"page_content": page_content})
            
            # Add the page number to each table if not already included
            tables = result.get("tables", [])
            for table in tables:
                if "page" not in table:
                    table["page"] = page_number
            
            return tables
        except Exception as e:
            logger.error(f"Error extracting tables from page {page_number}: {str(e)}")
            return []
    
    async def extract_metrics(self, document_content: str) -> List[Dict[str, Any]]:
        """
        Extract financial metrics from document content.
        
        Args:
            document_content: The text content of the document
            
        Returns:
            List of extracted metrics
        """
        try:
            # Create the extraction chain
            chain = (
                self.metrics_extraction_prompt 
                | self.llm 
                | JsonOutputParser()
            )
            
            # Run the chain
            result = await chain.ainvoke({"document_content": document_content})
            
            return result.get("metrics", [])
        except Exception as e:
            logger.error(f"Error extracting metrics: {str(e)}")
            return []
    
    async def classify_document(self, document_content: str) -> Tuple[DocumentContentType, List[str]]:
        """
        Classify document type and extract time periods.
        
        Args:
            document_content: The text content of the document
            
        Returns:
            Tuple of document type and list of periods
        """
        try:
            # Create the classification chain
            chain = (
                self.document_classification_prompt 
                | self.llm 
                | JsonOutputParser()
            )
            
            # Run the chain
            result = await chain.ainvoke({"document_content": document_content})
            
            # Parse the result
            doc_type_str = result.get("document_type", "other")
            periods = result.get("periods", [])
            
            # Convert to DocumentContentType enum
            try:
                doc_type = DocumentContentType(doc_type_str)
            except ValueError:
                logger.warning(f"Invalid document type: {doc_type_str}. Using 'other' instead.")
                doc_type = DocumentContentType.OTHER
            
            return doc_type, periods
        except Exception as e:
            logger.error(f"Error classifying document: {str(e)}")
            return DocumentContentType.OTHER, []
    
    async def extract_citations(self, document_content: str) -> List[Citation]:
        """
        Extract citations from document content.
        
        Args:
            document_content: The text content of the document
            
        Returns:
            List of Citation objects
        """
        try:
            # Create the citation extraction chain
            chain = (
                self.citation_extraction_prompt 
                | self.llm 
                | JsonOutputParser()
            )
            
            # Run the chain
            result = await chain.ainvoke({"document_content": document_content})
            
            # Convert to Citation objects
            citations_data = result.get("citations", [])
            citations = []
            
            for citation_data in citations_data:
                citation = Citation(
                    id=citation_data.get("id", f"citation_{len(citations)}"),
                    page=citation_data.get("page", 0),
                    text=citation_data.get("text", ""),
                    section=citation_data.get("section")
                )
                citations.append(citation)
            
            return citations
        except Exception as e:
            logger.error(f"Error extracting citations: {str(e)}")
            return []
    
    def extract_text_from_pdf(self, pdf_data: bytes) -> Tuple[str, Dict[int, str]]:
        """
        Extract text from PDF file.
        
        Args:
            pdf_data: Raw bytes of the PDF file
            
        Returns:
            Tuple of full document text and dictionary mapping page numbers to page text
        """
        try:
            # Open the PDF file
            pdf_file = io.BytesIO(pdf_data)
            pdf_reader = PyPDF2.PdfReader(pdf_file)
            
            # Extract text from each page
            full_text = ""
            page_texts = {}
            
            for i, page in enumerate(pdf_reader.pages):
                page_text = page.extract_text()
                page_texts[i + 1] = page_text  # Page numbers are 1-indexed
                full_text += page_text + "\n\n"
            
            return full_text, page_texts
        except Exception as e:
            logger.error(f"Error extracting text from PDF: {str(e)}")
            return "", {}
    
    async def process_pdf(self, pdf_data: bytes, filename: str) -> Tuple[ProcessedDocument, List[Citation]]:
        """
        Process a PDF file using LangChain for enhanced extraction.
        
        Args:
            pdf_data: Raw bytes of the PDF file
            filename: Name of the PDF file
            
        Returns:
            Tuple of processed document and list of citations
        """
        logger.info(f"Processing PDF: {filename}")
        
        # Extract text from PDF
        full_text, page_texts = self.extract_text_from_pdf(pdf_data)
        
        if not full_text:
            logger.error(f"Failed to extract text from PDF: {filename}")
            raise ValueError("Could not extract text from PDF")
        
        # Process in parallel for efficiency
        import asyncio
        
        # Classify document and extract citations
        doc_type, periods = await self.classify_document(full_text)
        citations = await self.extract_citations(full_text)
        metrics = await self.extract_metrics(full_text)
        
        # Extract tables from each page
        tables = []
        for page_num, page_text in page_texts.items():
            page_tables = await self.extract_tables(page_text, page_num)
            tables.extend(page_tables)
        
        # Create document metadata
        metadata = {
            "filename": filename,
            "upload_timestamp": datetime.now().isoformat(),
            "file_size": len(pdf_data),
            "mime_type": "application/pdf",
            "user_id": "default-user",
            "citation_links": [citation.id for citation in citations]
        }
        
        # Prepare extracted data
        extracted_data = {
            "raw_text": full_text,
            "financial_data": self._organize_financial_data(metrics, periods),
            "tables": tables,
            "metrics": metrics
        }
        
        # Create processed document
        document = ProcessedDocument(
            metadata=metadata,
            content_type=doc_type,
            periods=periods,
            extracted_data=extracted_data,
            citations=citations,
            confidence_score=0.95,
            processing_status="completed"
        )
        
        logger.info(f"Successfully processed PDF: {filename}")
        return document, citations
    
    def _organize_financial_data(self, metrics: List[Dict[str, Any]], periods: List[str]) -> Dict[str, Any]:
        """
        Organize metrics into structured financial data.
        
        Args:
            metrics: List of extracted metrics
            periods: List of time periods
            
        Returns:
            Structured financial data
        """
        # Initialize structured data
        financial_data = {
            "revenue": {},
            "expenses": {},
            "profit": {},
            "assets": {},
            "liabilities": {},
            "equity": {}
        }
        
        # Organize metrics by category and period
        for metric in metrics:
            category = metric.get("category", "").lower()
            period = metric.get("period", "")
            value = metric.get("value", 0)
            name = metric.get("name", "").lower()
            
            # Skip metrics without a period
            if not period:
                continue
            
            # Map to appropriate category
            if category == "revenue" or "revenue" in name:
                financial_data["revenue"][period] = value
            elif category == "expenses" or "expense" in name or "cost" in name:
                financial_data["expenses"][period] = value
            elif category == "profitability" or "profit" in name or "income" in name:
                financial_data["profit"][period] = value
            elif "asset" in name:
                financial_data["assets"][period] = value
            elif "liabilit" in name or "debt" in name:
                financial_data["liabilities"][period] = value
            elif "equity" in name:
                financial_data["equity"][period] = value
        
        return financial_data
</file>
```

#### pdf\_processing/financial\_agent\.py
*Size: 36.5 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/pdf_processing/financial_agent.py">
import os
import logging
from typing import Dict, List, Any, Optional, Tuple, TypedDict, Annotated
from enum import Enum
import json
import datetime

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_anthropic import ChatAnthropic
from langchain_core.tools import tool, BaseTool, ToolException
from pydantic import BaseModel, Field
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda, RunnablePassthrough

from langgraph.graph import StateGraph, END
from langgraph.prebuilt.tool_executor import ToolExecutor
from langgraph.graph.message import add_messages

from models.document import Citation

logger = logging.getLogger(__name__)

# Define state and data structures
class AgentState(TypedDict):
    """State definition for financial analysis agent."""
    messages: List[Any]  # The message history
    documents: Dict[str, Any]  # Document metadata and content
    citations: List[Dict[str, Any]]  # Citations extracted from documents
    financial_data: Dict[str, Any]  # Structured financial data
    analysis_results: Dict[str, Any]  # Results of financial analysis
    tools_results: List[Dict[str, Any]]  # Results from tool executions
    chart_data: Optional[Dict[str, Any]]  # Data for visualization
    current_task: Optional[str]  # Current task being performed

class ChartType(str, Enum):
    """Types of financial charts."""
    BAR = "bar"
    LINE = "line"
    PIE = "pie"
    AREA = "area"
    SCATTER = "scatter"

# Tool definitions
class FinancialTools:
    """Tools for financial analysis."""
    
    @tool("calculate_financial_ratio")
    def calculate_financial_ratio(self, ratio_name: str, numerator_value: float, denominator_value: float, description: Optional[str] = None) -> Dict[str, Any]:
        """
        Calculate a financial ratio from numerator and denominator values.
        Provides ratio result and interpretation.
        
        Args:
            ratio_name: Name of the ratio to calculate (e.g., 'Current Ratio', 'Debt-to-Equity')
            numerator_value: Value for the numerator
            denominator_value: Value for the denominator
            description: Description of what this ratio represents (optional)
            
        Returns:
            Dictionary containing ratio calculation results and interpretation
        """
        try:
            ratio_value = numerator_value / denominator_value
            
            # Default description if none provided
            description = description
            if not description:
                if "current" in ratio_name.lower():
                    description = "Measures the company's ability to pay short-term obligations"
                elif "debt" in ratio_name.lower() and "equity" in ratio_name.lower():
                    description = "Measures the company's financial leverage"
                elif "profit" in ratio_name.lower() or "margin" in ratio_name.lower():
                    description = "Measures the company's profitability as a percentage of revenue"
                else:
                    description = f"The {ratio_name} financial metric"
            
            # Simple interpretation based on common ratios
            interpretation = ""
            if "current" in ratio_name.lower():
                if ratio_value < 1:
                    interpretation = "Current ratio below 1 indicates potential liquidity issues."
                elif ratio_value < 2:
                    interpretation = "Current ratio between 1-2 is generally acceptable but could be better."
                else:
                    interpretation = "Current ratio above 2 indicates strong liquidity position."
            elif "debt" in ratio_name.lower() and "equity" in ratio_name.lower():
                if ratio_value < 0.5:
                    interpretation = "Low debt-to-equity ratio indicates conservative financing."
                elif ratio_value < 1.5:
                    interpretation = "Moderate debt-to-equity ratio indicating balanced financing."
                else:
                    interpretation = "High debt-to-equity ratio indicates higher financial risk."
            elif "profit" in ratio_name.lower() or "margin" in ratio_name.lower():
                if ratio_value < 0.05:
                    interpretation = "Low profit margin indicating potential profitability issues."
                elif ratio_value < 0.15:
                    interpretation = "Moderate profit margin in line with many industries."
                else:
                    interpretation = "High profit margin indicating strong profitability."
            
            return {
                "ratio_name": ratio_name,
                "value": round(ratio_value, 4),
                "description": description,
                "interpretation": interpretation,
                "numerator": numerator_value,
                "denominator": denominator_value
            }
        except ZeroDivisionError:
            raise ToolException(f"Cannot calculate {ratio_name}: division by zero")
        except Exception as e:
            raise ToolException(f"Error calculating ratio: {str(e)}")
    
    @tool("generate_chart_data")
    def generate_chart_data(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate data for financial charts and visualizations.
        Returns structured data that can be used by charting libraries.
        """
        try:
            chart_data = {
                "type": input_data["chart_type"],
                "title": input_data["title"],
                "x_axis": input_data["x_axis_label"],
                "y_axis": input_data["y_axis_label"],
                "data": input_data["data_series"]
            }
            
            # Add chart-specific properties
            if input_data["chart_type"] == ChartType.PIE:
                chart_data["total"] = sum(item.get("value", 0) for item in input_data["data_series"])
                chart_data["data"] = [
                    {
                        "name": item.get("name", ""),
                        "value": item.get("value", 0),
                        "percentage": (item.get("value", 0) / chart_data["total"]) * 100 if chart_data["total"] > 0 else 0
                    }
                    for item in input_data["data_series"]
                ]
            
            if input_data["chart_type"] in [ChartType.LINE, ChartType.BAR, ChartType.AREA]:
                # Organize time series data
                periods = sorted(set(item.get("period") for item in input_data["data_series"] if "period" in item))
                series_names = sorted(set(item.get("series") for item in input_data["data_series"] if "series" in item))
                
                if periods and series_names:
                    formatted_data = []
                    for period in periods:
                        entry = {"period": period}
                        for series in series_names:
                            value = next(
                                (item.get("value", 0) for item in input_data["data_series"] 
                                 if item.get("period") == period and item.get("series") == series), 
                                0
                            )
                            entry[series] = value
                        formatted_data.append(entry)
                    
                    chart_data["data"] = formatted_data
                    chart_data["series"] = series_names
            
            return chart_data
        except Exception as e:
            raise ToolException(f"Error generating chart data: {str(e)}")
    
    @tool("analyze_financial_trend")
    def analyze_financial_trend(self, data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Analyze trends in financial data over time.
        Determines growth rate and trend direction.
        """
        try:
            if not data or len(data) < 2:
                raise ToolException("Need at least two data points to analyze trend")
            
            # Sort data by period
            sorted_data = sorted(data, key=lambda x: x.get("period", ""))
            
            metric = sorted_data[0].get("metric", "Financial Metric")
            periods = [item.get("period", f"Period {i+1}") for i, item in enumerate(sorted_data)]
            values = [item.get("value", 0) for item in sorted_data]
            
            # Calculate growth rate
            if values[0] == 0:
                growth_rate = 0
            else:
                growth_rate = (values[-1] - values[0]) / values[0]
            
            # Determine trend direction
            if growth_rate > 0.05:  # 5% threshold for upward trend
                trend_direction = "up"
            elif growth_rate < -0.05:  # -5% threshold for downward trend
                trend_direction = "down"
            else:
                trend_direction = "stable"
            
            return {
                "metric": metric,
                "values": values,
                "periods": periods,
                "growth_rate": round(growth_rate, 4),
                "trend_direction": trend_direction
            }
        except Exception as e:
            if isinstance(e, ToolException):
                raise e
            raise ToolException(f"Error analyzing financial trend: {str(e)}")
    
    @tool("extract_financial_fact")
    def extract_financial_fact(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Extract specific financial facts from the document.
        Returns facts related to a specific financial topic.
        """
        # This is a placeholder implementation that would normally access document data
        # In a real application, this would search through document content
        facts = {
            "revenue": [
                {"fact": "Revenue increased by 12.5% year-over-year", "confidence": 0.95},
                {"fact": "Q4 revenue was $24.5M", "confidence": 0.98},
                {"fact": "Recurring revenue represents 72% of total revenue", "confidence": 0.93}
            ],
            "expenses": [
                {"fact": "Operating expenses grew 8% year-over-year", "confidence": 0.94},
                {"fact": "R&D expenses represent 18% of total expenses", "confidence": 0.92},
                {"fact": "Sales & Marketing is the largest expense category", "confidence": 0.91}
            ],
            "profitability": [
                {"fact": "Gross margin improved to 68% in Q4", "confidence": 0.97},
                {"fact": "Net profit margin was 12.4%", "confidence": 0.95},
                {"fact": "EBITDA grew 15% year-over-year", "confidence": 0.92}
            ]
        }
        
        topic = input_data.get("topic", "").lower()
        
        if topic in facts:
            result = {"topic": input_data.get("topic", ""), "facts": facts[topic]}
            if input_data.get("time_period"):
                # Filter facts by time period (in a real implementation)
                result["time_period"] = input_data.get("time_period")
            return result
        else:
            return {"topic": input_data.get("topic", ""), "facts": []}

# Financial analysis agent
class FinancialAnalysisAgent:
    """Financial analysis agent using LangGraph."""
    
    def __init__(self):
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            raise ValueError("ANTHROPIC_API_KEY environment variable is not set")
        
        # Initialize LLM
        self.model = os.getenv("CLAUDE_MODEL", "claude-3-sonnet-latest")
        self.llm = ChatAnthropic(
            model=self.model,
            temperature=0.1,
            anthropic_api_key=api_key
        )
        
        # Initialize tools
        self.tools = FinancialTools()
        self.tool_list = [
            self.tools.calculate_financial_ratio,
            self.tools.generate_chart_data,
            self.tools.analyze_financial_trend,
            self.tools.extract_financial_fact
        ]
        self.tool_executor = ToolExecutor(self.tool_list)
        
        # Initialize system prompts
        self._init_system_prompts()
        
        # Build agent graph
        self.workflow = self._build_workflow()
    
    def _init_system_prompts(self):
        """Initialize system prompts for the agent."""
        
        self.orchestrator_prompt = """You are a Financial Analysis Orchestrator that helps analyze financial documents.
Your job is to determine the user's intent and route to the appropriate financial analysis function.

Choose from the following functions based on the user's request:
1. "analyze_financial_metrics" - Calculate and analyze key financial metrics (like revenue growth, profit margins)
2. "generate_visualization" - Create data visualization for financial trends
3. "extract_document_insights" - Extract key insights from documents
4. "answer_question" - Directly answer the user's question if sufficient information is available

Based on the user's message, choose the most appropriate function.
Return ONLY the function name, nothing else."""
        
        self.metrics_analysis_prompt = """You are a Financial Metrics Analyst specialized in analyzing financial metrics from documents.
Use the available financial data and documents to perform detailed metric analysis.

You have access to the following tools:
- calculate_financial_ratio: Calculate financial ratios and get interpretations
- analyze_financial_trend: Analyze trends in financial metrics over time
- extract_financial_fact: Extract specific facts about financial metrics

Think carefully about which financial metrics would be most relevant for the user's question.
When using tools, provide clear rationale for the metrics you're calculating and analyzing.
Always cite sources from the original documents when possible."""
        
        self.visualization_prompt = """You are a Financial Data Visualization expert specialized in creating meaningful charts.
Use the available financial data to create appropriate visualizations.

You have access to the following tools:
- generate_chart_data: Create data for charts based on financial metrics
- analyze_financial_trend: Analyze trends in financial metrics to determine what to visualize

Think carefully about the most appropriate chart type for the financial data:
- Bar charts: Good for comparing categorical data
- Line charts: Best for showing trends over time
- Pie charts: Useful for showing composition of a whole
- Area charts: Effective for showing cumulative totals over time
- Scatter plots: Good for showing relationships between variables

Choose appropriate labels, titles, and data points to make the visualization informative."""
        
        self.insights_prompt = """You are a Financial Insights Analyst specialized in extracting key insights from financial documents.
Your job is to extract the most important insights from financial documents and provide context.

You have access to the following tools:
- extract_financial_fact: Extract specific facts about financial topics
- analyze_financial_trend: Analyze trends in financial metrics

Think about what the most important insights are based on the user's question.
Focus on extracting insights that are:
1. Directly relevant to the user's question
2. Supported by data in the documents
3. Insightful and not just repetitions of raw numbers
4. Properly contextualized with industry benchmarks when available

Always cite the specific parts of the document where your insights come from."""
        
        self.final_response_prompt = """You are a Financial Analysis Assistant that provides comprehensive answers to questions about financial documents.
Now that analysis has been performed, provide a complete, well-structured response to the user's question.

Your response should:
1. Directly address the user's question
2. Incorporate all relevant financial metrics, visualizations, and insights
3. Present information in a clear, logical structure
4. Cite specific parts of the original documents
5. Add context and interpretation to make the information actionable

If charts or visualizations were created, describe what they show and what insights can be drawn from them.
Be thorough but concise, and focus on the most important information relevant to the user's question."""
    
    def _build_workflow(self) -> StateGraph:
        """Build the workflow for financial analysis."""
        # Create the workflow graph
        workflow = StateGraph(AgentState)
        
        # Add nodes
        workflow.add_node("orchestrator", self.route_intent)
        workflow.add_node("analyze_financial_metrics", self.analyze_financial_metrics)
        workflow.add_node("generate_visualization", self.generate_visualization)
        workflow.add_node("extract_document_insights", self.extract_document_insights)
        workflow.add_node("answer_question", self.answer_question)
        
        # Add edges
        workflow.add_conditional_edges(
            "orchestrator",
            self.get_next_step,
            {
                "analyze_financial_metrics": "analyze_financial_metrics",
                "generate_visualization": "generate_visualization",
                "extract_document_insights": "extract_document_insights",
                "answer_question": "answer_question",
                END: END
            }
        )
        
        workflow.add_edge("analyze_financial_metrics", "generate_visualization")
        workflow.add_edge("generate_visualization", "extract_document_insights")
        workflow.add_edge("extract_document_insights", "answer_question")
        workflow.add_edge("answer_question", END)
        
        # Set entry point
        workflow.set_entry_point("orchestrator")
        
        # Compile the workflow
        return workflow.compile()
    
    def route_intent(self, state: AgentState) -> AgentState:
        """Route to the appropriate next step based on user intent."""
        # Get the last user message
        messages = state["messages"]
        last_user_message = None
        for message in reversed(messages):
            if isinstance(message, HumanMessage):
                last_user_message = message.content
                break
        
        if not last_user_message:
            # Default to answering directly if no user message found
            new_state = state.copy()
            new_state["current_task"] = "answer_question"
            return new_state
        
        # Prepare the orchestrator prompt
        prompt = ChatPromptTemplate.from_messages([
            ("system", self.orchestrator_prompt),
            ("human", f"User request: {last_user_message}\n\nWhat financial analysis function should I use to address this request?")
        ])
        
        # Get routing decision from the LLM
        chain = prompt | self.llm | StrOutputParser()
        route = chain.invoke({})
        
        # Clean up the response
        route = route.strip().lower()
        if "analyze_financial_metrics" in route:
            task = "analyze_financial_metrics"
        elif "generate_visualization" in route:
            task = "generate_visualization"
        elif "extract_document_insights" in route:
            task = "extract_document_insights"
        else:
            task = "answer_question"
        
        # Update the state with the current task
        new_state = state.copy()
        new_state["current_task"] = task
        return new_state
    
    def get_next_step(self, state: AgentState) -> Dict[str, Any]:
        """Determine the next step in the workflow."""
        current_task = state.get("current_task")
        
        if current_task == "analyze_financial_metrics":
            return {"next": "analyze_financial_metrics"}
        elif current_task == "generate_visualization":
            return {"next": "generate_visualization"}
        elif current_task == "extract_document_insights":
            return {"next": "extract_document_insights"}
        elif current_task == "answer_question":
            return {"next": "answer_question"}
        else:
            # Default to answering the question
            return {"next": "answer_question"}
    
    def analyze_financial_metrics(self, state: AgentState) -> AgentState:
        """Analyze financial metrics using the metrics analysis tools."""
        # Create a system message with the metrics analysis prompt
        messages = state["messages"]
        system_message = SystemMessage(content=self.metrics_analysis_prompt)
        
        # Add context about available documents and financial data
        documents_info = "Available financial documents:\n"
        for doc_id, doc in state.get("documents", {}).items():
            documents_info += f"- {doc.get('filename', 'Unnamed document')}\n"
        
        financial_data_info = "Available financial data:\n"
        for category, data in state.get("financial_data", {}).items():
            financial_data_info += f"- {category.capitalize()}: {data}\n"
        
        context_message = SystemMessage(content=f"{documents_info}\n{financial_data_info}")
        
        # Get tools description
        tools_description = "You have access to the following tools:\n"
        for tool in self.tool_list:
            tools_description += f"- {tool.name}: {tool.description}\n"
        
        tools_message = SystemMessage(content=tools_description)
        
        # Combine messages for the LLM
        combined_messages = [system_message, context_message, tools_message] + messages
        
        # Get the analysis steps from the LLM
        tool_message = self.llm.invoke(combined_messages)
        
        # Parse the tools to use
        parsed_tools = []
        try:
            import re
            # Look for tool calls in the format: calculate_financial_ratio({"ratio_name": "...", ...})
            tool_calls = re.finditer(r'(\w+)\(({[^}]+})\)', tool_message.content)
            
            for match in tool_calls:
                tool_name = match.group(1)
                tool_args = json.loads(match.group(2))
                parsed_tools.append({"name": tool_name, "arguments": tool_args})
        except Exception as e:
            logger.error(f"Error parsing tool calls: {str(e)}")
        
        # Execute the tools
        tools_results = []
        for tool in parsed_tools:
            try:
                result = self.tool_executor.execute(
                    tool["name"], 
                    tool["arguments"]
                )
                tools_results.append({
                    "tool": tool["name"],
                    "arguments": tool["arguments"],
                    "result": result
                })
            except Exception as e:
                logger.error(f"Error executing tool {tool['name']}: {str(e)}")
                tools_results.append({
                    "tool": tool["name"],
                    "arguments": tool["arguments"],
                    "error": str(e)
                })
        
        # Update the state with the current task
        new_state = state.copy()
        new_state["tools_results"] = state.get("tools_results", []) + tools_results
        
        # Analyze the results to extract financial metrics
        analysis_results = {}
        for tool_result in tools_results:
            if tool_result.get("tool") == "calculate_financial_ratio" and "result" in tool_result:
                result = tool_result["result"]
                if "ratio_name" in result and "value" in result:
                    if "ratios" not in analysis_results:
                        analysis_results["ratios"] = []
                    analysis_results["ratios"].append(result)
            
            elif tool_result.get("tool") == "analyze_financial_trend" and "result" in tool_result:
                result = tool_result["result"]
                if "trends" not in analysis_results:
                    analysis_results["trends"] = []
                analysis_results["trends"].append(result)
            
            elif tool_result.get("tool") == "extract_financial_fact" and "result" in tool_result:
                result = tool_result["result"]
                if "facts" not in analysis_results:
                    analysis_results["facts"] = []
                analysis_results["facts"].extend(result.get("facts", []))
        
        new_state["analysis_results"] = analysis_results
        
        # Add to message history
        new_state["messages"] = add_messages(
            new_state["messages"],
            AIMessage(content=f"I've analyzed the financial metrics and found {len(tools_results)} relevant results. Now I'll prepare visualizations based on these metrics.")
        )
        
        return new_state
    
    def generate_visualization(self, state: AgentState) -> AgentState:
        """Generate financial visualizations based on the financial data and analysis results."""
        # Create a system message with the visualization prompt
        system_message = SystemMessage(content=self.visualization_prompt)
        
        # Get tools description
        tools_description = "You have access to the following tools:\n"
        for tool in self.tool_list:
            if tool.name in ["generate_chart_data", "analyze_financial_trend"]:
                tools_description += f"- {tool.name}: {tool.description}\n"
        
        tools_message = SystemMessage(content=tools_description)
        
        # Add context about available analysis results
        analysis_results = state.get("analysis_results", {})
        chart_data = state.get("chart_data")
        
        context = "Financial Analysis Results:\n"
        
        if "ratios" in analysis_results:
            context += "\nFinancial Ratios:\n"
            for ratio in analysis_results["ratios"]:
                context += f"- {ratio.get('ratio_name', 'Unnamed ratio')}: {ratio.get('value', 'N/A')}\n"
        
        if "trends" in analysis_results:
            context += "\nFinancial Trends:\n"
            for trend in analysis_results["trends"]:
                context += f"- {trend.get('metric', 'Unnamed metric')}: {trend.get('trend_direction', 'N/A')} trend with {trend.get('growth_rate', 'N/A')} growth rate\n"
        
        context_message = SystemMessage(content=context)
        
        # Combine messages for the LLM
        combined_messages = [system_message, tools_message, context_message] + state["messages"]
        
        # Get visualization suggestion from the LLM
        vis_message = self.llm.invoke(combined_messages)
        
        # Update the state
        new_state = state.copy()
        
        # Parse the visualization tools to use
        parsed_tools = []
        try:
            import re
            # Look for tool calls in the format: generate_chart_data({"chart_type": "...", ...})
            tool_calls = re.finditer(r'(\w+)\(({[^}]+})\)', vis_message.content)
            
            for match in tool_calls:
                tool_name = match.group(1)
                if tool_name == "generate_chart_data":
                    tool_args = json.loads(match.group(2))
                    parsed_tools.append({"name": tool_name, "arguments": tool_args})
        except Exception as e:
            logger.error(f"Error parsing visualization tool calls: {str(e)}")
        
        # Execute the visualization tools
        chart_data = None
        for tool in parsed_tools:
            try:
                result = self.tool_executor.execute(
                    tool["name"], 
                    tool["arguments"]
                )
                
                if tool["name"] == "generate_chart_data":
                    chart_data = result
                    break  # Use the first successful chart
            except Exception as e:
                logger.error(f"Error generating chart data: {str(e)}")
        
        # If no charts were generated, create a default chart
        if not chart_data and "ratios" in analysis_results:
            try:
                # Create a default bar chart for ratios
                ratios = analysis_results["ratios"]
                chart_data = self.tool_executor.execute(
                    "generate_chart_data",
                    {
                        "chart_type": "bar",
                        "x_axis_label": "Ratio",
                        "y_axis_label": "Value",
                        "data_series": [
                            {"name": ratio.get("ratio_name", f"Ratio {i}"), "value": ratio.get("value", 0)}
                            for i, ratio in enumerate(ratios)
                        ],
                        "title": "Financial Ratios"
                    }
                )
            except Exception as e:
                logger.error(f"Error generating default chart: {str(e)}")
        
        # Update the state
        new_state["chart_data"] = chart_data
        
        # Add to message history
        chart_message = "I've prepared a visualization based on the financial analysis."
        if chart_data:
            chart_message += f" Generated a {chart_data.get('type', 'chart')} chart titled '{chart_data.get('title', 'Financial Data')}'."
        new_state["messages"] = add_messages(
            new_state["messages"],
            AIMessage(content=chart_message)
        )
        
        return new_state
    
    def extract_document_insights(self, state: AgentState) -> AgentState:
        """Extract key insights from financial documents."""
        # Create a system message with the insights prompt
        system_message = SystemMessage(content=self.insights_prompt)
        
        # Add context about available citations
        citations = state.get("citations", [])
        citations_info = "Available citations from documents:\n"
        for i, citation in enumerate(citations[:10]):  # Limit to first 10 citations
            citations_info += f"{i+1}. {citation.get('text', 'No text')} (Page {citation.get('page', 'N/A')})\n"
        
        if len(citations) > 10:
            citations_info += f"... and {len(citations) - 10} more citations\n"
        
        context_message = SystemMessage(content=citations_info)
        
        # Combine messages for the LLM
        combined_messages = [system_message, context_message] + state["messages"]
        
        # Get insights from the LLM
        insights_message = self.llm.invoke(combined_messages)
        
        # Update the state
        new_state = state.copy()
        
        # Parse insights and add to analysis results
        if "analysis_results" not in new_state:
            new_state["analysis_results"] = {}
        
        # Extract insights from the message
        insights = []
        
        # Simple parsing - in a real app we'd use a more robust approach
        lines = insights_message.content.split("\n")
        current_insight = ""
        
        for line in lines:
            line = line.strip()
            if line.startswith("-") or line.startswith("â€¢") or line.startswith("*"):
                if current_insight:
                    insights.append(current_insight)
                current_insight = line[1:].strip()
            elif current_insight and line:
                current_insight += " " + line
        
        if current_insight:
            insights.append(current_insight)
        
        # If no insights were extracted, use the whole message
        if not insights and insights_message.content.strip():
            insights = [insights_message.content.strip()]
        
        # Add insights to analysis results
        new_state["analysis_results"]["insights"] = insights
        
        # Add to message history
        insight_summary = f"I've extracted {len(insights)} key insights from the documents."
        new_state["messages"] = add_messages(
            new_state["messages"],
            AIMessage(content=insight_summary)
        )
        
        return new_state
    
    def answer_question(self, state: AgentState) -> AgentState:
        """Generate the final response to the user's question."""
        # Create a system message with the final response prompt
        system_message = SystemMessage(content=self.final_response_prompt)
        
        # Add context about analysis results
        analysis_results = state.get("analysis_results", {})
        chart_data = state.get("chart_data")
        
        context = "Financial Analysis Results:\n"
        
        if "ratios" in analysis_results:
            context += "\nFinancial Ratios:\n"
            for ratio in analysis_results["ratios"]:
                context += f"- {ratio.get('ratio_name', 'Unnamed ratio')}: {ratio.get('value', 'N/A')}"
                if "interpretation" in ratio:
                    context += f" ({ratio['interpretation']})"
                context += "\n"
        
        if "trends" in analysis_results:
            context += "\nFinancial Trends:\n"
            for trend in analysis_results["trends"]:
                context += f"- {trend.get('metric', 'Unnamed metric')}: {trend.get('trend_direction', 'N/A')} trend with {trend.get('growth_rate', 'N/A')} growth rate\n"
        
        if "insights" in analysis_results:
            context += "\nKey Insights:\n"
            for i, insight in enumerate(analysis_results["insights"]):
                context += f"{i+1}. {insight}\n"
        
        if chart_data:
            context += f"\nVisualization Generated:\n- Type: {chart_data.get('type', 'Chart')}\n- Title: {chart_data.get('title', 'Financial Data')}\n"
        
        context_message = SystemMessage(content=context)
        
        # Combine messages for the LLM
        combined_messages = [system_message, context_message] + state["messages"]
        
        # Generate the final response
        final_response = self.llm.invoke(combined_messages)
        
        # Update the state
        new_state = state.copy()
        new_state["messages"] = add_messages(
            new_state["messages"],
            final_response
        )
        
        return new_state
    
    async def process_financial_query(
        self, 
        query: str,
        documents: Dict[str, Any],
        citations: List[Dict[str, Any]],
        financial_data: Dict[str, Any],
        history: List[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Process a financial query through the agent workflow.
        
        Args:
            query: User's financial question
            documents: Document metadata and content
            citations: Citations extracted from documents
            financial_data: Structured financial data
            history: Previous conversation history
            
        Returns:
            Dictionary with the response and additional information
        """
        if history is None:
            history = []
            
        # Convert history to message format
        messages = []
        for msg in history:
            if msg["role"] == "user":
                messages.append(HumanMessage(content=msg["content"]))
            elif msg["role"] == "assistant":
                messages.append(AIMessage(content=msg["content"]))
            
        # Add current query
        messages.append(HumanMessage(content=query))
        
        # Set up initial state
        initial_state = {
            "messages": messages,
            "documents": documents,
            "citations": citations,
            "financial_data": financial_data,
            "analysis_results": {},
            "tools_results": [],
            "chart_data": None,
            "current_task": None
        }
        
        try:
            # Run the workflow
            final_state = await self.workflow.ainvoke(initial_state)
            
            # Extract the final assistant message
            final_message = None
            for msg in reversed(final_state["messages"]):
                if isinstance(msg, AIMessage):
                    final_message = msg
                    break
            
            if not final_message:
                return {
                    "error": "Failed to generate a response",
                    "content": "I couldn't generate a proper analysis at this time."
                }
            
            # Return the response and additional data
            return {
                "content": final_message.content,
                "analysis_results": final_state["analysis_results"],
                "chart_data": final_state["chart_data"],
                "citations_used": final_state.get("citations_used", [])
            }
            
        except Exception as e:
            logger.error(f"Error processing financial query: {str(e)}", exc_info=True)
            return {
                "error": str(e),
                "content": "I encountered an error while analyzing the financial data. Please try again with a different question."
            }
</file>
```

#### pdf\_processing/langchain\_service\.py
*Size: 7.5 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/pdf_processing/langchain_service.py">
import os
import logging
from typing import Dict, List, Any, Optional, Tuple

from langchain_core.prompts import ChatPromptTemplate
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain_core.runnables import RunnableLambda
from langchain_core.runnables.config import RunnableConfig

from models.message import Message
from models.document import ProcessedDocument, Citation

logger = logging.getLogger(__name__)

class LangChainService:
    def __init__(self):
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            raise ValueError("ANTHROPIC_API_KEY environment variable is not set")
        
        self.model = os.getenv("CLAUDE_MODEL", "claude-3-sonnet-latest")
        self.llm = ChatAnthropic(
            model=self.model,
            temperature=0.2,
            anthropic_api_key=api_key
        )
        
        # Initialize prompt templates
        self._init_prompt_templates()
    
    def _init_prompt_templates(self):
        """Initialize commonly used prompt templates."""
        # Financial Analysis System Prompt
        self.financial_analysis_system_prompt = """You are a financial document analysis assistant specialized in extracting insights from financial statements, reports, and related documents.
        Your goal is to provide accurate, detailed analysis with citations to the source material.
        When referencing information from documents, include citation markers in the format [Citation: id].
        Always maintain professional language and ensure all financial analyses are backed by data from the documents."""
        
        # Citation extraction prompt
        self.citation_extraction_prompt = ChatPromptTemplate.from_messages([
            ("system", """Extract citations from this financial document for relevant figures, statements, and tables.
                For each important piece of financial information, identify the exact text, page number, and section.
                Return the citations as a JSON array with the following fields for each citation:
                - id: A unique identifier for the citation
                - page: The page number where the citation appears
                - text: The exact text being cited
                - section: The section name or heading where the citation appears (if available)
                
                Focus on extracting citations for key financial metrics, trends, ratios, and important statements."""),
            ("human", "{document_text}")
        ])
        
        # Financial analysis prompt with citations
        self.financial_analysis_prompt = ChatPromptTemplate.from_messages([
            ("system", self.financial_analysis_system_prompt),
            ("human", """Please analyze the following financial information and respond to this question: {question}
            
            Document extracts with citations:
            {document_extracts}
            
            Previous conversation context:
            {conversation_history}
            
            Please be specific and cite your sources using the citation IDs provided in square brackets [Citation: id].
            """)
        ])
    
    async def extract_citations(self, document_text: str) -> List[Citation]:
        """
        Extract citations from document text using LangChain.
        
        Args:
            document_text: The text extracted from the document
            
        Returns:
            List of Citation objects
        """
        try:
            # Create extraction chain
            extraction_chain = (
                self.citation_extraction_prompt 
                | self.llm 
                | JsonOutputParser()
            )
            
            # Run the chain
            citations_data = await extraction_chain.ainvoke({"document_text": document_text})
            
            # Convert to Citation objects
            citations = []
            for i, citation_data in enumerate(citations_data):
                citation = Citation(
                    id=citation_data.get("id", f"citation_{i}"),
                    page=citation_data.get("page", 0),
                    text=citation_data.get("text", ""),
                    section=citation_data.get("section")
                )
                citations.append(citation)
            
            return citations
            
        except Exception as e:
            logger.error(f"Error extracting citations: {str(e)}")
            return []
    
    async def analyze_document_content(
        self, 
        question: str, 
        document_extracts: List[str], 
        conversation_history: List[Dict[str, Any]] = None
    ) -> str:
        """
        Analyze document content and answer user questions with citations.
        
        Args:
            question: The user's question
            document_extracts: List of document extracts with citation information
            conversation_history: Previous conversation turns for context
            
        Returns:
            AI response with citation references
        """
        if conversation_history is None:
            conversation_history = []
        
        # Format document extracts with citations
        formatted_extracts = "\n\n".join(document_extracts)
        
        # Format conversation history
        formatted_history = ""
        if conversation_history:
            for i, message in enumerate(conversation_history):
                role = message.get("role", "user")
                content = message.get("content", "")
                formatted_history += f"{role.capitalize()}: {content}\n\n"
        
        # Create analysis chain
        analysis_chain = (
            self.financial_analysis_prompt 
            | self.llm 
            | StrOutputParser()
        )
        
        # Run the chain
        response = await analysis_chain.ainvoke({
            "question": question,
            "document_extracts": formatted_extracts,
            "conversation_history": formatted_history
        })
        
        return response
    
    async def generate_insights(self, financial_data: Dict[str, Any]) -> List[str]:
        """
        Generate financial insights from extracted data.
        
        Args:
            financial_data: Dictionary containing financial data
            
        Returns:
            List of insights
        """
        # Create a prompt for generating insights
        insights_prompt = ChatPromptTemplate.from_messages([
            ("system", """Generate key financial insights based on the provided financial data.
                Focus on identifying trends, anomalies, and noteworthy patterns.
                Provide 3-5 concise, specific insights that would be valuable for financial decision-making."""),
            ("human", "Financial data: {financial_data}")
        ])
        
        # Create insights chain
        insights_chain = (
            insights_prompt 
            | self.llm 
            | RunnableLambda(lambda x: x.content.split("\n"))  # Split into separate insights
        )
        
        # Run the chain
        insights = await insights_chain.ainvoke({"financial_data": str(financial_data)})
        
        # Clean and filter insights
        cleaned_insights = [
            insight.strip().replace("- ", "") 
            for insight in insights 
            if insight.strip() and not insight.strip().startswith("Financial insights:")
        ]
        
        return cleaned_insights
</file>
```

#### pdf\_processing/langgraph\_service\.py
*Size: 67.0 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/pdf_processing/langgraph_service.py">
import os
import json
import gc
import logging
import psutil
import re
import uuid
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple, TypedDict, cast
from enum import Enum

from anthropic import Anthropic
from langchain_core.messages import SystemMessage
from langchain_anthropic import ChatAnthropic
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

from utils.database import SessionLocal
from models.document import ProcessedDocument

logger = logging.getLogger(__name__)

# Define state types
class ConversationNodeType(str, Enum):
    """Types of nodes in the conversation graph."""
    ROUTER = "router"
    DOCUMENT_PROCESSOR = "document_processor"
    RESPONSE_GENERATOR = "response_generator"
    CITATION_PROCESSOR = "citation_processor"
    END = "end"

class AgentState(TypedDict):
    """State definition for conversation agent."""
    conversation_id: str
    messages: List[Dict[str, Any]]
    documents: List[Dict[str, Any]]
    citations: List[Dict[str, Any]]
    active_documents: List[str]
    current_message: Optional[Dict[str, Any]]
    current_response: Optional[Dict[str, Any]]
    citations_used: List[Dict[str, Any]]
    context: Dict[str, Any]

class LangGraphService:
    """Service to manage LangGraph workflows for financial analysis."""
    
    def __init__(self):
        """Initialize the LangGraph service."""
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            raise ValueError("ANTHROPIC_API_KEY environment variable is not set")
        
        self.model = os.getenv("CLAUDE_MODEL", "claude-3-5-sonnet-20241022")
        # Initialize with parameters set for the latest Claude model which has citation support built-in
        # Note: We don't use the LangChain wrapper's PDF support - we handle PDFs directly in the simple_document_qa method
        self.llm = ChatAnthropic(
            model=self.model,
            temperature=0.3,
            anthropic_api_key=api_key,
            max_tokens=4000,
            # Use model_kwargs to set the system message and other model-specific parameters
            model_kwargs={
                "system": "You are a financial document analysis assistant that provides precise answers with citations. Always cite your sources when answering questions about documents."
                # We don't need the PDF beta flag here since we handle PDFs directly in the simple_document_qa method
            }
        )
        
        # Create memory saver for graph state persistence
        self.memory = MemorySaver()
        
        # Initialize conversation manager
        self.conversation_states = {}
        
        # Initialize system prompts
        self._init_system_prompts()
        
        # Setup conversation graph
        self.conversation_graph = self._create_conversation_graph()
        # Also set workflow attribute for consistent naming
        self.workflow = self.conversation_graph
        
        logger.info(f"LangGraphService initialized with model: {self.model}")
    
    def _init_system_prompts(self):
        """Initialize system prompts for different nodes."""
        self.router_prompt = """You are a router for a financial document analysis conversation.
        Your job is to determine what action to take next based on the user's message and conversation context.
        
        Choose one of the following options:
        - "document_processor": If the user is referring to documents or we need to process document context
        - "response_generator": If we have enough context to generate a response
        - "citation_processor": If we need to process citations before responding
        - "end": If the conversation should end
        
        Reply with just the action name, nothing else."""
        
        self.document_processor_prompt = """You are a document processing agent for financial analysis.
        Your job is to extract relevant information from documents based on the user's query.
        
        For each document mentioned in the query or relevant to the query:
        1. Identify key sections that address the user's question
        2. Extract important financial data, metrics, and insights
        3. Format the information in a structured way
        4. Include citation information so the main assistant can properly cite sources
        
        Be thorough but focus on relevance to the user's specific question."""
        
        self.response_generator_prompt = """You are a financial document analysis assistant specializing in answering questions about financial documents.
        
        When responding to the user:
        1. Provide clear, direct answers to their questions
        2. Base your responses on the document content provided
        3. Use specific financial data, metrics, and insights from the documents
        4. Always cite your sources using [Citation: ID] format when referencing specific information
        5. Be professional and precise in your analysis
        6. If you're uncertain about something, acknowledge it rather than guessing
        7. If the user asks about something not covered in the documents, politely explain that you don't have that information
        
        The user has uploaded financial documents which you can reference and cite."""
        
        self.citation_processor_prompt = """You are a citation processing agent for financial document analysis.
        Your job is to ensure all citations in a response are properly formatted and accurate.
        
        For each citation in the response:
        1. Verify the citation against the document content
        2. Ensure the citation format is consistent
        3. Check that citations are relevant to the user's query
        4. Remove any citations that cannot be verified
        
        The final response should maintain academic-level citation quality."""
    
    def _create_conversation_graph(self) -> StateGraph:
        """Create the conversation state graph."""
        workflow = StateGraph(AgentState)
        
        # Add nodes
        workflow.add_node("router", self._router_node)
        workflow.add_node("document_processor", self._document_processor_node)
        workflow.add_node("response_generator", self._response_generator_node)
        workflow.add_node("citation_processor", self._citation_processor_node)
        
        # Add edges for non-router nodes
        workflow.add_edge("document_processor", "response_generator")
        workflow.add_edge("response_generator", "citation_processor")
        workflow.add_edge("citation_processor", END)
        
        # Add conditional edges for router only
        workflow.add_conditional_edges(
            "router",
            self._route_conversation,
            {
                "document_processor": "document_processor",
                "response_generator": "response_generator",
                "citation_processor": "citation_processor",
                "end": END
            }
        )
        
        # Set entry point
        workflow.set_entry_point("router")
        
        return workflow.compile()
    
    def _router_node(self, state: AgentState) -> AgentState:
        """Route the conversation based on the current state."""
        messages = self._format_messages_for_llm(state, is_router=True)
        response = self.llm.invoke(messages)
        
        # Update state with router decision
        new_state = state.copy()
        new_state["context"] = {
            **new_state.get("context", {}),
            "router_decision": response.content.strip().lower()
        }
        
        return new_state
    
    def _route_conversation(self, state: AgentState) -> str:
        """Determine the next node based on router output."""
        router_decision = state.get("context", {}).get("router_decision", "")
        
        if "document_processor" in router_decision:
            return "document_processor"
        elif "response_generator" in router_decision:
            return "response_generator"
        elif "citation_processor" in router_decision:
            return "citation_processor"
        elif "end" in router_decision:
            return "end"
        else:
            # Default to response generator if no clear decision
            return "response_generator"
    
    def _document_processor_node(self, state: AgentState) -> AgentState:
        """Process documents referenced in the conversation."""
        active_docs = state.get("active_documents", [])
        logger.info(f"Document processor node triggered with {len(active_docs)} active document(s)")
        logger.info(f"Active document IDs: {active_docs}")
        
        documents = state.get("documents", [])
        document_ids = [doc.get("id") for doc in documents]
        logger.info(f"Current document IDs in state: {document_ids}")
        
        # Check if we need to add documents to the state
        docs_to_add = [doc_id for doc_id in active_docs if doc_id not in document_ids]
        
        if not docs_to_add:
            logger.info("No new documents to add to state")
            return state
        
        logger.info(f"Documents to add: {docs_to_add}")
        
        # Get document content for each document ID
        for doc_id in docs_to_add:
            try:
                doc_content = self._get_document_content(doc_id)
                
                # Log document content status
                if doc_content:
                    content_length = len(doc_content)
                    preview = doc_content[:100] + "..." if content_length > 100 else doc_content
                    logger.info(f"Retrieved content for document {doc_id} ({content_length} chars)")
                    logger.info(f"Content preview: {preview}")
                else:
                    logger.warning(f"No content found for document {doc_id}")
                
                # Add document to state
                doc_data = {
                    "id": doc_id,
                    "raw_text": doc_content
                }
                documents.append(doc_data)
                logger.info(f"Added document {doc_id} to state")
            except Exception as e:
                logger.error(f"Error retrieving content for document {doc_id}: {str(e)}")
                logger.exception(e)
                # Add an empty document with an error flag
                documents.append({
                    "id": doc_id,
                    "raw_text": f"[Error retrieving document content: {str(e)}]",
                    "error": True
                })
        
        # Update the state with the new documents
        state["documents"] = documents
        logger.info(f"Updated state with {len(state['documents'])} documents")
        
        # Log memory usage after processing
        current_memory = psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024
        logger.info(f"Current memory usage after document processing: {current_memory:.2f} MB")
        
        return state
    
    async def _response_generator_node(
        self, 
        state: AgentState, 
        anthropic_api_key: Optional[str] = None, 
        claude_model: Optional[str] = None
    ) -> Dict[str, Any]:
        """Generate a response using Claude or Anthropic API."""
        try:
            # Monitor memory and track memory usage pattern throughout processing
            memory_usage = self._monitor_memory_usage("response_generator_start")
            self._optimize_memory_if_needed(memory_usage)
            
            # Prepare model name and API key
            model = claude_model or os.getenv("CLAUDE_MODEL", "claude-3-5-sonnet-latest")
            api_key = anthropic_api_key or os.getenv("ANTHROPIC_API_KEY")
            
            if not api_key:
                logger.error("No Anthropic API key provided")
                return {"response": "Error: Missing Anthropic API key configuration."}
            
            logger.info(f"Generating response using model: {model}")
            
            # Get the latest user message
            latest_message = self._get_latest_user_message(state)
            
            if not latest_message:
                logger.warning("No latest user message found")
                return {"response": "I don't see a question to respond to."}
            
            query = latest_message.get("content", "")
            logger.info(f"User query: {query[:100]}...")
            
            # Prepare document context
            document_context = self._prepare_document_context(state)
            
            # Check if we have any document content
            if not document_context:
                logger.warning("No document context available for LLM messages")
                
                # Check if we should have documents
                active_docs = state.get("active_documents", [])
                if active_docs:
                    logger.warning(f"Expected documents ({active_docs}) but couldn't prepare context")
                    return {
                        "response": "I'm having trouble retrieving the document content. Please check that the document was properly uploaded and try again."
                    }
            else:
                doc_context_length = len(document_context)
                logger.info(f"Document context prepared: {doc_context_length} characters")
                
                # Log a preview of the document context
                preview_length = min(200, doc_context_length)
                if preview_length > 0:
                    logger.info(f"Document context preview: {document_context[:preview_length]}...")
            
            # Prepare conversation history
            messages = []
            
            # System message
            system_message = """You are a financial document assistant. Your role is to analyze financial documents and answer questions about them.
When referencing information from documents, always provide citations that include document ID and 
the relevant section or page if available.
Format your responses in well-structured markdown.
"""
            messages.append({"role": "system", "content": system_message})
            
            # Add document context as a system message if available
            if document_context:
                context_message = f"Here are the financial documents to reference:\n\n{document_context}"
                messages.append({"role": "system", "content": context_message})
            
            # Add conversation history
            chat_history = state.get("messages", [])
            for msg in chat_history[-10:]:  # Last 10 messages to stay within context limits
                role = "user" if msg.get("role") == "user" else "assistant"
                content = msg.get("content", "")
                
                # Skip empty messages
                if not content:
                    continue
                    
                messages.append({"role": role, "content": content})
            
            # Add the latest query from the user if not already included
            if messages[-1]["role"] != "user":
                messages.append({"role": "user", "content": query})
                
            # Log the full prompt for debugging
            message_summary = "\n".join([f"{m['role']}: {m['content'][:50]}..." for m in messages])
            logger.info(f"Sending messages to Claude:\n{message_summary}")
            
            # Check memory before API call
            pre_api_memory = self._monitor_memory_usage("before_claude_api_call")
            self._optimize_memory_if_needed(pre_api_memory)
            
            # Set up the client
            client = Anthropic(api_key=api_key)
            
            # Prepare request parameters
            params = {
                "model": model,
                "messages": messages,
                "max_tokens": 4000,
                "temperature": 0.2,
            }
            
            # Add citation support if the model supports it (claude-3-5-sonnet models)
            if "claude-3-5-sonnet" in model:
                logger.info("Using model with citation support")
                params["citation_search"] = {
                    "enabled": True,
                    "annotations": {"citations": True}
                }
            
            # Generate the response from Claude
            logger.info("Sending request to Claude API")
            start_time = time.time()
            
            response = client.messages.create(**params)
            
            end_time = time.time()
            logger.info(f"Claude API response received in {end_time - start_time:.2f} seconds")
            
            # Process the response
            ai_response = response.content[0].text
            logger.info(f"Response length: {len(ai_response)} characters")
            logger.info(f"Response preview: {ai_response[:200]}...")
            
            # Extract and format citations
            citations = self._process_citations_from_response(response, ai_response)
            
            # Monitor memory after processing
            post_memory = self._monitor_memory_usage("response_generator_end")
            self._optimize_memory_if_needed(post_memory)
            
            # Return the response with citations
            return {
                "response": ai_response,
                "citations": citations
            }
            
        except Exception as e:
            logger.error(f"Error generating response: {str(e)}")
            logger.exception(e)
            return {
                "response": "I encountered an error while processing your request. Please try again or contact support if the issue persists.",
                "error": str(e)
            }
    
    def _citation_processor_node(self, state: AgentState) -> AgentState:
        """Process and validate citations in the response."""
        if not state.get("current_response"):
            return state
        
        # Get the current response and citations
        response_content = state["current_response"]["content"]
        citations_used = state.get("citations_used", [])
        
        # Format message for citation processing
        citation_prompt = f"""
            {self.citation_processor_prompt}
            
            Original response: 
            {response_content}
            
            Citations used:
            {json.dumps(citations_used, indent=2)}
            
            Please verify and format these citations properly.
            """
        
        messages = [SystemMessage(content=citation_prompt)]
        
        # Call LLM to process citations
        response = self.llm.invoke(messages)
        
        # Update state with processed response
        new_state = state.copy()
        new_state["current_response"]["content"] = response.content
        
        # Add response to message history
        new_state["messages"].append({
            "role": "assistant",
            "content": response.content,
            "citations": citations_used
        })
        
        return new_state
    
    def _format_messages_for_llm(self, state: AgentState, system_prompt: Optional[str] = None, is_router: bool = False) -> List[Dict[str, Any]]:
        """Format messages for LLM with appropriate system prompt and document context."""
        # Use the router prompt if is_router is True
        if is_router:
            system_prompt = self.router_prompt
        elif system_prompt is None:
            system_prompt = self.response_generator_prompt
            
        # Get document context
        document_context = ""
        if "document_context" in state and state["document_context"]:
            # Use the cached document context if available
            document_context = state["document_context"]
            logger.info("Using cached document context from state")
        else:
            # Generate it fresh if not cached
            document_context = self._prepare_document_context(state)
            logger.info(f"Generated fresh document context (length: {len(document_context)})")
        
        # Log if document context is available
        if document_context:
            logger.info(f"Document context available for LLM messages (length: {len(document_context)})")
        else:
            logger.warning("No document context available for LLM messages")
        
        # Enhance system prompt with document context
        enhanced_system_prompt = system_prompt
        if document_context:
            # Create a system prompt that clearly separates document content from instructions
            enhanced_system_prompt = f"""
{system_prompt}

YOU HAVE ACCESS TO THE FOLLOWING DOCUMENTS:
-------------------------------------------------
{document_context}
-------------------------------------------------

IMPORTANT INSTRUCTIONS:
1. These documents contain financial information that you MUST use to answer the user's questions.
2. Always reference the specific document and its content in your responses.
3. If you can't find relevant information in the documents, acknowledge this limitation.
4. If no document is available, inform the user that you need a document uploaded to answer their question.
"""
            logger.info("Enhanced system prompt with document context")
        
        # Format messages for the LLM
        messages = []
        
        # Add system message with enhanced prompt
        messages.append({
            "role": "system",
            "content": enhanced_system_prompt
        })
        
        # Add conversation history
        for msg in state.get("messages", []):
            role = msg.get("role", "user")
            content = msg.get("content", "")
            
            # Skip system messages in history
            if role != "system":
                messages.append({
                    "role": role,
                    "content": content
                })
        
        # Add current message if present
        if state.get("current_message"):
            current_msg = state["current_message"]
            messages.append({
                "role": current_msg.get("role", "user"),
                "content": current_msg.get("content", "")
            })
        
        # Log message count and message roles
        message_roles = [msg["role"] for msg in messages]
        logger.info(f"Formatted {len(messages)} messages for LLM with roles: {message_roles}")
        
        # Check if document context is actually included in the system prompt
        if document_context and "DOCUMENTS" in messages[0]["content"]:
            preview = messages[0]["content"][:100] + "..." if len(messages[0]["content"]) > 100 else messages[0]["content"]
            logger.info(f"System prompt with document context preview: {preview}")
        
        return messages
    
    def _prepare_document_context(self, state: AgentState) -> str:
        """Prepare document context for inclusion in LLM prompt."""
        if not state.get("documents"):
            logger.warning("No documents available in state for document context preparation")
            logger.warning(f"State keys: {list(state.keys())}")
            logger.warning(f"Active documents: {state.get('active_documents', [])}")
            return ""
        
        document_context = []
        logger.info(f"Preparing document context from {len(state.get('documents', []))} documents")
        
        for i, doc in enumerate(state.get("documents", [])):
            doc_id = doc.get("id", f"doc_{i}")
            title = doc.get("title", "") or doc.get("name", f"Document {i+1}")
            
            logger.info(f"Processing document {i+1}: ID={doc_id}, Title={title}")
            logger.info(f"Document keys: {list(doc.keys())}")
            
            # Check for raw_text in different possible locations
            raw_text = ""
            content_source = "none"
            
            # Try to get raw_text directly from the document
            if "raw_text" in doc and doc.get("raw_text"):
                raw_text = doc.get("raw_text")
                content_source = "raw_text"
                logger.info(f"Found content in raw_text field for document {doc_id} ({len(raw_text)} characters)")
            
            # If no raw_text directly, try extracted_data
            elif "extracted_data" in doc and doc.get("extracted_data"):
                logger.info(f"Extracted data keys: {list(doc.get('extracted_data', {}).keys())}")
                
                if "raw_text" in doc.get("extracted_data", {}):
                    raw_text = doc.get("extracted_data").get("raw_text")
                    content_source = "extracted_data.raw_text"
                    logger.info(f"Found content in extracted_data.raw_text for document {doc_id} ({len(raw_text)} characters)")
                
                # For chunked large documents, use a summarized version
                elif "text_chunks" in doc.get("extracted_data") and doc.get("extracted_data").get("text_chunks"):
                    chunks = doc.get("extracted_data").get("text_chunks")
                    content_source = "extracted_data.text_chunks"
                    # Use first chunk, middle chunk, and last chunk to represent the document
                    if len(chunks) <= 3:
                        raw_text = "\n\n".join(chunks)
                    else:
                        raw_text = f"{chunks[0]}\n\n[...Document continues...]\n\n{chunks[len(chunks)//2]}\n\n[...Document continues...]\n\n{chunks[-1]}"
                    logger.info(f"Using chunked text for large document {doc_id} ({len(raw_text)} characters from {len(chunks)} chunks)")
            
            # If we still don't have content, check other common fields
            if not raw_text and "content" in doc and doc.get("content"):
                raw_text = doc.get("content")
                content_source = "content"
                logger.info(f"Found content in content field for document {doc_id} ({len(raw_text)} characters)")
                
            if not raw_text and "text" in doc and doc.get("text"):
                raw_text = doc.get("text")
                content_source = "text"
                logger.info(f"Found content in text field for document {doc_id} ({len(raw_text)} characters)")
            
            if raw_text:
                # Truncate very long documents to prevent context overflow
                MAX_DOC_LENGTH = 10000  # Characters per document
                truncated = False
                
                if len(raw_text) > MAX_DOC_LENGTH:
                    original_length = len(raw_text)
                    raw_text = raw_text[:MAX_DOC_LENGTH] + f"\n\n[Document truncated due to length. Original size: {original_length} characters]"
                    truncated = True
                    logger.info(f"Truncated document {doc_id} from {original_length} to {MAX_DOC_LENGTH} chars for context")
                
                document_context.append(
                    f"Document: {title}\n"
                    f"ID: {doc_id}\n"
                    f"Content: {raw_text}\n"
                    f"------ END OF DOCUMENT ------\n"
                )
                logger.info(f"Added document {doc_id} to context (source: {content_source}, truncated: {truncated})")
            else:
                logger.warning(f"No content found for document {doc_id} in any expected field")
                # Add placeholder for document with no content
                document_context.append(
                    f"Document: {title}\n"
                    f"ID: {doc_id}\n"
                    f"Content: [No content available]\n"
                    f"------ END OF DOCUMENT ------\n"
                )
        
        final_context = "\n\n".join(document_context)
        logger.info(f"Final document context prepared: {len(final_context)} characters, {len(document_context)} documents")
        
        if not final_context:
            logger.warning("Document context preparation resulted in EMPTY context!")
        
        return final_context
    
    def _get_latest_user_message(self, state: AgentState) -> Optional[Dict[str, Any]]:
        """Get the latest user message from state."""
        # Check current message first
        if state.get("current_message") and state["current_message"].get("role") == "user":
            return state["current_message"]
        
        # Otherwise check message history in reverse
        for msg in reversed(state["messages"]):
            if msg.get("role") == "user":
                return msg
        
        return None
    
    def _extract_citations_from_text(self, text: str, available_citations: List[Dict[str, Any]]) -> Tuple[str, List[Dict[str, Any]]]:
        """
        Extract citation references from text and map them to actual citations.
        
        Args:
            text: The text to process
            available_citations: List of available citation objects
            
        Returns:
            Tuple of processed text and list of used citations
        """
        used_citations = []
        citation_map = {}
        
        # Create a map of citation IDs to citation objects
        for citation in available_citations:
            cid = citation.get("id", "")
            if cid:
                citation_map[cid] = citation
        
        # Look for citation patterns in text
        citation_pattern = r'\[Citation:\s*([^\]]+)\]'
        matches = re.finditer(citation_pattern, text)
        
        for match in matches:
            cite_id = match.group(1).strip()
            if cite_id in citation_map and citation_map[cite_id] not in used_citations:
                used_citations.append(citation_map[cite_id])
        
        return text, used_citations
    
    async def initialize_conversation(
        self, 
        conversation_id: str, 
        user_id: str, 
        document_ids: Optional[List[str]] = None,
        conversation_title: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Initialize a new conversation state with LangGraph.
        
        Args:
            conversation_id: ID of the conversation
            user_id: ID of the user
            document_ids: List of document IDs relevant to the conversation
            conversation_title: Optional title for the conversation
            
        Returns:
            Initial conversation state
        """
        try:
            logger.info(f"Initializing conversation {conversation_id} for user {user_id}")
            
            # Create initial state
            initial_state: AgentState = {
                "conversation_id": conversation_id,
                "messages": [],
                "documents": [],
                "citations": [],
                "active_documents": document_ids or [],
                "current_message": None,
                "current_response": None,
                "citations_used": [],
                "context": {
                    "user_id": user_id,
                    "title": conversation_title or f"Conversation {conversation_id[:8]}",
                    "documents_loaded": False
                }
            }
            
            # Store state in conversation_states directly
            thread_id = f"conversation_{conversation_id}"
            self.conversation_states[thread_id] = initial_state
            
            return {
                "conversation_id": conversation_id,
                "status": "initialized",
                "state": initial_state
            }
            
        except Exception as e:
            logger.exception(f"Error initializing conversation: {e}")
            raise
    
    async def add_documents_to_conversation(
        self, 
        conversation_id: str, 
        documents: List[ProcessedDocument]
    ) -> Dict[str, Any]:
        """
        Add documents to conversation context.
        
        Args:
            conversation_id: ID of the conversation
            documents: List of processed documents to add
            
        Returns:
            Updated conversation state
        """
        try:
            logger.info(f"Adding {len(documents)} documents to conversation {conversation_id}")
            
            # Get current state from conversation_states dictionary
            thread_id = f"conversation_{conversation_id}"
            state = self.conversation_states.get(thread_id)
            
            if not state:
                raise ValueError(f"Conversation {conversation_id} not found")
            
            # Extract document data and citations
            doc_data = []
            all_citations = []
            
            for doc in documents:
                # Extract document content from extracted_data if available
                raw_text = ""
                if hasattr(doc, "extracted_data") and doc.extracted_data:
                    if "raw_text" in doc.extracted_data:
                        raw_text = doc.extracted_data["raw_text"]
                        logger.info(f"Using raw_text for document {doc.metadata.id} ({len(raw_text)} characters)")
                
                # Create truncated summary for UI display purposes
                summary = raw_text[:500] + "..." if len(raw_text) > 500 else raw_text
                
                # Extract basic document info
                doc_info = {
                    "id": str(doc.metadata.id),
                    "title": doc.metadata.filename,
                    "document_type": doc.content_type.value,
                    "summary": summary,
                    "raw_text": raw_text,  # Include full raw text for LLM context
                    "upload_timestamp": str(doc.metadata.upload_timestamp)
                }
                
                # Add extracted_data as well if it exists
                if hasattr(doc, "extracted_data") and doc.extracted_data:
                    doc_info["extracted_data"] = doc.extracted_data
                
                doc_data.append(doc_info)
                
                # Extract citations
                if doc.citations:
                    for citation in doc.citations:
                        citation_obj = {
                            "id": citation.id,
                            "text": citation.text,
                            "page": citation.page,
                            "document_id": str(doc.metadata.id),
                            "document_title": doc.metadata.filename,
                            "document_type": doc.content_type.value
                        }
                        all_citations.append(citation_obj)
            
            # Update state
            new_state = state.copy()
            new_state["documents"].extend(doc_data)
            new_state["citations"].extend(all_citations)
            new_state["context"]["documents_loaded"] = True
            
            # Add active document IDs
            for doc in documents:
                doc_id = str(doc.metadata.id)
                if doc_id not in new_state["active_documents"]:
                    new_state["active_documents"].append(doc_id)
            
            # Save updated state
            self.conversation_states[thread_id] = new_state
            
            return {
                "conversation_id": conversation_id,
                "status": "documents_added",
                "document_count": len(documents),
                "citation_count": len(all_citations)
            }
            
        except Exception as e:
            logger.exception(f"Error adding documents to conversation: {e}")
            raise
    
    async def process_message(
        self, 
        conversation_id: str, 
        message_text: str,
        user_id: Optional[str] = None,
        message_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Process a message within a conversation.
        
        Args:
            conversation_id: ID of the conversation
            message_text: Text of the message to process
            user_id: Optional ID of the user sending the message
            message_id: Optional ID of the message
            
        Returns:
            Result containing the response, citations, and status
        """
        try:
            # Initialize conversation state if it doesn't exist
            if conversation_id not in self.conversation_states:
                logger.info(f"Initializing new conversation state for {conversation_id}")
                self.conversation_states[conversation_id] = self._create_empty_state()
                self.conversation_states[conversation_id]["conversation_id"] = conversation_id
            
            # Get the conversation state
            state = self.conversation_states[conversation_id]
            
            # Add user message to conversation
            if "messages" not in state:
                state["messages"] = []
                
            user_message = {
                "id": message_id or str(uuid.uuid4()),
                "role": "user",
                "content": message_text,
                "created_at": datetime.now().isoformat(),
                "user_id": user_id
            }
            
            state["messages"].append(user_message)
            state["current_message"] = user_message
            
            # Run the message through our workflow graph
            logger.info(f"Running message through workflow for conversation {conversation_id}")
            try:
                # Execute the graph with the current state
                result = await self.workflow.ainvoke(state)
                
                if not result:
                    logger.error("No result returned from workflow")
                    raise ValueError("No result returned from workflow")
                
                # Extract the AI response from the result
                if 'messages' in result and len(result['messages']) > 0:
                    # Get the latest AI message
                    ai_messages = [msg for msg in result['messages'] if msg['role'] == 'assistant']
                    
                    if ai_messages:
                        latest_ai_message = ai_messages[-1]
                        response_content = latest_ai_message.get('content', '')
                        
                        # Extract citations if available
                        citations = []
                        if latest_ai_message.get('citations'):
                            citations = latest_ai_message['citations']
                            logger.info(f"Found {len(citations)} citations in response")
                        
                        # Update the stored state with the new state including AI response
                        self.conversation_states[conversation_id] = result
                        
                        # Return the response and any citations
                        return {
                            "response": response_content,
                            "citations": citations,
                            "status": "success"
                        }
                    else:
                        logger.warning("No assistant message found in result")
                        return {
                            "response": "I couldn't generate a response at this time.",
                            "citations": [],
                            "status": "error"
                        }
                else:
                    logger.warning("No messages found in result")
                    return {
                        "response": "I couldn't generate a response at this time.",
                        "citations": [],
                        "status": "error"
                    }
                
            except Exception as e:
                logger.error(f"Error in workflow execution: {str(e)}", exc_info=True)
                return {
                    "response": f"An error occurred while processing your message: {str(e)}",
                    "citations": [],
                    "status": "error"
                }
            
        except Exception as e:
            logger.error(f"Error processing message: {str(e)}", exc_info=True)
            return {
                "response": f"An error occurred while processing your message: {str(e)}",
                "citations": [],
                "status": "error"
            }
    
    async def get_conversation_history(
        self, 
        conversation_id: str,
        limit: int = 50
    ) -> List[Dict[str, Any]]:
        """
        Get conversation history.
        
        Args:
            conversation_id: ID of the conversation
            limit: Maximum number of messages to return
            
        Returns:
            List of conversation messages
        """
        try:
            # Get current state
            thread_id = f"conversation_{conversation_id}"
            config = self.conversation_graph.get_config()
            state = cast(AgentState, self.memory.load(thread_id, config.name))
            
            if not state:
                raise ValueError(f"Conversation {conversation_id} not found")
            
            # Get messages with limit
            messages = state.get("messages", [])[-limit:]
            
            # Format messages
            formatted_messages = []
            for msg in messages:
                message = {
                    "id": str(uuid.uuid4()),  # Generate ID since messages may not have one
                    "conversation_id": conversation_id,
                    "content": msg.get("content", ""),
                    "role": msg.get("role", "user"),
                    "citations": msg.get("citations", []),
                    "timestamp": msg.get("timestamp", "")
                }
                formatted_messages.append(message)
            
            return formatted_messages
            
        except Exception as e:
            logger.exception(f"Error getting conversation history: {e}")
            raise

    async def simple_document_qa(
        self,
        question: str,
        documents: List[Dict[str, Any]],
        conversation_history: List[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Simple question-answering against document content without full graph execution.
        This is a lightweight wrapper around the response_generator node for basic QA.
        Uses Claude's citation feature to provide accurate references to document content.
        
        Args:
            question: The user's question
            documents: List of documents with their content
            conversation_history: Previous conversation messages (optional)
            
        Returns:
            Dictionary with AI response text and extracted citations
        """
        try:
            logger.info(f"Running simple_document_qa with {len(documents)} documents")
            
            # Check for empty document list
            if not documents:
                logger.warning("No documents provided to simple_document_qa")
                return {
                    "content": "I don't have any documents to analyze. Please upload a document first.",
                    "citations": []
                }
            
            # Detailed document diagnostic logging
            logger.info(f"===== Begin document diagnostic information for {len(documents)} documents =====")
            for i, doc in enumerate(documents):
                # Basic document metadata
                doc_id = doc.get('id', f'doc_{i}')
                doc_type = doc.get("document_type", doc.get("mime_type", "unknown"))
                doc_title = doc.get("title", doc.get("filename", f"Untitled document {i}"))
                
                # Content availability checks
                has_raw_text = 'raw_text' in doc and bool(doc.get('raw_text'))
                raw_text_len = len(doc.get('raw_text', '')) if has_raw_text else 0
                
                has_content = 'content' in doc and bool(doc.get('content'))
                content_type = type(doc.get('content')).__name__ if has_content else "None"
                content_len = len(doc.get('content', '')) if has_content and isinstance(doc.get('content'), (str, bytes)) else 0
                
                has_extracted_data = 'extracted_data' in doc and bool(doc.get('extracted_data'))
                has_text = 'text' in doc and bool(doc.get('text'))
                
                # Log comprehensive document info
                logger.info(f"Document {i+1}/{len(documents)} - ID: {doc_id}, Title: {doc_title}, Type: {doc_type}")
                logger.info(f"Content availability: raw_text={has_raw_text}({raw_text_len} chars), content={has_content}({content_type}, {content_len}), extracted_data={has_extracted_data}, text={has_text}")
            
            logger.info(f"===== End document diagnostic information =====")
            
            # Prepare documents for Claude API
            user_content = []
            
            # Import the repository to get document binary content if needed
            try:
                from repositories.document_repository import DocumentRepository
                from utils.database import get_db
                
                # Create a repository instance to fetch binary data if needed
                repository = None
                async for db in get_db():
                    repository = DocumentRepository(db)
                    break  # Just get the first one
                
                if repository:
                    logger.info("Successfully created document repository for binary access")
                else:
                    logger.warning("Could not create document repository - no database connection available")
            except Exception as repo_error:
                logger.warning(f"Could not create document repository for binary access: {str(repo_error)}")
                repository = None

            # Process each document
            for i, doc in enumerate(documents):
                doc_id = doc.get('id', f'doc_{i}')
                doc_title = doc.get("title", doc.get("filename", f"Document {doc_id}"))
                
                # Check if this is a PDF document
                is_pdf = False
                if doc.get("mime_type") == "application/pdf" or doc.get("document_type") == "application/pdf" or (doc.get("filename", "").lower().endswith(".pdf")):
                    is_pdf = True

                # For PDFs, try to get binary content
                if is_pdf:
                    pdf_binary = None
                    
                    # First check if binary content is already in the document
                    if "content" in doc and isinstance(doc.get("content"), bytes):
                        pdf_binary = doc.get("content")
                        logger.info(f"Using existing binary content for PDF document {doc_id}: {len(pdf_binary)} bytes")
                    
                    # If not, try to get it from repository
                    elif repository:
                        try:
                            pdf_content = await repository.get_document_content(doc_id)
                            if pdf_content and "content" in pdf_content and isinstance(pdf_content["content"], bytes):
                                pdf_binary = pdf_content["content"]
                                logger.info(f"Retrieved binary PDF data ({len(pdf_binary)} bytes) for document {doc_id}")
                        except Exception as e:
                            logger.warning(f"Could not retrieve binary data for document {doc_id}: {str(e)}")
                    
                    # If we have binary PDF data, encode it as base64 for Claude
                    if pdf_binary:
                        try:
                            import base64
                            base64_data = base64.b64encode(pdf_binary).decode('utf-8')
                            
                            # Create the document block in Claude's format
                            pdf_doc = {
                                "type": "document",
                                "title": doc_title,
                                "source": {
                                    "type": "base64",
                                    "media_type": "application/pdf",
                                    "data": base64_data
                                }
                            }
                            
                            user_content.append(pdf_doc)
                            logger.info(f"Added PDF document {doc_id} with base64 encoding to content")
                            continue
                        except Exception as e:
                            logger.error(f"Error encoding PDF as base64: {str(e)}")
                
                # For non-PDF documents or if PDF processing failed, fallback to text
                # Try to find content in various possible locations
                doc_content = None
                
                # Look for content in various fields with fallbacks
                if "raw_text" in doc and doc["raw_text"]:
                    doc_content = doc["raw_text"]
                    logger.info(f"Using raw_text field for document {doc_id}")
                elif "content" in doc and doc["content"] and isinstance(doc["content"], str):
                    doc_content = doc["content"]
                    logger.info(f"Using content field for document {doc_id}")
                elif "extracted_data" in doc and isinstance(doc["extracted_data"], dict) and "raw_text" in doc["extracted_data"]:
                    doc_content = doc["extracted_data"]["raw_text"]
                    logger.info(f"Using extracted_data.raw_text for document {doc_id}")
                elif "text" in doc and doc["text"]:
                    doc_content = doc["text"]
                    logger.info(f"Using text field for document {doc_id}")
                
                # If content was found, create a document block for Claude
                if doc_content and len(str(doc_content).strip()) > 0:
                    # Ensure content is a string
                    if not isinstance(doc_content, str):
                        try:
                            doc_content = str(doc_content)
                        except Exception as e:
                            logger.warning(f"Could not convert content to string: {e}")
                            continue
                    
                    # Create the document block
                    text_doc = {
                        "type": "document",
                        "title": doc_title,
                        "source": {
                            "type": "text",
                            "media_type": "text/plain",
                            "data": doc_content
                        }
                    }
                    
                    user_content.append(text_doc)
                    logger.info(f"Added text document {doc_id} with {len(doc_content)} chars to content")
                else:
                    logger.warning(f"Could not find any content for document {doc_id}, skipping")
            
            # If no documents were prepared, return an error message
            if not any(item.get("type") == "document" for item in user_content):
                logger.warning("No documents were prepared for the Claude API")
                return {
                    "content": "I couldn't process the document content. Please ensure the documents were properly uploaded and contain readable text.",
                    "citations": []
                }
            
            # Add the question as a text block
            user_content.append({"type": "text", "text": question})
            
            # Create the system prompt
            system_message = "You are a financial document analysis assistant that provides precise answers with citations. When answering questions: 1. Focus on information directly from the provided documents 2. Use citations to support your statements 3. Provide specific financial data from the documents where relevant 4. If a question cannot be answered from the documents, clearly state that 5. Be precise and factual in your analysis."
            
            # Format messages for Anthropic API
            anthropic_messages = []
            
            # Add conversation history if provided
            if conversation_history:
                for msg in conversation_history:
                    role = msg.get("role", "").lower()
                    content = msg.get("content", "")
                    
                    # Map roles to Claude's expected format
                    if role in ["user", "human"]:
                        anthropic_messages.append({"role": "user", "content": content})
                    elif role in ["assistant", "ai"]:
                        anthropic_messages.append({"role": "assistant", "content": content})
            
            # Add current message with documents and question
            anthropic_messages.append({
                "role": "user",
                "content": user_content
            })
            
            # Log the API call
            logger.info(f"Calling Anthropic API with {len(anthropic_messages)} messages and {len([item for item in user_content if item.get('type') == 'document'])} documents")
            
            # Use a model that supports citations
            model_name = os.getenv("CLAUDE_MODEL", "claude-3-5-sonnet-20241022")
            logger.info(f"Using Claude model: {model_name}")
            
            # Create the Anthropic client
            from anthropic import Anthropic
            anthropic_client = Anthropic(api_key=os.environ.get("ANTHROPIC_API_KEY"))
            
            # Call the API
            try:
                response = anthropic_client.messages.create(
                    model=model_name,
                    system=system_message,
                    messages=anthropic_messages,
                    max_tokens=4000
                )
                
                # Process the response
                ai_response = response.content[0].text
                logger.info(f"Claude API response received: {len(ai_response)} characters")
                
                # Extract and format citations
                citations = self._process_citations_from_response(response, ai_response)
                
                return {
                    "content": ai_response,
                    "citations": citations
                }
            except Exception as api_error:
                logger.error(f"Error calling Claude API: {str(api_error)}", exc_info=True)
                return {
                    "content": f"An error occurred while processing your request: {str(api_error)}",
                    "citations": []
                }
        except Exception as e:
            logger.error(f"Error in simple_document_qa: {str(e)}", exc_info=True)
            return {
                "content": f"An error occurred while processing your request: {str(e)}",
                "citations": []
            }
    
    def _process_response_with_citations(self, content_blocks) -> str:
        """
        Process response content blocks to extract text.
        
        Args:
            content_blocks: Content blocks from the response
            
        Returns:
            Extracted text from all content blocks
        """
        if not content_blocks:
            return ""
            
        # If content is not a list, just convert to string
        if not isinstance(content_blocks, list):
            return str(content_blocks)
            
        # Extract text from content blocks
        full_text = ""
        for block in content_blocks:
            if isinstance(block, dict) and 'text' in block:
                full_text += block['text']
            elif hasattr(block, 'text'):
                full_text += block.text
            elif isinstance(block, str):
                full_text += block
                
        return full_text
    
    def _extract_citations_from_response(self, response):
        """Extract citation data from Claude API response."""
        citations = []
        
        if hasattr(response, 'content') and isinstance(response.content, list):
            for block in response.content:
                if isinstance(block, dict) and block.get('type') == 'text':
                    # Extract any citation annotations
                    annotations = block.get('annotations', [])
                    for annotation in annotations:
                        if annotation.get('type') == 'citation':
                            # Process citation
                            citation_data = annotation.get('citation', {})
                            
                            # Determine citation type and extract appropriate fields
                            if 'document' in citation_data:
                                doc_idx = citation_data.get('document', {}).get('index', 0)
                                doc_id = f"doc_{doc_idx}"
                                text = citation_data.get('text', '')
                                
                                citations.append({
                                    "document_index": doc_idx,
                                    "document_id": doc_id,
                                    "text": text
                                })
        
        return citations
    
    def _process_citations_from_response(self, response, ai_response: str) -> List[Dict[str, Any]]:
        """
        Process and extract citations from the Claude API response.
        Returns a list of citation objects in a standardized format.
        
        Args:
            response: The direct Anthropic API response
            ai_response: The text content from the response
            
        Returns:
            List of standardized citation dictionaries
        """
        try:
            # Initialize empty list for citations
            citations = []
            
            # Check if response has content blocks
            if hasattr(response, 'content') and response.content:
                # Process each content block
                for block in response.content:
                    # Check for citations directly in the content block
                    if hasattr(block, 'citations') and block.citations:
                        logger.info(f"Found {len(block.citations)} citations in content block")
                        
                        for citation in block.citations:
                            # Process each citation
                            citation_dict = self._convert_citation_to_dict(citation)
                            if citation_dict:
                                citations.append(citation_dict)
                    
                    # Check for citations in annotations
                    if hasattr(block, 'annotations') and block.annotations:
                        logger.info(f"Found {len(block.annotations)} annotations in content block")
                        
                        for annotation in block.annotations:
                            if hasattr(annotation, 'citations') and annotation.citations:
                                for citation in annotation.citations:
                                    citation_dict = self._convert_citation_to_dict(citation)
                                    if citation_dict:
                                        citations.append(citation_dict)
            
            # Check for top-level citations (older API format)
            if hasattr(response, 'citations') and response.citations:
                logger.info(f"Found {len(response.citations)} top-level citations in response")
                
                for citation in response.citations:
                    citation_dict = self._convert_citation_to_dict(citation)
                    if citation_dict:
                        citations.append(citation_dict)
            
            # Check for top-level annotations (older API format)
            if hasattr(response, 'annotations') and response.annotations:
                logger.info(f"Found {len(response.annotations)} top-level annotations in response")
                
                for annotation in response.annotations:
                    if hasattr(annotation, 'citations') and annotation.citations:
                        for citation in annotation.citations:
                            citation_dict = self._convert_citation_to_dict(citation)
                            if citation_dict:
                                citations.append(citation_dict)
            
            # Log citation count
            if citations:
                logger.info(f"Extracted {len(citations)} citations from the Claude API response")
                
                # Log first citation as an example
                if len(citations) > 0:
                    logger.info(f"Example citation: {citations[0]}")
            else:
                logger.info("No citations found in the Claude API response")
            
            return citations
            
        except Exception as e:
            logger.error(f"Error processing citations from response: {str(e)}", exc_info=True)
            return []
    
    def _convert_citation_to_dict(self, citation) -> Dict[str, Any]:
        """
        Convert a citation object from the Anthropic API to our standardized dictionary format.
        
        Args:
            citation: Citation object from Anthropic API
            
        Returns:
            Standardized citation dictionary
        """
        try:
            # Determine citation type
            citation_type = getattr(citation, 'type', None)
            if not citation_type and hasattr(citation, 'page'):
                citation_type = "page_location"
            elif not citation_type and (hasattr(citation, 'start_index') or hasattr(citation, 'start_char_index')):
                citation_type = "char_location"
            else:
                citation_type = "standard"
            
            # Extract document information
            document_id = None
            if hasattr(citation, 'document'):
                # Extract ID from document object
                document_id = getattr(citation.document, 'id', None)
                if document_id is None and hasattr(citation.document, 'index'):
                    document_id = f"doc_{citation.document.index}"
            
            # Extract quoted text
            quoted_text = ""
            if hasattr(citation, 'text'):
                quoted_text = citation.text
            elif hasattr(citation, 'quote'):
                quoted_text = citation.quote
            
            # Base citation information
            citation_dict = {
                "type": citation_type,
                "cited_text": quoted_text,
                "document_id": document_id
            }
            
            # Add type-specific fields
            if citation_type == "page_location" and hasattr(citation, 'page'):
                # For PDF page citations
                start_page = getattr(citation.page, 'start', 1)
                end_page = getattr(citation.page, 'end', start_page)
                
                citation_dict.update({
                    "start_page_number": start_page,
                    "end_page_number": end_page
                })
            elif citation_type == "char_location":
                # For character-based citations
                start_index = getattr(citation, 'start_index', 
                                     getattr(citation, 'start_char_index', 0))
                end_index = getattr(citation, 'end_index',
                                   getattr(citation, 'end_char_index', 0))
                
                citation_dict.update({
                    "start_char_index": start_index,
                    "end_char_index": end_index
                })
            
            return citation_dict
        except Exception as e:
            logger.error(f"Error converting citation to dictionary: {str(e)}", exc_info=True)
            return {"type": "unknown", "cited_text": str(citation), "error": str(e)}
    
    async def transition_to_full_graph(
        self,
        conversation_id: str,
        current_state: AgentState
    ) -> str:
        """
        Transition a conversation from simple QA to full graph execution.
        This allows a conversation that started with simple_document_qa to later
        use the full power of the conversation graph for more complex needs.
        
        Args:
            conversation_id: ID of the conversation
            current_state: Current simple QA state
            
        Returns:
            Unique thread ID for the full graph execution
        """
        # Initialize the conversation with the full graph
        thread_id = str(uuid.uuid4())
        
        # Create config and metadata for the memory store
        config = {"configurable": {"thread_id": thread_id}}
        
        # Create a checkpoint with the state data
        checkpoint = {
            "id": thread_id,  # Use thread_id as checkpoint id
            "state": current_state
        }
        
        # Create metadata for the checkpoint
        metadata = {
            "conversation_id": conversation_id,
            "timestamp": datetime.now().isoformat(),
            "type": "transition_to_full_graph"
        }
        
        # Store the initial state with proper parameters
        self.memory.put(config, checkpoint, metadata)
        
        # Store the thread ID for later use
        self.conversation_states[conversation_id] = thread_id
        
        # Return the thread ID for future reference
        logger.info(f"Transitioned conversation {conversation_id} to full graph execution")
        return thread_id
    
    def _monitor_memory_usage(self, operation: str = "general") -> float:
        """
        Monitor and log memory usage at various points in document processing.
        Returns current memory usage in MB.
        """
        process = psutil.Process(os.getpid())
        memory_mb = process.memory_info().rss / 1024 / 1024
        logger.info(f"Memory usage ({operation}): {memory_mb:.2f} MB")
        return memory_mb
        
    def _optimize_memory_if_needed(self, current_memory_mb: float, threshold_mb: float = 1000) -> None:
        """
        Perform memory optimization if current usage exceeds threshold.
        
        Args:
            current_memory_mb: Current memory usage in MB
            threshold_mb: Threshold in MB above which optimization will be performed
        """
        if current_memory_mb > threshold_mb:
            logger.warning(f"Memory usage ({current_memory_mb:.2f} MB) exceeds threshold ({threshold_mb} MB). Running garbage collection.")
            
            # Get memory before optimization
            before_gc = self._monitor_memory_usage("before_gc")
            
            # Force garbage collection
            gc.collect()
            
            # Get memory after optimization
            after_gc = self._monitor_memory_usage("after_gc")
            
            # Log memory savings
            memory_freed = before_gc - after_gc
            logger.info(f"Garbage collection freed {memory_freed:.2f} MB of memory")
    
    def _create_empty_state(self) -> AgentState:
        """
        Create an empty conversation state.
        
        Returns:
            Empty conversation state
        """
        return {
            "conversation_id": "",
            "messages": [],
            "documents": [],
            "citations": [],
            "active_documents": [],
            "current_message": None,
            "current_response": None,
            "citations_used": [],
            "context": {}
        }
</file>
```

#### pytest\.ini
*Size: 409 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/pytest.ini">
[pytest]
asyncio_mode = auto
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
markers =
    unit: mark a test as a unit test
    integration: mark a test as an integration test
    performance: mark a test as a performance test
    slow: mark test as slow (skipped unless explicitly requested)
filterwarnings =
    ignore::DeprecationWarning
    ignore::UserWarning 
</file>
```

#### repositories/\_\_init\_\_\.py
*Size: 213 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/repositories/__init__.py">
# Import repositories here to make them available
from .document_repository import DocumentRepository
from .conversation_repository import ConversationRepository
from .analysis_repository import AnalysisRepository
</file>
```

#### repositories/analysis\_repository\.py
*Size: 8.6 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/repositories/analysis_repository.py">
import logging
import uuid
from typing import List, Optional, Dict, Any
from datetime import datetime
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from sqlalchemy import update, delete, func, and_, desc, or_

from models.database_models import AnalysisResult, Document, User

logger = logging.getLogger(__name__)

class AnalysisRepository:
    """Repository for analysis operations."""
    
    def __init__(self, db: AsyncSession):
        """Initialize the analysis repository."""
        self.db = db
    
    async def create_analysis(
        self,
        document_id: str,
        analysis_type: str,
        result_data: Dict[str, Any]
    ) -> AnalysisResult:
        """
        Create a new analysis result.
        
        Args:
            document_id: ID of the document being analyzed
            analysis_type: Type of analysis (e.g., "financial_ratios", "sentiment", etc.)
            result_data: JSON data containing analysis results
            
        Returns:
            Created analysis result
        """
        # Create the analysis record
        analysis = AnalysisResult(
            id=str(uuid.uuid4()),
            document_id=document_id,
            analysis_type=analysis_type,
            result_data=result_data,
            created_at=datetime.utcnow()
        )
        
        # Add to database
        self.db.add(analysis)
        await self.db.commit()
        await self.db.refresh(analysis)
        
        return analysis
    
    async def get_analysis(self, analysis_id: str) -> Optional[AnalysisResult]:
        """
        Get an analysis result by ID.
        
        Args:
            analysis_id: ID of the analysis
            
        Returns:
            Analysis result if found, None otherwise
        """
        result = await self.db.execute(
            select(AnalysisResult).where(AnalysisResult.id == analysis_id)
        )
        return result.scalars().first()
    
    async def list_document_analyses(
        self,
        document_id: str,
        analysis_type: Optional[str] = None,
        limit: int = 10,
        offset: int = 0
    ) -> List[AnalysisResult]:
        """
        List analysis results for a document.
        
        Args:
            document_id: ID of the document
            analysis_type: Optional analysis type to filter by
            limit: Maximum number of results to return
            offset: Starting index
            
        Returns:
            List of analysis results
        """
        query = select(AnalysisResult).where(AnalysisResult.document_id == document_id)
        
        if analysis_type:
            query = query.where(AnalysisResult.analysis_type == analysis_type)
        
        query = query.order_by(desc(AnalysisResult.created_at)).limit(limit).offset(offset)
        
        result = await self.db.execute(query)
        return result.scalars().all()
    
    async def list_latest_analyses(
        self,
        document_ids: List[str],
        analysis_type: Optional[str] = None,
        limit: int = 10
    ) -> List[AnalysisResult]:
        """
        List the latest analysis results for multiple documents.
        
        Args:
            document_ids: List of document IDs
            analysis_type: Optional analysis type to filter by
            limit: Maximum number of results to return per document
            
        Returns:
            List of analysis results
        """
        query = (
            select(AnalysisResult)
            .where(AnalysisResult.document_id.in_(document_ids))
        )
        
        if analysis_type:
            query = query.where(AnalysisResult.analysis_type == analysis_type)
        
        query = query.order_by(desc(AnalysisResult.created_at))
        
        # Use a window function to get the latest N analyses per document
        # This is a bit complex with SQLAlchemy, so we'll just get all and filter
        result = await self.db.execute(query)
        all_analyses = result.scalars().all()
        
        # Group by document_id
        analyses_by_document = {}
        for analysis in all_analyses:
            if analysis.document_id not in analyses_by_document:
                analyses_by_document[analysis.document_id] = []
            
            if len(analyses_by_document[analysis.document_id]) < limit:
                analyses_by_document[analysis.document_id].append(analysis)
        
        # Flatten the dictionary into a list
        latest_analyses = []
        for doc_analyses in analyses_by_document.values():
            latest_analyses.extend(doc_analyses)
        
        # Sort by created_at (newest first)
        latest_analyses.sort(key=lambda x: x.created_at, reverse=True)
        
        return latest_analyses
    
    async def update_analysis(
        self,
        analysis_id: str,
        update_data: Dict[str, Any]
    ) -> Optional[AnalysisResult]:
        """
        Update an analysis result.
        
        Args:
            analysis_id: ID of the analysis
            update_data: Dictionary of fields to update
            
        Returns:
            Updated analysis result if found, None otherwise
        """
        await self.db.execute(
            update(AnalysisResult)
            .where(AnalysisResult.id == analysis_id)
            .values(**update_data)
        )
        await self.db.commit()
        
        return await self.get_analysis(analysis_id)
    
    async def delete_analysis(self, analysis_id: str) -> bool:
        """
        Delete an analysis result.
        
        Args:
            analysis_id: ID of the analysis
            
        Returns:
            True if analysis was deleted, False otherwise
        """
        # Delete from database
        await self.db.execute(
            delete(AnalysisResult).where(AnalysisResult.id == analysis_id)
        )
        await self.db.commit()
        
        return True
    
    async def count_document_analyses(
        self,
        document_id: str,
        analysis_type: Optional[str] = None
    ) -> int:
        """
        Count the number of analysis results for a document.
        
        Args:
            document_id: ID of the document
            analysis_type: Optional analysis type to filter by
            
        Returns:
            Number of analysis results
        """
        query = select(func.count()).select_from(AnalysisResult).where(AnalysisResult.document_id == document_id)
        
        if analysis_type:
            query = query.where(AnalysisResult.analysis_type == analysis_type)
        
        result = await self.db.execute(query)
        return result.scalar()
    
    async def search_analyses(
        self,
        document_ids: List[str],
        query: str,
        analysis_type: Optional[str] = None,
        limit: int = 10,
        offset: int = 0
    ) -> List[AnalysisResult]:
        """
        Search analysis results by content.
        
        Args:
            document_ids: List of document IDs to search within
            query: Search query
            analysis_type: Optional analysis type to filter by
            limit: Maximum number of results to return
            offset: Starting index
            
        Returns:
            List of matching analysis results
        """
        # We need to search in the JSON result_data, which is more complex
        # For simplicity, we'll convert the JSON to a string and search in that
        # In a real implementation, you might want to use the database's JSON search capabilities
        
        # Get all analyses for the documents
        base_query = (
            select(AnalysisResult)
            .where(AnalysisResult.document_id.in_(document_ids))
        )
        
        if analysis_type:
            base_query = base_query.where(AnalysisResult.analysis_type == analysis_type)
        
        # For PostgreSQL you would use something like:
        # base_query = base_query.where(
        #     func.json_to_string(AnalysisResult.result_data).ilike(f"%{query}%")
        # )
        
        # Since we're using SQLite for development, we'll fetch all and filter in Python
        result = await self.db.execute(base_query)
        all_analyses = result.scalars().all()
        
        # Filter by query
        matching_analyses = []
        for analysis in all_analyses:
            result_data_str = str(analysis.result_data)
            if query.lower() in result_data_str.lower():
                matching_analyses.append(analysis)
        
        # Sort by created_at (newest first) and apply limit/offset
        matching_analyses.sort(key=lambda x: x.created_at, reverse=True)
        return matching_analyses[offset:offset + limit]
</file>
```

#### repositories/conversation\_repository\.py
*Size: 14.4 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/repositories/conversation_repository.py">
import logging
import uuid
from typing import List, Optional, Dict, Any
from datetime import datetime
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from sqlalchemy import update, delete, func, and_, desc, or_

from models.database_models import Conversation, Message, User, Document, Citation, MessageCitation, ConversationDocument, AnalysisBlock
from models.document import Citation as CitationSchema
from utils.storage import StorageService

logger = logging.getLogger(__name__)

class ConversationRepository:
    """Repository for conversation operations."""
    
    def __init__(self, db: AsyncSession):
        """Initialize the conversation repository."""
        self.db = db
    
    async def create_conversation(self, title: str, user_id: str, document_ids: Optional[List[str]] = None) -> Conversation:
        """
        Create a new conversation.
        
        Args:
            title: Title of the conversation
            user_id: ID of the user creating the conversation
            document_ids: Optional list of document IDs to associate with the conversation
            
        Returns:
            Created conversation
        """
        # Create the conversation record
        conversation = Conversation(
            id=str(uuid.uuid4()),
            title=title,
            user_id=user_id,
            created_at=datetime.utcnow(),
            updated_at=datetime.utcnow()
        )
        
        # Add to database
        self.db.add(conversation)
        await self.db.flush()
        
        # Associate documents if provided
        if document_ids:
            for doc_id in document_ids:
                conversation_document = ConversationDocument(
                    conversation_id=conversation.id,
                    document_id=doc_id
                )
                self.db.add(conversation_document)
        
        await self.db.commit()
        await self.db.refresh(conversation)
        
        return conversation
    
    async def get_conversation(self, conversation_id: str) -> Optional[Conversation]:
        """
        Get a conversation by ID.
        
        Args:
            conversation_id: ID of the conversation
            
        Returns:
            Conversation if found, None otherwise
        """
        result = await self.db.execute(
            select(Conversation).where(Conversation.id == conversation_id)
        )
        return result.scalars().first()
    
    async def list_conversations(self, user_id: str, limit: int = 10, offset: int = 0) -> List[Conversation]:
        """
        List conversations for a user.
        
        Args:
            user_id: ID of the user
            limit: Maximum number of conversations to return
            offset: Starting index
            
        Returns:
            List of conversations
        """
        result = await self.db.execute(
            select(Conversation)
            .where(Conversation.user_id == user_id)
            .order_by(Conversation.updated_at.desc())
            .limit(limit)
            .offset(offset)
        )
        return result.scalars().all()
    
    async def count_conversations(self, user_id: str) -> int:
        """
        Count the number of conversations for a user.
        
        Args:
            user_id: ID of the user
            
        Returns:
            Number of conversations
        """
        result = await self.db.execute(
            select(func.count()).select_from(Conversation).where(Conversation.user_id == user_id)
        )
        return result.scalar()
    
    async def update_conversation(self, conversation_id: str, update_data: Dict[str, Any]) -> Optional[Conversation]:
        """
        Update a conversation.
        
        Args:
            conversation_id: ID of the conversation
            update_data: Dictionary of fields to update
            
        Returns:
            Updated conversation if found, None otherwise
        """
        # Always update the updated_at timestamp
        update_data["updated_at"] = datetime.utcnow()
        
        await self.db.execute(
            update(Conversation)
            .where(Conversation.id == conversation_id)
            .values(**update_data)
        )
        await self.db.commit()
        
        return await self.get_conversation(conversation_id)
    
    async def delete_conversation(self, conversation_id: str) -> bool:
        """
        Delete a conversation.
        
        Args:
            conversation_id: ID of the conversation
            
        Returns:
            True if conversation was deleted, False otherwise
        """
        # Delete from database
        await self.db.execute(
            delete(Conversation).where(Conversation.id == conversation_id)
        )
        await self.db.commit()
        
        return True
    
    async def add_message(
        self, 
        conversation_id: str, 
        content: str, 
        role: str,
        citation_ids: Optional[List[str]] = None
    ) -> Optional[Message]:
        """
        Add a message to a conversation.
        
        Args:
            conversation_id: ID of the conversation
            content: Message content
            role: Message role (user, assistant, system)
            citation_ids: Optional list of citation IDs to associate with the message
            
        Returns:
            Created message if conversation found, None otherwise
        """
        # Check if conversation exists
        conversation = await self.get_conversation(conversation_id)
        if not conversation:
            return None
        
        # Update conversation last updated timestamp
        await self.update_conversation(conversation_id, {})
        
        # Create message
        message = Message(
            id=str(uuid.uuid4()),
            conversation_id=conversation_id,
            content=content,
            role=role,
            created_at=datetime.utcnow()
        )
        
        # Add to database
        self.db.add(message)
        await self.db.flush()
        
        # Associate citations if provided
        if citation_ids:
            for citation_id in citation_ids:
                message_citation = MessageCitation(
                    message_id=message.id,
                    citation_id=citation_id
                )
                self.db.add(message_citation)
        
        await self.db.commit()
        await self.db.refresh(message)
        
        return message
    
    async def get_message(self, message_id: str) -> Optional[Message]:
        """
        Get a message by ID.
        
        Args:
            message_id: ID of the message
            
        Returns:
            Message if found, None otherwise
        """
        result = await self.db.execute(
            select(Message).where(Message.id == message_id)
        )
        return result.scalars().first()
        
    async def update_message(self, message: Message) -> Optional[Message]:
        """
        Update a message with new data.
        
        Args:
            message: Message object with updated fields
            
        Returns:
            Updated message if successful, None otherwise
        """
        try:
            # Just merge the message object with the database
            self.db.add(message)
            await self.db.commit()
            await self.db.refresh(message)
            
            logger.info(f"Updated message {message.id} - attributes: {dir(message)}")
            
            return message
        except Exception as e:
            logger.error(f"Error updating message: {e}")
            await self.db.rollback()
            return None
    
    async def get_conversation_messages(self, conversation_id: str, limit: int = 50, offset: int = 0) -> List[Message]:
        """
        Get messages for a conversation.
        
        Args:
            conversation_id: ID of the conversation
            limit: Maximum number of messages to return
            offset: Starting index
            
        Returns:
            List of messages
        """
        result = await self.db.execute(
            select(Message)
            .where(Message.conversation_id == conversation_id)
            .order_by(Message.created_at.asc())
            .limit(limit)
            .offset(offset)
        )
        return result.scalars().all()
    
    async def get_message_citations(self, message_id: str) -> List[Citation]:
        """
        Get citations for a message.
        
        Args:
            message_id: ID of the message
            
        Returns:
            List of citations
        """
        result = await self.db.execute(
            select(Citation)
            .join(MessageCitation, MessageCitation.citation_id == Citation.id)
            .where(MessageCitation.message_id == message_id)
        )
        return result.scalars().all()
    
    async def add_analysis_block(
        self,
        message_id: str,
        block_type: str,
        title: str,
        content: Dict[str, Any]
    ) -> Optional[AnalysisBlock]:
        """
        Add an analysis block to a message.
        
        Args:
            message_id: ID of the message
            block_type: Type of analysis block (chart, insight, etc.)
            title: Title of the block
            content: JSON content of the block
            
        Returns:
            Created analysis block if message found, None otherwise
        """
        # Check if message exists
        message = await self.get_message(message_id)
        if not message:
            return None
        
        # Create analysis block
        analysis_block = AnalysisBlock(
            id=str(uuid.uuid4()),
            message_id=message_id,
            block_type=block_type,
            title=title,
            content=content,
            created_at=datetime.utcnow()
        )
        
        # Add to database
        self.db.add(analysis_block)
        await self.db.commit()
        await self.db.refresh(analysis_block)
        
        return analysis_block
    
    async def get_message_analysis_blocks(self, message_id: str) -> List[AnalysisBlock]:
        """
        Get analysis blocks for a message.
        
        Args:
            message_id: ID of the message
            
        Returns:
            List of analysis blocks
        """
        result = await self.db.execute(
            select(AnalysisBlock)
            .where(AnalysisBlock.message_id == message_id)
            .order_by(AnalysisBlock.created_at.asc())
        )
        return result.scalars().all()
    
    async def add_document_to_conversation(self, conversation_id: str, document_id: str) -> bool:
        """
        Add a document to a conversation.
        
        Args:
            conversation_id: ID of the conversation
            document_id: ID of the document
            
        Returns:
            True if successful, False otherwise
        """
        # Check if the association already exists
        result = await self.db.execute(
            select(ConversationDocument)
            .where(and_(
                ConversationDocument.conversation_id == conversation_id,
                ConversationDocument.document_id == document_id
            ))
        )
        
        if result.scalars().first():
            # Already associated
            return True
        
        # Create the association
        conversation_document = ConversationDocument(
            conversation_id=conversation_id,
            document_id=document_id
        )
        
        self.db.add(conversation_document)
        await self.db.commit()
        
        return True
    
    async def remove_document_from_conversation(self, conversation_id: str, document_id: str) -> bool:
        """
        Remove a document from a conversation.
        
        Args:
            conversation_id: ID of the conversation
            document_id: ID of the document
            
        Returns:
            True if successful, False otherwise
        """
        await self.db.execute(
            delete(ConversationDocument)
            .where(and_(
                ConversationDocument.conversation_id == conversation_id,
                ConversationDocument.document_id == document_id
            ))
        )
        await self.db.commit()
        
        return True
    
    async def get_conversation_documents(self, conversation_id: str) -> List[Document]:
        """
        Get documents for a conversation.
        
        Args:
            conversation_id: ID of the conversation
            
        Returns:
            List of documents
        """
        result = await self.db.execute(
            select(Document)
            .join(ConversationDocument, ConversationDocument.document_id == Document.id)
            .where(ConversationDocument.conversation_id == conversation_id)
        )
        return result.scalars().all()
    
    async def search_conversations(
        self, 
        user_id: str, 
        query: str, 
        limit: int = 10, 
        offset: int = 0
    ) -> List[Conversation]:
        """
        Search conversations by title and content.
        
        Args:
            user_id: ID of the user
            query: Search query
            limit: Maximum number of conversations to return
            offset: Starting index
            
        Returns:
            List of matching conversations
        """
        # Search conversations by title
        conversations_query = (
            select(Conversation)
            .where(and_(
                Conversation.user_id == user_id,
                Conversation.title.ilike(f"%{query}%")
            ))
        )
        
        # Also get conversations with messages matching the query
        message_conversations_query = (
            select(Conversation)
            .join(Message, Message.conversation_id == Conversation.id)
            .where(and_(
                Conversation.user_id == user_id,
                Message.content.ilike(f"%{query}%")
            ))
            .distinct()
        )
        
        # Combine results
        combined_query = (
            select(Conversation)
            .where(or_(
                Conversation.id.in_(conversations_query.with_only_columns(Conversation.id)),
                Conversation.id.in_(message_conversations_query.with_only_columns(Conversation.id))
            ))
            .order_by(Conversation.updated_at.desc())
            .limit(limit)
            .offset(offset)
        )
        
        result = await self.db.execute(combined_query)
        return result.scalars().all()
</file>
```

#### repositories/document\_repository\.py
*Size: 21.9 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/repositories/document_repository.py">
import logging
import uuid
from typing import List, Optional, Dict, Any, BinaryIO
from datetime import datetime
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from sqlalchemy import update, delete, func
import json
import os

from models.database_models import Document, Citation, User, DocumentType, ProcessingStatusEnum
from models.document import ProcessedDocument, DocumentMetadata, DocumentUploadResponse, Citation as CitationSchema
from utils.storage import StorageService

logger = logging.getLogger(__name__)

class DocumentRepository:
    """Repository for document operations."""
    
    def __init__(self, db: AsyncSession, storage_service: Optional[StorageService] = None):
        """
        Initialize the document repository.
        
        Args:
            db: Database session
            storage_service: Optional storage service for file operations
        """
        self.db = db
        self.storage_service = storage_service or StorageService.get_storage_service()
    
    async def create_document(self, file_data: bytes, filename: str, user_id: str, mime_type: str) -> Document:
        """
        Create a new document record.
        
        Args:
            file_data: Raw bytes of the file
            filename: Name of the file
            user_id: ID of the user uploading the document
            mime_type: MIME type of the file
            
        Returns:
            Created document record
        """
        # Generate a unique ID for the document
        document_id = str(uuid.uuid4())
        
        # Store the file
        file_path = await self.storage_service.save_file(
            file_data=file_data,
            file_id=f"{document_id}.pdf",
            content_type=mime_type
        )
        
        # Create document record
        document = Document(
            id=document_id,
            filename=filename,
            file_path=file_path,
            file_size=len(file_data),
            mime_type=mime_type,
            user_id=user_id,
            upload_timestamp=datetime.utcnow(),
            processing_status=ProcessingStatusEnum.PENDING
        )
        
        # Save to database
        self.db.add(document)
        await self.db.commit()
        await self.db.refresh(document)
        
        return document
    
    async def get_document(self, document_id: str) -> Optional[Document]:
        """
        Get a document by ID.
        
        Args:
            document_id: ID of the document
            
        Returns:
            Document if found, None otherwise
        """
        # Ensure document_id is a string, not a list
        if isinstance(document_id, list):
            # If it's a list with items, use the first one
            if document_id:
                document_id = document_id[0]
            else:
                logger.error("Empty document_id list provided to get_document")
                return None
                
        try:
            result = await self.db.execute(
                select(Document).where(Document.id == document_id)
            )
            return result.scalars().first()
        except Exception as e:
            logger.error(f"Error retrieving document {document_id}: {str(e)}")
            return None
    
    async def get_document_content(self, document_id: str) -> Optional[Dict[str, Any]]:
        """
        Get the content of a document by ID.
        
        Args:
            document_id: ID of the document
            
        Returns:
            Document content dictionary with raw text and file content if found, None otherwise
        """
        document = await self.get_document(document_id)
        if not document:
            logger.warning(f"Document {document_id} not found in database")
            return None
            
        try:
            # Get the file path
            file_path = f"{document_id}.pdf"
            logger.info(f"Retrieving document content using file path: {file_path}")
            
            # Get the raw PDF content from storage
            logger.info(f"Requesting file from storage service for document {document_id}")
            pdf_content = await self.storage_service.get_file(file_path)
            
            # Log PDF content retrieval success
            if pdf_content:
                pdf_size = len(pdf_content) if pdf_content else 0
                logger.info(f"Retrieved PDF content for document {document_id}: {pdf_size} bytes")
            
            # Prepare the response data
            content_data = {
                "content": pdf_content,
                "id": document_id,
                "filename": document.filename
            }
            
            # Add raw text if available - first try document.raw_text, then extracted_data
            logger.info(f"[PDF-VISIBILITY-FIX] Document {document_id} raw_text check: present={document.raw_text is not None}")
            logger.info(f"[PDF-VISIBILITY-FIX] Document {document_id} extracted_data check: present={document.extracted_data is not None}, type={type(document.extracted_data).__name__ if document.extracted_data else 'None'}")
            
            if document.extracted_data:
                if isinstance(document.extracted_data, dict):
                    logger.info(f"[PDF-VISIBILITY-FIX] Document {document_id} extracted_data keys: {list(document.extracted_data.keys())}")
                    if "raw_text" in document.extracted_data:
                        logger.info(f"[PDF-VISIBILITY-FIX] Document {document_id} has raw_text in extracted_data ({len(str(document.extracted_data['raw_text']))} chars)")
                    else:
                        logger.info(f"[PDF-VISIBILITY-FIX] Document {document_id} missing raw_text in extracted_data")
                else:
                    logger.info(f"[PDF-VISIBILITY-FIX] Document {document_id} extracted_data is not a dictionary")
            
            if document.raw_text:
                content_data["raw_text"] = document.raw_text
                logger.info(f"[PDF-VISIBILITY-FIX] Using document.raw_text for document {document_id}: {len(document.raw_text)} characters")
            elif document.extracted_data and isinstance(document.extracted_data, dict) and "raw_text" in document.extracted_data:
                # Extract raw text from extracted_data as fallback
                content_data["raw_text"] = document.extracted_data["raw_text"]
                logger.info(f"[PDF-VISIBILITY-FIX] Using extracted_data.raw_text for document {document_id}: {len(str(document.extracted_data['raw_text']))} characters")
            else:
                logger.warning(f"[PDF-VISIBILITY-FIX] No raw text available for document {document_id} - all extraction attempts failed")
                content_data["raw_text"] = "Document text not yet extracted"
            
            # Add extracted data if available
            if document.extracted_data:
                content_data["extracted_data"] = document.extracted_data
                logger.info(f"Extracted data available for document {document_id}: {list(document.extracted_data.keys()) if isinstance(document.extracted_data, dict) else 'not a dict'}")
            else:
                logger.warning(f"No extracted data available for document {document_id}")
                content_data["extracted_data"] = {}
            
            # Log content retrieval success
            logger.info(f"Successfully retrieved content for document {document_id}")
            
            return content_data
        except Exception as e:
            logger.error(f"Error retrieving document content for {document_id}: {str(e)}")
            
            # Try to return just the document fields even if file retrieval failed
            if document:
                logger.info(f"Returning partial content for document {document_id} (file retrieval failed)")
                return {
                    "id": document_id,
                    "filename": document.filename,
                    "raw_text": document.raw_text or "Document text not available",
                    "extracted_data": document.extracted_data or {}
                }
            
            return None
    
    async def list_documents(self, user_id: str, limit: int = 10, offset: int = 0) -> List[Document]:
        """
        List documents for a user.
        
        Args:
            user_id: ID of the user
            limit: Maximum number of documents to return
            offset: Starting index
            
        Returns:
            List of documents
        """
        result = await self.db.execute(
            select(Document)
            .where(Document.user_id == user_id)
            .order_by(Document.upload_timestamp.desc())
            .limit(limit)
            .offset(offset)
        )
        return result.scalars().all()
    
    async def count_documents(self, user_id: str) -> int:
        """
        Count the number of documents for a user.
        
        Args:
            user_id: ID of the user
            
        Returns:
            Number of documents
        """
        result = await self.db.execute(
            select(func.count()).select_from(Document).where(Document.user_id == user_id)
        )
        return result.scalar()
    
    async def update_document(self, document_id: str, update_data: Dict[str, Any]) -> Optional[Document]:
        """
        Update a document.
        
        Args:
            document_id: ID of the document
            update_data: Dictionary of fields to update
            
        Returns:
            Updated document if found, None otherwise
        """
        await self.db.execute(
            update(Document)
            .where(Document.id == document_id)
            .values(**update_data)
        )
        await self.db.commit()
        
        return await self.get_document(document_id)
    
    async def update_document_status(
        self, document_id: str, status: ProcessingStatusEnum, error_message: Optional[str] = None
    ) -> Optional[Document]:
        """
        Update a document's processing status.
        
        Args:
            document_id: ID of the document
            status: New processing status
            error_message: Optional error message if status is FAILED
            
        Returns:
            Updated document if found, None otherwise
        """
        update_data = {
            "processing_status": status,
            "processing_timestamp": datetime.utcnow()
        }
        
        if error_message:
            update_data["error_message"] = error_message
        
        return await self.update_document(document_id, update_data)
    
    async def update_document_content(
        self, 
        document_id: str, 
        document_type: Optional[DocumentType] = None, 
        periods: Optional[List[str]] = None,
        extracted_data: Optional[Dict[str, Any]] = None,
        raw_text: Optional[str] = None,
        confidence_score: Optional[float] = None,
        update_existing: bool = False
    ) -> Optional[Document]:
        """
        Update a document's content after processing.
        
        Args:
            document_id: ID of the document
            document_type: Type of financial document
            periods: List of time periods in the document
            extracted_data: Extracted structured data
            raw_text: Optional raw text of the document
            confidence_score: Confidence score of the extraction
            update_existing: If True, merge with existing extracted_data instead of replacing
            
        Returns:
            Updated document if found, None otherwise
        """
        # Build the update data with only provided fields
        update_data = {"extraction_timestamp": datetime.utcnow()}
        
        if document_type is not None:
            update_data["document_type"] = document_type
            
        if periods is not None:
            update_data["periods"] = periods
            
        if confidence_score is not None:
            update_data["confidence_score"] = confidence_score
            
        if raw_text is not None:
            update_data["raw_text"] = raw_text
        
        # Handle extracted_data separately if update_existing is True
        if extracted_data is not None:
            if update_existing:
                # Get current document to merge extracted_data
                current_doc = await self.get_document(document_id)
                if current_doc and current_doc.extracted_data:
                    # Deep merge the extracted data
                    merged_data = self._merge_dicts(current_doc.extracted_data, extracted_data)
                    update_data["extracted_data"] = merged_data
                else:
                    update_data["extracted_data"] = extracted_data
            else:
                update_data["extracted_data"] = extracted_data
        
        return await self.update_document(document_id, update_data)
    
    def _merge_dicts(self, dict1: Dict[str, Any], dict2: Dict[str, Any]) -> Dict[str, Any]:
        """
        Deep merge two dictionaries.
        Values from dict2 will override values in dict1 unless both are dictionaries,
        in which case they will be merged recursively.
        
        Args:
            dict1: First dictionary
            dict2: Second dictionary (takes precedence)
            
        Returns:
            Merged dictionary
        """
        result = dict1.copy()
        
        for key, value in dict2.items():
            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                # Recursively merge nested dictionaries
                result[key] = self._merge_dicts(result[key], value)
            else:
                # Override or add the value
                result[key] = value
                
        return result
    
    async def delete_document(self, document_id: str) -> bool:
        """
        Delete a document.
        
        Args:
            document_id: ID of the document
            
        Returns:
            True if document was deleted, False otherwise
        """
        # Get document to get the file path
        document = await self.get_document(document_id)
        if not document:
            return False
        
        # Delete the file
        file_id = f"{document_id}.pdf"
        await self.storage_service.delete_file(file_id)
        
        # Delete from database
        await self.db.execute(
            delete(Document).where(Document.id == document_id)
        )
        await self.db.commit()
        
        return True
    
    async def add_citation(
        self, document_id: str, page: int, text: str, section: Optional[str] = None, bounding_box: Optional[Dict[str, Any]] = None
    ) -> Optional[Citation]:
        """
        Add a citation to a document.
        
        Args:
            document_id: ID of the document
            page: Page number
            text: Citation text
            section: Optional section name
            bounding_box: Optional bounding box coordinates
            
        Returns:
            Created citation if document found, None otherwise
        """
        # Check if document exists
        document = await self.get_document(document_id)
        if not document:
            return None
        
        # Create citation
        citation = Citation(
            id=str(uuid.uuid4()),
            document_id=document_id,
            page=page,
            text=text,
            section=section,
            bounding_box=bounding_box
        )
        
        # Save to database
        self.db.add(citation)
        await self.db.commit()
        await self.db.refresh(citation)
        
        return citation
    
    async def get_citation(self, citation_id: str) -> Optional[Citation]:
        """
        Get a citation by ID.
        
        Args:
            citation_id: ID of the citation
            
        Returns:
            Citation if found, None otherwise
        """
        result = await self.db.execute(
            select(Citation).where(Citation.id == citation_id)
        )
        return result.scalars().first()
    
    async def update_citation(self, citation_id: str, metadata: Optional[Dict[str, Any]] = None) -> bool:
        """
        Update a citation's metadata.
        
        Args:
            citation_id: ID of the citation
            metadata: New metadata dictionary
            
        Returns:
            True if updated, False otherwise
        """
        # Get the citation
        citation = await self.get_citation(citation_id)
        if not citation:
            return False
        
        # Update metadata if provided
        if metadata is not None:
            citation.metadata = metadata
        
        # Save changes
        await self.db.commit()
        
        return True
    
    async def get_document_citations(self, document_id: str) -> List[Citation]:
        """
        Get citations for a document.
        
        Args:
            document_id: ID of the document
            
        Returns:
            List of citations
        """
        result = await self.db.execute(
            select(Citation).where(Citation.document_id == document_id)
        )
        return result.scalars().all()
    
    # Methods to convert between database models and API schemas
    
    def document_to_api_schema(self, document: Document) -> ProcessedDocument:
        """Convert a database document model to an API schema."""
        # Avoid lazy loading by not accessing citations directly
        
        # Create metadata
        metadata = DocumentMetadata(
            id=document.id,
            filename=document.filename,
            upload_timestamp=document.upload_timestamp,
            file_size=document.file_size,
            mime_type=document.mime_type,
            user_id=document.user_id,
            citation_links=[]  # Initialize with empty list to avoid lazy loading
        )
        
        # Create processed document
        processed_document = ProcessedDocument(
            metadata=metadata,
            content_type=document.document_type.value if document.document_type else "other",
            extraction_timestamp=document.extraction_timestamp or document.upload_timestamp,
            periods=document.periods or [],
            extracted_data=document.extracted_data or {},
            citations=[],  # Initialize with empty list to avoid lazy loading
            confidence_score=document.confidence_score or 0.0,
            processing_status=document.processing_status.value if document.processing_status else "pending",
            error_message=document.error_message
        )
        
        return processed_document
    
    def document_to_metadata_schema(self, document: Document) -> DocumentMetadata:
        """Convert a database document model to a metadata schema."""
        # Avoid lazy loading by not accessing citations directly
        metadata = DocumentMetadata(
            id=document.id,
            filename=document.filename,
            upload_timestamp=document.upload_timestamp,
            file_size=document.file_size,
            mime_type=document.mime_type,
            user_id=document.user_id,
            citation_links=[]  # Initialize with empty list to avoid lazy loading
        )
        
        return metadata
    
    def document_to_upload_response(self, document: Document) -> DocumentUploadResponse:
        """Convert a database document model to an upload response schema."""
        return DocumentUploadResponse(
            document_id=document.id,
            filename=document.filename,
            status=document.processing_status.value if document.processing_status else "pending",
            message=f"Document uploaded and processing has {'started' if document.processing_status == ProcessingStatusEnum.PENDING else 'completed'}"
        )
    
    def citation_to_api_schema(self, citation: Citation) -> CitationSchema:
        """Convert a database Citation to an API CitationSchema."""
        return CitationSchema(
            id=str(citation.id),
            text=citation.text,
            documentId=str(citation.document_id),
            page=citation.page,
            highlightId=citation.highlight_id,
            rects=citation.bounding_box if citation.bounding_box else [],
            messageId=str(citation.message_id) if citation.message_id else None,
            analysisId=str(citation.analysis_id) if citation.analysis_id else None,
        )
        
    def get_document_file_path(self, document_id: str) -> str:
        """
        Get the physical file path for a document.
        
        Args:
            document_id: ID of the document
            
        Returns:
            Absolute path to the document file
        """
        # The storage service uses the document ID with a .pdf extension as the file ID
        file_id = f"{document_id}.pdf"
        return self.storage_service.get_file_path(file_id)
    
    async def get_document_binary(self, document_id: str) -> Optional[bytes]:
        """
        Get the binary data for a document.
        
        Args:
            document_id: ID of the document
            
        Returns:
            Binary data of the document file if available, None otherwise
        """
        try:
            # First check if we have the document in the database
            document = await self.get_document(document_id)
            if not document:
                return None
            
            # If we have binary_data stored in the database, return it
            if hasattr(document, 'binary_data') and document.binary_data:
                return document.binary_data
            
            # If we don't have binary data in the DB, try to read from file
            file_path = self.get_document_file_path(document_id)
            if os.path.exists(file_path):
                with open(file_path, 'rb') as f:
                    return f.read()
            
            # No binary data found
            return None
        except Exception as e:
            logging.error(f"Error getting document binary data: {str(e)}", exc_info=True)
            return None
</file>
```

#### requirements\.txt
*Size: 383 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/requirements.txt">
fastapi==0.110.0
uvicorn==0.28.0
python-multipart==0.0.9
httpx==0.27.0
pydantic==2.6.1
anthropic==0.21.3
python-dotenv==1.0.1
pytest==7.4.4
starlette==0.36.3
langchain
langchain-anthropic
langchain-community
langchain-core
langgraph
redis==5.0.1
tiktoken==0.6.0
PyPDF2==3.0.1
sqlalchemy==2.0.23
alembic==1.13.1
psycopg2-binary==2.9.9
boto3==1.34.45
aiofiles==23.2.1
aiosqlite==0.19.0
</file>
```

#### restart\_server\.sh
*Size: 1.6 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/restart_server.sh">
#!/bin/bash

# Colors for output
GREEN='\033[0;32m'
RED='\033[0;31m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

echo -e "${BLUE}Restarting FastAPI server...${NC}"

# Check if server is already running
PID=$(lsof -t -i:8000 2>/dev/null)
if [ ! -z "$PID" ]; then
    echo -e "${BLUE}Server is running with PID $PID. Stopping...${NC}"
    kill -9 $PID
    sleep 1
    
    # Verify it's stopped
    if lsof -t -i:8000 &>/dev/null; then
        echo -e "${RED}Failed to stop server. Please check manually.${NC}"
        exit 1
    else
        echo -e "${GREEN}Server stopped successfully.${NC}"
    fi
else
    echo -e "${BLUE}No server running on port 8000.${NC}"
fi

# Start the server in the background
echo -e "${BLUE}Starting server...${NC}"
cd "$(dirname "$0")"
nohup python -m app.main > server.log 2>&1 &
NEW_PID=$!

echo -e "${GREEN}Server started with PID $NEW_PID${NC}"

# Wait for server to be ready
echo -e "${BLUE}Waiting for server to be ready...${NC}"
MAX_ATTEMPTS=10
ATTEMPT=0
while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
    ATTEMPT=$((ATTEMPT+1))
    echo -e "${BLUE}Checking server status (attempt $ATTEMPT/$MAX_ATTEMPTS)...${NC}"
    
    # Check if process is still running
    if ! ps -p $NEW_PID > /dev/null; then
        echo -e "${RED}Server process died. Check server.log for details.${NC}"
        exit 1
    fi
    
    # Try to connect to the server
    if curl -s http://127.0.0.1:8000/api/health > /dev/null; then
        echo -e "${GREEN}Server is up and running!${NC}"
        exit 0
    fi
    
    sleep 2
done

echo -e "${RED}Server did not start properly within the timeout period.${NC}"
echo -e "${BLUE}Check server.log for details.${NC}"
exit 1 
</file>
```

#### run\.py
*Size: 1.6 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/run.py">
import uvicorn
import os
import logging
import sys
from dotenv import load_dotenv

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

# Load environment variables from .env file
load_dotenv()

def main():
    """Start the FastAPI server."""
    try:
        # Check for required environment variables
        required_vars = ["ANTHROPIC_API_KEY"]
        missing_vars = [var for var in required_vars if not os.getenv(var)]
        
        if missing_vars:
            logger.error(f"The following required environment variables are missing: {', '.join(missing_vars)}")
            logger.error("Please set these variables in your environment or in a .env file")
            sys.exit(1)
        
        # Get server configuration from environment variables
        host = os.getenv("HOST", "0.0.0.0")
        port = int(os.getenv("PORT", "8000"))
        debug = os.getenv("DEBUG", "False").lower() == "true"
        reload = debug
        log_level = "debug" if debug else "info"
        
        logger.info(f"Starting FastAPI server on {host}:{port} with debug={debug}")
        logger.info("LangChain and LangGraph integration enabled")
        
        # Start the FastAPI server
        uvicorn.run(
            "app.main:app",
            host=host,
            port=port,
            reload=reload,
            log_level=log_level
        )
        
    except Exception as e:
        logger.error(f"Error starting server: {str(e)}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()
</file>
```

#### run\_server\.py
*Size: 628 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/run_server.py">
#!/usr/bin/env python
import sys
import os
from pathlib import Path
import uvicorn

# Configure Python's path to include the project root
current_dir = Path(__file__).parent.absolute()
parent_dir = current_dir.parent
sys.path.append(str(current_dir))
sys.path.append(str(parent_dir))

if __name__ == "__main__":
    print(f"Current directory: {current_dir}")
    print(f"Parent directory: {parent_dir}")
    print(f"sys.path: {sys.path}")
    
    # Start the FastAPI server
    uvicorn.run(
        "app.main:app",
        host="127.0.0.1",
        port=8000,
        reload=True,
        reload_dirs=[str(current_dir)],
    ) 
</file>
```

#### services/\_\_init\_\_\.py
*Size: 145 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/services/__init__.py">
# Import services here to make them available
from .conversation_service import ConversationService
from .analysis_service import AnalysisService
</file>
```

#### services/analysis\_service\.py
*Size: 29.1 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/services/analysis_service.py">
import os
import logging
import json
import uuid
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple
import asyncio

from repositories.analysis_repository import AnalysisRepository
from repositories.document_repository import DocumentRepository
from pdf_processing.claude_service import ClaudeService
from pdf_processing.financial_agent import FinancialAnalysisAgent
from models.database_models import AnalysisResult, Document

logger = logging.getLogger(__name__)

# Define the financial analysis template at module level
financial_analysis_template = """
You are an advanced AI system functioning as a Regional Bank Financial Analyst. Your primary role is to analyze internal financial documents, provide insights on financial trends or anomalies, and create visualizations to illustrate financial data.

First, review the following financial documents and knowledge base:

<financial_documents>
{document_text}
</financial_documents>

<knowledge_base>
{{KNOWLEDGE_BASE}}
</knowledge_base>

Now, analyze the following user query:

<user_query>
{{USER_QUERY}}
</user_query>

Before providing your final response, wrap your analysis planning inside <financial_analysis_planning> tags using the following structure:

1. Query Breakdown: Identify key areas to focus on based on the user query.
2. Relevant Information: Extract and quote pertinent data from the financial documents and knowledge base.
3. Key Data Points: List relevant data points from the provided sources.
4. Financial Ratios and Metrics: Identify and list key ratios and metrics relevant to the query, focusing on those specific to regional banks.
5. Industry Benchmarks: Consider industry benchmarks and how the bank's performance compares.
6. Time Periods: Analyze trends over multiple time periods (e.g., quarter-over-quarter, year-over-year, multi-year trends).
7. Analytical Approach: Outline your approach, including planned calculations and comparisons.
8. Visualization Planning: Plan the following visualizations:
   - Multi-period Balance Sheet Composition stacked Column Chart
   - Balance Sheet Change Analysis Column Chart
   - Asset Composition Line Chart
   - Liability Composition Line Chart
   - Margin Analysis
   - Non-Interest Revenue Trend Chart
   - Non-Interest Revenue Period over period Chart
   - Key Financial Ratio Trend Line Charts
   - Expense Composition Trend Stacked Bar Chart
9. Visualization Insights: For each proposed visualization, list key insights you expect to highlight. These insights should be rendered only within or beneath each chart component in the final artifact.
10. Next Actions: Brainstorm possible deeper analyses that could follow from your initial findings, focusing only on analyses possible with the provided files.
11. Challenges and Limitations: Consider potential challenges or limitations in your analysis.
12. Tool Evaluation: Assess whether the beta analysis tool in Claude.ai could benefit this specific query.
13. External Factors: Identify potential external factors affecting the financial data and explain their possible impacts.
14. Key Terms: List and define key financial terms relevant to the query.
15. Regional Bank Specifics: Identify any metrics or considerations that are particularly important for regional banks.

Guidelines for your analysis and response:

1. Incorporate information from both the financial documents and the knowledge base.
2. Focus on core banking concepts like Funds Transfer Pricing when relevant.
3. Use LaTeX rendering for all mathematical calculations, enclosing formulas in $$ symbols.
4. For period-over-period changes, use the most recent linked quarter unless specified otherwise.
5. Provide detailed explanations, breaking down complex concepts into understandable terms.
6. Highlight any inconsistencies or unusual patterns in the financial data, offering possible explanations.
7. Support all recommendations and insights with data from the financial documents.
8. Consider using the beta analysis tool in Claude.ai when appropriate for deeper financial analysis.
9. Generate a single visualization artifact containing all proposed charts, graphs, and text blocks.
10. Present all analysis and key insights within the artifact using a mixture of cards or text blocks.
11. Use React and Recharts for visualizations with multiple data views.
12. Ensure all cards have the current metric and a period-over-period change percentage.
13. Create all suggested charts without exception.
14. Ensure that "Key Findings" are only rendered in or beneath each chart component within the artifact.
15. For suggested next actions, only propose further analyses of details from the provided financials.

Structure your final response as follows:

<response>
Query Restatement: [Restate the user's query]

Approach Overview: [Brief explanation of your analytical approach]

Artifact:
[Single artifact containing all charts, graphs, text blocks, and cards]
[Include all analysis and key insights within this artifact]
[For each chart, graph, or analysis section:]
   Key Insights:
   - [First key insight]
   - [Second key insight]
   - [Third key insight]

Summary and Recommendations:
[Concise summary of findings and data-supported recommendations]

Suggested Next Actions:
1. [First suggested deeper analysis of provided financials, phrased to directly trigger the next analysis]
2. [Second suggested deeper analysis of provided financials, phrased to directly trigger the next analysis]
3. [Third suggested deeper analysis of provided financials, phrased to directly trigger the next analysis]
</response>

 Provide your response within <response> tags.
"""

class AnalysisService:
    """Service for managing financial analysis."""
    
    def __init__(
        self,
        analysis_repository: AnalysisRepository,
        document_repository: DocumentRepository
    ):
        """
        Initialize the analysis service.
        
        Args:
            analysis_repository: Repository for analysis operations
            document_repository: Repository for document operations
        """
        self.analysis_repository = analysis_repository
        self.document_repository = document_repository
        self.claude_service = ClaudeService()
        self.financial_agent = FinancialAnalysisAgent()
    
    async def run_analysis(
        self,
        document_ids: List[str],
        analysis_type: str,
        parameters: Optional[Dict[str, Any]] = None
    ) -> Tuple[str, Dict[str, Any]]:
        """
        Run financial analysis on one or more documents.
        Routes to the appropriate analysis method based on analysis_type.

        Args:
            document_ids: List of document IDs to analyze
            analysis_type: Type of analysis to run
            parameters: Optional parameters for the analysis

        Returns:
            Tuple of (analysis_id, result_data_with_metadata)
        """
        if parameters is None:
            parameters = {}

        if not document_ids:
            raise ValueError("No documents provided for analysis")

        # For now, handle single document analysis primarily
        document_id = document_ids[0]
        document = await self.document_repository.get_document(document_id)
        if not document:
            raise ValueError(f"Document {document_id} not found")

        try:
            # --- ROUTING LOGIC ---
            if analysis_type == "comprehensive" or analysis_type == "comprehensive_tools":
                logger.info(f"Routing to comprehensive tool-based analysis for document {document_id}")
                result_data = await self._run_tool_based_comprehensive_analysis(document, parameters)
                # Ensure the analysis type reflects tool usage if requested directly
                if analysis_type == "comprehensive_tools":
                    analysis_type = "comprehensive_tools"
                else:
                    # If comprehensive was called, mark it as tool-based if successful
                    # This might need adjustment based on how you distinguish
                    analysis_type = "comprehensive_tools"

            elif analysis_type == "financial_ratios":
                 # If you keep other analysis types, implement their calls here
                 # result_data = await self._run_financial_ratio_analysis(document, parameters)
                 logger.warning(f"Analysis type '{analysis_type}' might not be fully migrated to tool-based flow yet.")
                 # Fallback to comprehensive for now, or raise error
                 result_data = await self._run_tool_based_comprehensive_analysis(document, parameters)
                 analysis_type = "comprehensive_tools" # Mark as tool-based for consistency

            # Keep existing analysis type routing
            elif analysis_type == "trend_analysis":
                result_data = await self._run_trend_analysis(document, parameters)
            elif analysis_type == "benchmarking":
                result_data = await self._run_benchmark_analysis(document, parameters)
            elif analysis_type == "sentiment_analysis":
                result_data = await self._run_sentiment_analysis(document, parameters)
            else:
                # Default to comprehensive tool-based analysis if type is unknown or not specifically handled
                logger.warning(f"Unknown or unhandled analysis type '{analysis_type}'. Defaulting to comprehensive tool-based analysis.")
                result_data = await self._run_tool_based_comprehensive_analysis(document, parameters)
                analysis_type = "comprehensive_tools" # Mark as tool-based

            # --- End Routing Logic ---

            # Save the analysis result
            # Ensure result_data structure matches what the DB expects (e.g., needs metrics, ratios, insights keys)
            db_result_data = {
                "analysis_text": result_data.get("analysis_text", ""),
                "metrics": result_data.get("metrics", []), # Extract metrics if returned by Claude
                "ratios": result_data.get("ratios", []), # Extract ratios if returned
                "insights": result_data.get("insights", []), # Extract insights if returned
                "visualization_data": result_data.get("visualization_data", {"charts": [], "tables": []}),
                "citation_references": result_data.get("citation_references", {}),
                "comparative_periods": result_data.get("comparative_periods", []) # Extract comparisons if returned
                # Add other fields expected by the DB model if necessary
            }

            analysis = await self.analysis_repository.create_analysis(
                document_id=document_id,
                analysis_type=analysis_type,
                result_data=db_result_data # Pass the structured data for DB
            )

            # Create an ID for the analysis response (can be different from DB ID if needed)
            analysis_response_id = f"analysis-{analysis.id}"

            # Structure the final response payload for the API
            # This structure should match the frontend expectations closely
            response_payload = {
                "id": analysis_response_id,
                "documentIds": document_ids,
                "analysisType": analysis_type,
                "timestamp": analysis.created_at.isoformat(),
                "analysisText": result_data.get("analysis_text", ""),
                "visualizationData": result_data.get("visualization_data", {"charts": [], "tables": []}),
                "metrics": result_data.get("metrics", []), # Include metrics in the response
                "ratios": result_data.get("ratios", []), # Include ratios if available
                "comparativePeriods": result_data.get("comparative_periods", []), # Include comparisons
                "insights": result_data.get("insights", []), # Include insights if available
                "citationReferences": result_data.get("citation_references", {}),
                # Add other relevant metadata
                "document_type": document.document_type.value if document.document_type else "other",
                "periods": document.periods or [],
                "query": parameters.get("query", "")
            }

            return analysis_response_id, response_payload

        except Exception as e:
            logger.error(f"Error running analysis for document {document_id}: {str(e)}", exc_info=True)
            raise # Re-raise the exception to be handled by the API layer

    async def _run_tool_based_comprehensive_analysis(
        self,
        document: Document,
        parameters: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Run comprehensive analysis using Claude with tool-based visualization generation.

        Args:
            document: Document to analyze
            parameters: Analysis parameters

        Returns:
            Dictionary containing the analysis results with visualizations
        """
        try:
            logger.info(f"Running comprehensive tool-based analysis for document: {document.id}")

            # Get document text - prioritize raw_text if available
            document_text = document.raw_text
            if not document_text and document.extracted_data and isinstance(document.extracted_data, dict):
                document_text = document.extracted_data.get("raw_text", "")

            if not document_text:
                logger.warning(f"No text content found for document {document.id}, attempting fallback.")
                # Fallback: create minimal text if none exists
                document_text = f"Document ID: {document.id}, Filename: {document.filename}. No text content could be extracted."
                # Consider raising an error if text is absolutely required
                # raise ValueError(f"No text content found in document {document.id}")

            # Get user query from parameters or use default
            user_query = parameters.get("query", "Provide a comprehensive financial analysis of this document, generating relevant charts and tables using the provided tools.")
            logger.info(f"User query: {user_query}")

            # Get knowledge base if available
            knowledge_base = parameters.get("knowledge_base", "")

            # Call the Claude service method that uses tools
            analysis_result = await self.claude_service.analyze_with_visualization_tools(
                document_text=document_text,
                user_query=user_query,
                knowledge_base=knowledge_base
            )

            # analysis_result is expected to contain:
            # {
            #   "analysis_text": "...",
            #   "visualizations": { "charts": [...], "tables": [...] }
            # }

            # Format the result for the analysis repository and API response
            # The structure returned by analyze_with_visualization_tools should already be close
            result_data = {
                "analysis_text": analysis_result.get("analysis_text", ""),
                "visualization_data": analysis_result.get("visualizations", {"charts": [], "tables": []}),
                # Add other fields if the tool-based method returns them (e.g., metrics)
                "metrics": analysis_result.get("metrics", []),
                "ratios": analysis_result.get("ratios", []),
                "insights": analysis_result.get("insights", []),
                "comparative_periods": analysis_result.get("comparative_periods", []),
                "citation_references": analysis_result.get("citation_references", {}),
                # Add metadata
                "document_type": document.document_type.value if document.document_type else "other",
                "periods": document.periods or [],
                "query": user_query
            }

            logger.info(f"Completed tool-based comprehensive analysis for document {document.id}")
            # Log counts for verification
            viz_data = result_data['visualization_data']
            logger.info(f"Charts generated: {len(viz_data.get('charts', []))}")
            logger.info(f"Tables generated: {len(viz_data.get('tables', []))}")
            logger.info(f"Metrics extracted: {len(result_data.get('metrics', []))}")
            logger.info(f"Comparisons extracted: {len(result_data.get('comparative_periods', []))}")


            return result_data

        except Exception as e:
            logger.error(f"Error in tool-based comprehensive analysis: {str(e)}", exc_info=True)
            # Return error information structure
            return {
                "analysis_text": f"Error during comprehensive analysis: {str(e)}",
                "visualization_data": {"charts": [], "tables": []},
                "metrics": [],
                "ratios": [],
                "insights": [f"Error: {str(e)}"],
                "comparative_periods": [],
                "citation_references": {},
                "document_type": document.document_type.value if document.document_type else "other",
                "periods": document.periods or [],
                "query": parameters.get("query", "")
            }

    async def _run_financial_ratio_analysis(
        self,
        document: Document,
        parameters: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Run financial ratio analysis.
        
        Args:
            document: Document to analyze
            parameters: Analysis parameters
            
        Returns:
            Dictionary containing the analysis results
        """
        # Extract financial data from the document
        financial_data = document.extracted_data.get("financial_data", {})
        
        if not financial_data:
            raise ValueError("No financial data found in document")
        
        # Use the financial agent to calculate ratios
        ratios = await self.financial_agent.calculate_financial_ratios(
            financial_data=financial_data,
            parameters=parameters
        )
        
        # Build the result data
        result_data = {
            "ratios": ratios,
            "document_type": document.document_type.value if document.document_type else "other",
            "periods": document.periods or [],
            "insights": []
        }
        
        # Generate insights if requested
        if parameters.get("generate_insights", True):
            insights = await self.financial_agent.generate_insights_from_ratios(ratios)
            result_data["insights"] = insights
        
        # Prepare chart data if requested
        if parameters.get("generate_charts", True):
            chart_data = await self.financial_agent.prepare_chart_data(
                financial_data=financial_data,
                ratios=ratios,
                parameters=parameters
            )
            result_data["chart_data"] = chart_data
        
        return result_data
    
    async def _run_trend_analysis(
        self,
        document: Document,
        parameters: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Run trend analysis.
        
        Args:
            document: Document to analyze
            parameters: Analysis parameters
            
        Returns:
            Dictionary containing the analysis results
        """
        # Extract financial data from the document
        financial_data = document.extracted_data.get("financial_data", {})
        
        if not financial_data:
            raise ValueError("No financial data found in document")
        
        # Get time periods from the document
        periods = document.periods
        if not periods or len(periods) < 2:
            raise ValueError("Trend analysis requires at least two time periods")
        
        # Use the financial agent to analyze trends
        trends = await self.financial_agent.analyze_trends(
            financial_data=financial_data,
            periods=periods,
            parameters=parameters
        )
        
        # Build the result data
        result_data = {
            "trends": trends,
            "document_type": document.document_type.value if document.document_type else "other",
            "periods": periods,
            "insights": []
        }
        
        # Generate insights if requested
        if parameters.get("generate_insights", True):
            insights = await self.financial_agent.generate_insights_from_trends(trends)
            result_data["insights"] = insights
        
        # Prepare chart data if requested
        if parameters.get("generate_charts", True):
            chart_data = await self.financial_agent.prepare_trend_chart_data(
                trends=trends,
                periods=periods,
                parameters=parameters
            )
            result_data["chart_data"] = chart_data
        
        return result_data
    
    async def _run_benchmark_analysis(
        self,
        document: Document,
        parameters: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Run benchmark analysis.
        
        Args:
            document: Document to analyze
            parameters: Analysis parameters
            
        Returns:
            Dictionary containing the analysis results
        """
        # Extract financial data from the document
        financial_data = document.extracted_data.get("financial_data", {})
        
        if not financial_data:
            raise ValueError("No financial data found in document")
        
        # Get benchmark data (in a real implementation, this would come from a database or API)
        industry = parameters.get("industry", "general")
        benchmark_data = await self.financial_agent.get_industry_benchmarks(industry)
        
        # Use the financial agent to compare with benchmarks
        comparison = await self.financial_agent.compare_with_benchmarks(
            financial_data=financial_data,
            benchmarks=benchmark_data,
            parameters=parameters
        )
        
        # Build the result data
        result_data = {
            "benchmark_comparison": comparison,
            "industry": industry,
            "document_type": document.document_type.value if document.document_type else "other",
            "periods": document.periods or [],
            "insights": []
        }
        
        # Generate insights if requested
        if parameters.get("generate_insights", True):
            insights = await self.financial_agent.generate_insights_from_benchmark(comparison)
            result_data["insights"] = insights
        
        # Prepare chart data if requested
        if parameters.get("generate_charts", True):
            chart_data = await self.financial_agent.prepare_benchmark_chart_data(
                comparison=comparison,
                parameters=parameters
            )
            result_data["chart_data"] = chart_data
        
        return result_data
    
    async def _run_sentiment_analysis(
        self,
        document: Document,
        parameters: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Run sentiment analysis on document text.
        
        Args:
            document: Document to analyze
            parameters: Analysis parameters
            
        Returns:
            Dictionary containing the analysis results
        """
        # Get document text
        text = document.raw_text
        
        if not text:
            raise ValueError("No text content found in document")
        
        # Use Claude to analyze sentiment
        sentiment_analysis = await self.claude_service.analyze_document_sentiment(text)
        
        # Build the result data
        result_data = {
            "sentiment": sentiment_analysis["sentiment"],
            "sentiment_score": sentiment_analysis["score"],
            "document_type": document.document_type.value if document.document_type else "other",
            "key_phrases": sentiment_analysis.get("key_phrases", []),
            "insights": sentiment_analysis.get("insights", [])
        }
        
        # Prepare chart data if requested
        if parameters.get("generate_charts", True):
            chart_data = [{
                "type": "gauge",
                "title": "Sentiment Score",
                "data": {
                    "value": sentiment_analysis["score"],
                    "min": -1,
                    "max": 1,
                    "thresholds": [
                        { "value": -0.5, "color": "red" },
                        { "value": 0, "color": "yellow" },
                        { "value": 0.5, "color": "green" }
                    ]
                }
            }]
            
            result_data["chart_data"] = chart_data
        
        return result_data
    
    async def get_analysis(self, analysis_id: str) -> Dict[str, Any]:
        """
        Get an analysis by ID.

        Args:
            analysis_id: ID of the analysis

        Returns:
            Dictionary containing the analysis
        """
        # Strip any prefix if present
        clean_id = analysis_id
        if analysis_id.startswith('analysis-'):
            clean_id = analysis_id.replace('analysis-', '', 1) # Remove only the first instance

        # Get the analysis from the repository
        analysis = await self.analysis_repository.get_analysis(clean_id)
        if not analysis:
            raise ValueError(f"Analysis {analysis_id} not found")

        # Format the result data to match the structure expected by the API endpoint
        result_data = analysis.result_data or {}
        visualization_data = result_data.get("visualization_data", {})
        # Ensure visualization_data is a dict
        if visualization_data is None:
             visualization_data = {}

        response_payload = {
            "id": f"analysis-{analysis.id}", # Add prefix back
            "documentIds": [analysis.document_id], # Wrap in list
            "analysisType": analysis.analysis_type,
            "timestamp": analysis.created_at.isoformat(),
            "analysisText": result_data.get("analysis_text", ""),
            "visualizationData": {
                 "charts": visualization_data.get("charts", []),
                 "tables": visualization_data.get("tables", []),
                 # Include other potential keys if they exist
                 **{k: v for k, v in visualization_data.items() if k not in ['charts', 'tables']}
            },
            "metrics": result_data.get("metrics", []),
            "ratios": result_data.get("ratios", []),
            "comparativePeriods": result_data.get("comparative_periods", []),
            "insights": result_data.get("insights", []),
            "citationReferences": result_data.get("citation_references", {}),
            # Add other relevant metadata if stored (or retrieve from document)
        }
        # Fetch document details to add metadata if needed
        document = await self.document_repository.get_document(analysis.document_id)
        if document:
            response_payload["document_type"] = document.document_type.value if document.document_type else "other"
            response_payload["periods"] = document.periods or []
            # Add query if stored (assuming it might be in parameters in result_data)
            response_payload["query"] = result_data.get("query", "")


        return response_payload

    async def list_document_analyses(
        self,
        document_id: str,
        analysis_type: Optional[str] = None,
        limit: int = 10,
        offset: int = 0
    ) -> List[Dict[str, Any]]:
        """
        List analyses for a document.

        Args:
            document_id: ID of the document
            analysis_type: Optional analysis type to filter by
            limit: Maximum number of analyses to return
            offset: Starting index

        Returns:
            List of analyses summaries
        """
        analyses = await self.analysis_repository.list_document_analyses(
            document_id=document_id,
            analysis_type=analysis_type,
            limit=limit,
            offset=offset
        )

        # Format the results
        formatted_analyses = []
        for analysis in analyses:
            summary = self._generate_analysis_summary(analysis.result_data or {})
            formatted_analyses.append({
                "id": f"analysis-{analysis.id}", # Add prefix
                "document_id": analysis.document_id,
                "analysis_type": analysis.analysis_type,
                "created_at": analysis.created_at.isoformat(),
                "summary": summary
            })

        return formatted_analyses

    def _generate_analysis_summary(self, result_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Generate a summary of analysis results.
        """
        viz_data = result_data.get("visualization_data", {})
        if viz_data is None:
            viz_data = {}

        summary = {
            "insights_count": len(result_data.get("insights", [])),
            "metrics_count": len(result_data.get("metrics", [])),
            "ratios_count": len(result_data.get("ratios", [])),
            "comparisons_count": len(result_data.get("comparative_periods", [])),
            "charts_count": len(viz_data.get("charts", [])),
            "tables_count": len(viz_data.get("tables", [])),
        }

        # Include a sample insight if available
        if result_data.get("insights") and len(result_data["insights"]) > 0:
            summary["sample_insight"] = result_data["insights"][0][:100] + "..." # Truncate

        return summary
</file>
```

#### services/conversation\_service\.py
*Size: 46.9 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/services/conversation_service.py">
import os
import uuid
import json
import logging
from datetime import datetime
from typing import List, Dict, Any, Optional, Tuple, Union
import asyncio

from repositories.conversation_repository import ConversationRepository
from repositories.document_repository import DocumentRepository
from repositories.analysis_repository import AnalysisRepository
from pdf_processing.claude_service import ClaudeService
from models.database_models import Message, Conversation, Document, Citation, AnalysisBlock, User

logger = logging.getLogger(__name__)

class ConversationService:
    """Service for managing conversations and messages."""
    
    def __init__(
        self, 
        conversation_repository: ConversationRepository,
        document_repository: DocumentRepository,
        analysis_repository: Optional[AnalysisRepository] = None
    ):
        """
        Initialize the conversation service.
        
        Args:
            conversation_repository: Repository for conversation operations
            document_repository: Repository for document operations
            analysis_repository: Optional repository for analysis operations
        """
        self.conversation_repository = conversation_repository
        self.document_repository = document_repository
        self.analysis_repository = analysis_repository
        
        # Initialize Claude service with API key from environment variable
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            logger.warning("ANTHROPIC_API_KEY not found in environment variables. Claude integration will not work.")
            logger.warning("Please ensure ANTHROPIC_API_KEY is set in your .env file or environment variables.")
        else:
            # Mask API key for logging (first 8 chars and last 4)
            if len(api_key) > 12:
                masked_key = f"{api_key[:8]}...{api_key[-4:]}"
            else:
                masked_key = "***masked***"
            logger.info(f"Found ANTHROPIC_API_KEY in environment variables: {masked_key}")
        
        self.claude_service = ClaudeService(api_key=api_key)
    
    async def create_conversation(
        self,
        title: str,
        user_id: str,
        document_ids: Optional[List[str]] = None
    ) -> Conversation:
        """
        Create a new conversation.
        
        Args:
            title: Title of the conversation
            user_id: ID of the user creating the conversation
            document_ids: Optional list of document IDs to associate with the conversation
            
        Returns:
            Created conversation
        """
        # Verify that all documents exist and belong to the user
        if document_ids:
            for doc_id in document_ids:
                document = await self.document_repository.get_document(doc_id)
                if not document:
                    raise ValueError(f"Document {doc_id} not found")
                if document.user_id != user_id:
                    raise ValueError(f"User {user_id} does not have access to document {doc_id}")
        
        # Create the conversation
        conversation = await self.conversation_repository.create_conversation(
            title=title,
            user_id=user_id,
            document_ids=document_ids
        )
        
        # Create a welcome message
        welcome_message = f"Welcome to your conversation about "
        if document_ids and len(document_ids) > 0:
            doc_count = len(document_ids)
            welcome_message += f"the {doc_count} document{'s' if doc_count > 1 else ''} you've uploaded. "
        else:
            welcome_message += "financial documents. Please upload a document to begin analysis. "
        
        welcome_message += "You can ask me questions about the financial information in these documents, " \
                         "and I'll provide insights and analysis."
        
        # Add the welcome message
        await self.conversation_repository.add_message(
            conversation_id=conversation.id,
            content=welcome_message,
            role="assistant"
        )
        
        return conversation
    
    async def get_conversation(self, conversation_id: str) -> Optional[Conversation]:
        """
        Get a conversation by ID.
        
        Args:
            conversation_id: ID of the conversation
            
        Returns:
            Conversation if found, None otherwise
        """
        return await self.conversation_repository.get_conversation(conversation_id)
    
    async def list_conversations(
        self,
        user_id: str,
        limit: int = 10,
        offset: int = 0
    ) -> List[Conversation]:
        """
        List conversations for a user.
        
        Args:
            user_id: ID of the user
            limit: Maximum number of conversations to return
            offset: Starting index
            
        Returns:
            List of conversations
        """
        return await self.conversation_repository.list_conversations(user_id, limit, offset)
    
    async def get_message(self, message_id: str) -> Optional[Message]:
        """
        Get a message by ID.
        
        Args:
            message_id: ID of the message
            
        Returns:
            Message if found, None otherwise
        """
        return await self.conversation_repository.get_message(message_id)
    
    async def add_message(
        self,
        conversation_id: str,
        content: str,
        role: str,
        citation_ids: Optional[List[str]] = None
    ) -> Optional[Message]:
        """
        Add a message to a conversation.
        
        Args:
            conversation_id: ID of the conversation
            content: Message content
            role: Message role (user, assistant, system)
            citation_ids: Optional list of citation IDs to associate with the message
            
        Returns:
            Created message if conversation found, None otherwise
        """
        # Verify that the conversation exists
        conversation = await self.conversation_repository.get_conversation(conversation_id)
        if not conversation:
            logger.error(f"Conversation {conversation_id} not found when adding message")
            return None
        
        # Verify that the citation IDs are valid if provided
        if citation_ids:
            for citation_id in citation_ids:
                citation = await self.document_repository.get_citation(citation_id)
                if not citation:
                    logger.warning(f"Citation {citation_id} not found when adding message")
        
        return await self.conversation_repository.add_message(
            conversation_id=conversation_id,
            content=content,
            role=role,
            citation_ids=citation_ids
        )
    
    async def get_conversation_messages(
        self,
        conversation_id: str,
        limit: int = 50,
        offset: int = 0
    ) -> List[Message]:
        """
        Get messages for a conversation.
        
        Args:
            conversation_id: ID of the conversation
            limit: Maximum number of messages to return
            offset: Starting index
            
        Returns:
            List of messages
        """
        return await self.conversation_repository.get_conversation_messages(
            conversation_id=conversation_id,
            limit=limit,
            offset=offset
        )
    
    async def get_conversation_context(
        self,
        conversation_id: str,
        limit: int = 10
    ) -> Dict[str, Any]:
        """
        Get context information for a conversation, including documents and recent messages.
        
        Args:
            conversation_id: ID of the conversation
            limit: Maximum number of messages to include in context
            
        Returns:
            Dictionary containing conversation context
        """
        # Get the conversation
        conversation = await self.conversation_repository.get_conversation(conversation_id)
        if not conversation:
            return {}
        
        # Get recent messages
        messages = await self.conversation_repository.get_conversation_messages(
            conversation_id=conversation_id,
            limit=limit
        )
        
        # Format messages for context
        formatted_messages = []
        for msg in messages:
            # Get citations for this message
            citations = await self.conversation_repository.get_message_citations(msg.id)
            
            formatted_messages.append({
                "id": msg.id,
                "role": msg.role,
                "content": msg.content,
                "created_at": msg.created_at.isoformat(),
                "citation_ids": [citation.id for citation in citations]
            })
        
        # Get associated documents
        documents = await self.conversation_repository.get_conversation_documents(conversation_id)
        
        # Format documents for context
        formatted_documents = []
        for doc in documents:
            try:
                # Check if doc is a dictionary or an ORM object
                doc_id = doc["id"] if isinstance(doc, dict) else doc.id
                
                # Get document content for citation processing
                content_obj = await self.document_repository.get_document_content(doc_id)
                content_data = None
                raw_text = None
                extracted_data = None
                
                # Extract content and raw text from the dictionary returned by repository
                if content_obj and isinstance(content_obj, dict):
                    content_data = content_obj.get("content")
                    raw_text = content_obj.get("raw_text")
                    extracted_data = content_obj.get("extracted_data")
                    
                    content_size = len(content_data) if content_data and isinstance(content_data, (str, bytes)) else 0
                    raw_text_size = len(raw_text) if raw_text else 0
                    
                    logger.info(f"Retrieved content for document {doc_id}: content size={content_size}, raw_text size={raw_text_size}")
                    
                    # If we have raw_text but it's empty, log a warning
                    if raw_text is not None and not raw_text:
                        logger.warning(f"Empty raw_text for document {doc_id}")
                    
                    # If we don't have text but have binary content, try to extract it
                    if not raw_text and content_data and isinstance(content_data, bytes):
                        try:
                            # Try to extract text directly from PDF
                            import PyPDF2
                            from io import BytesIO
                            
                            logger.info(f"Attempting direct text extraction from binary PDF for document {doc_id}")
                            pdf_reader = PyPDF2.PdfReader(BytesIO(content_data))
                            extracted_text = ""
                            
                            for page_num in range(len(pdf_reader.pages)):
                                page = pdf_reader.pages[page_num]
                                extracted_text += page.extract_text() + "\n\n"
                            
                            if extracted_text.strip():
                                raw_text = extracted_text
                                logger.info(f"Successfully extracted {len(raw_text)} chars of text directly from PDF")
                        except Exception as e:
                            logger.warning(f"Failed to extract text from PDF: {str(e)}")
                else:
                    logger.warning(f"Document content not found for {doc_id}")
                
                # Log available content types
                available_content = []
                if content_data: available_content.append("content")
                if raw_text: available_content.append("raw_text")
                if extracted_data: available_content.append("extracted_data")
                logger.info(f"Document {doc_id} available content types: {', '.join(available_content)}")
                
                # Add document to the list with its content - both raw text and PDF bytes
                doc_title = doc["filename"] if isinstance(doc, dict) else doc.filename
                doc_type = doc.get("document_type", "unknown") if isinstance(doc, dict) else getattr(doc, "document_type", "unknown")
                
                formatted_doc = {
                    "id": doc_id,
                    "title": doc_title,
                    "filename": doc_title,
                    "document_type": doc_type,
                    "mime_type": doc.get("mime_type", "application/pdf") if isinstance(doc, dict) else getattr(doc, "mime_type", "application/pdf"),
                    "upload_timestamp": doc.get("upload_timestamp", "") if isinstance(doc, dict) else getattr(doc, "upload_timestamp", ""),
                }
                
                # Add content data if available
                if content_data is not None:
                    formatted_doc["content"] = content_data
                
                # Add raw text if available
                if raw_text:
                    formatted_doc["raw_text"] = raw_text
                    
                # Add extracted data if available
                if extracted_data:
                    formatted_doc["extracted_data"] = extracted_data
                
                formatted_documents.append(formatted_doc)
                logger.info(f"Added document {doc_id} to context for conversation {conversation_id}")
            except Exception as e:
                logger.error(f"Error processing document: {str(e)}")
                logger.exception(e)
                continue
        
        # Build the context
        context = {
            "conversation_id": conversation.id,
            "title": conversation.title,
            "created_at": conversation.created_at.isoformat(),
            "updated_at": conversation.updated_at.isoformat(),
            "messages": formatted_messages,
            "documents": formatted_documents
        }
        
        return context
    
    async def process_user_message(
        self,
        conversation_id: str,
        content: str,
        citation_ids: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        Process a user message and generate a response with the AI.
        This involves adding the user message to the conversation history,
        retrieving the conversation context, generating a response,
        and adding the AI's response to the conversation history.
        
        Supports document citations through Claude's citation feature.
        
        Args:
            conversation_id: ID of the conversation
            content: The user's message content
            citation_ids: Optional list of citation IDs to include
            
        Returns:
            Dictionary with response details
        """
        # Get conversation and validate it exists
        conversation = await self.conversation_repository.get_conversation(conversation_id)
        if not conversation:
            raise ValueError(f"Conversation with ID {conversation_id} not found")
        
        # Add user message to conversation
        user_message = await self.add_message(
            conversation_id=conversation_id,
            content=content,
            role="user",
            citation_ids=citation_ids
        )
        
        if not user_message:
            raise ValueError("Failed to add user message to conversation")
        
        # Get conversation context
        context = await self.get_conversation_context(conversation_id)
        
        # Extract document texts for system prompt
        document_texts = []
        if context.get("documents"):
            # Process each document
            for doc_info in context["documents"]:
                try:
                    # Get document content for citation processing
                    content_obj = await self.document_repository.get_document_content(doc_info["id"])
                    content_data = None
                    raw_text = None
                    extracted_data = None
                    
                    # Extract content and raw text from the dictionary returned by repository
                    if content_obj and isinstance(content_obj, dict):
                        content_data = content_obj.get("content")
                        raw_text = content_obj.get("raw_text")
                        extracted_data = content_obj.get("extracted_data")
                        
                        # Create proper document dictionary instead of just raw text
                        doc_dict = {
                            "id": doc_info["id"],
                            "title": doc_info.get("filename", "Document"),
                            "type": "document"
                        }
                        
                        # Add the raw text if available
                        if raw_text:
                            doc_dict["raw_text"] = raw_text
                            
                            # Add document to list as properly structured dictionary
                            document_texts.append(doc_dict)
                            logger.info(f"Added document {doc_info['id']} dictionary to context (raw_text length: {len(raw_text)})")
                        else:
                            # Try to extract text from PDF if we have binary content
                            if content_data and isinstance(content_data, bytes):
                                try:
                                    import PyPDF2
                                    from io import BytesIO
                                    logger.info(f"Trying to extract text directly from PDF for document {doc_info['id']}")
                                    
                                    pdf_reader = PyPDF2.PdfReader(BytesIO(content_data))
                                    extracted_text = ""
                                    
                                    for page_num in range(len(pdf_reader.pages)):
                                        page = pdf_reader.pages[page_num]
                                        page_text = page.extract_text()
                                        if page_text:
                                            extracted_text += page_text + "\n\n"
                                    
                                    if extracted_text.strip():
                                        doc_dict["raw_text"] = extracted_text
                                        document_texts.append(doc_dict)
                                        logger.info(f"Added document {doc_info['id']} with extracted text to context (length: {len(extracted_text)})")
                                    else:
                                        logger.warning(f"Could not extract text from PDF for document {doc_info['id']}")
                                except Exception as pdf_error:
                                    logger.warning(f"Error extracting text from PDF for document {doc_info['id']}: {str(pdf_error)}")
                            else:
                                logger.warning(f"No raw_text or PDF content available for document {doc_info['id']}")
                except Exception as e:
                    logger.error(f"Error processing document content for LLM: {str(e)}")
                    logger.exception(e)
                    continue
        
        # Get conversation messages
        messages = await self.conversation_repository.get_conversation_messages(
            conversation_id=conversation_id,
            limit=10  # Get last 10 messages for context
        )
        
        # Convert messages to the format expected by Claude API
        message_history = []
        for msg in messages:
            if msg.id != user_message.id:  # Skip the message we just added
                message_history.append({
                    "role": msg.role,
                    "content": msg.content
                })
        
        # Decide which processing approach to use
        approach = await self._decide_processing_approach(
            conversation_id=conversation_id,
            message_content=content,
            document_texts=document_texts,
            conversation_history=message_history
        )
        
        # Process using the selected approach
        if approach == "simple_qa":
            # Use LangGraph for simple document QA
            if hasattr(self.claude_service, "langgraph_service") and self.claude_service.langgraph_service:
                try:
                    logger.info(f"Using LangGraph for simple QA in conversation {conversation_id}")
                    response = await self._process_with_langgraph(
                        conversation_id=conversation_id,
                        content=content,
                        document_texts=document_texts,
                        messages=message_history
                    )
                    return response
                except Exception as e:
                    logger.error(f"Error using LangGraph for simple QA: {str(e)}")
                    logger.info("Falling back to direct Claude API")
                    # Fall through to direct API approach
            
            # Use direct Claude API if LangGraph is not available or failed
            system_prompt = self._build_system_prompt(document_texts, [])
            
            # Generate response
            response_content = await self.claude_service.generate_response(
                system_prompt=system_prompt,
                messages=message_history + [{"role": "user", "content": content}]
            )
            
            # Add assistant message to conversation
            assistant_message = await self.add_message(
                conversation_id=conversation_id,
                content=response_content,
                role="assistant"
            )
            
            if not assistant_message:
                raise ValueError("Failed to add assistant message to conversation")
            
            return {
                "success": True,
                "message": assistant_message
            }
            
        elif approach == "citations":
            # Use citation-aware processing with LangGraph
            logger.info(f"Using citation-based approach for conversation {conversation_id}")
            return await self._process_with_langgraph(
                conversation_id=conversation_id,
                content=content,
                document_texts=document_texts,
                messages=message_history
            )
        
        elif approach == "full_graph":
            # Implement full conversation graph approach here (future)
            logger.info(f"Full graph approach not yet implemented, falling back to citation approach for conversation {conversation_id}")
            return await self._process_with_langgraph(
                conversation_id=conversation_id,
                content=content,
                document_texts=document_texts,
                messages=message_history
            )
        
        else:
            # Unknown approach, fall back to simple QA
            logger.warning(f"Unknown processing approach '{approach}', falling back to simple QA for conversation {conversation_id}")
            system_prompt = self._build_system_prompt(document_texts, [])
            
            # Generate response
            response_content = await self.claude_service.generate_response(
                system_prompt=system_prompt,
                messages=message_history + [{"role": "user", "content": content}]
            )
            
            # Add assistant message to conversation
            assistant_message = await self.add_message(
                conversation_id=conversation_id,
                content=response_content,
                role="assistant"
            )
            
            if not assistant_message:
                raise ValueError("Failed to add assistant message to conversation")
            
            return {
                "success": True,
                "message": assistant_message
            }
    
    def _build_system_prompt(self, document_texts: List[Dict[str, Any]], citations: List[Dict[str, Any]]) -> str:
        """
        Build a system prompt for Claude based on the conversation context.
        
        Args:
            document_texts: List of document texts
            citations: List of citations
            
        Returns:
            System prompt string
        """
        prompt = """You are a financial document analysis assistant specialized in analyzing financial statements and reports.
Your role is to help users understand financial documents, extract insights, and provide financial analysis.

Here are some important guidelines:
1. Always provide accurate financial analysis and calculations.
2. Cite sources when referencing specific data from documents.
3. Use clear, professional language suitable for financial discussions.
4. When unsure, acknowledge limitations and avoid making up information.
5. When generating visualizations, follow the provided format exactly.
6. When analyzing financial documents, focus on key metrics, trends, and insights.
7. Provide context and explanations for financial terms and concepts.

"""
        
        # Add document context if available
        if document_texts and len(document_texts) > 0:
            prompt += "\nHere are the financial documents available for reference:\n\n"
            for i, doc in enumerate(document_texts):
                # Handle string or dictionary format
                if isinstance(doc, str):
                    # If document_texts contains raw strings instead of dictionaries
                    doc_id = f'doc_{i}'
                    doc_title = f'Document {i+1}'
                    doc_type = 'text/plain'
                    doc_text = doc  # The string itself is the text
                elif isinstance(doc, dict):
                    # If document_texts contains dictionaries (preferred format)
                    doc_id = doc.get('id', f'doc_{i}')
                    doc_title = doc.get('title', doc.get('filename', 'Untitled Document'))
                    doc_type = doc.get('content_type', doc.get('document_type', 'unknown'))
                    
                    # Get text from various possible fields
                    doc_text = ""
                    if 'raw_text' in doc:
                        doc_text = doc['raw_text']
                    elif 'text' in doc:
                        doc_text = doc['text']
                    elif 'content' in doc and isinstance(doc['content'], str):
                        doc_text = doc['content']
                else:
                    # Skip invalid document formats
                    logger.warning(f"Skipping invalid document format in system prompt: {type(doc)}")
                    continue
                
                # Add document metadata
                prompt += f"DOCUMENT {i+1} (ID: {doc_id}):\nTitle: {doc_title}\nType: {doc_type}\n"
                
                # Add a snippet of the document text if available
                if doc_text:
                    # Limit to 1000 characters to avoid making the prompt too large
                    text_preview = doc_text[:1000] + "..." if len(doc_text) > 1000 else doc_text
                    prompt += f"\nContent preview:\n{text_preview}\n"
                else:
                    prompt += "\nNo text content available for this document.\n"
                
                prompt += "\n"
        
        # Add citation context if available
        if citations and len(citations) > 0:
            prompt += "\nThe user has referenced the following citations:\n\n"
            for i, citation in enumerate(citations):
                cit_id = citation.get('id', f'citation_{i}')
                doc_id = citation.get('document_id', 'unknown')
                content = citation.get('content', 'No content available')
                metadata = citation.get('metadata', {})
                
                prompt += f"CITATION {i+1} (ID: {cit_id}):\n"
                prompt += f"From document: {doc_id}\n"
                prompt += f"Content: {content}\n"
                if metadata:
                    prompt += f"Metadata: {metadata}\n"
                prompt += "\n"
        
        # Add visualization instructions
        prompt += """
When you need to create a financial visualization, use the following JSON format and enclose it within triple backticks:
```json
{
  "visualization_type": "chart_type",  // One of: bar, line, pie, area, scatter
  "title": "Chart Title",
  "data": [
    { "name": "Category1", "value": 100 },
    { "name": "Category2", "value": 200 }
  ],
  "x_axis": "X Axis Label",  // For bar, line, area, scatter charts
  "y_axis": "Y Axis Label",  // For bar, line, area, scatter charts
  "insight": "Brief explanation of what this visualization shows"
}
```

When analyzing financial documents, focus on:
1. Key financial metrics (revenue, profit, assets, liabilities, etc.)
2. Year-over-year or quarter-over-quarter trends
3. Financial ratios (profitability, liquidity, solvency, efficiency)
4. Anomalies or significant changes
5. Industry context and benchmarking when possible
"""
        
        return prompt
    
    def _parse_claude_response(self, response: str) -> Tuple[str, List[Dict[str, Any]]]:
        """
        Parse Claude's response to extract visualizations and clean the text.
        
        Args:
            response: Response string from Claude
            
        Returns:
            Tuple of (cleaned response text, list of visualization objects)
        """
        import re
        
        # Find all JSON blocks enclosed in triple backticks
        json_pattern = r"```json\s*([\s\S]*?)\s*```"
        json_blocks = re.findall(json_pattern, response)
        
        visualizations = []
        for json_block in json_blocks:
            try:
                visualization = json.loads(json_block)
                visualizations.append(visualization)
            except json.JSONDecodeError:
                logger.warning(f"Failed to parse JSON block: {json_block}")
        
        # Remove the JSON blocks from the response
        cleaned_response = re.sub(json_pattern, "[Visualization]", response)
        
        return cleaned_response, visualizations
    
    async def _process_visualizations(
        self,
        message_id: str,
        visualizations: List[Dict[str, Any]]
    ):
        """
        Process and store visualizations as analysis blocks.
        
        Args:
            message_id: ID of the message to associate with the visualizations
            visualizations: List of visualization data
        """
        for i, viz in enumerate(visualizations):
            title = viz.get("title", f"Visualization {i+1}")
            block_type = viz.get("visualization_type", "chart")
            
            if not block_type in ["bar", "line", "pie", "area", "scatter"]:
                block_type = "chart"  # Default to chart if unrecognized
            
            await self.conversation_repository.add_analysis_block(
                message_id=message_id,
                block_type=block_type,
                title=title,
                content=viz
            )
    
    async def add_document_to_conversation(
        self,
        conversation_id: str,
        document_id: str
    ) -> bool:
        """
        Add a document to a conversation.
        
        Args:
            conversation_id: ID of the conversation
            document_id: ID of the document to add
            
        Returns:
            True if successful, False otherwise
        """
        logger.info(f"Starting document addition process - conversation={conversation_id}, document={document_id}")
        
        # Verify that the conversation and document exist
        conversation = await self.conversation_repository.get_conversation(conversation_id)
        if not conversation:
            logger.error(f"Conversation {conversation_id} not found when adding document {document_id}")
            return False
        
        document = await self.document_repository.get_document(document_id)
        if not document:
            logger.error(f"Document {document_id} not found when adding to conversation {conversation_id}")
            return False
            
        # Log document details for debugging
        doc_status = getattr(document, "processing_status", "unknown")
        doc_type = getattr(document, "document_type", "unknown")
        doc_filename = getattr(document, "filename", "unknown")
        logger.info(f"Document details: ID={document_id}, Filename={doc_filename}, Type={doc_type}, Status={doc_status}")
        
        # Add document to conversation
        success = await self.conversation_repository.add_document_to_conversation(
            conversation_id=conversation_id,
            document_id=document_id
        )
        
        if success:
            # Add a system message about the added document
            await self.conversation_repository.add_message(
                conversation_id=conversation_id,
                content=f"Document '{document.filename}' has been added to the conversation.",
                role="system"
            )
        
        return success
    
    async def remove_document_from_conversation(
        self,
        conversation_id: str,
        document_id: str
    ) -> bool:
        """
        Remove a document from a conversation.
        
        Args:
            conversation_id: ID of the conversation
            document_id: ID of the document to remove
            
        Returns:
            True if successful, False otherwise
        """
        # Verify that the conversation exists
        conversation = await self.conversation_repository.get_conversation(conversation_id)
        if not conversation:
            return False
        
        # Remove document from conversation
        success = await self.conversation_repository.remove_document_from_conversation(
            conversation_id=conversation_id,
            document_id=document_id
        )
        
        if success:
            # Get the document to access its filename
            document = await self.document_repository.get_document(document_id)
            filename = document.filename if document else "Unknown document"
            
            # Add a system message about the removed document
            await self.conversation_repository.add_message(
                conversation_id=conversation_id,
                content=f"Document '{filename}' has been removed from the conversation.",
                role="system"
            )
        
        return success
    
    async def _decide_processing_approach(
        self,
        conversation_id: str,
        message_content: str,
        document_texts: List[Dict[str, Any]],
        conversation_history: List[Dict[str, Any]]
    ) -> str:
        """
        Decide which processing approach to use based on the message and context.
        Starts with simple QA for basic questions, but can transition to more 
        complex processing for analytical questions.
        
        Args:
            conversation_id: ID of the conversation
            message_content: User's message
            document_texts: List of document texts
            conversation_history: Previous conversation history
            
        Returns:
            The most appropriate processing approach: "simple_qa", "citations", "full_graph"
        """
        # If no documents, use simple response
        if not document_texts or len(document_texts) == 0:
            logger.info(f"No documents available for conversation {conversation_id}, using simple_qa approach")
            return "simple_qa"
        
        # If message explicitly mentions citations or refers to specific parts of a document
        if any(term in message_content.lower() for term in ["cite", "citation", "reference", "page", "section", "paragraph"]):
            logger.info(f"User message for conversation {conversation_id} mentions citations, using citations approach")
            return "citations"
        
        # If message requires financial analysis
        if any(term in message_content.lower() for term in ["analyze", "analysis", "calculate", "ratio", "trend", "chart", "compare"]):
            logger.info(f"User message for conversation {conversation_id} requests financial analysis, using full_graph approach")
            return "full_graph"
        
        # Default to simple QA for basic questions
        logger.info(f"Using default simple_qa approach for conversation {conversation_id}")
        return "simple_qa"
    
    async def _process_with_langgraph(
        self,
        conversation_id: str,
        content: str,
        document_texts: List[Dict[str, Any]],
        messages: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Process a user message using LangGraph for simple document QA.
        Handles citation data from Claude API responses to provide source references.
        
        Args:
            conversation_id: ID of the conversation
            content: The user's message content
            document_texts: List of document texts
            messages: Conversation history messages
            
        Returns:
            Dictionary with response details
        """
        try:
            # Validate document_texts to ensure it's a list of dictionaries
            if not isinstance(document_texts, list):
                logger.warning(f"document_texts is not a list: {type(document_texts)}")
                if isinstance(document_texts, str):
                    logger.warning("Converting string document_text to a list with one document")
                    # Convert to a proper document format
                    document_texts = [{
                        "id": "doc_1",
                        "title": "Document",
                        "raw_text": document_texts,
                        "content_type": "text/plain"
                    }]
                elif isinstance(document_texts, dict):
                    logger.warning("Converting dictionary document_text to a list with one document")
                    document_texts = [document_texts]
                else:
                    logger.error(f"Invalid document_texts format: {type(document_texts)}")
                    document_texts = []
            
            # Validate each document in the list
            valid_documents = []
            for i, doc in enumerate(document_texts):
                if not isinstance(doc, dict):
                    logger.warning(f"Document at index {i} is not a dictionary: {type(doc)}")
                    if isinstance(doc, str):
                        # Convert string to document dictionary
                        valid_documents.append({
                            "id": f"doc_{i+1}",
                            "title": f"Document {i+1}",
                            "raw_text": doc,
                            "content_type": "text/plain"
                        })
                        logger.info(f"Converted string to document dictionary at index {i}")
                    else:
                        logger.warning(f"Skipping invalid document at index {i}")
                        continue
                else:
                    valid_documents.append(doc)
            
            document_texts = valid_documents
            
            # Log document information before sending
            logger.info(f"Processing {len(document_texts)} documents with LangGraph")
            for i, doc in enumerate(document_texts):
                doc_id = doc.get('id', f'doc_{i+1}')
                has_content = 'raw_text' in doc and bool(doc.get('raw_text'))
                content_length = len(doc.get('raw_text', '')) if has_content else 0
                logger.info(f"Document {i+1}: ID={doc_id}, has_content={has_content}, length={content_length}")
                
                # Add a preview of content for debugging
                if has_content and content_length > 0:
                    content_preview = doc.get('raw_text', '')[:100] + "..." if content_length > 100 else doc.get('raw_text', '')
                    logger.info(f"Document {i+1} content preview: {content_preview}")
            
            # Generate response with LangGraph
            logger.info("Using LangGraph for basic response generation with documents")
            response_data = await self.claude_service.generate_response_with_langgraph(
                question=content,
                document_texts=document_texts,
                conversation_history=messages
            )
            
            # Extract content and citations from response
            response_content = response_data.get("content", "I'm sorry, I couldn't generate a response.")
            response_citations = response_data.get("citations", [])
            
            # Check if the response is an error message from Claude
            if "error" in response_content.lower() and ("api key" in response_content.lower() or "authentication" in response_content.lower()):
                logger.error(f"Claude API authentication error: {response_content}")
                
                # Add assistance message about the error
                assistant_message = await self.add_message(
                    conversation_id=conversation_id,
                    content=f"I apologize, but there was an error processing your request: {response_content}",
                    role="assistant"
                )
                
                return {
                    "success": False,
                    "error": "Authentication error with Claude API",
                    "message": assistant_message
                }
            
            # Create citation objects to store in database
            citation_links = []
            citation_objects = []
            
            if response_citations:
                logger.info(f"Processing {len(response_citations)} citations from LangGraph response")
                
                # Map of document indexes to document IDs
                document_map = {}
                for i, doc in enumerate(document_texts):
                    if "id" in doc:
                        document_map[i] = doc["id"]
                
                # Process each citation
                for citation in response_citations:
                    try:
                        # Create a citation object for database storage
                        citation_id = str(uuid.uuid4())
                        citation_type = citation.get("type", "unknown")
                        
                        # Get document ID from document_index if available
                        document_id = None
                        document_index = citation.get("document_index")
                        if document_index is not None and document_index in document_map:
                            document_id = document_map[document_index]
                        
                        # Create the base citation object
                        citation_obj = {
                            "id": citation_id,
                            "text": citation.get("cited_text", ""),
                            "document_id": document_id,
                            "document_title": citation.get("document_title", "")
                        }
                        
                        # Add type-specific location information
                        if citation_type == "char_location":
                            citation_obj["location_type"] = "text"
                            citation_obj["start_char"] = citation.get("start_char_index")
                            citation_obj["end_char"] = citation.get("end_char_index")
                        elif citation_type == "page_location":
                            citation_obj["location_type"] = "page"
                            citation_obj["start_page"] = citation.get("start_page_number")
                            citation_obj["end_page"] = citation.get("end_page_number")
                        elif citation_type == "content_block_location":
                            citation_obj["location_type"] = "block"
                            citation_obj["start_block"] = citation.get("start_block_index")
                            citation_obj["end_block"] = citation.get("end_block_index")
                        
                        # Store citation and track ID for message linking
                        citation_objects.append(citation_obj)
                        citation_links.append(citation_id)
                        
                        logger.debug(f"Processed citation: {citation_id} from {citation_type}")
                    except Exception as e:
                        logger.error(f"Error processing citation: {str(e)}")
            
            # Save citations to repository if possible
            citation_ids = []
            if citation_objects and hasattr(self, 'citation_repository') and self.citation_repository:
                try:
                    for citation_obj in citation_objects:
                        citation_id = await self.citation_repository.add_citation(citation_obj)
                        if citation_id:
                            citation_ids.append(citation_id)
                except Exception as e:
                    logger.error(f"Error saving citations to repository: {str(e)}")
            
            # Add assistant message with citation links
            assistant_message = await self.add_message(
                conversation_id=conversation_id,
                content=response_content,
                role="assistant",
                citation_ids=citation_ids if citation_ids else citation_links
            )
            
            if not assistant_message:
                logger.error("Failed to add assistant message")
                return {
                    "success": False,
                    "error": "Failed to save assistant message"
                }
            
            return {
                "success": True,
                "message": assistant_message
            }
            
        except Exception as e:
            logger.error(f"Error in _process_with_langgraph: {str(e)}", exc_info=True)
            
            # Add fallback message on error
            try:
                error_message = await self.add_message(
                    conversation_id=conversation_id,
                    content="I apologize, but I encountered an error processing your request. Please try again or rephrase your question.",
                    role="assistant"
                )
                
                return {
                    "success": False,
                    "error": str(e),
                    "message": error_message
                }
            except Exception as add_error:
                logger.error(f"Failed to add error message: {str(add_error)}")
                return {
                    "success": False,
                    "error": f"Multiple errors: {str(e)} and {str(add_error)}"
                }
</file>
```

#### test\_api\.sh
*Size: 3.8 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/test_api.sh">
#!/bin/bash
# Test script for FDAS API endpoints

# ANSI colors for better output
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# URL for the API - change this if your server is running on a different port
API_URL=${API_URL:-"http://127.0.0.1:8000"}

# Temp file for IDs
TMP_FILE=".tmp_ids.txt"
touch $TMP_FILE

echo -e "${BLUE}===================================${NC}"
echo -e "${BLUE}   FDAS API Testing Script        ${NC}"
echo -e "${BLUE}===================================${NC}"
echo -e "${YELLOW}API URL: ${API_URL}${NC}\n"

# Function to print the section header
print_section() {
    echo -e "\n${BLUE}=== $1 ===${NC}"
}

# Function to test an API endpoint and capture the response
test_endpoint() {
    local method=$1
    local endpoint=$2
    local data=$3
    local expectation=$4
    local variable_name=$5

    echo -e "${YELLOW}Testing ${method} ${endpoint}${NC}"
    echo -e "${BLUE}Full URL: ${API_URL}${endpoint}${NC}"
    
    # Execute the appropriate curl command based on method with verbose output
    if [ "$method" = "GET" ]; then
        response=$(curl -s -X GET "${API_URL}${endpoint}")
    elif [ "$method" = "POST" ]; then
        echo -e "${BLUE}Request data: ${data}${NC}"
        response=$(curl -s -X POST "${API_URL}${endpoint}" -H "Content-Type: application/json" -d "${data}")
    elif [ "$method" = "DELETE" ]; then
        response=$(curl -s -X DELETE "${API_URL}${endpoint}")
    else
        echo -e "${RED}Unknown method: ${method}${NC}"
        return 1
    fi
    
    # Print actual request and response
    echo -e "${BLUE}Response: ${NC}"
    echo "$response"
    
    # Check if the response contains what we expect
    if [[ $response == *"$expectation"* ]]; then
        echo -e "${GREEN}SUCCESS: Response contains expected value${NC}"
    else
        echo -e "${RED}FAILURE: Response does not contain expected value${NC}"
    fi
    
    # If a variable name is provided, extract the ID from the response and save it
    if [ -n "$variable_name" ]; then
        id=$(echo $response | grep -o -E '"id":"[^"]+"' | head -1 | cut -d '"' -f 4)
        if [ -n "$id" ]; then
            echo "$variable_name=$id" >> $TMP_FILE
            echo -e "${GREEN}Saved $variable_name=$id${NC}"
        else
            echo -e "${RED}Could not extract ID from response${NC}"
        fi
    fi
    
    echo ""
}

# Load IDs from temporary file
load_vars() {
    if [ -f $TMP_FILE ]; then
        source $TMP_FILE
    fi
}

# Clean up on exit
cleanup() {
    if [ -f $TMP_FILE ]; then
        rm $TMP_FILE
    fi
}
trap cleanup EXIT

# 1. Create Conversation
print_section "Create Conversation"
test_endpoint "POST" "/api/conversation" \
  '{"title":"Test Conversation","user_id":"default-user"}' \
  "session_id" "conversation_id"

# Load variables from temp file
load_vars

# 2. Send Message
print_section "Send Message"
test_endpoint "POST" "/api/conversation/${conversation_id}/message" \
  '{"session_id":"'$conversation_id'","content":"What are some key financial metrics to look for in a balance sheet?","referenced_documents":[],"referenced_analyses":[],"citation_links":[]}' \
  "content" "message_id"

# Load variables from temp file
load_vars

# 3. Get Conversation History
print_section "Get Conversation History"
test_endpoint "GET" "/api/conversation/${conversation_id}/history?limit=10" \
  '' \
  "role"

# 4. List Conversations
print_section "List Conversations"
test_endpoint "GET" "/api/conversation?limit=10&offset=0" \
  '' \
  "title"

# 5. Delete Conversation
print_section "Delete Conversation"
if [ -n "$conversation_id" ]; then
    test_endpoint "DELETE" "/api/conversation/${conversation_id}" \
      '' \
      ""
else
    echo -e "${RED}Cannot delete conversation - ID not found${NC}"
fi

echo -e "\n${GREEN}===== API Testing Complete =====${NC}"
</file>
```

#### test\_citations\_with\_pdf\.py
*Size: 7.0 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/test_citations_with_pdf.py">
#!/usr/bin/env python
import os
import asyncio
import logging
import json
from dotenv import load_dotenv
import argparse
from pdf_processing.langgraph_service import LangGraphService
from pdf_processing.claude_service import ClaudeService
from colorama import init, Fore, Style

# Initialize colorama for colored terminal output
init()

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Get the parent directory path
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
# Load environment variables from the parent directory
dotenv_path = os.path.join(parent_dir, '.env')
logger.info(f"Loading .env file from: {dotenv_path}")
load_dotenv(dotenv_path)

# Verify API key is loaded
api_key = os.getenv("ANTHROPIC_API_KEY")
if api_key:
    # Mask the API key for logging purposes
    masked_key = api_key[:4] + '*' * (len(api_key) - 8) + api_key[-4:] if len(api_key) > 8 else "****"
    logger.info(f"ANTHROPIC_API_KEY loaded: {masked_key}")
else:
    logger.warning("ANTHROPIC_API_KEY not found in environment variables!")

def format_citation_display(citation, doc_title):
    """Format a citation for display"""
    c_type = citation.get("type", "unknown")
    
    if c_type == "char_location":
        return (
            f"{Fore.GREEN}[CITATION from '{doc_title}']{Style.RESET_ALL}\n"
            f"Text: \"{Fore.YELLOW}{citation.get('cited_text', '')}{Style.RESET_ALL}\"\n"
            f"Location: Characters {citation.get('start_char_index', 0)}-{citation.get('end_char_index', 0)}\n"
        )
    elif c_type == "page_location":
        return (
            f"{Fore.GREEN}[CITATION from '{doc_title}']{Style.RESET_ALL}\n"
            f"Text: \"{Fore.YELLOW}{citation.get('cited_text', '')}{Style.RESET_ALL}\"\n"
            f"Location: Pages {citation.get('start_page_number', 1)}-{citation.get('end_page_number', 1)}\n"
        )
    elif c_type == "content_block_location":
        return (
            f"{Fore.GREEN}[CITATION from '{doc_title}']{Style.RESET_ALL}\n"
            f"Text: \"{Fore.YELLOW}{citation.get('cited_text', '')}{Style.RESET_ALL}\"\n"
            f"Location: Blocks {citation.get('start_block_index', 0)}-{citation.get('end_block_index', 0)}\n"
        )
    else:
        return (
            f"{Fore.RED}[UNKNOWN CITATION TYPE: {c_type}]{Style.RESET_ALL}\n"
            f"Text: \"{citation.get('cited_text', '')}\"\n"
        )

async def test_citations_with_pdf(pdf_path, question):
    """Test citation functionality with a PDF document."""
    try:
        # Initialize Claude and LangGraph services
        logger.info("Initializing services...")
        claude_service = ClaudeService(api_key=api_key)
        langgraph_service = claude_service.langgraph_service
        
        if not langgraph_service:
            logger.error("Failed to initialize LangGraph service")
            return
        
        # Prepare the document
        logger.info(f"Reading PDF from {pdf_path}")
        with open(pdf_path, 'rb') as pdf_file:
            pdf_content = pdf_file.read()
        
        # Create document object
        document = {
            "id": "test_document",
            "title": os.path.basename(pdf_path),
            "mime_type": "application/pdf",
            "content": pdf_content
        }
        
        # Run the test
        logger.info(f"Querying document with question: {question}")
        print(f"\n{Fore.CYAN}QUESTION:{Style.RESET_ALL} {question}\n")
        
        # Add time tracking
        import time
        start_time = time.time()
        
        # Call the service with citation support
        response = await langgraph_service.simple_document_qa(
            question=question,
            documents=[document],
            conversation_history=[]  # Empty conversation history for this test
        )
        
        # Calculate time taken
        elapsed_time = time.time() - start_time
        
        # Check response format
        if not isinstance(response, dict):
            logger.error(f"Unexpected response type: {type(response)}")
            print(f"\n{Fore.RED}ERROR:{Style.RESET_ALL} Response was not in the expected format.\n")
            return
        
        # Extract content and citations
        content = response.get("content", "")
        citations = response.get("citations", [])
        
        # Display results
        print(f"\n{Fore.CYAN}RESPONSE:{Style.RESET_ALL} (generated in {elapsed_time:.2f} seconds)\n")
        print(f"{Fore.YELLOW}{content if content else 'No content in response'}{Style.RESET_ALL}")
        
        # Debug response details
        print(f"\n{Fore.CYAN}DEBUG INFO:{Style.RESET_ALL}")
        print(f"Response keys: {list(response.keys()) if isinstance(response, dict) else 'Not a dictionary'}")
        if isinstance(response, dict):
            for key, value in response.items():
                if key == 'citations':
                    print(f"Citations: {len(value)}")
                else:
                    value_str = str(value)[:100] + "..." if value and len(str(value)) > 100 else str(value)
                    print(f"{key}: {value_str}")
        
        print(f"\n{Fore.CYAN}CITATION COUNT:{Style.RESET_ALL} {len(citations)}\n")
        
        if citations:
            print(f"{Fore.CYAN}CITATIONS:{Style.RESET_ALL}\n")
            for i, citation in enumerate(citations):
                print(f"{Fore.BLUE}Citation #{i+1}:{Style.RESET_ALL}")
                print(format_citation_display(citation, document["title"]))
        else:
            print(f"{Fore.YELLOW}No citations were provided in the response.{Style.RESET_ALL}\n")
            
        # Technical details
        print(f"\n{Fore.CYAN}TECHNICAL DETAILS:{Style.RESET_ALL}\n")
        print(f"Response structure: {list(response.keys())}")
        print(f"Citation structure: {json.dumps(citations[0] if citations else {}, indent=2)}")
        
        return response
    
    except Exception as e:
        logger.error(f"Error during citation test: {str(e)}")
        print(f"\n{Fore.RED}ERROR:{Style.RESET_ALL} {str(e)}\n")
        return None

def main():
    parser = argparse.ArgumentParser(description="Test Claude citations with a PDF document")
    parser.add_argument("--pdf", type=str, help="Path to the PDF file")
    parser.add_argument("--question", type=str, default="What are the key financial metrics mentioned in this document?", 
                        help="Question to ask about the document")
    args = parser.parse_args()
    
    # Use default PDF path if not specified
    pdf_path = args.pdf
    if not pdf_path:
        pdf_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 
            "ExampleDocs", 
            "Mueller Industries Earnings Release.pdf"
        )
    
    if not os.path.exists(pdf_path):
        logger.error(f"PDF file not found at {pdf_path}")
        return
    
    # Run the test
    asyncio.run(test_citations_with_pdf(pdf_path, args.question))

if __name__ == "__main__":
    main() 
</file>
```

#### test\_claude\_api\.py
*Size: 2.5 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/test_claude_api.py">
#!/usr/bin/env python
"""
A simple script to test the Claude API directly and verify the API key.
"""

import os
import asyncio
import logging
from dotenv import load_dotenv
from anthropic import AsyncAnthropic
import sys

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

async def test_claude_api():
    # Load environment variables from .env file
    env_file = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.env')
    load_dotenv(env_file)
    
    # Get API key from environment variables
    api_key = os.environ.get("ANTHROPIC_API_KEY")
    
    if not api_key:
        logger.error("ANTHROPIC_API_KEY not found in environment variables")
        logger.error(f"Checked .env file at: {env_file}")
        logger.error("Please ensure ANTHROPIC_API_KEY is set in your .env file")
        return False
    
    # Mask API key for logging (first 8 chars and last 4)
    if len(api_key) > 12:
        masked_key = f"{api_key[:8]}...{api_key[-4:]}"
    else:
        masked_key = "***masked***"
    
    logger.info(f"Found ANTHROPIC_API_KEY: {masked_key}")
    
    # Initialize Claude client
    try:
        client = AsyncAnthropic(
            api_key=api_key,
            default_headers={
                "anthropic-beta": "pdfs-2024-09-25"  # Enable PDF support beta
            }
        )
        logger.info("Successfully initialized Claude client")
    except Exception as e:
        logger.error(f"Failed to initialize Claude client: {str(e)}")
        return False
    
    # Test a simple API call
    try:
        logger.info("Testing Claude API with a simple request...")
        response = await client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=300,
            system="You are a helpful assistant that provides concise answers.",
            messages=[{"role": "user", "content": "Hello, how are you today?"}]
        )
        
        logger.info(f"Successfully received response from Claude API!")
        logger.info(f"Response: {response.content[0].text}")
        return True
    except Exception as e:
        logger.error(f"Error calling Claude API: {str(e)}")
        return False

if __name__ == "__main__":
    success = asyncio.run(test_claude_api())
    if success:
        logger.info("Claude API test completed successfully! âœ…")
        sys.exit(0)
    else:
        logger.error("Claude API test failed. Please check the logs above for details. âŒ")
        sys.exit(1) 
</file>
```

#### test\_document\_api\.py
*Size: 1.3 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/test_document_api.py">
#!/usr/bin/env python3
"""
Simple test script to verify the document API endpoints.
"""

import asyncio
import logging
from models.document import DocumentUploadResponse, ProcessedDocument, DocumentMetadata
from repositories.document_repository import DocumentRepository
from utils.database import SessionLocal
from models.database_models import User, Document, ProcessingStatusEnum

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_document_repository():
    """Test the document repository."""
    async with SessionLocal() as session:
        # Create a document repository
        document_repository = DocumentRepository(session)
        
        # List documents
        user_id = "default-user"
        documents = await document_repository.list_documents(user_id)
        logger.info(f"Found {len(documents)} documents for user {user_id}")
        
        # Print document details
        for doc in documents:
            logger.info(f"Document ID: {doc.id}")
            logger.info(f"Filename: {doc.filename}")
            logger.info(f"Status: {doc.processing_status}")
            logger.info(f"Type: {doc.document_type}")
            logger.info("---")

def main():
    """Run the test."""
    asyncio.run(test_document_repository())

if __name__ == "__main__":
    main() 
</file>
```

#### test\_document\_api\_only\.sh
*Size: 2.7 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/test_document_api_only.sh">
#!/bin/bash
# Test script for FDAS Document API endpoints only

BASE_URL="http://localhost:8000"
CURRENT_USER="default-user"

# Colors for output
GREEN='\033[0;32m'
RED='\033[0;31m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

echo -e "${BLUE}Starting FDAS Document API tests...${NC}"

# Test health endpoint
echo -e "\n${BLUE}Testing health endpoint...${NC}"
curl -s "${BASE_URL}/health" | jq .

# Test root endpoint
echo -e "\n${BLUE}Testing root endpoint...${NC}"
curl -s "${BASE_URL}/" | jq .

# Create test_data directory if it doesn't exist
mkdir -p ./test_data

# Create a simple PDF file for testing if it doesn't exist
if [ ! -f "./test_data/sample_financial_report.pdf" ]; then
    echo -e "\n${BLUE}Creating test PDF file...${NC}"
    echo "%PDF-1.5
%Test PDF file for API testing
1 0 obj
<< /Type /Catalog /Pages 2 0 R >>
endobj
2 0 obj
<< /Type /Pages /Kids [3 0 R] /Count 1 >>
endobj
3 0 obj
<< /Type /Page /Parent 2 0 R /MediaBox [0 0 612 792] /Contents 4 0 R >>
endobj
4 0 obj
<< /Length 45 >>
stream
BT /F1 12 Tf 100 700 Td (Test Financial Report) Tj ET
endstream
endobj
trailer
<< /Root 1 0 R /Size 5 >>
%%EOF" > ./test_data/sample_financial_report.pdf
    echo -e "${GREEN}Created test PDF file${NC}"
fi

# Upload a test document
echo -e "\n${BLUE}Uploading a test document...${NC}"
DOC_RESPONSE=$(curl -s -X POST "${BASE_URL}/api/documents/upload" \
    -F "file=@./test_data/sample_financial_report.pdf" \
    -F "user_id=${CURRENT_USER}")
echo $DOC_RESPONSE | jq .
DOCUMENT_ID=$(echo $DOC_RESPONSE | jq -r '.document_id')

if [ -z "$DOCUMENT_ID" ] || [ "$DOCUMENT_ID" == "null" ]; then
    echo -e "${RED}Failed to upload document${NC}"
else
    echo -e "${GREEN}Uploaded document with ID: $DOCUMENT_ID${NC}"

    # List all documents
    echo -e "\n${BLUE}Listing all documents...${NC}"
    curl -s "${BASE_URL}/api/documents?user_id=${CURRENT_USER}" | jq .

    # Get document by ID
    echo -e "\n${BLUE}Getting document by ID...${NC}"
    curl -s "${BASE_URL}/api/documents/${DOCUMENT_ID}" | jq .

    # Get document count
    echo -e "\n${BLUE}Getting document count...${NC}"
    curl -s "${BASE_URL}/api/documents/count?user_id=${CURRENT_USER}" | jq .

    # Delete document
    echo -e "\n${BLUE}Deleting document...${NC}"
    curl -s -X DELETE "${BASE_URL}/api/documents/${DOCUMENT_ID}" | jq .
    
    # Verify document is deleted
    echo -e "\n${BLUE}Verifying document is deleted...${NC}"
    DELETE_CHECK=$(curl -s "${BASE_URL}/api/documents/${DOCUMENT_ID}")
    if [[ "$DELETE_CHECK" == *"Document not found"* ]]; then
        echo -e "${GREEN}Document deleted successfully${NC}"
    else
        echo -e "${RED}Document deletion failed${NC}"
    fi
fi

echo -e "\n${GREEN}Document API test script completed${NC}" 
</file>
```

#### test\_document\_endpoints\.sh
*Size: 3.8 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/test_document_endpoints.sh">
#!/bin/bash
# Test script specifically for Document API endpoints

BASE_URL="http://localhost:8001"
CURRENT_USER="default-user"

# Colors for output
GREEN='\033[0;32m'
RED='\033[0;31m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

echo -e "${BLUE}Starting Document API Endpoint Tests...${NC}"

# Test health endpoint to make sure the server is running
echo -e "\n${BLUE}Testing health endpoint...${NC}"
HEALTH_RESPONSE=$(curl -s "${BASE_URL}/health")
echo $HEALTH_RESPONSE | jq .

if [[ $HEALTH_RESPONSE != *"ok"* ]]; then
  echo -e "${RED}Server is not responding correctly. Make sure it's running.${NC}"
  exit 1
fi

# 1. Upload a test document
echo -e "\n${BLUE}1. Testing document upload...${NC}"
UPLOAD_RESPONSE=$(curl -s -X POST "${BASE_URL}/api/documents/upload" \
    -F "file=@./test_data/sample.pdf" \
    -F "user_id=${CURRENT_USER}")
echo $UPLOAD_RESPONSE | jq .

DOCUMENT_ID=$(echo $UPLOAD_RESPONSE | jq -r '.document_id')

if [ -z "$DOCUMENT_ID" ] || [ "$DOCUMENT_ID" == "null" ]; then
    echo -e "${RED}Failed to upload document${NC}"
    exit 1
else
    echo -e "${GREEN}Uploaded document with ID: $DOCUMENT_ID${NC}"
    
    # Wait for processing to start
    echo -e "\n${BLUE}Waiting for document processing to begin...${NC}"
    sleep 2

    # 2. Test retrieving a specific document
    echo -e "\n${BLUE}2. Testing GET /api/documents/{document_id}...${NC}"
    GET_DOC_RESPONSE=$(curl -s -v "${BASE_URL}/api/documents/${DOCUMENT_ID}" 2>&1)
    echo "$GET_DOC_RESPONSE" | jq 2>/dev/null || echo "$GET_DOC_RESPONSE"
    
    # 3. Test listing all documents
    echo -e "\n${BLUE}3. Testing GET /api/documents...${NC}"
    LIST_DOCS_RESPONSE=$(curl -s -v "${BASE_URL}/api/documents?user_id=${CURRENT_USER}&page=1&page_size=10" 2>&1)
    echo "$LIST_DOCS_RESPONSE" | jq 2>/dev/null || echo "$LIST_DOCS_RESPONSE"
    
    # 4. Test getting document count
    echo -e "\n${BLUE}4. Testing GET /api/documents/count...${NC}"
    COUNT_RESPONSE=$(curl -s -v "${BASE_URL}/api/documents/count?user_id=${CURRENT_USER}" 2>&1)
    echo "$COUNT_RESPONSE" | jq 2>/dev/null || echo "$COUNT_RESPONSE"
    
    # Wait for processing to complete
    echo -e "\n${BLUE}Waiting for document processing to complete...${NC}"
    sleep 5
    
    # 5. Test getting document citations
    echo -e "\n${BLUE}5. Testing GET /api/documents/{document_id}/citations...${NC}"
    CITATIONS_RESPONSE=$(curl -s "${BASE_URL}/api/documents/${DOCUMENT_ID}/citations")
    echo $CITATIONS_RESPONSE | jq .
    
    # Check if there are any citations
    CITATION_COUNT=$(echo $CITATIONS_RESPONSE | jq 'length')
    if [ "$CITATION_COUNT" -gt 0 ]; then
        CITATION_ID=$(echo $CITATIONS_RESPONSE | jq -r '.[0].id')
        
        # 6. Test getting a specific citation
        echo -e "\n${BLUE}6. Testing GET /api/documents/{document_id}/citations/{citation_id}...${NC}"
        curl -s "${BASE_URL}/api/documents/${DOCUMENT_ID}/citations/${CITATION_ID}" | jq .
    else
        echo -e "${BLUE}No citations available to test citation retrieval endpoints${NC}"
    fi
    
    # 7. Test deleting the document
    echo -e "\n${BLUE}7. Testing DELETE /api/documents/{document_id}...${NC}"
    DELETE_RESPONSE=$(curl -s -X DELETE "${BASE_URL}/api/documents/${DOCUMENT_ID}")
    echo $DELETE_RESPONSE | jq .
    
    # Verify document was deleted by trying to retrieve it again
    echo -e "\n${BLUE}Verifying document deletion...${NC}"
    GET_DELETED_RESPONSE=$(curl -s -w "%{http_code}" "${BASE_URL}/api/documents/${DOCUMENT_ID}" -o /dev/null)
    
    if [ "$GET_DELETED_RESPONSE" == "404" ]; then
        echo -e "${GREEN}Document successfully deleted (received 404 Not Found)${NC}"
    else
        echo -e "${RED}Document may not have been deleted. Received HTTP $GET_DELETED_RESPONSE${NC}"
    fi
fi

echo -e "\n${GREEN}Document API endpoint tests completed${NC}" 
</file>
```

#### test\_document\_persistence\.sh
*Size: 654 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/test_document_persistence.sh">
#!/bin/bash
# Script to run document persistence tests

# Colors for output
GREEN='\033[0;32m'
RED='\033[0;31m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

echo -e "${BLUE}Running document persistence tests...${NC}"

# Run unit tests for DocumentRepository
echo -e "\n${BLUE}Running DocumentRepository unit tests...${NC}"
python -m pytest tests/test_document_repository.py -v

# Run API tests for document endpoints
echo -e "\n${BLUE}Running document API tests...${NC}"
python -m pytest tests/test_document_api.py -v

# Run the API test script
echo -e "\n${BLUE}Running API test script...${NC}"
bash test_api.sh

echo -e "\n${GREEN}Tests completed.${NC}" 
</file>
```

#### test\_document\_upload\.py
*Size: 2.7 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/test_document_upload.py">
#!/usr/bin/env python3
"""
Simple test script to test uploading a document.
"""

import asyncio
import logging
import os
from models.document import DocumentUploadResponse
from repositories.document_repository import DocumentRepository
from pdf_processing.document_service import DocumentService
from utils.database import SessionLocal

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_document_upload():
    """Test uploading a document."""
    # Check if test PDF exists
    test_pdf_path = os.path.join(os.path.dirname(__file__), "test_data", "sample.pdf")
    if not os.path.exists(test_pdf_path):
        logger.error(f"Test PDF not found at {test_pdf_path}")
        # Create test_data directory if it doesn't exist
        os.makedirs(os.path.dirname(test_pdf_path), exist_ok=True)
        # Create a simple test PDF
        with open(test_pdf_path, "wb") as f:
            # Write a simple PDF header
            f.write(b"%PDF-1.4\n")
            f.write(b"1 0 obj\n<</Type/Catalog/Pages 2 0 R>>\nendobj\n")
            f.write(b"2 0 obj\n<</Type/Pages/Kids[3 0 R]/Count 1>>\nendobj\n")
            f.write(b"3 0 obj\n<</Type/Page/MediaBox[0 0 612 792]/Parent 2 0 R/Resources<<>>>>\nendobj\n")
            f.write(b"xref\n0 4\n0000000000 65535 f\n0000000010 00000 n\n0000000053 00000 n\n0000000102 00000 n\n")
            f.write(b"trailer\n<</Size 4/Root 1 0 R>>\nstartxref\n183\n%%EOF\n")
        logger.info(f"Created test PDF at {test_pdf_path}")
    
    # Read the test PDF
    with open(test_pdf_path, "rb") as f:
        pdf_data = f.read()
    
    async with SessionLocal() as session:
        # Create a document repository
        document_repository = DocumentRepository(session)
        
        # Create a document service
        document_service = DocumentService(document_repository)
        
        # Upload the document
        filename = "sample.pdf"
        user_id = "default-user"
        response = await document_service.upload_document(pdf_data, filename, user_id)
        
        logger.info(f"Document uploaded with ID: {response.document_id}")
        logger.info(f"Status: {response.status}")
        
        # Wait for processing to complete
        logger.info("Waiting for document processing to complete...")
        await asyncio.sleep(2)
        
        # Get the document
        document = await document_repository.get_document(str(response.document_id))
        if document:
            logger.info(f"Document status: {document.processing_status}")
            logger.info(f"Document type: {document.document_type}")
        else:
            logger.error("Document not found")

def main():
    """Run the test."""
    asyncio.run(test_document_upload())

if __name__ == "__main__":
    main() 
</file>
```

#### test\_document\_visibility\.py
*Size: 8.8 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/test_document_visibility.py">
#!/usr/bin/env python
"""
Test script to verify document upload and visibility to the LLM.
This script tests the full flow from uploading a document to a conversation
and verifying that Claude can see and reference the document content.
"""

import os
import asyncio
import logging
import uuid
import time
from dotenv import load_dotenv
from repositories.document_repository import DocumentRepository
from repositories.conversation_repository import ConversationRepository
from pdf_processing.langgraph_service import LangGraphService
from pdf_processing.document_service import DocumentService
from services.conversation_service import ConversationService
from utils.database import SessionLocal
from models.database_models import ProcessingStatusEnum

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Verify API key is loaded
api_key = os.getenv("ANTHROPIC_API_KEY")
if not api_key:
    logger.error("ANTHROPIC_API_KEY not found in environment variables!")
    exit(1)

claude_model = os.getenv("CLAUDE_MODEL", "claude-3-5-sonnet-latest")
logger.info(f"Using Claude model: {claude_model}")

# Sample PDF path - using an existing financial report
PDF_PATH = os.path.join(
    os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 
    "ExampleDocs", 
    "Mueller Industries Earnings Release.pdf"
)

async def wait_for_document_processing(document_repository, document_id, timeout=120):
    """Wait for document processing to complete, with a timeout."""
    start_time = time.time()
    while time.time() - start_time < timeout:
        doc = await document_repository.get_document(document_id)
        logger.info(f"Document status: {doc.processing_status}")
        
        if doc.processing_status == ProcessingStatusEnum.COMPLETED:
            logger.info(f"Document processing completed in {time.time() - start_time:.2f} seconds")
            return True
        elif doc.processing_status == ProcessingStatusEnum.FAILED:
            logger.error(f"Document processing failed after {time.time() - start_time:.2f} seconds")
            return False
        
        # Wait a bit before checking again
        await asyncio.sleep(5)
    
    logger.error(f"Document processing timed out after {timeout} seconds")
    return False

async def test_document_visibility():
    """
    Test the complete flow:
    1. Create a conversation
    2. Upload a document
    3. Add document to conversation
    4. Send a message asking about the document
    5. Check if Claude responds with document citations
    """
    logger.info("=== Starting Document Visibility Test ===")
    
    # Check if test PDF exists
    if not os.path.exists(PDF_PATH):
        logger.error(f"Test PDF not found at {PDF_PATH}")
        return
    
    # Generate a unique test user ID for this test run
    test_user_id = f"test-user-{uuid.uuid4()}"
    
    # Read the test PDF
    with open(PDF_PATH, "rb") as f:
        pdf_data = f.read()
    
    async with SessionLocal() as session:
        # Initialize repositories and services
        document_repository = DocumentRepository(session)
        conversation_repository = ConversationRepository(session)
        
        document_service = DocumentService(document_repository)
        conversation_service = ConversationService(conversation_repository, document_repository)
        
        try:
            langgraph_service = LangGraphService()
            logger.info("Successfully initialized LangGraphService")
        except Exception as e:
            logger.error(f"Failed to initialize LangGraphService: {str(e)}")
            return None
        
        try:
            # Step 1: Create a conversation
            logger.info("Step 1: Creating a conversation")
            conversation = await conversation_service.create_conversation(
                user_id=test_user_id,
                title="Document Visibility Test"
            )
            conversation_id = str(conversation.id)
            logger.info(f"Created conversation with ID: {conversation_id}")
            
            # Step 2: Upload the document
            logger.info("Step 2: Uploading document")
            filename = os.path.basename(PDF_PATH)
            upload_response = await document_service.upload_document(
                file_data=pdf_data,
                filename=filename,
                user_id=test_user_id
            )
            document_id = str(upload_response.document_id)
            logger.info(f"Document uploaded with ID: {document_id}")
            
            # Wait for document processing to complete
            logger.info("Waiting for document processing to complete...")
            processing_completed = await wait_for_document_processing(document_repository, document_id)
            
            if not processing_completed:
                logger.error("Document processing did not complete successfully, aborting test")
                return None
            
            # Step 3: Add document to conversation
            logger.info("Step 3: Adding document to conversation")
            try:
                await langgraph_service.add_document_to_conversation(
                    conversation_id=conversation_id,
                    document_id=document_id
                )
                logger.info(f"Added document {document_id} to conversation {conversation_id}")
            except Exception as e:
                logger.error(f"Error adding document to conversation: {str(e)}", exc_info=True)
                return None
            
            # Step 4: Send a message asking about the document
            logger.info("Step 4: Sending a message to query the document")
            query_message = "What were Mueller Industries' net sales in the first quarter? Please cite the document."
            
            # Add some explicit logging to debug the conversation state before processing
            logger.info(f"Sending query about document: {query_message}")
            
            # Process the message through LangGraph
            try:
                response = await langgraph_service.process_message(
                    conversation_id=conversation_id,
                    message_content=query_message
                )
                
                # Step 5: Check the response
                logger.info("\n=== Query Results ===")
                logger.info(f"Query: {query_message}")
                logger.info(f"Response: {response.get('message_content', 'No response')}")
                
                # Check if the response contains citations or references to the document
                response_text = response.get('message_content', '').lower()
                has_citations = any(marker in response_text for marker in 
                                ['according to the document', 'the document states', 
                                    'based on the document', 'mueller industries', 
                                    'earnings release', 'first quarter'])
                
                if has_citations:
                    logger.info("âœ… SUCCESS: Response contains references to the document content")
                else:
                    logger.error("âŒ FAILURE: Response does not contain references to the document")
                
                # Check if citations were generated
                citations = response.get('citations', [])
                if citations:
                    logger.info(f"âœ… SUCCESS: Response includes {len(citations)} citations")
                    # Log the first few citations
                    for i, citation in enumerate(citations[:3]):
                        logger.info(f"Citation {i+1}: {citation}")
                else:
                    logger.warning("âš ï¸ No structured citations found in the response")
                
                return response
            except Exception as e:
                logger.error(f"Error processing message: {str(e)}", exc_info=True)
                return None
            
        except Exception as e:
            logger.error(f"Error during test: {str(e)}", exc_info=True)
            return None

def main():
    """Run the test."""
    response = asyncio.run(test_document_visibility())
    
    # Final summary
    if response:
        logger.info("\n=== Test Summary ===")
        if response.get('message_content'):
            logger.info("Test completed - check logs for details")
            print("\nFinal Response from Claude:")
            print("-" * 50)
            print(response.get('message_content'))
            print("-" * 50)
        else:
            logger.error("Test completed but no response content was received")
    else:
        logger.error("Test failed - see error logs for details")

if __name__ == "__main__":
    main()
</file>
```

#### test\_imports\.py
*Size: 1.7 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/test_imports.py">
#!/usr/bin/env python
import sys
import os
from pathlib import Path

# Add the parent directory to sys.path to help with imports
current_dir = Path(__file__).parent.absolute()
parent_dir = current_dir.parent
sys.path.append(str(parent_dir))

print(f"Current directory: {current_dir}")
print(f"Parent directory: {parent_dir}")
print(f"sys.path: {sys.path}")

try:
    print("\nTesting imports...")
    from app.routes import document, conversation, analysis
    print("âœ… app.routes imports successful")
except ImportError as e:
    print(f"âŒ Error importing app.routes: {e}")

try:
    from utils.database import get_db
    print("âœ… utils.database imports successful")
except ImportError as e:
    print(f"âŒ Error importing utils.database: {e}")

try:
    from models.database_models import Base, User, Document, Conversation
    print("âœ… models.database_models imports successful")
except ImportError as e:
    print(f"âŒ Error importing models.database_models: {e}")

try:
    from repositories.conversation_repository import ConversationRepository
    print("âœ… repositories.conversation_repository imports successful")
except ImportError as e:
    print(f"âŒ Error importing repositories.conversation_repository: {e}")

try:
    from services.conversation_service import ConversationService
    print("âœ… services.conversation_service imports successful")
except ImportError as e:
    print(f"âŒ Error importing services.conversation_service: {e}")

try:
    from pdf_processing.claude_service import ClaudeService
    print("âœ… pdf_processing.claude_service imports successful")
except ImportError as e:
    print(f"âŒ Error importing pdf_processing.claude_service: {e}")

print("\nImport test complete.") 
</file>
```

#### test\_langgraph\_with\_pdf\.py
*Size: 6.2 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/test_langgraph_with_pdf.py">
#!/usr/bin/env python
import os
import asyncio
import logging
from dotenv import load_dotenv
import PyPDF2
import argparse
from pdf_processing.langgraph_service import LangGraphService
from unittest.mock import patch, MagicMock

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Get the parent directory path
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
# Load environment variables from the parent directory
dotenv_path = os.path.join(parent_dir, '.env')
logger.info(f"Loading .env file from: {dotenv_path}")
load_dotenv(dotenv_path)

# Verify API key is loaded
api_key = os.getenv("ANTHROPIC_API_KEY")
if api_key:
    # Mask the API key for logging purposes
    masked_key = api_key[:4] + '*' * (len(api_key) - 8) + api_key[-4:] if len(api_key) > 8 else "****"
    logger.info(f"ANTHROPIC_API_KEY loaded: {masked_key}")
else:
    logger.warning("ANTHROPIC_API_KEY not found in environment variables!")

def extract_text_from_pdf(pdf_path):
    """Extract text content from a PDF file."""
    logger.info(f"Extracting text from {pdf_path}")
    
    text_content = ""
    
    try:
        with open(pdf_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            num_pages = len(reader.pages)
            
            logger.info(f"PDF has {num_pages} pages")
            
            for page_num in range(num_pages):
                page = reader.pages[page_num]
                text_content += page.extract_text() + "\n\n"
                
        logger.info(f"Successfully extracted {len(text_content)} characters")
        return text_content
    except Exception as e:
        logger.error(f"Error extracting text from PDF: {str(e)}")
        return None

def mock_response_for_mueller(text, question):
    """Generate a simulated response based on the document content."""
    logger.info("Using mock response generator (API key issue)")
    
    # Extract key financial data from the PDF text
    if "net sales" in question.lower() and "first quarter" in question.lower():
        return """Based on the Mueller Industries Earnings Release, net sales for the first quarter (Q1) of 2021 were $818.2 million. This represents an increase from the same period in the previous year (Q1 2020), when net sales were $602.5 million. This significant increase of $215.7 million (or approximately 35.8%) was driven by higher copper prices and increased unit volumes."""
    elif "operating income" in question.lower():
        return """According to the Mueller Industries Earnings Release, operating income for the first quarter of 2021 was $118.9 million, compared to $47.4 million in the first quarter of 2020. This represents a significant increase of $71.5 million or approximately 150.8% compared to the same period in the previous year."""
    elif "earnings" in question.lower() or "net income" in question.lower():
        return """Based on the Mueller Industries Earnings Release, net income for the first quarter of 2021 was $78.7 million, or $1.40 per diluted share. This compares to $28.0 million, or $0.50 per diluted share, for the same period in 2020. This represents a significant increase of $50.7 million or approximately 181% compared to the prior year."""
    else:
        return """Based on my analysis of the Mueller Industries Earnings Release, I can provide the following information in response to your question:

The document is a quarterly earnings release for Mueller Industries, Inc. for the first quarter of 2021. The company reported strong financial performance with:

- Net sales of $818.2 million (up from $602.5 million in Q1 2020)
- Operating income of $118.9 million (up from $47.4 million in Q1 2020)
- Net income of $78.7 million or $1.40 per diluted share (up from $28.0 million or $0.50 per diluted share in Q1 2020)

The company attributes this growth to higher copper prices and strong demand across their businesses, particularly in the housing and commercial construction markets."""

async def test_langgraph_qa(pdf_path, question, use_mock=False):
    """Test the LangGraph QA functionality with a PDF document."""
    # Extract text from PDF
    pdf_text = extract_text_from_pdf(pdf_path)
    
    if not pdf_text:
        logger.error("Failed to extract text from PDF")
        return
    
    # Create document object
    document = {
        "id": "mueller_earnings",
        "title": "Mueller Industries Earnings Release",
        "text": pdf_text
    }
    
    # Initialize LangGraph service
    langgraph_service = LangGraphService()
    
    # Run QA with the document
    logger.info(f"Querying document with question: {question}")
    
    response = None
    try:
        if use_mock:
            # Use mock response if requested
            response = mock_response_for_mueller(pdf_text, question)
        else:
            # Try to use the real service
            response = await langgraph_service.simple_document_qa(
                question=question,
                documents=[document]
            )
    except Exception as e:
        logger.error(f"Error during QA: {str(e)}")
        # Fall back to mock if there's an error
        logger.info("Falling back to mock response")
        response = mock_response_for_mueller(pdf_text, question)
    
    logger.info("Response received:")
    print(f"\nQuestion: {question}\n")
    print(f"Answer: {response}\n")
    
    return response

def main():
    parser = argparse.ArgumentParser(description="Test LangGraph QA with a PDF document")
    parser.add_argument("--question", type=str, default="What was Mueller Industries' net sales in the first quarter?", 
                        help="Question to ask about the document")
    parser.add_argument("--mock", action="store_true", help="Use mock response instead of real API")
    args = parser.parse_args()
    
    # Path to the PDF
    pdf_path = os.path.join(
        os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 
        "ExampleDocs", 
        "Mueller Industries Earnings Release.pdf"
    )
    
    if not os.path.exists(pdf_path):
        logger.error(f"PDF file not found at {pdf_path}")
        return
    
    # Run the test
    asyncio.run(test_langgraph_qa(pdf_path, args.question, args.mock))

if __name__ == "__main__":
    main() 
</file>
```

#### test\_pdf\_visibility\_fix\.py
*Size: 6.8 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/test_pdf_visibility_fix.py">
#!/usr/bin/env python
"""
A test script to verify PDF visibility fixes.

This script:
1. Creates a new conversation
2. Uploads a sample PDF file
3. Adds the PDF to the conversation
4. Sends a message asking about the PDF content
5. Verifies that Claude can "see" the PDF content in its response
"""

import os
import json
import asyncio
import logging
import uuid
from datetime import datetime
from fastapi.testclient import TestClient

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# Import app and modules
from app.main import app
from services.conversation_service import ConversationService
from repositories.conversation_repository import ConversationRepository
from repositories.document_repository import DocumentRepository
from pdf_processing.claude_service import ClaudeService
from sqlalchemy.ext.asyncio import AsyncSession


# Create test client
client = TestClient(app)

async def test_pdf_visibility():
    """Test that Claude can "see" the content of an uploaded PDF"""
    try:
        # We'll use the FastAPI test client instead of direct service calls
        # to avoid database session management complexities
        
        # Step 1: Create a new conversation
        logger.info("Creating a new conversation...")
        user_id = str(uuid.uuid4())
        conversation_response = client.post(
            "/api/conversation",
            json={"title": "PDF Visibility Test", "user_id": user_id}
        )
        assert conversation_response.status_code in [200, 201], f"Failed to create conversation: {conversation_response.text}"
        conversation_data = conversation_response.json()
        # API might return id or session_id 
        conversation_id = conversation_data.get("id", conversation_data.get("session_id"))
        logger.info(f"Created conversation with ID: {conversation_id}")
        
        # Step 2: Upload a test PDF
        logger.info("Uploading test PDF...")
        test_pdf_path = "test_data/sample_financial_report.pdf"
        if not os.path.exists(test_pdf_path):
            logger.warning(f"Test PDF not found at {test_pdf_path}, using sample.pdf instead")
            test_pdf_path = "test_data/sample.pdf"
        
        with open(test_pdf_path, "rb") as pdf_file:
            response = client.post(
                "/api/documents/upload",
                files={"file": ("test_financial_report.pdf", pdf_file, "application/pdf")},
                data={"user_id": user_id}
            )
        
        assert response.status_code == 200, f"Failed to upload PDF: {response.text}"
        upload_data = response.json()
        document_id = upload_data["document_id"]
        logger.info(f"Uploaded document with ID: {document_id}")
        
        # Wait for document processing to complete
        logger.info("Waiting for document processing to complete...")
        retries = 30  # Increased from 10 to 30
        processing_completed = False
        
        for i in range(retries):
            doc_response = client.get(f"/api/documents/{document_id}")
            assert doc_response.status_code == 200, f"Failed to get document: {doc_response.text}"
            doc_data = doc_response.json()
            
            if doc_data["processing_status"] == "completed":
                processing_completed = True
                logger.info("Document processing completed successfully!")
                break
                
            if doc_data["processing_status"] == "failed":
                assert False, f"Document processing failed: {doc_data.get('error_message', 'Unknown error')}"
                
            logger.info(f"Document status: {doc_data['processing_status']} (attempt {i+1}/{retries})")
            await asyncio.sleep(3)  # Increased from 2 to 3 seconds
        
        assert processing_completed, "Document processing did not complete in time"
        
        # Step 3: Add PDF to conversation
        logger.info("Adding document to conversation...")
        add_doc_response = client.post(
            f"/api/conversation/{conversation_id}/document/{document_id}"
        )
        assert add_doc_response.status_code == 200, f"Failed to add document to conversation: {add_doc_response.text}"
        logger.info("Document added to conversation successfully")
        
        # Step 4: Send a message asking about the PDF
        logger.info("Sending message to conversation...")
        message = "What information do you see in the PDF I uploaded? Please provide specific details from the document."
        
        message_response = client.post(
            f"/api/conversation/{conversation_id}/message",
            json={"content": message}
        )
        assert message_response.status_code == 200, f"Failed to send message: {message_response.text}"
        response_data = message_response.json()
        
        # Step 5: Verify Claude's response mentions PDF content
        logger.info("Checking Claude's response...")
        messages_response = client.get(f"/api/conversation/{conversation_id}/messages")
        assert messages_response.status_code == 200, f"Failed to get messages: {messages_response.text}"
        
        messages = messages_response.json()
        assistant_messages = [m for m in messages if m["role"] == "assistant"]
        
        # Get the latest assistant message
        if assistant_messages:
            latest_message = assistant_messages[-1]
            response_text = latest_message["content"]
            
            logger.info(f"Claude's response: {response_text[:200]}...")
            
            # Check if the response contains actual content from the PDF
            # This depends on the test PDF content, so we check for general indicators
            # that Claude can see the document
            assert "I can see" in response_text or "document shows" in response_text or "according to" in response_text, \
                "Claude's response doesn't indicate it can see the document content"
            
            # Check for citations
            if "citations" in latest_message and latest_message["citations"]:
                logger.info(f"Found {len(latest_message['citations'])} citations in response")
                for citation in latest_message["citations"]:
                    logger.info(f"Citation: {citation}")
            else:
                logger.info("No citations found in response")
            
            logger.info("âœ… Test passed! Claude can see the PDF content")
            
        else:
            logger.error("No assistant messages found in the conversation")
            assert False, "No assistant messages found"
        
        return True
        
    except Exception as e:
        logger.error(f"Test failed: {str(e)}")
        raise


if __name__ == "__main__":
    asyncio.run(test_pdf_visibility())
</file>
```

#### utils/\_\_init\_\_\.py
*Size: 159 bytes*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/utils/__init__.py">
# Import utilities here to make them available
from .database import get_db, Base
from .init_db import init_db, run_init_db
from .storage import StorageService
</file>
```

#### utils/database\.py
*Size: 1.8 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/utils/database.py">
import os
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import declarative_base

# Get the database URL from environment variables
DATABASE_URL = os.getenv("DATABASE_URL", "sqlite:///./fdas.db")

# Convert SQLite URL to work with SQLAlchemy asynchronous
if DATABASE_URL.startswith("sqlite"):
    # For SQLite, we need to convert to the async variant
    DATABASE_URL = DATABASE_URL.replace("sqlite:///", "sqlite+aiosqlite:///", 1)

# Create async engine
engine = create_async_engine(
    DATABASE_URL,
    echo=True if os.getenv("DEBUG") == "True" else False,
    future=True,
)

# Create session factory
SessionLocal = sessionmaker(
    autocommit=False,
    autoflush=False,
    bind=engine,
    class_=AsyncSession,
    expire_on_commit=False,
)

# Create Base class for models
Base = declarative_base()

# Dependency to get database session
async def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        await db.close()

# For non-async operations
sync_engine = None
SyncSessionLocal = None

if DATABASE_URL.startswith("sqlite+aiosqlite"):
    # Create sync engine for SQLite
    sync_url = DATABASE_URL.replace("sqlite+aiosqlite:///", "sqlite:///", 1)
    sync_engine = create_engine(sync_url, connect_args={"check_same_thread": False})
    SyncSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=sync_engine)
else:
    # For PostgreSQL or other databases
    sync_url = DATABASE_URL.replace("+asyncpg", "", 1) if "+asyncpg" in DATABASE_URL else DATABASE_URL
    sync_engine = create_engine(sync_url)
    SyncSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=sync_engine)
</file>
```

#### utils/db\_verification\.py
*Size: 1.5 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/utils/db_verification.py">
import logging
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from models.database_models import Document

logger = logging.getLogger(__name__)

async def verify_document_persistence(db: AsyncSession, document_id: str) -> bool:
    """
    Verify that a document exists in the database.
    
    Args:
        db: Database session
        document_id: ID of the document to verify
        
    Returns:
        True if document exists, False otherwise
    """
    result = await db.execute(
        select(Document).where(Document.id == document_id)
    )
    document = result.scalars().first()
    
    if document:
        logger.info(f"Document {document_id} found in database.")
        return True
    else:
        logger.warning(f"Document {document_id} not found in database.")
        return False

async def test_db_setup(db: AsyncSession) -> bool:
    """
    Test database setup by querying the Document table.
    
    Args:
        db: Database session
        
    Returns:
        True if the database is set up correctly, False otherwise
    """
    try:
        # Test if the Document table exists and can be queried
        result = await db.execute(select(Document).limit(1))
        _ = result.scalars().first()  # Just to execute the query
        logger.info("Database connected successfully and Document table exists.")
        return True
    except Exception as e:
        logger.error(f"Database connection error: {str(e)}")
        return False 
</file>
```

#### utils/dependencies\.py
*Size: 2.3 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/utils/dependencies.py">
from fastapi import Depends
from sqlalchemy.ext.asyncio import AsyncSession
from typing import Optional

from utils.database import get_db
from repositories.document_repository import DocumentRepository
from repositories.conversation_repository import ConversationRepository
from repositories.analysis_repository import AnalysisRepository
from pdf_processing.document_service import DocumentService
from services.conversation_service import ConversationService
from services.analysis_service import AnalysisService
from utils.storage import StorageService

# Document dependencies
async def get_document_repository(db: AsyncSession = Depends(get_db)) -> DocumentRepository:
    """
    Get document repository with DB session dependency.
    """
    storage_service = StorageService.get_storage_service()
    return DocumentRepository(db, storage_service)

async def get_document_service(
    document_repository: DocumentRepository = Depends(get_document_repository)
) -> DocumentService:
    """
    Get document service with repository dependency.
    """
    return DocumentService(document_repository)

# Conversation dependencies
async def get_conversation_repository(db: AsyncSession = Depends(get_db)) -> ConversationRepository:
    """
    Get conversation repository with DB session dependency.
    """
    return ConversationRepository(db)

async def get_conversation_service(
    conversation_repository: ConversationRepository = Depends(get_conversation_repository),
    document_repository: DocumentRepository = Depends(get_document_repository)
) -> ConversationService:
    """
    Get conversation service with repository dependencies.
    """
    return ConversationService(conversation_repository, document_repository)

# Analysis dependencies
async def get_analysis_repository(db: AsyncSession = Depends(get_db)) -> AnalysisRepository:
    """
    Get analysis repository with DB session dependency.
    """
    return AnalysisRepository(db)

async def get_analysis_service(
    analysis_repository: AnalysisRepository = Depends(get_analysis_repository),
    document_repository: DocumentRepository = Depends(get_document_repository)
) -> AnalysisService:
    """
    Get analysis service with repository dependencies.
    """
    return AnalysisService(analysis_repository, document_repository) 
</file>
```

#### utils/error\_handling\.py
*Size: 6.2 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/utils/error_handling.py">
"""
Utilities for standardized error handling across API endpoints.
"""
import logging
from typing import Dict, Any, Optional, List, Union, Type
from fastapi import HTTPException, Request
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from pydantic import ValidationError
import os

from models.error import create_error_response, ValidationErrorDetail

logger = logging.getLogger(__name__)

# Get allowed origins from environment
def get_allowed_origins():
    return os.getenv(
        "ALLOWED_ORIGINS", 
        "http://localhost:3000,http://localhost:3001,http://localhost:3002,http://localhost:3003,http://127.0.0.1:3000,http://127.0.0.1:3001,http://127.0.0.1:3002,http://127.0.0.1:3003"
    ).split(",")

# Add CORS headers to any response
def add_cors_headers(response: JSONResponse) -> JSONResponse:
    origins = get_allowed_origins()
    
    # If the response already has CORS headers, don't modify it
    if "access-control-allow-origin" in response.headers:
        return response
    
    # Add CORS headers - use the first origin as default, or * if no origins are defined
    response.headers["Access-Control-Allow-Origin"] = origins[0] if origins else "*"
    response.headers["Access-Control-Allow-Credentials"] = "true"
    response.headers["Access-Control-Allow-Methods"] = "*"
    response.headers["Access-Control-Allow-Headers"] = "*"
    
    return response


def format_validation_errors(errors: List[Dict[str, Any]]) -> List[ValidationErrorDetail]:
    """
    Format validation errors into a standard structure.
    
    Args:
        errors: List of validation error dictionaries
        
    Returns:
        List of ValidationErrorDetail objects
    """
    return [
        ValidationErrorDetail(
            loc=err.get("loc", []),
            msg=err.get("msg", "Validation error"),
            type=err.get("type", "validation_error")
        )
        for err in errors
    ]


class StandardHTTPException(HTTPException):
    """
    Extended HTTP exception with standardized error response format.
    """
    def __init__(
        self, 
        status_code: int, 
        detail: Union[str, List[Dict[str, Any]], Dict[str, Any]],
        error_type: Optional[str] = None,
        headers: Optional[Dict[str, Any]] = None
    ):
        self.error_type = error_type
        super().__init__(status_code=status_code, detail=detail, headers=headers)


async def http_exception_handler(request: Request, exc: HTTPException) -> JSONResponse:
    """
    Handle HTTPException and return standardized error response.
    
    Args:
        request: FastAPI request object
        exc: HTTPException instance
        
    Returns:
        JSONResponse with standardized error format
    """
    # Get error type if available (for StandardHTTPException)
    error_type = getattr(exc, "error_type", None)
    
    # Create standard error response
    content = create_error_response(
        status_code=exc.status_code,
        detail=exc.detail,
        error_type=error_type or get_error_type_from_status(exc.status_code)
    )
    
    # Log the error (except for 404s which can be noisy)
    if exc.status_code != 404:
        logger.error(f"HTTPException: {exc.status_code} - {exc.detail}")
    
    # Create the response
    response = JSONResponse(
        status_code=exc.status_code,
        content=content,
        headers=exc.headers or {}
    )
    
    # Add CORS headers
    return add_cors_headers(response)


async def validation_exception_handler(request: Request, exc: RequestValidationError) -> JSONResponse:
    """
    Handle validation exceptions and return standardized error response.
    
    Args:
        request: FastAPI request object
        exc: RequestValidationError instance
        
    Returns:
        JSONResponse with standardized error format
    """
    # Convert errors to standard format
    errors = format_validation_errors(exc.errors())
    
    # Create standard error response
    content = create_error_response(
        status_code=422,
        detail=errors,
        error_type="validation_error"
    )
    
    logger.error(f"Validation error: {errors}")
    
    # Create response
    response = JSONResponse(
        status_code=422,
        content=content
    )
    
    # Add CORS headers
    return add_cors_headers(response)


def get_error_type_from_status(status_code: int) -> str:
    """
    Map HTTP status code to an error type string.
    
    Args:
        status_code: HTTP status code
        
    Returns:
        String representing the error type
    """
    error_types = {
        400: "bad_request",
        401: "unauthorized",
        403: "forbidden",
        404: "not_found",
        409: "conflict",
        422: "validation_error",
        429: "too_many_requests",
        500: "server_error",
        503: "service_unavailable"
    }
    
    return error_types.get(status_code, "unknown_error")


def handle_exception(
    exc: Exception, 
    default_status: int = 500,
    default_message: str = "An unexpected error occurred"
) -> StandardHTTPException:
    """
    Convert any exception to a StandardHTTPException with appropriate status and message.
    
    Args:
        exc: The exception to handle
        default_status: Default HTTP status code
        default_message: Default error message
        
    Returns:
        StandardHTTPException with appropriate error details
    """
    # Handle ValueError specially
    if isinstance(exc, ValueError):
        error_message = str(exc)
        
        # Check for common patterns in error messages
        if "not found" in error_message.lower() or "does not exist" in error_message.lower():
            return StandardHTTPException(
                status_code=404,
                detail=error_message,
                error_type="not_found"
            )
        
        # Default for ValueError is bad request
        return StandardHTTPException(
            status_code=400,
            detail=error_message,
            error_type="bad_request"
        )
    
    # Log unexpected exceptions
    logger.exception(f"Unhandled exception: {exc}")
    
    # Return a generic server error for unexpected exceptions
    return StandardHTTPException(
        status_code=default_status,
        detail=default_message,
        error_type="server_error"
    )
</file>
```

#### utils/init\_db\.py
*Size: 2.2 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/utils/init_db.py">
import asyncio
import logging
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
import os

from .database import engine, Base, SessionLocal

logger = logging.getLogger(__name__)

async def create_tables():
    """Create database tables."""
    try:
        async with engine.begin() as conn:
            logger.info("Creating database tables...")
            await conn.run_sync(Base.metadata.create_all)
        logger.info("Database tables created successfully.")
    except Exception as e:
        logger.error(f"Error creating database tables: {str(e)}")
        raise

async def create_default_user():
    """Create a default user if no users exist."""
    # Import here to avoid circular imports
    from models.database_models import User
    
    try:
        async with SessionLocal() as session:
            # Check if any users exist
            result = await session.execute(select(User).limit(1))
            existing_user = result.scalars().first()
            
            if not existing_user:
                logger.info("Creating default user...")
                default_user = User(
                    username="default",
                    email="default@example.com",
                    hashed_password="notarealpassword",  # In a real app, this would be properly hashed
                    is_active=True
                )
                session.add(default_user)
                await session.commit()
                logger.info(f"Default user created with ID: {default_user.id}")
                return default_user
            
            logger.info("Default user already exists.")
            return existing_user
    except Exception as e:
        logger.error(f"Error creating default user: {str(e)}")
        raise

async def init_db():
    """Initialize the database."""
    try:
        await create_tables()
        await create_default_user()
        logger.info("Database initialization completed successfully.")
    except Exception as e:
        logger.error(f"Database initialization failed: {str(e)}")
        raise

def run_init_db():
    """Run the database initialization."""
    asyncio.run(init_db())

if __name__ == "__main__":
    run_init_db()
</file>
```

#### utils/message\_converters\.py
*Size: 11.0 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/utils/message_converters.py">
"""
Utility functions for converting between different message formats.

This module provides conversion functions for:
1. Converting between Claude API message format and internal message models
2. Converting between frontend message format and internal message models
3. Converting citations between different formats
"""

import uuid
from typing import List, Dict, Any, Optional
from datetime import datetime

from models.message import Message, MessageRole
from models.citation import Citation, CitationType, CharLocationCitation, PageLocationCitation, ContentBlock, AnthropicMessage

def claude_message_to_internal(claude_message: Dict[str, Any]) -> Message:
    """
    Convert a Claude API message to our internal Message model.
    
    Args:
        claude_message: Message from Claude API
        
    Returns:
        Internal Message model
    """
    message_id = str(uuid.uuid4())
    role = claude_message.get("role", "assistant").lower()
    
    # Extract content from Claude message format
    content = ""
    content_blocks = []
    citations = []
    
    # Process content blocks if they exist
    if "content" in claude_message and isinstance(claude_message["content"], list):
        for block in claude_message["content"]:
            if block.get("type") == "text":
                content += block.get("text", "")
                
                # Convert citations if they exist
                if "citations" in block:
                    for citation in block.get("citations", []):
                        citation_obj = _convert_claude_citation(citation)
                        if citation_obj:
                            citations.append(citation_obj)
                
                # Create content block
                content_block = ContentBlock(
                    text=block.get("text", ""),
                    citations=[_convert_claude_citation(citation) for citation in block.get("citations", [])]
                )
                content_blocks.append(content_block)
    elif "content" in claude_message and isinstance(claude_message["content"], str):
        content = claude_message["content"]
    
    # Create Message object
    message = Message(
        id=message_id,
        session_id=claude_message.get("session_id", ""),
        timestamp=datetime.now().isoformat(),
        role=MessageRole(role),
        content=content,
        content_blocks=content_blocks,
        citations=citations,
        referenced_documents=claude_message.get("referenced_documents", []),
        referenced_analyses=claude_message.get("referenced_analyses", [])
    )
    
    return message

def internal_message_to_claude(message: Message) -> Dict[str, Any]:
    """
    Convert an internal Message model to Claude API format.
    
    Args:
        message: Internal Message model
        
    Returns:
        Message in Claude API format
    """
    # Create Claude message structure
    claude_message = {
        "role": message.role.value,
    }
    
    # Handle content blocks if they exist
    if message.content_blocks:
        claude_message["content"] = []
        for block in message.content_blocks:
            content_block = {
                "type": "text",
                "text": block.text
            }
            
            # Add citations if they exist
            if block.citations:
                content_block["citations"] = [
                    _convert_internal_citation_to_claude(citation)
                    for citation in block.citations
                ]
            
            claude_message["content"].append(content_block)
    else:
        # Simple text content
        claude_message["content"] = [{"type": "text", "text": message.content}]
    
    return claude_message

def frontend_message_to_internal(frontend_message: Dict[str, Any]) -> Message:
    """
    Convert a frontend message format to our internal Message model.
    
    Args:
        frontend_message: Message from frontend
        
    Returns:
        Internal Message model
    """
    # Extract fields from frontend message
    message_id = frontend_message.get("id", str(uuid.uuid4()))
    session_id = frontend_message.get("sessionId", "")
    timestamp = frontend_message.get("timestamp", datetime.now().isoformat())
    role = frontend_message.get("role", "user").lower()
    content = frontend_message.get("content", "")
    
    # Extract citations if they exist
    citations = []
    if "citationLinks" in frontend_message and frontend_message["citationLinks"]:
        for citation in frontend_message["citationLinks"]:
            citation_obj = _convert_frontend_citation(citation)
            if citation_obj:
                citations.append(citation_obj)
    
    # Create Message object
    message = Message(
        id=message_id,
        session_id=session_id,
        timestamp=timestamp,
        role=MessageRole(role),
        content=content,
        citations=citations,
        referenced_documents=frontend_message.get("referencedDocuments", []),
        referenced_analyses=frontend_message.get("referencedAnalyses", [])
    )
    
    return message

def internal_message_to_frontend(message: Message) -> Dict[str, Any]:
    """
    Convert an internal Message model to frontend format.
    
    Args:
        message: Internal Message model
        
    Returns:
        Message in frontend format
    """
    # Create frontend message structure
    frontend_message = {
        "id": message.id,
        "sessionId": message.session_id,
        "timestamp": message.timestamp,
        "role": message.role.value,
        "content": message.content,
        "referencedDocuments": message.referenced_documents,
        "referencedAnalyses": message.referenced_analyses,
    }
    
    # Add citations if they exist
    if message.citations:
        frontend_message["citationLinks"] = [
            _convert_internal_citation_to_frontend(citation)
            for citation in message.citations
        ]
    
    return frontend_message

def _convert_claude_citation(claude_citation: Dict[str, Any]) -> Optional[Citation]:
    """
    Convert a Claude citation to internal Citation model.
    
    Args:
        claude_citation: Citation from Claude API
        
    Returns:
        Internal Citation model or None if conversion fails
    """
    try:
        citation_type = claude_citation.get("type")
        
        if citation_type == "char_location":
            # Text document citation
            return CharLocationCitation(
                type=CitationType.CHAR_LOCATION,
                cited_text=claude_citation.get("content", {}).get("quote", ""),
                document_index=0,  # Default to first document
                document_title=claude_citation.get("document", {}).get("title", ""),
                start_char_index=claude_citation.get("start_char_offset", 0),
                end_char_index=claude_citation.get("end_char_offset", 0)
            )
        elif citation_type == "page_location":
            # PDF document citation
            page_num = claude_citation.get("page", 1)
            return PageLocationCitation(
                type=CitationType.PAGE_LOCATION,
                cited_text=claude_citation.get("content", {}).get("quote", ""),
                document_index=0,  # Default to first document
                document_title=claude_citation.get("document", {}).get("title", ""),
                start_page_number=page_num,
                end_page_number=page_num
            )
        else:
            # Unsupported citation type
            return None
    except Exception as e:
        print(f"Error converting Claude citation: {e}")
        return None

def _convert_internal_citation_to_claude(citation: Citation) -> Dict[str, Any]:
    """
    Convert an internal Citation model to Claude API format.
    
    Args:
        citation: Internal Citation model
        
    Returns:
        Citation in Claude API format
    """
    if citation.type == CitationType.CHAR_LOCATION:
        citation = citation  # type: CharLocationCitation
        return {
            "type": "char_location",
            "start_char_offset": citation.start_char_index,
            "end_char_offset": citation.end_char_index,
            "content": {
                "quote": citation.cited_text
            },
            "document": {
                "title": citation.document_title,
                "url": ""
            }
        }
    elif citation.type == CitationType.PAGE_LOCATION:
        citation = citation  # type: PageLocationCitation
        return {
            "type": "page_location",
            "page": citation.start_page_number,
            "content": {
                "quote": citation.cited_text
            },
            "document": {
                "title": citation.document_title,
                "url": ""
            }
        }
    elif citation.type == CitationType.CONTENT_BLOCK_LOCATION:
        citation = citation  # type: ContentBlockLocationCitation
        return {
            "type": "content_block_location",
            "start_block_index": citation.start_block_index,
            "end_block_index": citation.end_block_index,
            "content": {
                "quote": citation.cited_text
            },
            "document": {
                "title": citation.document_title,
                "url": ""
            }
        }
    else:
        # Unsupported citation type
        return {}

def _convert_frontend_citation(frontend_citation: Dict[str, Any]) -> Optional[Citation]:
    """
    Convert a frontend citation to internal Citation model.
    
    Args:
        frontend_citation: Citation from frontend
        
    Returns:
        Internal Citation model or None if conversion fails
    """
    try:
        # Most frontend citations will be page-based (PDF)
        page_num = frontend_citation.get("page", 1)
        return PageLocationCitation(
            type=CitationType.PAGE_LOCATION,
            cited_text=frontend_citation.get("text", ""),
            document_index=0,  # Default to first document
            document_title=frontend_citation.get("title", ""),
            start_page_number=page_num,
            end_page_number=page_num
        )
    except Exception as e:
        print(f"Error converting frontend citation: {e}")
        return None

def _convert_internal_citation_to_frontend(citation: Citation) -> Dict[str, Any]:
    """
    Convert an internal Citation model to frontend format.
    
    Args:
        citation: Internal Citation model
        
    Returns:
        Citation in frontend format
    """
    frontend_citation = {
        "text": citation.cited_text,
        "documentId": f"doc-{citation.document_index}"  # Generate a document ID
    }
    
    if citation.type == CitationType.PAGE_LOCATION:
        citation = citation  # type: PageLocationCitation
        frontend_citation["page"] = citation.start_page_number
        
    elif citation.type == CitationType.CHAR_LOCATION:
        citation = citation  # type: CharLocationCitation
        frontend_citation["startChar"] = citation.start_char_index
        frontend_citation["endChar"] = citation.end_char_index
    
    return frontend_citation 
</file>
```

#### utils/response\.py
*Size: 3.7 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/utils/response.py">
"""
Utilities for standardized response handling across API endpoints.
"""
import logging
from typing import Dict, Any, Optional, List, Union, Type
from fastapi import HTTPException
from fastapi.responses import JSONResponse
import os

logger = logging.getLogger(__name__)

# Get allowed origins from environment
def get_allowed_origins():
    return os.getenv(
        "ALLOWED_ORIGINS", 
        "http://localhost:3000,http://localhost:3001,http://localhost:3002,http://localhost:3003,http://127.0.0.1:3000,http://127.0.0.1:3001,http://127.0.0.1:3002,http://127.0.0.1:3003"
    ).split(",")

# Add CORS headers to any response
def add_cors_headers(response: JSONResponse) -> JSONResponse:
    origins = get_allowed_origins()
    
    # If the response already has CORS headers, don't modify it
    if "access-control-allow-origin" in response.headers:
        return response
    
    # Add CORS headers - use the first origin as default, or * for development
    response.headers["Access-Control-Allow-Origin"] = origins[0] if origins else "*"
    response.headers["Access-Control-Allow-Credentials"] = "true"
    response.headers["Access-Control-Allow-Methods"] = "*"
    response.headers["Access-Control-Allow-Headers"] = "*"
    
    return response

# Create standardized error response
def create_error_response(
    status_code: int, 
    detail: Union[str, List[Dict[str, Any]], Dict[str, Any]],
    error_type: Optional[str] = None
) -> Dict[str, Any]:
    """
    Create a standardized error response.
    
    Args:
        status_code: HTTP status code
        detail: Error details
        error_type: Error type
        
    Returns:
        Dictionary with standardized error format
    """
    return {
        "error": {
            "status_code": status_code,
            "type": error_type or get_error_type_from_status(status_code),
            "detail": detail
        }
    }

def get_error_type_from_status(status_code: int) -> str:
    """
    Map HTTP status code to an error type string.
    
    Args:
        status_code: HTTP status code
        
    Returns:
        String representing the error type
    """
    error_types = {
        400: "bad_request",
        401: "unauthorized",
        403: "forbidden",
        404: "not_found",
        409: "conflict",
        422: "validation_error",
        429: "too_many_requests",
        500: "server_error",
        503: "service_unavailable"
    }
    
    return error_types.get(status_code, "unknown_error")

def handle_exception(
    exc: Exception, 
    default_status: int = 500,
    default_message: str = "An unexpected error occurred"
) -> HTTPException:
    """
    Convert any exception to an HTTPException with appropriate status and message.
    
    Args:
        exc: The exception to handle
        default_status: Default HTTP status code
        default_message: Default error message
        
    Returns:
        HTTPException with appropriate error details
    """
    # Handle ValueError specially
    if isinstance(exc, ValueError):
        error_message = str(exc)
        
        # Check for common patterns in error messages
        if "not found" in error_message.lower() or "does not exist" in error_message.lower():
            return HTTPException(
                status_code=404,
                detail=error_message
            )
        
        # Default for ValueError is bad request
        return HTTPException(
            status_code=400,
            detail=error_message
        )
    
    # Log unexpected exceptions
    logger.exception(f"Unhandled exception: {exc}")
    
    # Return a generic server error for unexpected exceptions
    return HTTPException(
        status_code=default_status,
        detail=default_message
    ) 
</file>
```

#### utils/storage\.py
*Size: 6.0 KB*
```
<file path="/Users/alexc/Documents/AlexCoding/cfin/backend/utils/storage.py">
import os
import io
import uuid
import aiofiles
from typing import BinaryIO, Optional
import boto3
import logging
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)

class StorageService(ABC):
    """Abstract base class for storage services."""
    
    @abstractmethod
    async def save_file(self, file_data: bytes, file_id: str, content_type: str) -> str:
        """Save a file to storage and return the path or URL."""
        pass
    
    @abstractmethod
    async def get_file(self, file_id: str) -> Optional[bytes]:
        """Get a file's contents from storage."""
        pass
    
    @abstractmethod
    async def delete_file(self, file_id: str) -> bool:
        """Delete a file from storage."""
        pass
    
    @abstractmethod
    def get_file_path(self, file_id: str) -> str:
        """Get the physical path to a file in storage."""
        pass
    
    @staticmethod
    def get_storage_service() -> 'StorageService':
        """Factory method to get the appropriate storage service."""
        storage_type = os.getenv("STORAGE_TYPE", "local").lower()
        
        if storage_type == "s3":
            return S3StorageService()
        else:
            return LocalStorageService()


class LocalStorageService(StorageService):
    """Storage service for local filesystem."""
    
    def __init__(self):
        self.upload_dir = os.getenv("UPLOAD_DIR", "./uploads")
        # Create upload directory if it doesn't exist
        os.makedirs(self.upload_dir, exist_ok=True)
    
    async def save_file(self, file_data: bytes, file_id: str, content_type: str) -> str:
        """Save a file to local storage."""
        file_path = os.path.join(self.upload_dir, file_id)
        
        try:
            async with aiofiles.open(file_path, "wb") as f:
                await f.write(file_data)
            logger.info(f"File {file_id} saved to {file_path}")
            return file_path
        except Exception as e:
            logger.error(f"Error saving file {file_id}: {str(e)}")
            raise
    
    async def get_file(self, file_id: str) -> Optional[bytes]:
        """Get a file's contents from local storage."""
        file_path = os.path.join(self.upload_dir, file_id)
        
        try:
            if not os.path.exists(file_path):
                logger.warning(f"File {file_id} not found at {file_path}")
                return None
            
            async with aiofiles.open(file_path, "rb") as f:
                data = await f.read()
            return data
        except Exception as e:
            logger.error(f"Error reading file {file_id}: {str(e)}")
            return None
    
    async def delete_file(self, file_id: str) -> bool:
        """Delete a file from local storage."""
        file_path = os.path.join(self.upload_dir, file_id)
        
        try:
            if not os.path.exists(file_path):
                logger.warning(f"File {file_id} not found at {file_path}")
                return False
            
            os.remove(file_path)
            logger.info(f"File {file_id} deleted from {file_path}")
            return True
        except Exception as e:
            logger.error(f"Error deleting file {file_id}: {str(e)}")
            return False
    
    def get_file_path(self, file_id: str) -> str:
        """Get the physical path to a file in local storage."""
        return os.path.join(self.upload_dir, file_id)


class S3StorageService(StorageService):
    """Storage service for AWS S3."""
    
    def __init__(self):
        self.bucket_name = os.getenv("S3_BUCKET_NAME")
        if not self.bucket_name:
            raise ValueError("S3_BUCKET_NAME environment variable is not set")
        
        self.region = os.getenv("S3_REGION", "us-west-2")
        
        self.s3_client = boto3.client(
            's3',
            region_name=self.region,
            aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
            aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY")
        )
    
    async def save_file(self, file_data: bytes, file_id: str, content_type: str) -> str:
        """Save a file to S3 storage."""
        try:
            file_obj = io.BytesIO(file_data)
            self.s3_client.upload_fileobj(
                file_obj,
                self.bucket_name,
                file_id,
                ExtraArgs={
                    "ContentType": content_type,
                }
            )
            s3_url = f"s3://{self.bucket_name}/{file_id}"
            logger.info(f"File {file_id} uploaded to S3: {s3_url}")
            return s3_url
        except Exception as e:
            logger.error(f"Error uploading file {file_id} to S3: {str(e)}")
            raise
    
    async def get_file(self, file_id: str) -> Optional[bytes]:
        """Get a file's contents from S3 storage."""
        try:
            file_obj = io.BytesIO()
            self.s3_client.download_fileobj(
                self.bucket_name,
                file_id,
                file_obj
            )
            file_obj.seek(0)
            data = file_obj.read()
            return data
        except Exception as e:
            logger.error(f"Error downloading file {file_id} from S3: {str(e)}")
            return None
    
    async def delete_file(self, file_id: str) -> bool:
        """Delete a file from S3 storage."""
        try:
            self.s3_client.delete_object(
                Bucket=self.bucket_name,
                Key=file_id
            )
            logger.info(f"File {file_id} deleted from S3 bucket {self.bucket_name}")
            return True
        except Exception as e:
            logger.error(f"Error deleting file {file_id} from S3: {str(e)}")
            return False
    
    def get_file_path(self, file_id: str) -> str:
        """
        Get the path to a file in S3 storage.
        
        Note: For S3, there's no direct file path. This returns a URL that can
        be used for accessing the file, but it's not a local path.
        """
        # For S3, we don't have a physical path, so return an S3 URL
        return f"s3://{self.bucket_name}/{file_id}"
</file>
```

